[INFO 17:00:06] Experiments Running command 'my_main'
[INFO 17:00:06] Experiments Started run with ID "3"
[DEBUG 17:00:06] Experiments Starting Heartbeat
Loading train graph:  powerlaw
[DEBUG 17:00:06] my_main Started
train graphs in total:  200
Loading test graph:  powerlaw
merged graphs length:  205
/home/docker/app/src/agent/colge/utils/config.py:10: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  model_config = yaml.load(config_file)
  0%|          | 0/2000 [00:00<?, ?it/s]epoch:  0
graph: 0, nodes: 180, edges: 531
[INFO] Global_t: 1, Episode_t: 1, Action: 108, Reward: 1.82, Epsilon: 0.99
[INFO] Global_t: 2, Episode_t: 2, Action: 11, Reward: 3.11, Epsilon: 0.97
[INFO] Global_t: 3, Episode_t: 3, Action: 140, Reward: 1.52, Epsilon: 0.95
[INFO] Global_t: 4, Episode_t: 4, Action: 37, Reward: 2.27, Epsilon: 0.93
[INFO] Global_t: 5, Episode_t: 5, Action: 161, Reward: 0.92, Epsilon: 0.91
[INFO] Global_t: 6, Episode_t: 6, Action: 28, Reward: 3.28, Epsilon: 0.89
[INFO] Global_t: 7, Episode_t: 7, Action: 57, Reward: 1.54, Epsilon: 0.87
[INFO] Global_t: 8, Episode_t: 8, Action: 60, Reward: 1.59, Epsilon: 0.85
  0%|          | 8/2000 [00:02<09:15,  3.58it/s]
[INFO] Global step: 8, Cumulative rewards: 16.059959999999997, Runtime (s): 2.23
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] Global_t: 9, Episode_t: 1, Action: 46, Reward: 2.75, Epsilon: 0.83
[INFO] Global_t: 10, Episode_t: 2, Action: 138, Reward: 2.12, Epsilon: 0.81
[INFO] Global_t: 11, Episode_t: 3, Action: 178, Reward: 1.37, Epsilon: 0.79
[INFO] Global_t: 12, Episode_t: 4, Action: 141, Reward: 1.14, Epsilon: 0.77
[INFO] Global_t: 13, Episode_t: 5, Action: 214, Reward: 1.04, Epsilon: 0.75
[INFO] Global_t: 14, Episode_t: 6, Action: 107, Reward: 1.62, Epsilon: 0.74
[INFO] Global_t: 15, Episode_t: 7, Action: 35, Reward: 1.70, Epsilon: 0.72
[INFO] Global_t: 16, Episode_t: 8, Action: 201, Reward: 1.34, Epsilon: 0.70
  1%|          | 16/2000 [00:05<10:14,  3.23it/s]
[INFO] Global step: 16, Cumulative rewards: 13.084439999999997, Runtime (s): 5.29
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.599527359008789
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6101133823394775
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6805529594421387
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9109649658203125
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1752095222473145
average cummulative reward vector is:  [0.06023079 0.053675   0.05954098 0.0552736  0.06217823]
average cummulative reward is:  0.05817971940350686
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] Global_t: 17, Episode_t: 1, Action: 75, Reward: 2.15, Epsilon: 0.68
[INFO] Global_t: 18, Episode_t: 2, Action: 206, Reward: 2.00, Epsilon: 0.66
[INFO] Global_t: 19, Episode_t: 3, Action: 106, Reward: 1.68, Epsilon: 0.64
[INFO] Global_t: 20, Episode_t: 4, Action: 161, Reward: 1.16, Epsilon: 0.62
[INFO] Global_t: 21, Episode_t: 5, Action: 149, Reward: 1.21, Epsilon: 0.60
[INFO] Global_t: 22, Episode_t: 6, Action: 215, Reward: 1.21, Epsilon: 0.58
[INFO] Global_t: 23, Episode_t: 7, Action: 219, Reward: 0.94, Epsilon: 0.56
[INFO] Global_t: 24, Episode_t: 8, Action: 84, Reward: 2.17, Epsilon: 0.54
  1%|          | 24/2000 [00:17<21:44,  1.51it/s]
[INFO] Global step: 24, Cumulative rewards: 12.524040000000001, Runtime (s): 17.11
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] Global_t: 25, Episode_t: 1, Action: 180, Reward: 1.15, Epsilon: 0.52
[INFO] Global_t: 26, Episode_t: 2, Action: 174, Reward: 1.57, Epsilon: 0.50
[INFO] Global_t: 27, Episode_t: 3, Action: 176, Reward: 1.20, Epsilon: 0.48
[INFO] Global_t: 28, Episode_t: 4, Action: 173, Reward: 1.08, Epsilon: 0.46
[INFO] Global_t: 29, Episode_t: 5, Action: 99, Reward: 2.06, Epsilon: 0.44
[INFO] Global_t: 30, Episode_t: 6, Action: 198, Reward: 0.98, Epsilon: 0.42
[INFO] Global_t: 31, Episode_t: 7, Action: 187, Reward: 2.08, Epsilon: 0.40
[INFO] Global_t: 32, Episode_t: 8, Action: 55, Reward: 1.71, Epsilon: 0.38
  2%|▏         | 32/2000 [00:19<18:11,  1.80it/s]
[INFO] Global step: 32, Cumulative rewards: 11.8212, Runtime (s): 19.58
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.55614972114563
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.72318434715271
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.512051820755005
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.9811248779296875
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.8696033954620361
average cummulative reward vector is:  [0.06367184 0.0493162  0.0598418  0.05745771 0.0603621 ]
average cummulative reward is:  0.05812993122844455
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] Global_t: 33, Episode_t: 1, Action: 0, Reward: 5.67, Epsilon: 0.36
[INFO] Global_t: 34, Episode_t: 2, Action: 131, Reward: 0.68, Epsilon: 0.34
[INFO] Global_t: 35, Episode_t: 3, Action: 183, Reward: 0.90, Epsilon: 0.32
[INFO] Global_t: 36, Episode_t: 4, Action: 179, Reward: 1.21, Epsilon: 0.30
[INFO] Global_t: 37, Episode_t: 5, Action: 118, Reward: 1.22, Epsilon: 0.28
[INFO] Global_t: 38, Episode_t: 6, Action: 142, Reward: 0.96, Epsilon: 0.26
[INFO] Global_t: 39, Episode_t: 7, Action: 54, Reward: 1.70, Epsilon: 0.25
[INFO] Global_t: 40, Episode_t: 8, Action: 31, Reward: 1.82, Epsilon: 0.23
  2%|▏         | 40/2000 [00:36<33:09,  1.01s/it]
[INFO] Global step: 40, Cumulative rewards: 14.15532, Runtime (s): 36.29
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] Global_t: 41, Episode_t: 1, Action: 34, Reward: 2.73, Epsilon: 0.21
[INFO] Global_t: 42, Episode_t: 2, Action: 110, Reward: 1.79, Epsilon: 0.19
[INFO] Global_t: 43, Episode_t: 3, Action: 120, Reward: 1.53, Epsilon: 0.17
[INFO] Global_t: 44, Episode_t: 4, Action: 113, Reward: 1.44, Epsilon: 0.15
[INFO] Global_t: 45, Episode_t: 5, Action: 186, Reward: 1.22, Epsilon: 0.13
[INFO] Global_t: 46, Episode_t: 6, Action: 172, Reward: 1.14, Epsilon: 0.11
[INFO] Global_t: 47, Episode_t: 7, Action: 105, Reward: 1.34, Epsilon: 0.09
[INFO] Global_t: 48, Episode_t: 8, Action: 209, Reward: 0.52, Epsilon: 0.07
  2%|▏         | 48/2000 [00:39<26:48,  1.21it/s]
[INFO] Global step: 48, Cumulative rewards: 11.70336, Runtime (s): 39.31
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0345795154571533
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5892939567565918
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5718836784362793
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5552349090576172
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.713242769241333
average cummulative reward vector is:  [0.06237553 0.0508088  0.05614344 0.05196822 0.06397957]
average cummulative reward is:  0.05705511188531502
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 49, loss: 7215700992.0
[INFO] Global_t: 49, Episode_t: 1, Action: 46, Reward: 2.47, Epsilon: 0.05
[INFO] model update: t: 50, loss: 5199668183040.0
[INFO] Global_t: 50, Episode_t: 2, Action: 3, Reward: 7.83, Epsilon: 0.03
[INFO] model update: t: 51, loss: 284291039232.0
[INFO] Global_t: 51, Episode_t: 3, Action: 10, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 52, loss: 204363890688.0
[INFO] Global_t: 52, Episode_t: 4, Action: 21, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 53, loss: 302630174720.0
[INFO] Global_t: 53, Episode_t: 5, Action: 22, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 54, loss: 287780765696.0
[INFO] Global_t: 54, Episode_t: 6, Action: 28, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 55, loss: 151175118848.0
[INFO] Global_t: 55, Episode_t: 7, Action: 17, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 56, loss: 62551044.0
[INFO] Global_t: 56, Episode_t: 8, Action: 4, Reward: 3.57, Epsilon: 0.01
  3%|▎         | 56/2000 [00:53<35:57,  1.11s/it]
[INFO] Global step: 56, Cumulative rewards: 24.318119999999997, Runtime (s): 53.53
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 57, loss: 139437457408.0
[INFO] Global_t: 57, Episode_t: 1, Action: 8, Reward: 5.79, Epsilon: 0.01
[INFO] model update: t: 58, loss: 136161484800.0
[INFO] Global_t: 58, Episode_t: 2, Action: 0, Reward: 6.27, Epsilon: 0.01
[INFO] model update: t: 59, loss: 24434176000.0
[INFO] Global_t: 59, Episode_t: 3, Action: 4, Reward: 4.30, Epsilon: 0.01
[INFO] model update: t: 60, loss: 1628964736.0
[INFO] Global_t: 60, Episode_t: 4, Action: 14, Reward: 3.57, Epsilon: 0.01
[INFO] model update: t: 61, loss: 27475781632.0
[INFO] Global_t: 61, Episode_t: 5, Action: 3, Reward: 3.13, Epsilon: 0.01
[INFO] model update: t: 62, loss: 57402986496.0
[INFO] Global_t: 62, Episode_t: 6, Action: 5, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 63, loss: 33403498496.0
[INFO] Global_t: 63, Episode_t: 7, Action: 28, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 64, loss: 8399955456.0
[INFO] Global_t: 64, Episode_t: 8, Action: 19, Reward: 1.53, Epsilon: 0.01
  3%|▎         | 64/2000 [00:58<31:26,  1.03it/s]
[INFO] Global step: 64, Cumulative rewards: 29.59872, Runtime (s): 58.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.1704370975494385
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.443384170532227
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.172460556030273
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.962162971496582
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.43634033203125
average cummulative reward vector is:  [0.14949974 0.13279861 0.1484306  0.12086402 0.15603199]
average cummulative reward is:  0.14152499139700264
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 65, loss: 424642176.0
[INFO] Global_t: 65, Episode_t: 1, Action: 4, Reward: 5.41, Epsilon: 0.01
[INFO] model update: t: 66, loss: 13783085056.0
[INFO] Global_t: 66, Episode_t: 2, Action: 9, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 67, loss: 16230690816.0
[INFO] Global_t: 67, Episode_t: 3, Action: 8, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 68, loss: 7689779200.0
[INFO] Global_t: 68, Episode_t: 4, Action: 2, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 69, loss: 103476640.0
[INFO] Global_t: 69, Episode_t: 5, Action: 3, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 70, loss: 4994969600.0
[INFO] Global_t: 70, Episode_t: 6, Action: 16, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 71, loss: 9425544192.0
[INFO] Global_t: 71, Episode_t: 7, Action: 10, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 72, loss: 6959457280.0
[INFO] Global_t: 72, Episode_t: 8, Action: 11, Reward: 1.39, Epsilon: 0.01
  4%|▎         | 72/2000 [01:26<54:48,  1.71s/it]
[INFO] Global step: 72, Cumulative rewards: 20.73636, Runtime (s): 86.09
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 73, loss: 1993935616.0
[INFO] Global_t: 73, Episode_t: 1, Action: 14, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 74, loss: 304289472.0
[INFO] Global_t: 74, Episode_t: 2, Action: 0, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 75, loss: 3219216896.0
[INFO] Global_t: 75, Episode_t: 3, Action: 9, Reward: 4.18, Epsilon: 0.01
[INFO] model update: t: 76, loss: 5282058240.0
[INFO] Global_t: 76, Episode_t: 4, Action: 10, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 77, loss: 3219593472.0
[INFO] Global_t: 77, Episode_t: 5, Action: 13, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 78, loss: 891456192.0
[INFO] Global_t: 78, Episode_t: 6, Action: 5, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 79, loss: 103902328.0
[INFO] Global_t: 79, Episode_t: 7, Action: 6, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 80, loss: 800015680.0
[INFO] Global_t: 80, Episode_t: 8, Action: 81, Reward: 1.68, Epsilon: 0.01
  4%|▍         | 80/2000 [01:31<44:39,  1.40s/it]
[INFO] Global step: 80, Cumulative rewards: 26.1708, Runtime (s): 91.47
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.829371452331543
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.840850591659546
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.380079507827759
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.631938219070435
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.5856523513793945
average cummulative reward vector is:  [0.13425132 0.1143794  0.14095164 0.1259778  0.13758145]
average cummulative reward is:  0.13062832172662103
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 81, loss: 2133352448.0
[INFO] Global_t: 81, Episode_t: 1, Action: 9, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 82, loss: 2150726656.0
[INFO] Global_t: 82, Episode_t: 2, Action: 8, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 83, loss: 1031369984.0
[INFO] Global_t: 83, Episode_t: 3, Action: 3, Reward: 2.59, Epsilon: 0.01
[INFO] model update: t: 84, loss: 256486080.0
[INFO] Global_t: 84, Episode_t: 4, Action: 4, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 85, loss: 173143248.0
[INFO] Global_t: 85, Episode_t: 5, Action: 0, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 86, loss: 646126208.0
[INFO] Global_t: 86, Episode_t: 6, Action: 1, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 87, loss: 1282202496.0
[INFO] Global_t: 87, Episode_t: 7, Action: 2, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 88, loss: 922194048.0
[INFO] Global_t: 88, Episode_t: 8, Action: 27, Reward: 1.93, Epsilon: 0.01
  4%|▍         | 88/2000 [02:04<1:10:39,  2.22s/it]
[INFO] Global step: 88, Cumulative rewards: 20.79336, Runtime (s): 124.55
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 89, loss: 746768704.0
[INFO] Global_t: 89, Episode_t: 1, Action: 9, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 90, loss: 200787568.0
[INFO] Global_t: 90, Episode_t: 2, Action: 2, Reward: 5.47, Epsilon: 0.01
[INFO] model update: t: 91, loss: 111596504.0
[INFO] Global_t: 91, Episode_t: 3, Action: 6, Reward: 5.32, Epsilon: 0.01
[INFO] model update: t: 92, loss: 404244128.0
[INFO] Global_t: 92, Episode_t: 4, Action: 7, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 93, loss: 212950320.0
[INFO] Global_t: 93, Episode_t: 5, Action: 14, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 94, loss: 58947000.0
[INFO] Global_t: 94, Episode_t: 6, Action: 10, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 95, loss: 154506832.0
[INFO] Global_t: 95, Episode_t: 7, Action: 4, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 96, loss: 176275456.0
[INFO] Global_t: 96, Episode_t: 8, Action: 16, Reward: 1.55, Epsilon: 0.01
  5%|▍         | 96/2000 [02:09<55:19,  1.74s/it]  
[INFO] Global step: 96, Cumulative rewards: 29.50956, Runtime (s): 129.66
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.819770097732544
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8323075771331787
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8181190490722656
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.101630449295044
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.0924248695373535
average cummulative reward vector is:  [0.13688526 0.11884676 0.14082732 0.1197993  0.13358844]
average cummulative reward is:  0.12998941694943222
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 97, loss: 12374046.0
[INFO] Global_t: 97, Episode_t: 1, Action: 60, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 98, loss: 102567520.0
[INFO] Global_t: 98, Episode_t: 2, Action: 1, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 99, loss: 110393056.0
[INFO] Global_t: 99, Episode_t: 3, Action: 13, Reward: 3.20, Epsilon: 0.01
[INFO] model update: t: 100, loss: 19011710.0
[INFO] Global_t: 100, Episode_t: 4, Action: 4, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 101, loss: 61171212.0
[INFO] Global_t: 101, Episode_t: 5, Action: 8, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 102, loss: 101371488.0
[INFO] Global_t: 102, Episode_t: 6, Action: 6, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 103, loss: 6983134.0
[INFO] Global_t: 103, Episode_t: 7, Action: 9, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 104, loss: 67022296.0
[INFO] Global_t: 104, Episode_t: 8, Action: 19, Reward: 1.69, Epsilon: 0.01
  5%|▌         | 104/2000 [02:34<1:08:33,  2.17s/it]
[INFO] Global step: 104, Cumulative rewards: 21.08988, Runtime (s): 154.96
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 105, loss: 76519312.0
[INFO] Global_t: 105, Episode_t: 1, Action: 7, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 106, loss: 2494533.25
[INFO] Global_t: 106, Episode_t: 2, Action: 1, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 107, loss: 61105712.0
[INFO] Global_t: 107, Episode_t: 3, Action: 5, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 108, loss: 41084208.0
[INFO] Global_t: 108, Episode_t: 4, Action: 27, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 109, loss: 10708619.0
[INFO] Global_t: 109, Episode_t: 5, Action: 13, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 110, loss: 56166940.0
[INFO] Global_t: 110, Episode_t: 6, Action: 24, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 111, loss: 27276050.0
[INFO] Global_t: 111, Episode_t: 7, Action: 14, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 112, loss: 13112936.0
[INFO] Global_t: 112, Episode_t: 8, Action: 0, Reward: 2.24, Epsilon: 0.01
  6%|▌         | 112/2000 [02:41<55:08,  1.75s/it]  
[INFO] Global step: 112, Cumulative rewards: 22.332720000000002, Runtime (s): 161.20
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.996364116668701
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.239279270172119
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.12514853477478
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.676806926727295
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.375216245651245
average cummulative reward vector is:  [0.14376842 0.12980347 0.14901503 0.13375654 0.14104194]
average cummulative reward is:  0.1394770796274408
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 113, loss: 64375208.0
[INFO] Global_t: 113, Episode_t: 1, Action: 7, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 114, loss: 7403796.5
[INFO] Global_t: 114, Episode_t: 2, Action: 11, Reward: 4.93, Epsilon: 0.01
[INFO] model update: t: 115, loss: 35178256.0
[INFO] Global_t: 115, Episode_t: 3, Action: 6, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 116, loss: 34748700.0
[INFO] Global_t: 116, Episode_t: 4, Action: 30, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 117, loss: 4991078.0
[INFO] Global_t: 117, Episode_t: 5, Action: 8, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 118, loss: 25211156.0
[INFO] Global_t: 118, Episode_t: 6, Action: 9, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 119, loss: 18204986.0
[INFO] Global_t: 119, Episode_t: 7, Action: 13, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 120, loss: 6383404.0
[INFO] Global_t: 120, Episode_t: 8, Action: 5, Reward: 1.95, Epsilon: 0.01
  6%|▌         | 120/2000 [03:10<1:13:06,  2.33s/it]
[INFO] Global step: 120, Cumulative rewards: 26.576520000000002, Runtime (s): 190.71
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 121, loss: 26116460.0
[INFO] Global_t: 121, Episode_t: 1, Action: 7, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 122, loss: 5890904.5
[INFO] Global_t: 122, Episode_t: 2, Action: 16, Reward: 3.20, Epsilon: 0.01
[INFO] model update: t: 123, loss: 9480333.0
[INFO] Global_t: 123, Episode_t: 3, Action: 1, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 124, loss: 12905934.0
[INFO] Global_t: 124, Episode_t: 4, Action: 19, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 125, loss: 2904569.5
[INFO] Global_t: 125, Episode_t: 5, Action: 3, Reward: 2.94, Epsilon: 0.01
[INFO] model update: t: 126, loss: 8319488.0
[INFO] Global_t: 126, Episode_t: 6, Action: 5, Reward: 2.56, Epsilon: 0.01
[INFO] model update: t: 127, loss: 7568166.0
[INFO] Global_t: 127, Episode_t: 7, Action: 4, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 128, loss: 2780945.75
[INFO] Global_t: 128, Episode_t: 8, Action: 15, Reward: 1.62, Epsilon: 0.01
  6%|▋         | 128/2000 [03:16<57:45,  1.85s/it]  
[INFO] Global step: 128, Cumulative rewards: 21.9546, Runtime (s): 196.52
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5625498294830322
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5387110710144043
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.814340353012085
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.135099649429321
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.0836341381073
average cummulative reward vector is:  [0.12755947 0.11152014 0.13840464 0.12725888 0.14306613]
average cummulative reward is:  0.12956185298375472
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 129, loss: 4722533.0
[INFO] Global_t: 129, Episode_t: 1, Action: 4, Reward: 6.22, Epsilon: 0.01
[INFO] model update: t: 130, loss: 6132272.5
[INFO] Global_t: 130, Episode_t: 2, Action: 8, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 131, loss: 2280923.75
[INFO] Global_t: 131, Episode_t: 3, Action: 30, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 132, loss: 3872907.5
[INFO] Global_t: 132, Episode_t: 4, Action: 3, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 133, loss: 7955798.5
[INFO] Global_t: 133, Episode_t: 5, Action: 2, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 134, loss: 1492650.75
[INFO] Global_t: 134, Episode_t: 6, Action: 10, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 135, loss: 5470137.5
[INFO] Global_t: 135, Episode_t: 7, Action: 18, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 136, loss: 5160000.5
[INFO] Global_t: 136, Episode_t: 8, Action: 52, Reward: 1.92, Epsilon: 0.01
  7%|▋         | 136/2000 [03:47<1:16:37,  2.47s/it]
[INFO] Global step: 136, Cumulative rewards: 22.434120000000004, Runtime (s): 227.73
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 137, loss: 1987257.5
[INFO] Global_t: 137, Episode_t: 1, Action: 1, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 138, loss: 6277288.5
[INFO] Global_t: 138, Episode_t: 2, Action: 7, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 139, loss: 2018121.0
[INFO] Global_t: 139, Episode_t: 3, Action: 6, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 140, loss: 4216174.5
[INFO] Global_t: 140, Episode_t: 4, Action: 8, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 141, loss: 3396232.75
[INFO] Global_t: 141, Episode_t: 5, Action: 4, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 142, loss: 1281954.25
[INFO] Global_t: 142, Episode_t: 6, Action: 15, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 143, loss: 2711579.5
[INFO] Global_t: 143, Episode_t: 7, Action: 0, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 144, loss: 2023321.125
[INFO] Global_t: 144, Episode_t: 8, Action: 16, Reward: 1.83, Epsilon: 0.01
  7%|▋         | 144/2000 [03:55<1:01:59,  2.00s/it]
[INFO] Global step: 144, Cumulative rewards: 21.79884, Runtime (s): 235.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.151341915130615
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5842018127441406
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9692299365997314
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.33985161781311
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.951394557952881
average cummulative reward vector is:  [0.14332342 0.11004653 0.14123962 0.13271168 0.13894355]
average cummulative reward is:  0.1332529593893671
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 145, loss: 1314088.5
[INFO] Global_t: 145, Episode_t: 1, Action: 6, Reward: 4.97, Epsilon: 0.01
[INFO] model update: t: 146, loss: 3951346.0
[INFO] Global_t: 146, Episode_t: 2, Action: 4, Reward: 5.51, Epsilon: 0.01
[INFO] model update: t: 147, loss: 854013.5
[INFO] Global_t: 147, Episode_t: 3, Action: 20, Reward: 4.80, Epsilon: 0.01
[INFO] model update: t: 148, loss: 2158544.5
[INFO] Global_t: 148, Episode_t: 4, Action: 9, Reward: 5.71, Epsilon: 0.01
[INFO] model update: t: 149, loss: 3636499.5
[INFO] Global_t: 149, Episode_t: 5, Action: 8, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 150, loss: 1448348.625
[INFO] Global_t: 150, Episode_t: 6, Action: 2, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 151, loss: 3878054.75
[INFO] Global_t: 151, Episode_t: 7, Action: 24, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 152, loss: 549858.9375
[INFO] Global_t: 152, Episode_t: 8, Action: 5, Reward: 3.31, Epsilon: 0.01

[INFO] Global step: 152, Cumulative rewards: 32.88924, Runtime (s): 259.96
------------------------------------------------------------
 
  8%|▊         | 152/2000 [04:19<1:11:52,  2.33s/it]graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 153, loss: 3346459.5
[INFO] Global_t: 153, Episode_t: 1, Action: 7, Reward: 6.23, Epsilon: 0.01
[INFO] model update: t: 154, loss: 2693834.0
[INFO] Global_t: 154, Episode_t: 2, Action: 4, Reward: 4.98, Epsilon: 0.01
[INFO] model update: t: 155, loss: 2091741.125
[INFO] Global_t: 155, Episode_t: 3, Action: 10, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 156, loss: 4332947.0
[INFO] Global_t: 156, Episode_t: 4, Action: 8, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 157, loss: 895660.625
[INFO] Global_t: 157, Episode_t: 5, Action: 30, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 158, loss: 2388368.0
[INFO] Global_t: 158, Episode_t: 6, Action: 16, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 159, loss: 2116769.25
[INFO] Global_t: 159, Episode_t: 7, Action: 13, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 160, loss: 1053213.375
[INFO] Global_t: 160, Episode_t: 8, Action: 15, Reward: 1.74, Epsilon: 0.01
  8%|▊         | 160/2000 [04:25<56:50,  1.85s/it]  
[INFO] Global step: 160, Cumulative rewards: 27.27156, Runtime (s): 265.82
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.979875326156616
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9386630058288574
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.007956266403198
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.152763843536377
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8208675384521484
average cummulative reward vector is:  [0.14001842 0.12223403 0.14310601 0.12930888 0.13875108]
average cummulative reward is:  0.13468368270657227
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 161, loss: 1800545.75
[INFO] Global_t: 161, Episode_t: 1, Action: 3, Reward: 6.31, Epsilon: 0.01
[INFO] model update: t: 162, loss: 871740.75
[INFO] Global_t: 162, Episode_t: 2, Action: 5, Reward: 6.24, Epsilon: 0.01
[INFO] model update: t: 163, loss: 704069.75
[INFO] Global_t: 163, Episode_t: 3, Action: 8, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 164, loss: 1889486.0
[INFO] Global_t: 164, Episode_t: 4, Action: 17, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 165, loss: 492058.75
[INFO] Global_t: 165, Episode_t: 5, Action: 13, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 166, loss: 804674.6875
[INFO] Global_t: 166, Episode_t: 6, Action: 14, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 167, loss: 2424236.25
[INFO] Global_t: 167, Episode_t: 7, Action: 16, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 168, loss: 598358.0
[INFO] Global_t: 168, Episode_t: 8, Action: 18, Reward: 2.69, Epsilon: 0.01
  8%|▊         | 168/2000 [04:50<1:07:48,  2.22s/it]
[INFO] Global step: 168, Cumulative rewards: 34.7004, Runtime (s): 290.44
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 169, loss: 2644129.5
[INFO] Global_t: 169, Episode_t: 1, Action: 4, Reward: 5.78, Epsilon: 0.01
[INFO] model update: t: 170, loss: 1246954.0
[INFO] Global_t: 170, Episode_t: 2, Action: 7, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 171, loss: 1444639.25
[INFO] Global_t: 171, Episode_t: 3, Action: 15, Reward: 2.63, Epsilon: 0.01
[INFO] model update: t: 172, loss: 1453798.625
[INFO] Global_t: 172, Episode_t: 4, Action: 10, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 173, loss: 425062.4375
[INFO] Global_t: 173, Episode_t: 5, Action: 5, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 174, loss: 1327768.25
[INFO] Global_t: 174, Episode_t: 6, Action: 28, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 175, loss: 955890.875
[INFO] Global_t: 175, Episode_t: 7, Action: 20, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 176, loss: 1446789.125
[INFO] Global_t: 176, Episode_t: 8, Action: 1, Reward: 2.51, Epsilon: 0.01
  9%|▉         | 176/2000 [04:56<53:37,  1.76s/it]  
[INFO] Global step: 176, Cumulative rewards: 23.15676, Runtime (s): 296.03
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.965121269226074
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8293182849884033
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.090165138244629
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.046172142028809
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.903756856918335
average cummulative reward vector is:  [0.13920526 0.12004468 0.15109208 0.12709112 0.14456102]
average cummulative reward is:  0.13639883171745126
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 177, loss: 836284.625
[INFO] Global_t: 177, Episode_t: 1, Action: 5, Reward: 5.23, Epsilon: 0.01
[INFO] model update: t: 178, loss: 525451.375
[INFO] Global_t: 178, Episode_t: 2, Action: 4, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 179, loss: 1092551.625
[INFO] Global_t: 179, Episode_t: 3, Action: 8, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 180, loss: 625190.0
[INFO] Global_t: 180, Episode_t: 4, Action: 13, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 181, loss: 855988.125
[INFO] Global_t: 181, Episode_t: 5, Action: 7, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 182, loss: 962343.375
[INFO] Global_t: 182, Episode_t: 6, Action: 2, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 183, loss: 643194.6875
[INFO] Global_t: 183, Episode_t: 7, Action: 42, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 184, loss: 506700.75
[INFO] Global_t: 184, Episode_t: 8, Action: 1, Reward: 2.08, Epsilon: 0.01
  9%|▉         | 184/2000 [05:21<1:06:14,  2.19s/it]
[INFO] Global step: 184, Cumulative rewards: 22.0452, Runtime (s): 321.46
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 185, loss: 746484.25
[INFO] Global_t: 185, Episode_t: 1, Action: 13, Reward: 4.98, Epsilon: 0.01
[INFO] model update: t: 186, loss: 738914.375
[INFO] Global_t: 186, Episode_t: 2, Action: 0, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 187, loss: 516621.6875
[INFO] Global_t: 187, Episode_t: 3, Action: 2, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 188, loss: 261433.6875
[INFO] Global_t: 188, Episode_t: 4, Action: 1, Reward: 4.60, Epsilon: 0.01
[INFO] model update: t: 189, loss: 1021890.625
[INFO] Global_t: 189, Episode_t: 5, Action: 35, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 190, loss: 485816.375
[INFO] Global_t: 190, Episode_t: 6, Action: 18, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 191, loss: 802499.75
[INFO] Global_t: 191, Episode_t: 7, Action: 14, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 192, loss: 714295.375
[INFO] Global_t: 192, Episode_t: 8, Action: 3, Reward: 4.08, Epsilon: 0.01
 10%|▉         | 192/2000 [05:26<51:24,  1.71s/it]  
[INFO] Global step: 192, Cumulative rewards: 30.557519999999997, Runtime (s): 326.10
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8335845470428467
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8611843585968018
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8409290313720703
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.152516603469849
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5061728954315186
average cummulative reward vector is:  [0.13498763 0.12050116 0.14316475 0.12633949 0.1297086 ]
average cummulative reward is:  0.13094032624331228
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 193, loss: 989269.0
[INFO] Global_t: 193, Episode_t: 1, Action: 7, Reward: 5.44, Epsilon: 0.01
[INFO] model update: t: 194, loss: 322183.375
[INFO] Global_t: 194, Episode_t: 2, Action: 3, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 195, loss: 812755.0
[INFO] Global_t: 195, Episode_t: 3, Action: 11, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 196, loss: 741227.3125
[INFO] Global_t: 196, Episode_t: 4, Action: 187, Reward: 0.79, Epsilon: 0.01
[INFO] model update: t: 197, loss: 780397.375
[INFO] Global_t: 197, Episode_t: 5, Action: 14, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 198, loss: 589693.75
[INFO] Global_t: 198, Episode_t: 6, Action: 1, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 199, loss: 1064300.125
[INFO] Global_t: 199, Episode_t: 7, Action: 13, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 200, loss: 681083.0625
[INFO] Global_t: 200, Episode_t: 8, Action: 10, Reward: 2.77, Epsilon: 0.01
 10%|█         | 200/2000 [05:50<1:02:59,  2.10s/it]
[INFO] Global step: 200, Cumulative rewards: 23.48628, Runtime (s): 350.25
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 201, loss: 514418.25
[INFO] Global_t: 201, Episode_t: 1, Action: 2, Reward: 5.55, Epsilon: 0.01
[INFO] model update: t: 202, loss: 1196202.75
[INFO] Global_t: 202, Episode_t: 2, Action: 10, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 203, loss: 229989.046875
[INFO] Global_t: 203, Episode_t: 3, Action: 8, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 204, loss: 1238284.625
[INFO] Global_t: 204, Episode_t: 4, Action: 4, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 205, loss: 729587.6875
[INFO] Global_t: 205, Episode_t: 5, Action: 14, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 206, loss: 1202667.75
[INFO] Global_t: 206, Episode_t: 6, Action: 7, Reward: 2.08, Epsilon: 0.01
[INFO] model update: t: 207, loss: 809282.6875
[INFO] Global_t: 207, Episode_t: 7, Action: 3, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 208, loss: 597693.0625
[INFO] Global_t: 208, Episode_t: 8, Action: 1, Reward: 1.96, Epsilon: 0.01

[INFO] Global step: 208, Cumulative rewards: 23.173799999999993, Runtime (s): 356.77
------------------------------------------------------------
 
 10%|█         | 208/2000 [05:56<51:11,  1.71s/it]  
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.1071836948394775
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.022986173629761
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.117049932479858
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.259746313095093
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8275980949401855
average cummulative reward vector is:  [0.14348211 0.12381829 0.15219344 0.13151449 0.14081909]
average cummulative reward is:  0.1383654813851919
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 209, loss: 1976186.0
[INFO] Global_t: 209, Episode_t: 1, Action: 8, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 210, loss: 546627.375
[INFO] Global_t: 210, Episode_t: 2, Action: 11, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 211, loss: 1539326.875
[INFO] Global_t: 211, Episode_t: 3, Action: 24, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 212, loss: 542509.3125
[INFO] Global_t: 212, Episode_t: 4, Action: 0, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 213, loss: 1387925.5
[INFO] Global_t: 213, Episode_t: 5, Action: 19, Reward: 2.87, Epsilon: 0.01
[INFO] model update: t: 214, loss: 807934.125
[INFO] Global_t: 214, Episode_t: 6, Action: 1, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 215, loss: 794553.125
[INFO] Global_t: 215, Episode_t: 7, Action: 2, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 216, loss: 1897462.625
[INFO] Global_t: 216, Episode_t: 8, Action: 6, Reward: 2.25, Epsilon: 0.01
 11%|█         | 216/2000 [06:21<1:03:15,  2.13s/it]
[INFO] Global step: 216, Cumulative rewards: 25.06536, Runtime (s): 381.51
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 217, loss: 477504.375
[INFO] Global_t: 217, Episode_t: 1, Action: 3, Reward: 5.38, Epsilon: 0.01
[INFO] model update: t: 218, loss: 3479858.0
[INFO] Global_t: 218, Episode_t: 2, Action: 5, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 219, loss: 615131.5
[INFO] Global_t: 219, Episode_t: 3, Action: 1, Reward: 3.02, Epsilon: 0.01
[INFO] model update: t: 220, loss: 2707786.5
[INFO] Global_t: 220, Episode_t: 4, Action: 0, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 221, loss: 537629.0625
[INFO] Global_t: 221, Episode_t: 5, Action: 22, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 222, loss: 2227466.0
[INFO] Global_t: 222, Episode_t: 6, Action: 10, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 223, loss: 401464.125
[INFO] Global_t: 223, Episode_t: 7, Action: 4, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 224, loss: 828379.0
[INFO] Global_t: 224, Episode_t: 8, Action: 6, Reward: 1.64, Epsilon: 0.01
 11%|█         | 224/2000 [06:27<50:44,  1.71s/it]  
[INFO] Global step: 224, Cumulative rewards: 23.361599999999996, Runtime (s): 387.50
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.687096118927002
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9199142456054688
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.969834089279175
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.979896068572998
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.735386371612549
average cummulative reward vector is:  [0.12865105 0.12182176 0.14787842 0.12341612 0.13797258]
average cummulative reward is:  0.1319479858663746
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 225, loss: 1139034.625
[INFO] Global_t: 225, Episode_t: 1, Action: 1, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 226, loss: 727260.3125
[INFO] Global_t: 226, Episode_t: 2, Action: 0, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 227, loss: 1261062.5
[INFO] Global_t: 227, Episode_t: 3, Action: 11, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 228, loss: 650950.5625
[INFO] Global_t: 228, Episode_t: 4, Action: 8, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 229, loss: 1396911.875
[INFO] Global_t: 229, Episode_t: 5, Action: 16, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 230, loss: 448720.875
[INFO] Global_t: 230, Episode_t: 6, Action: 5, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 231, loss: 1046636.3125
[INFO] Global_t: 231, Episode_t: 7, Action: 13, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 232, loss: 607312.375
[INFO] Global_t: 232, Episode_t: 8, Action: 4, Reward: 3.10, Epsilon: 0.01
 12%|█▏        | 232/2000 [06:51<1:01:36,  2.09s/it]
[INFO] Global step: 232, Cumulative rewards: 29.279160000000005, Runtime (s): 411.25
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 233, loss: 785177.0
[INFO] Global_t: 233, Episode_t: 1, Action: 5, Reward: 6.26, Epsilon: 0.01
[INFO] model update: t: 234, loss: 1021658.375
[INFO] Global_t: 234, Episode_t: 2, Action: 6, Reward: 5.74, Epsilon: 0.01
[INFO] model update: t: 235, loss: 409116.34375
[INFO] Global_t: 235, Episode_t: 3, Action: 9, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 236, loss: 1117229.5
[INFO] Global_t: 236, Episode_t: 4, Action: 15, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 237, loss: 521812.8125
[INFO] Global_t: 237, Episode_t: 5, Action: 8, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 238, loss: 2224557.75
[INFO] Global_t: 238, Episode_t: 6, Action: 57, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 239, loss: 344150.25
[INFO] Global_t: 239, Episode_t: 7, Action: 29, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 240, loss: 1009531.875
[INFO] Global_t: 240, Episode_t: 8, Action: 10, Reward: 2.10, Epsilon: 0.01
 12%|█▏        | 240/2000 [06:55<48:01,  1.64s/it]  
[INFO] Global step: 240, Cumulative rewards: 27.849480000000003, Runtime (s): 415.88
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.785325288772583
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.220252990722656
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7281901836395264
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.211904287338257
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6646857261657715
average cummulative reward vector is:  [0.13427658 0.12528519 0.13820191 0.12851215 0.13149005]
average cummulative reward is:  0.13155317599940214
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 241, loss: 1016998.3125
[INFO] Global_t: 241, Episode_t: 1, Action: 5, Reward: 6.29, Epsilon: 0.01
[INFO] model update: t: 242, loss: 725188.875
[INFO] Global_t: 242, Episode_t: 2, Action: 2, Reward: 3.74, Epsilon: 0.01
[INFO] model update: t: 243, loss: 1579382.375
[INFO] Global_t: 243, Episode_t: 3, Action: 11, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 244, loss: 500006.28125
[INFO] Global_t: 244, Episode_t: 4, Action: 14, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 245, loss: 1776410.5
[INFO] Global_t: 245, Episode_t: 5, Action: 9, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 246, loss: 342753.46875
[INFO] Global_t: 246, Episode_t: 6, Action: 7, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 247, loss: 1391007.25
[INFO] Global_t: 247, Episode_t: 7, Action: 8, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 248, loss: 278977.9375
[INFO] Global_t: 248, Episode_t: 8, Action: 16, Reward: 3.08, Epsilon: 0.01
 12%|█▏        | 248/2000 [07:22<1:02:39,  2.15s/it]
[INFO] Global step: 248, Cumulative rewards: 25.22532, Runtime (s): 442.55
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 249, loss: 876527.3125
[INFO] Global_t: 249, Episode_t: 1, Action: 6, Reward: 5.55, Epsilon: 0.01
[INFO] model update: t: 250, loss: 489211.1875
[INFO] Global_t: 250, Episode_t: 2, Action: 5, Reward: 3.93, Epsilon: 0.01
[INFO] model update: t: 251, loss: 719772.5625
[INFO] Global_t: 251, Episode_t: 3, Action: 0, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 252, loss: 862583.875
[INFO] Global_t: 252, Episode_t: 4, Action: 20, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 253, loss: 381870.125
[INFO] Global_t: 253, Episode_t: 5, Action: 8, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 254, loss: 1180536.25
[INFO] Global_t: 254, Episode_t: 6, Action: 3, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 255, loss: 569992.375
[INFO] Global_t: 255, Episode_t: 7, Action: 32, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 256, loss: 1530712.0
[INFO] Global_t: 256, Episode_t: 8, Action: 57, Reward: 1.92, Epsilon: 0.01
 13%|█▎        | 256/2000 [07:28<49:39,  1.71s/it]  
[INFO] Global step: 256, Cumulative rewards: 25.350960000000004, Runtime (s): 448.05
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9482333660125732
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.790034532546997
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9353041648864746
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.368034362792969
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7996268272399902
average cummulative reward vector is:  [0.13329211 0.11567477 0.1458959  0.12792266 0.13821962]
average cummulative reward is:  0.13220101252566727
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 257, loss: 436664.5
[INFO] Global_t: 257, Episode_t: 1, Action: 5, Reward: 5.29, Epsilon: 0.01
[INFO] model update: t: 258, loss: 1012732.1875
[INFO] Global_t: 258, Episode_t: 2, Action: 10, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 259, loss: 372478.375
[INFO] Global_t: 259, Episode_t: 3, Action: 9, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 260, loss: 401419.9375
[INFO] Global_t: 260, Episode_t: 4, Action: 0, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 261, loss: 765877.875
[INFO] Global_t: 261, Episode_t: 5, Action: 12, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 262, loss: 426822.0625
[INFO] Global_t: 262, Episode_t: 6, Action: 31, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 263, loss: 489586.1875
[INFO] Global_t: 263, Episode_t: 7, Action: 7, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 264, loss: 519862.46875
[INFO] Global_t: 264, Episode_t: 8, Action: 18, Reward: 1.80, Epsilon: 0.01
 13%|█▎        | 264/2000 [07:54<1:02:48,  2.17s/it]
[INFO] Global step: 264, Cumulative rewards: 24.24888, Runtime (s): 474.05
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 265, loss: 454054.15625
[INFO] Global_t: 265, Episode_t: 1, Action: 5, Reward: 5.90, Epsilon: 0.01
[INFO] model update: t: 266, loss: 431112.90625
[INFO] Global_t: 266, Episode_t: 2, Action: 1, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 267, loss: 395098.3125
[INFO] Global_t: 267, Episode_t: 3, Action: 7, Reward: 3.23, Epsilon: 0.01
[INFO] model update: t: 268, loss: 416374.8125
[INFO] Global_t: 268, Episode_t: 4, Action: 26, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 269, loss: 374944.375
[INFO] Global_t: 269, Episode_t: 5, Action: 14, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 270, loss: 318523.03125
[INFO] Global_t: 270, Episode_t: 6, Action: 17, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 271, loss: 314719.4375
[INFO] Global_t: 271, Episode_t: 7, Action: 18, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 272, loss: 420033.90625
[INFO] Global_t: 272, Episode_t: 8, Action: 11, Reward: 2.49, Epsilon: 0.01
 14%|█▎        | 272/2000 [07:59<49:33,  1.72s/it]  
[INFO] Global step: 272, Cumulative rewards: 25.3944, Runtime (s): 479.41
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8416996002197266
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9990410804748535
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8572139739990234
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.408488988876343
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.730868101119995
average cummulative reward vector is:  [0.12715053 0.12331181 0.14249399 0.13214579 0.13521022]
average cummulative reward is:  0.13206246607773403
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 273, loss: 491306.3125
[INFO] Global_t: 273, Episode_t: 1, Action: 13, Reward: 5.39, Epsilon: 0.01
[INFO] model update: t: 274, loss: 374233.59375
[INFO] Global_t: 274, Episode_t: 2, Action: 4, Reward: 5.24, Epsilon: 0.01
[INFO] model update: t: 275, loss: 495117.875
[INFO] Global_t: 275, Episode_t: 3, Action: 8, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 276, loss: 417879.9375
[INFO] Global_t: 276, Episode_t: 4, Action: 2, Reward: 4.84, Epsilon: 0.01
[INFO] model update: t: 277, loss: 397151.1875
[INFO] Global_t: 277, Episode_t: 5, Action: 1, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 278, loss: 353322.875
[INFO] Global_t: 278, Episode_t: 6, Action: 29, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 279, loss: 297575.3125
[INFO] Global_t: 279, Episode_t: 7, Action: 25, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 280, loss: 348110.375
[INFO] Global_t: 280, Episode_t: 8, Action: 6, Reward: 3.02, Epsilon: 0.01
 14%|█▍        | 280/2000 [08:23<1:00:29,  2.11s/it]
[INFO] Global step: 280, Cumulative rewards: 31.445520000000002, Runtime (s): 503.56
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 281, loss: 259416.65625
[INFO] Global_t: 281, Episode_t: 1, Action: 3, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 282, loss: 500694.53125
[INFO] Global_t: 282, Episode_t: 2, Action: 4, Reward: 5.11, Epsilon: 0.01
[INFO] model update: t: 283, loss: 515619.6875
[INFO] Global_t: 283, Episode_t: 3, Action: 14, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 284, loss: 479170.21875
[INFO] Global_t: 284, Episode_t: 4, Action: 2, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 285, loss: 937376.5625
[INFO] Global_t: 285, Episode_t: 5, Action: 17, Reward: 2.10, Epsilon: 0.01
[INFO] model update: t: 286, loss: 535613.5
[INFO] Global_t: 286, Episode_t: 6, Action: 13, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 287, loss: 455852.3125
[INFO] Global_t: 287, Episode_t: 7, Action: 32, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 288, loss: 497816.1875
[INFO] Global_t: 288, Episode_t: 8, Action: 8, Reward: 1.90, Epsilon: 0.01
 14%|█▍        | 288/2000 [08:29<48:12,  1.69s/it]  
[INFO] Global step: 288, Cumulative rewards: 24.853559999999998, Runtime (s): 509.23
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.931088447570801
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.190794467926025
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.679882049560547
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.342501878738403
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6678431034088135
average cummulative reward vector is:  [0.13053684 0.12853264 0.13686202 0.13019579 0.13561129]
average cummulative reward is:  0.13234771751343594
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 289, loss: 389063.28125
[INFO] Global_t: 289, Episode_t: 1, Action: 5, Reward: 5.52, Epsilon: 0.01
[INFO] model update: t: 290, loss: 1264751.125
[INFO] Global_t: 290, Episode_t: 2, Action: 2, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 291, loss: 392079.5625
[INFO] Global_t: 291, Episode_t: 3, Action: 6, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 292, loss: 1349077.125
[INFO] Global_t: 292, Episode_t: 4, Action: 1, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 293, loss: 699634.0
[INFO] Global_t: 293, Episode_t: 5, Action: 9, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 294, loss: 1106957.25
[INFO] Global_t: 294, Episode_t: 6, Action: 8, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 295, loss: 780491.6875
[INFO] Global_t: 295, Episode_t: 7, Action: 18, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 296, loss: 599334.625
[INFO] Global_t: 296, Episode_t: 8, Action: 33, Reward: 2.07, Epsilon: 0.01
 15%|█▍        | 296/2000 [08:54<1:01:00,  2.15s/it]
[INFO] Global step: 296, Cumulative rewards: 23.884439999999998, Runtime (s): 534.98
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 297, loss: 395686.25
[INFO] Global_t: 297, Episode_t: 1, Action: 0, Reward: 5.60, Epsilon: 0.01
[INFO] model update: t: 298, loss: 295948.84375
[INFO] Global_t: 298, Episode_t: 2, Action: 119, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 299, loss: 482180.46875
[INFO] Global_t: 299, Episode_t: 3, Action: 7, Reward: 6.10, Epsilon: 0.01
[INFO] model update: t: 300, loss: 1091568.5
[INFO] Global_t: 300, Episode_t: 4, Action: 3, Reward: 5.76, Epsilon: 0.01
[INFO] model update: t: 301, loss: 421575.125
[INFO] Global_t: 301, Episode_t: 5, Action: 12, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 302, loss: 774490.25
[INFO] Global_t: 302, Episode_t: 6, Action: 8, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 303, loss: 394064.25
[INFO] Global_t: 303, Episode_t: 7, Action: 15, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 304, loss: 867972.75
[INFO] Global_t: 304, Episode_t: 8, Action: 5, Reward: 3.77, Epsilon: 0.01
 15%|█▌        | 304/2000 [08:59<47:44,  1.69s/it]  
[INFO] Global step: 304, Cumulative rewards: 32.78136000000001, Runtime (s): 539.91
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.822490930557251
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9675986766815186
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.046328067779541
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.279672861099243
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9235856533050537
average cummulative reward vector is:  [0.13439684 0.12202894 0.14780355 0.13154626 0.14186882]
average cummulative reward is:  0.13552888161791213
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 305, loss: 292855.0
[INFO] Global_t: 305, Episode_t: 1, Action: 5, Reward: 5.86, Epsilon: 0.01
[INFO] model update: t: 306, loss: 621201.1875
[INFO] Global_t: 306, Episode_t: 2, Action: 1, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 307, loss: 425200.6875
[INFO] Global_t: 307, Episode_t: 3, Action: 9, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 308, loss: 483568.125
[INFO] Global_t: 308, Episode_t: 4, Action: 11, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 309, loss: 302772.4375
[INFO] Global_t: 309, Episode_t: 5, Action: 16, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 310, loss: 391694.9375
[INFO] Global_t: 310, Episode_t: 6, Action: 13, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 311, loss: 274600.25
[INFO] Global_t: 311, Episode_t: 7, Action: 15, Reward: 1.68, Epsilon: 0.01
[INFO] model update: t: 312, loss: 445888.96875
[INFO] Global_t: 312, Episode_t: 8, Action: 19, Reward: 2.01, Epsilon: 0.01
 16%|█▌        | 312/2000 [09:26<1:01:43,  2.19s/it]
[INFO] Global step: 312, Cumulative rewards: 24.600839999999998, Runtime (s): 566.89
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 313, loss: 595392.125
[INFO] Global_t: 313, Episode_t: 1, Action: 4, Reward: 5.90, Epsilon: 0.01
[INFO] model update: t: 314, loss: 902145.6875
[INFO] Global_t: 314, Episode_t: 2, Action: 5, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 315, loss: 502692.03125
[INFO] Global_t: 315, Episode_t: 3, Action: 7, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 316, loss: 1499063.875
[INFO] Global_t: 316, Episode_t: 4, Action: 2, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 317, loss: 260370.75
[INFO] Global_t: 317, Episode_t: 5, Action: 32, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 318, loss: 796004.9375
[INFO] Global_t: 318, Episode_t: 6, Action: 26, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 319, loss: 448562.125
[INFO] Global_t: 319, Episode_t: 7, Action: 8, Reward: 0.98, Epsilon: 0.01
[INFO] model update: t: 320, loss: 615941.4375
[INFO] Global_t: 320, Episode_t: 8, Action: 3, Reward: 1.40, Epsilon: 0.01

[INFO] Global step: 320, Cumulative rewards: 21.131639999999997, Runtime (s): 573.09
------------------------------------------------------------
 
 16%|█▌        | 320/2000 [09:33<49:30,  1.77s/it]  
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7108635902404785
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.980781078338623
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.64482045173645
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.216699838638306
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.944267988204956
average cummulative reward vector is:  [0.13309447 0.12551435 0.1345959  0.13287079 0.14533253]
average cummulative reward is:  0.1342816096899301
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 321, loss: 744707.625
[INFO] Global_t: 321, Episode_t: 1, Action: 5, Reward: 5.36, Epsilon: 0.01
[INFO] model update: t: 322, loss: 394422.375
[INFO] Global_t: 322, Episode_t: 2, Action: 7, Reward: 3.31, Epsilon: 0.01
[INFO] model update: t: 323, loss: 185111.25
[INFO] Global_t: 323, Episode_t: 3, Action: 17, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 324, loss: 409248.6875
[INFO] Global_t: 324, Episode_t: 4, Action: 18, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 325, loss: 325917.28125
[INFO] Global_t: 325, Episode_t: 5, Action: 10, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 326, loss: 325462.4375
[INFO] Global_t: 326, Episode_t: 6, Action: 22, Reward: 1.89, Epsilon: 0.01
[INFO] model update: t: 327, loss: 314230.375
[INFO] Global_t: 327, Episode_t: 7, Action: 4, Reward: 1.89, Epsilon: 0.01
[INFO] model update: t: 328, loss: 346120.28125
[INFO] Global_t: 328, Episode_t: 8, Action: 20, Reward: 2.15, Epsilon: 0.01
 16%|█▋        | 328/2000 [09:57<1:00:23,  2.17s/it]
[INFO] Global step: 328, Cumulative rewards: 21.7518, Runtime (s): 597.88
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 329, loss: 213100.75
[INFO] Global_t: 329, Episode_t: 1, Action: 0, Reward: 5.01, Epsilon: 0.01
[INFO] model update: t: 330, loss: 331254.375
[INFO] Global_t: 330, Episode_t: 2, Action: 6, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 331, loss: 426080.90625
[INFO] Global_t: 331, Episode_t: 3, Action: 9, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 332, loss: 282811.75
[INFO] Global_t: 332, Episode_t: 4, Action: 8, Reward: 4.19, Epsilon: 0.01
[INFO] model update: t: 333, loss: 377892.4375
[INFO] Global_t: 333, Episode_t: 5, Action: 7, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 334, loss: 416184.78125
[INFO] Global_t: 334, Episode_t: 6, Action: 1, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 335, loss: 426236.71875
[INFO] Global_t: 335, Episode_t: 7, Action: 5, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 336, loss: 328931.6875
[INFO] Global_t: 336, Episode_t: 8, Action: 17, Reward: 2.45, Epsilon: 0.01
 17%|█▋        | 336/2000 [10:01<45:46,  1.65s/it]  
[INFO] Global step: 336, Cumulative rewards: 32.38728, Runtime (s): 601.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.736903667449951
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9554855823516846
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.129032850265503
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.033089876174927
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.137134075164795
average cummulative reward vector is:  [0.13020132 0.12363079 0.15524945 0.12601589 0.15220188]
average cummulative reward is:  0.13745986518986417
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 337, loss: 394637.4375
[INFO] Global_t: 337, Episode_t: 1, Action: 5, Reward: 5.38, Epsilon: 0.01
[INFO] model update: t: 338, loss: 459324.59375
[INFO] Global_t: 338, Episode_t: 2, Action: 1, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 339, loss: 521481.8125
[INFO] Global_t: 339, Episode_t: 3, Action: 13, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 340, loss: 524081.3125
[INFO] Global_t: 340, Episode_t: 4, Action: 20, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 341, loss: 379803.1875
[INFO] Global_t: 341, Episode_t: 5, Action: 12, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 342, loss: 361408.75
[INFO] Global_t: 342, Episode_t: 6, Action: 6, Reward: 3.24, Epsilon: 0.01
[INFO] model update: t: 343, loss: 307645.28125
[INFO] Global_t: 343, Episode_t: 7, Action: 14, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 344, loss: 258587.375
[INFO] Global_t: 344, Episode_t: 8, Action: 56, Reward: 1.75, Epsilon: 0.01
 17%|█▋        | 344/2000 [10:27<58:56,  2.14s/it]
[INFO] Global step: 344, Cumulative rewards: 25.43772, Runtime (s): 627.57
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 345, loss: 237619.0625
[INFO] Global_t: 345, Episode_t: 1, Action: 4, Reward: 4.89, Epsilon: 0.01
[INFO] model update: t: 346, loss: 520106.96875
[INFO] Global_t: 346, Episode_t: 2, Action: 5, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 347, loss: 235676.71875
[INFO] Global_t: 347, Episode_t: 3, Action: 10, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 348, loss: 419552.9375
[INFO] Global_t: 348, Episode_t: 4, Action: 8, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 349, loss: 276150.09375
[INFO] Global_t: 349, Episode_t: 5, Action: 6, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 350, loss: 389987.8125
[INFO] Global_t: 350, Episode_t: 6, Action: 2, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 351, loss: 222052.984375
[INFO] Global_t: 351, Episode_t: 7, Action: 0, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 352, loss: 265492.78125
[INFO] Global_t: 352, Episode_t: 8, Action: 13, Reward: 2.54, Epsilon: 0.01
 18%|█▊        | 352/2000 [10:32<45:57,  1.67s/it]
[INFO] Global step: 352, Cumulative rewards: 25.583999999999996, Runtime (s): 632.33
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7928524017333984
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.919630527496338
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.84090256690979
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.107388973236084
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6711978912353516
average cummulative reward vector is:  [0.12853289 0.12466736 0.14432459 0.12612103 0.13626774]
average cummulative reward is:  0.1319827231969509
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 353, loss: 396939.1875
[INFO] Global_t: 353, Episode_t: 1, Action: 1, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 354, loss: 191473.90625
[INFO] Global_t: 354, Episode_t: 2, Action: 9, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 355, loss: 316771.03125
[INFO] Global_t: 355, Episode_t: 3, Action: 14, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 356, loss: 224929.3125
[INFO] Global_t: 356, Episode_t: 4, Action: 6, Reward: 2.59, Epsilon: 0.01
[INFO] model update: t: 357, loss: 257683.078125
[INFO] Global_t: 357, Episode_t: 5, Action: 7, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 358, loss: 255685.515625
[INFO] Global_t: 358, Episode_t: 6, Action: 21, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 359, loss: 300682.5625
[INFO] Global_t: 359, Episode_t: 7, Action: 3, Reward: 3.31, Epsilon: 0.01
[INFO] model update: t: 360, loss: 238620.109375
[INFO] Global_t: 360, Episode_t: 8, Action: 0, Reward: 2.55, Epsilon: 0.01
 18%|█▊        | 360/2000 [10:56<57:10,  2.09s/it]
[INFO] Global step: 360, Cumulative rewards: 26.574240000000003, Runtime (s): 656.88
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 361, loss: 328491.90625
[INFO] Global_t: 361, Episode_t: 1, Action: 5, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 362, loss: 287365.75
[INFO] Global_t: 362, Episode_t: 2, Action: 1, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 363, loss: 351917.5625
[INFO] Global_t: 363, Episode_t: 3, Action: 2, Reward: 3.69, Epsilon: 0.01
[INFO] model update: t: 364, loss: 253983.6875
[INFO] Global_t: 364, Episode_t: 4, Action: 6, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 365, loss: 498356.84375
[INFO] Global_t: 365, Episode_t: 5, Action: 0, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 366, loss: 266218.3125
[INFO] Global_t: 366, Episode_t: 6, Action: 4, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 367, loss: 229420.71875
[INFO] Global_t: 367, Episode_t: 7, Action: 24, Reward: 1.68, Epsilon: 0.01
[INFO] model update: t: 368, loss: 259748.71875
[INFO] Global_t: 368, Episode_t: 8, Action: 35, Reward: 1.41, Epsilon: 0.01
 18%|█▊        | 368/2000 [11:02<45:44,  1.68s/it]
[INFO] Global step: 368, Cumulative rewards: 24.209880000000002, Runtime (s): 662.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.935372829437256
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.679586410522461
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9185948371887207
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.92240047454834
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.728201389312744
average cummulative reward vector is:  [0.13958053 0.11550023 0.14801612 0.12060911 0.13837849]
average cummulative reward is:  0.13241689695780776
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 369, loss: 325601.0625
[INFO] Global_t: 369, Episode_t: 1, Action: 9, Reward: 4.97, Epsilon: 0.01
[INFO] model update: t: 370, loss: 234598.578125
[INFO] Global_t: 370, Episode_t: 2, Action: 2, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 371, loss: 356467.25
[INFO] Global_t: 371, Episode_t: 3, Action: 21, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 372, loss: 295736.15625
[INFO] Global_t: 372, Episode_t: 4, Action: 16, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 373, loss: 271459.25
[INFO] Global_t: 373, Episode_t: 5, Action: 10, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 374, loss: 442703.125
[INFO] Global_t: 374, Episode_t: 6, Action: 20, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 375, loss: 296832.875
[INFO] Global_t: 375, Episode_t: 7, Action: 8, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 376, loss: 475800.6875
[INFO] Global_t: 376, Episode_t: 8, Action: 0, Reward: 2.34, Epsilon: 0.01
 19%|█▉        | 376/2000 [11:28<57:59,  2.14s/it]
[INFO] Global step: 376, Cumulative rewards: 22.51944, Runtime (s): 688.42
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 377, loss: 321658.25
[INFO] Global_t: 377, Episode_t: 1, Action: 7, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 378, loss: 243701.078125
[INFO] Global_t: 378, Episode_t: 2, Action: 17, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 379, loss: 279695.125
[INFO] Global_t: 379, Episode_t: 3, Action: 10, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 380, loss: 219413.75
[INFO] Global_t: 380, Episode_t: 4, Action: 13, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 381, loss: 323627.5
[INFO] Global_t: 381, Episode_t: 5, Action: 5, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 382, loss: 295657.125
[INFO] Global_t: 382, Episode_t: 6, Action: 4, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 383, loss: 139212.234375
[INFO] Global_t: 383, Episode_t: 7, Action: 11, Reward: 1.60, Epsilon: 0.01
[INFO] model update: t: 384, loss: 317822.125
[INFO] Global_t: 384, Episode_t: 8, Action: 1, Reward: 1.51, Epsilon: 0.01
 19%|█▉        | 384/2000 [11:33<46:01,  1.71s/it]
[INFO] Global step: 384, Cumulative rewards: 20.618160000000003, Runtime (s): 693.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.110100269317627
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.1306164264678955
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8976922035217285
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8003523349761963
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.85132098197937
average cummulative reward vector is:  [0.14074895 0.13063889 0.14750492 0.11794696 0.1429379 ]
average cummulative reward is:  0.13595552402654515
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 385, loss: 258782.203125
[INFO] Global_t: 385, Episode_t: 1, Action: 3, Reward: 5.49, Epsilon: 0.01
[INFO] model update: t: 386, loss: 264425.625
[INFO] Global_t: 386, Episode_t: 2, Action: 8, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 387, loss: 299906.28125
[INFO] Global_t: 387, Episode_t: 3, Action: 1, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 388, loss: 233425.8125
[INFO] Global_t: 388, Episode_t: 4, Action: 4, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 389, loss: 244130.90625
[INFO] Global_t: 389, Episode_t: 5, Action: 14, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 390, loss: 271195.3125
[INFO] Global_t: 390, Episode_t: 6, Action: 25, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 391, loss: 284425.375
[INFO] Global_t: 391, Episode_t: 7, Action: 10, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 392, loss: 230711.484375
[INFO] Global_t: 392, Episode_t: 8, Action: 16, Reward: 1.23, Epsilon: 0.01
 20%|█▉        | 392/2000 [11:58<56:47,  2.12s/it]
[INFO] Global step: 392, Cumulative rewards: 23.0874, Runtime (s): 718.60
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 393, loss: 348577.3125
[INFO] Global_t: 393, Episode_t: 1, Action: 137, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 394, loss: 181867.921875
[INFO] Global_t: 394, Episode_t: 2, Action: 8, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 395, loss: 285173.8125
[INFO] Global_t: 395, Episode_t: 3, Action: 1, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 396, loss: 255556.0
[INFO] Global_t: 396, Episode_t: 4, Action: 7, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 397, loss: 285679.875
[INFO] Global_t: 397, Episode_t: 5, Action: 9, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 398, loss: 304280.3125
[INFO] Global_t: 398, Episode_t: 6, Action: 12, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 399, loss: 468495.90625
[INFO] Global_t: 399, Episode_t: 7, Action: 10, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 400, loss: 200974.5
[INFO] Global_t: 400, Episode_t: 8, Action: 16, Reward: 2.52, Epsilon: 0.01
 20%|██        | 400/2000 [12:04<45:21,  1.70s/it]
[INFO] Global step: 400, Cumulative rewards: 22.6218, Runtime (s): 724.40
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.83331036567688
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.88340425491333
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6865341663360596
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.478121519088745
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8572838306427
average cummulative reward vector is:  [0.13282053 0.12085046 0.14029153 0.13701752 0.14339194]
average cummulative reward is:  0.13487439563635084
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 401, loss: 453146.875
[INFO] Global_t: 401, Episode_t: 1, Action: 4, Reward: 5.89, Epsilon: 0.01
[INFO] model update: t: 402, loss: 482318.3125
[INFO] Global_t: 402, Episode_t: 2, Action: 5, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 403, loss: 145339.078125
[INFO] Global_t: 403, Episode_t: 3, Action: 13, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 404, loss: 216026.8125
[INFO] Global_t: 404, Episode_t: 4, Action: 12, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 405, loss: 288504.71875
[INFO] Global_t: 405, Episode_t: 5, Action: 0, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 406, loss: 151276.96875
[INFO] Global_t: 406, Episode_t: 6, Action: 14, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 407, loss: 239773.609375
[INFO] Global_t: 407, Episode_t: 7, Action: 25, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 408, loss: 277369.21875
[INFO] Global_t: 408, Episode_t: 8, Action: 1, Reward: 1.84, Epsilon: 0.01
 20%|██        | 408/2000 [12:30<57:47,  2.18s/it]
[INFO] Global step: 408, Cumulative rewards: 24.319439999999997, Runtime (s): 750.73
------------------------------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 409, loss: 515444.9375
[INFO] Global_t: 409, Episode_t: 1, Action: 5, Reward: 6.10, Epsilon: 0.01
[INFO] model update: t: 410, loss: 248000.4375
[INFO] Global_t: 410, Episode_t: 2, Action: 11, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 411, loss: 208631.4375
[INFO] Global_t: 411, Episode_t: 3, Action: 9, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 412, loss: 185245.84375
[INFO] Global_t: 412, Episode_t: 4, Action: 19, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 413, loss: 452601.3125
[INFO] Global_t: 413, Episode_t: 5, Action: 2, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 414, loss: 739364.3125
[INFO] Global_t: 414, Episode_t: 6, Action: 6, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 415, loss: 151660.5625
[INFO] Global_t: 415, Episode_t: 7, Action: 7, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 416, loss: 664196.9375
[INFO] Global_t: 416, Episode_t: 8, Action: 4, Reward: 3.06, Epsilon: 0.01
 21%|██        | 416/2000 [12:36<45:36,  1.73s/it]
[INFO] Global step: 416, Cumulative rewards: 28.10676, Runtime (s): 756.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.204257249832153
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7918243408203125
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.045146465301514
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9426989555358887
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6891796588897705
average cummulative reward vector is:  [0.14494026 0.12007685 0.14577104 0.1254521  0.13324113]
average cummulative reward is:  0.1338962770194218
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 417, loss: 307464.34375
[INFO] Global_t: 417, Episode_t: 1, Action: 6, Reward: 5.64, Epsilon: 0.01
[INFO] model update: t: 418, loss: 681620.0625
[INFO] Global_t: 418, Episode_t: 2, Action: 4, Reward: 6.24, Epsilon: 0.01
[INFO] model update: t: 419, loss: 457218.25
[INFO] Global_t: 419, Episode_t: 3, Action: 0, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 420, loss: 292738.625
[INFO] Global_t: 420, Episode_t: 4, Action: 13, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 421, loss: 631420.0625
[INFO] Global_t: 421, Episode_t: 5, Action: 12, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 422, loss: 253467.796875
[INFO] Global_t: 422, Episode_t: 6, Action: 24, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 423, loss: 602196.5
[INFO] Global_t: 423, Episode_t: 7, Action: 20, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 424, loss: 726514.125
[INFO] Global_t: 424, Episode_t: 8, Action: 19, Reward: 1.89, Epsilon: 0.01
 21%|██        | 424/2000 [13:01<56:29,  2.15s/it]
[INFO] Global step: 424, Cumulative rewards: 29.4408, Runtime (s): 781.25
------------------------------------------------------------
 
graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 425, loss: 313363.96875
[INFO] Global_t: 425, Episode_t: 1, Action: 4, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 426, loss: 1840860.125
[INFO] Global_t: 426, Episode_t: 2, Action: 0, Reward: 5.84, Epsilon: 0.01
[INFO] model update: t: 427, loss: 553701.0
[INFO] Global_t: 427, Episode_t: 3, Action: 18, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 428, loss: 374617.6875
[INFO] Global_t: 428, Episode_t: 4, Action: 11, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 429, loss: 439804.75
[INFO] Global_t: 429, Episode_t: 5, Action: 7, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 430, loss: 237047.453125
[INFO] Global_t: 430, Episode_t: 6, Action: 1, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 431, loss: 349402.375
[INFO] Global_t: 431, Episode_t: 7, Action: 19, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 432, loss: 237866.015625
[INFO] Global_t: 432, Episode_t: 8, Action: 8, Reward: 1.75, Epsilon: 0.01
 22%|██▏       | 432/2000 [13:06<44:28,  1.70s/it]
[INFO] Global step: 432, Cumulative rewards: 28.326599999999996, Runtime (s): 786.48
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9472484588623047
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.016561031341553
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.610908269882202
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9459338188171387
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.854177951812744
average cummulative reward vector is:  [0.13816842 0.12708958 0.13692596 0.12000607 0.14192392]
average cummulative reward is:  0.13282279203353115
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 433, loss: 211172.0625
[INFO] Global_t: 433, Episode_t: 1, Action: 18, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 434, loss: 489106.65625
[INFO] Global_t: 434, Episode_t: 2, Action: 9, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 435, loss: 407168.875
[INFO] Global_t: 435, Episode_t: 3, Action: 11, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 436, loss: 317856.71875
[INFO] Global_t: 436, Episode_t: 4, Action: 2, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 437, loss: 448988.375
[INFO] Global_t: 437, Episode_t: 5, Action: 12, Reward: 1.88, Epsilon: 0.01
[INFO] model update: t: 438, loss: 244968.046875
[INFO] Global_t: 438, Episode_t: 6, Action: 51, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 439, loss: 290065.84375
[INFO] Global_t: 439, Episode_t: 7, Action: 1, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 440, loss: 325080.125
[INFO] Global_t: 440, Episode_t: 8, Action: 4, Reward: 2.25, Epsilon: 0.01
 22%|██▏       | 440/2000 [13:32<55:54,  2.15s/it]
[INFO] Global step: 440, Cumulative rewards: 21.686640000000004, Runtime (s): 812.05
------------------------------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 441, loss: 819070.625
[INFO] Global_t: 441, Episode_t: 1, Action: 4, Reward: 6.03, Epsilon: 0.01
[INFO] model update: t: 442, loss: 284979.15625
[INFO] Global_t: 442, Episode_t: 2, Action: 13, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 443, loss: 516558.96875
[INFO] Global_t: 443, Episode_t: 3, Action: 9, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 444, loss: 657299.5625
[INFO] Global_t: 444, Episode_t: 4, Action: 1, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 445, loss: 220873.015625
[INFO] Global_t: 445, Episode_t: 5, Action: 20, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 446, loss: 472850.78125
[INFO] Global_t: 446, Episode_t: 6, Action: 12, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 447, loss: 301160.28125
[INFO] Global_t: 447, Episode_t: 7, Action: 2, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 448, loss: 490681.96875
[INFO] Global_t: 448, Episode_t: 8, Action: 10, Reward: 1.74, Epsilon: 0.01
 22%|██▏       | 448/2000 [13:37<44:16,  1.71s/it]
[INFO] Global step: 448, Cumulative rewards: 25.30296, Runtime (s): 817.56
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.181804656982422
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.107017755508423
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.685607433319092
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.348002195358276
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.508424758911133
average cummulative reward vector is:  [0.14474684 0.12777662 0.13970984 0.13246285 0.13092796]
average cummulative reward is:  0.13512482119954888
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 449, loss: 275063.0
[INFO] Global_t: 449, Episode_t: 1, Action: 0, Reward: 5.13, Epsilon: 0.01
[INFO] model update: t: 450, loss: 555404.625
[INFO] Global_t: 450, Episode_t: 2, Action: 1, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 451, loss: 231761.390625
[INFO] Global_t: 451, Episode_t: 3, Action: 6, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 452, loss: 662640.5
[INFO] Global_t: 452, Episode_t: 4, Action: 4, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 453, loss: 929824.1875
[INFO] Global_t: 453, Episode_t: 5, Action: 5, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 454, loss: 137654.015625
[INFO] Global_t: 454, Episode_t: 6, Action: 10, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 455, loss: 1250940.0
[INFO] Global_t: 455, Episode_t: 7, Action: 12, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 456, loss: 1044625.0
[INFO] Global_t: 456, Episode_t: 8, Action: 8, Reward: 1.24, Epsilon: 0.01
 23%|██▎       | 456/2000 [14:03<55:31,  2.16s/it]
[INFO] Global step: 456, Cumulative rewards: 20.085, Runtime (s): 843.14
------------------------------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 457, loss: 357934.0
[INFO] Global_t: 457, Episode_t: 1, Action: 7, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 458, loss: 828890.5625
[INFO] Global_t: 458, Episode_t: 2, Action: 2, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 459, loss: 540263.25
[INFO] Global_t: 459, Episode_t: 3, Action: 4, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 460, loss: 349777.5625
[INFO] Global_t: 460, Episode_t: 4, Action: 18, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 461, loss: 492690.5
[INFO] Global_t: 461, Episode_t: 5, Action: 10, Reward: 3.02, Epsilon: 0.01
[INFO] model update: t: 462, loss: 188853.625
[INFO] Global_t: 462, Episode_t: 6, Action: 5, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 463, loss: 351689.875
[INFO] Global_t: 463, Episode_t: 7, Action: 30, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 464, loss: 643218.125
[INFO] Global_t: 464, Episode_t: 8, Action: 0, Reward: 3.26, Epsilon: 0.01
 23%|██▎       | 464/2000 [14:07<43:17,  1.69s/it]
[INFO] Global step: 464, Cumulative rewards: 25.034640000000003, Runtime (s): 847.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.913597822189331
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6848087310791016
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9349257946014404
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.250439882278442
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6368699073791504
average cummulative reward vector is:  [0.13590553 0.11727106 0.1477347  0.12896355 0.1337172 ]
average cummulative reward is:  0.13271840925742012
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 465, loss: 273111.71875
[INFO] Global_t: 465, Episode_t: 1, Action: 2, Reward: 5.86, Epsilon: 0.01
[INFO] model update: t: 466, loss: 267540.53125
[INFO] Global_t: 466, Episode_t: 2, Action: 5, Reward: 5.95, Epsilon: 0.01
[INFO] model update: t: 467, loss: 321231.34375
[INFO] Global_t: 467, Episode_t: 3, Action: 6, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 468, loss: 363321.875
[INFO] Global_t: 468, Episode_t: 4, Action: 0, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 469, loss: 268784.8125
[INFO] Global_t: 469, Episode_t: 5, Action: 12, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 470, loss: 214942.625
[INFO] Global_t: 470, Episode_t: 6, Action: 11, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 471, loss: 270494.75
[INFO] Global_t: 471, Episode_t: 7, Action: 49, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 472, loss: 294754.5
[INFO] Global_t: 472, Episode_t: 8, Action: 16, Reward: 1.89, Epsilon: 0.01
 24%|██▎       | 472/2000 [14:33<54:07,  2.13s/it]
[INFO] Global step: 472, Cumulative rewards: 31.062719999999995, Runtime (s): 873.07
------------------------------------------------------------
 
graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 473, loss: 239051.6875
[INFO] Global_t: 473, Episode_t: 1, Action: 2, Reward: 5.11, Epsilon: 0.01
[INFO] model update: t: 474, loss: 350446.78125
[INFO] Global_t: 474, Episode_t: 2, Action: 71, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 475, loss: 345247.0625
[INFO] Global_t: 475, Episode_t: 3, Action: 6, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 476, loss: 278011.75
[INFO] Global_t: 476, Episode_t: 4, Action: 13, Reward: 3.57, Epsilon: 0.01
[INFO] model update: t: 477, loss: 107345.78125
[INFO] Global_t: 477, Episode_t: 5, Action: 38, Reward: 3.54, Epsilon: 0.01
[INFO] model update: t: 478, loss: 313936.6875
[INFO] Global_t: 478, Episode_t: 6, Action: 45, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 479, loss: 158457.546875
[INFO] Global_t: 479, Episode_t: 7, Action: 3, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 480, loss: 103527.203125
[INFO] Global_t: 480, Episode_t: 8, Action: 4, Reward: 2.17, Epsilon: 0.01
 24%|██▍       | 480/2000 [14:37<41:31,  1.64s/it]
[INFO] Global step: 480, Cumulative rewards: 26.37156, Runtime (s): 877.11
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6118249893188477
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.1985204219818115
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.676081418991089
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.935577630996704
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7376790046691895
average cummulative reward vector is:  [0.13141921 0.1295206  0.13932514 0.11793645 0.13808898]
average cummulative reward is:  0.13125807521658878
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 481, loss: 219377.78125
[INFO] Global_t: 481, Episode_t: 1, Action: 0, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 482, loss: 275614.5625
[INFO] Global_t: 482, Episode_t: 2, Action: 1, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 483, loss: 322359.03125
[INFO] Global_t: 483, Episode_t: 3, Action: 10, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 484, loss: 300177.0625
[INFO] Global_t: 484, Episode_t: 4, Action: 6, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 485, loss: 203839.65625
[INFO] Global_t: 485, Episode_t: 5, Action: 9, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 486, loss: 231401.78125
[INFO] Global_t: 486, Episode_t: 6, Action: 2, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 487, loss: 319874.8125
[INFO] Global_t: 487, Episode_t: 7, Action: 26, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 488, loss: 221262.875
[INFO] Global_t: 488, Episode_t: 8, Action: 48, Reward: 1.92, Epsilon: 0.01
 24%|██▍       | 488/2000 [15:01<51:40,  2.05s/it]
[INFO] Global step: 488, Cumulative rewards: 22.582440000000005, Runtime (s): 901.20
------------------------------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 489, loss: 199175.8125
[INFO] Global_t: 489, Episode_t: 1, Action: 5, Reward: 6.23, Epsilon: 0.01
[INFO] model update: t: 490, loss: 422495.4375
[INFO] Global_t: 490, Episode_t: 2, Action: 3, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 491, loss: 336272.34375
[INFO] Global_t: 491, Episode_t: 3, Action: 15, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 492, loss: 213173.703125
[INFO] Global_t: 492, Episode_t: 4, Action: 42, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 493, loss: 227904.0
[INFO] Global_t: 493, Episode_t: 5, Action: 14, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 494, loss: 329185.65625
[INFO] Global_t: 494, Episode_t: 6, Action: 6, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 495, loss: 229039.296875
[INFO] Global_t: 495, Episode_t: 7, Action: 1, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 496, loss: 277590.375
[INFO] Global_t: 496, Episode_t: 8, Action: 12, Reward: 1.43, Epsilon: 0.01

[INFO] Global step: 496, Cumulative rewards: 27.27792, Runtime (s): 907.44
------------------------------------------------------------
 
 25%|██▍       | 496/2000 [15:07<41:50,  1.67s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9604103565216064
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9911272525787354
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.675297498703003
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.045898675918579
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9699859619140625
average cummulative reward vector is:  [0.14268816 0.12174236 0.13891721 0.1253028  0.147325  ]
average cummulative reward is:  0.13519510717178393
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 497, loss: 272612.4375
[INFO] Global_t: 497, Episode_t: 1, Action: 0, Reward: 5.07, Epsilon: 0.01
[INFO] model update: t: 498, loss: 252140.09375
[INFO] Global_t: 498, Episode_t: 2, Action: 3, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 499, loss: 371862.625
[INFO] Global_t: 499, Episode_t: 3, Action: 8, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 500, loss: 274970.125
[INFO] Global_t: 500, Episode_t: 4, Action: 4, Reward: 4.83, Epsilon: 0.01
[INFO] model update: t: 501, loss: 136941.0
[INFO] Global_t: 501, Episode_t: 5, Action: 12, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 502, loss: 566238.625
[INFO] Global_t: 502, Episode_t: 6, Action: 24, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 503, loss: 380266.5
[INFO] Global_t: 503, Episode_t: 7, Action: 27, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 504, loss: 464588.5625
[INFO] Global_t: 504, Episode_t: 8, Action: 5, Reward: 2.99, Epsilon: 0.01
 25%|██▌       | 504/2000 [15:31<51:12,  2.05s/it]
[INFO] Global step: 504, Cumulative rewards: 29.543519999999994, Runtime (s): 931.05
------------------------------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 505, loss: 1103132.875
[INFO] Global_t: 505, Episode_t: 1, Action: 6, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 506, loss: 360204.25
[INFO] Global_t: 506, Episode_t: 2, Action: 11, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 507, loss: 680893.75
[INFO] Global_t: 507, Episode_t: 3, Action: 9, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 508, loss: 272520.25
[INFO] Global_t: 508, Episode_t: 4, Action: 5, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 509, loss: 759080.25
[INFO] Global_t: 509, Episode_t: 5, Action: 15, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 510, loss: 551023.125
[INFO] Global_t: 510, Episode_t: 6, Action: 4, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 511, loss: 315925.65625
[INFO] Global_t: 511, Episode_t: 7, Action: 3, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 512, loss: 840404.6875
[INFO] Global_t: 512, Episode_t: 8, Action: 2, Reward: 2.20, Epsilon: 0.01
 26%|██▌       | 512/2000 [15:37<41:14,  1.66s/it]
[INFO] Global step: 512, Cumulative rewards: 26.727599999999995, Runtime (s): 937.05
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.010216474533081
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.97613263130188
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.487759590148926
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.847140312194824
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.970285654067993
average cummulative reward vector is:  [0.14321711 0.11911296 0.13292268 0.12154813 0.13903441]
average cummulative reward is:  0.13116705705300427
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 513, loss: 243018.171875
[INFO] Global_t: 513, Episode_t: 1, Action: 2, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 514, loss: 822343.75
[INFO] Global_t: 514, Episode_t: 2, Action: 0, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 515, loss: 237318.921875
[INFO] Global_t: 515, Episode_t: 3, Action: 1, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 516, loss: 537367.75
[INFO] Global_t: 516, Episode_t: 4, Action: 7, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 517, loss: 394811.875
[INFO] Global_t: 517, Episode_t: 5, Action: 17, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 518, loss: 200505.71875
[INFO] Global_t: 518, Episode_t: 6, Action: 9, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 519, loss: 244953.828125
[INFO] Global_t: 519, Episode_t: 7, Action: 5, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 520, loss: 323858.8125
[INFO] Global_t: 520, Episode_t: 8, Action: 70, Reward: 1.83, Epsilon: 0.01
 26%|██▌       | 520/2000 [16:02<52:24,  2.12s/it]
[INFO] Global step: 520, Cumulative rewards: 25.152720000000006, Runtime (s): 962.66
------------------------------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 521, loss: 241247.25
[INFO] Global_t: 521, Episode_t: 1, Action: 4, Reward: 5.61, Epsilon: 0.01
[INFO] model update: t: 522, loss: 224278.65625
[INFO] Global_t: 522, Episode_t: 2, Action: 8, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 523, loss: 327307.03125
[INFO] Global_t: 523, Episode_t: 3, Action: 2, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 524, loss: 167458.546875
[INFO] Global_t: 524, Episode_t: 4, Action: 11, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 525, loss: 285726.34375
[INFO] Global_t: 525, Episode_t: 5, Action: 1, Reward: 4.26, Epsilon: 0.01
[INFO] model update: t: 526, loss: 301064.6875
[INFO] Global_t: 526, Episode_t: 6, Action: 15, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 527, loss: 192814.03125
[INFO] Global_t: 527, Episode_t: 7, Action: 13, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 528, loss: 281218.75
[INFO] Global_t: 528, Episode_t: 8, Action: 34, Reward: 1.44, Epsilon: 0.01
 26%|██▋       | 528/2000 [16:08<42:14,  1.72s/it]
[INFO] Global step: 528, Cumulative rewards: 27.119279999999996, Runtime (s): 968.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.854278087615967
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.039384126663208
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8934552669525146
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9705746173858643
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.440431594848633
average cummulative reward vector is:  [0.13897895 0.12439514 0.14758033 0.1195278  0.12833441]
average cummulative reward is:  0.13176332529332613
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 529, loss: 242601.59375
[INFO] Global_t: 529, Episode_t: 1, Action: 3, Reward: 5.56, Epsilon: 0.01
[INFO] model update: t: 530, loss: 181579.984375
[INFO] Global_t: 530, Episode_t: 2, Action: 7, Reward: 5.38, Epsilon: 0.01
[INFO] model update: t: 531, loss: 117055.3046875
[INFO] Global_t: 531, Episode_t: 3, Action: 0, Reward: 4.39, Epsilon: 0.01
[INFO] model update: t: 532, loss: 638286.0
[INFO] Global_t: 532, Episode_t: 4, Action: 17, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 533, loss: 431305.125
[INFO] Global_t: 533, Episode_t: 5, Action: 16, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 534, loss: 397002.875
[INFO] Global_t: 534, Episode_t: 6, Action: 4, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 535, loss: 1230483.625
[INFO] Global_t: 535, Episode_t: 7, Action: 2, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 536, loss: 177723.65625
[INFO] Global_t: 536, Episode_t: 8, Action: 19, Reward: 1.98, Epsilon: 0.01
 27%|██▋       | 536/2000 [16:31<50:11,  2.06s/it]
[INFO] Global step: 536, Cumulative rewards: 31.966920000000005, Runtime (s): 991.64
------------------------------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 537, loss: 1043982.625
[INFO] Global_t: 537, Episode_t: 1, Action: 11, Reward: 5.31, Epsilon: 0.01
[INFO] model update: t: 538, loss: 342503.9375
[INFO] Global_t: 538, Episode_t: 2, Action: 1, Reward: 5.30, Epsilon: 0.01
[INFO] model update: t: 539, loss: 633131.875
[INFO] Global_t: 539, Episode_t: 3, Action: 3, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 540, loss: 239973.5625
[INFO] Global_t: 540, Episode_t: 4, Action: 2, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 541, loss: 415339.3125
[INFO] Global_t: 541, Episode_t: 5, Action: 15, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 542, loss: 384501.3125
[INFO] Global_t: 542, Episode_t: 6, Action: 8, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 543, loss: 525533.5
[INFO] Global_t: 543, Episode_t: 7, Action: 6, Reward: 1.67, Epsilon: 0.01
[INFO] model update: t: 544, loss: 1778208.0
[INFO] Global_t: 544, Episode_t: 8, Action: 42, Reward: 1.50, Epsilon: 0.01

 27%|██▋       | 544/2000 [16:36<39:46,  1.64s/it]576, Runtime (s): 996.94
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9878063201904297
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.272616147994995
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5755887031555176
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.00524115562439
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.064504146575928
average cummulative reward vector is:  [0.14287447 0.1265537  0.13188443 0.12689299 0.14120134]
average cummulative reward is:  0.1338813876715299
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 545, loss: 255495.75
[INFO] Global_t: 545, Episode_t: 1, Action: 14, Reward: 5.07, Epsilon: 0.01
[INFO] model update: t: 546, loss: 1689873.625
[INFO] Global_t: 546, Episode_t: 2, Action: 3, Reward: 5.13, Epsilon: 0.01
[INFO] model update: t: 547, loss: 1429505.625
[INFO] Global_t: 547, Episode_t: 3, Action: 5, Reward: 5.90, Epsilon: 0.01
[INFO] model update: t: 548, loss: 440942.4375
[INFO] Global_t: 548, Episode_t: 4, Action: 4, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 549, loss: 1627687.125
[INFO] Global_t: 549, Episode_t: 5, Action: 21, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 550, loss: 441889.9375
[INFO] Global_t: 550, Episode_t: 6, Action: 82, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 551, loss: 1820081.25
[INFO] Global_t: 551, Episode_t: 7, Action: 6, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 552, loss: 548953.5
[INFO] Global_t: 552, Episode_t: 8, Action: 12, Reward: 1.91, Epsilon: 0.01
 28%|██▊       | 552/2000 [17:01<49:56,  2.07s/it]
[INFO] Global step: 552, Cumulative rewards: 32.31036, Runtime (s): 1021.53
------------------------------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 553, loss: 4052737.0
[INFO] Global_t: 553, Episode_t: 1, Action: 0, Reward: 5.16, Epsilon: 0.01
[INFO] model update: t: 554, loss: 2286327.75
[INFO] Global_t: 554, Episode_t: 2, Action: 11, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 555, loss: 1003035.875
[INFO] Global_t: 555, Episode_t: 3, Action: 18, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 556, loss: 3122740.0
[INFO] Global_t: 556, Episode_t: 4, Action: 3, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 557, loss: 165020.234375
[INFO] Global_t: 557, Episode_t: 5, Action: 2, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 558, loss: 3366407.5
[INFO] Global_t: 558, Episode_t: 6, Action: 32, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 559, loss: 467928.71875
[INFO] Global_t: 559, Episode_t: 7, Action: 16, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 560, loss: 3287018.25
[INFO] Global_t: 560, Episode_t: 8, Action: 6, Reward: 2.78, Epsilon: 0.01
 28%|██▊       | 560/2000 [17:06<39:20,  1.64s/it]
[INFO] Global step: 560, Cumulative rewards: 27.550800000000002, Runtime (s): 1026.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.133781909942627
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.89245867729187
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8293423652648926
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.168939828872681
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6152918338775635
average cummulative reward vector is:  [0.14644421 0.12280231 0.13769208 0.13287734 0.13497204]
average cummulative reward is:  0.13495759626064274
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 561, loss: 5524196.5
[INFO] Global_t: 561, Episode_t: 1, Action: 0, Reward: 5.97, Epsilon: 0.01
[INFO] model update: t: 562, loss: 384115.6875
[INFO] Global_t: 562, Episode_t: 2, Action: 7, Reward: 6.23, Epsilon: 0.01
[INFO] model update: t: 563, loss: 8300657.0
[INFO] Global_t: 563, Episode_t: 3, Action: 2, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 564, loss: 4194122.0
[INFO] Global_t: 564, Episode_t: 4, Action: 12, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 565, loss: 1069321.5
[INFO] Global_t: 565, Episode_t: 5, Action: 17, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 566, loss: 3703413.5
[INFO] Global_t: 566, Episode_t: 6, Action: 4, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 567, loss: 238838.65625
[INFO] Global_t: 567, Episode_t: 7, Action: 21, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 568, loss: 4010655.0
[INFO] Global_t: 568, Episode_t: 8, Action: 16, Reward: 4.09, Epsilon: 0.01
 28%|██▊       | 568/2000 [17:31<49:19,  2.07s/it]
[INFO] Global step: 568, Cumulative rewards: 32.1288, Runtime (s): 1051.13
------------------------------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 569, loss: 182424.78125
[INFO] Global_t: 569, Episode_t: 1, Action: 5, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 570, loss: 3395322.5
[INFO] Global_t: 570, Episode_t: 2, Action: 1, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 571, loss: 1065406.375
[INFO] Global_t: 571, Episode_t: 3, Action: 8, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 572, loss: 447788.78125
[INFO] Global_t: 572, Episode_t: 4, Action: 14, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 573, loss: 315108.25
[INFO] Global_t: 573, Episode_t: 5, Action: 0, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 574, loss: 1380467.875
[INFO] Global_t: 574, Episode_t: 6, Action: 15, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 575, loss: 2801374.5
[INFO] Global_t: 575, Episode_t: 7, Action: 35, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 576, loss: 500313.0
[INFO] Global_t: 576, Episode_t: 8, Action: 21, Reward: 2.94, Epsilon: 0.01
 29%|██▉       | 576/2000 [17:37<39:38,  1.67s/it]
[INFO] Global step: 576, Cumulative rewards: 23.64732, Runtime (s): 1057.09
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6682052612304688
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.805459976196289
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6152255535125732
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8331520557403564
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.073913335800171
average cummulative reward vector is:  [0.13236211 0.12106204 0.13373115 0.122625   0.14972312]
average cummulative reward is:  0.1319006816241497
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 577, loss: 1403541.0
[INFO] Global_t: 577, Episode_t: 1, Action: 7, Reward: 5.32, Epsilon: 0.01
[INFO] model update: t: 578, loss: 1533526.0
[INFO] Global_t: 578, Episode_t: 2, Action: 4, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 579, loss: 559892.0625
[INFO] Global_t: 579, Episode_t: 3, Action: 1, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 580, loss: 2104205.0
[INFO] Global_t: 580, Episode_t: 4, Action: 6, Reward: 3.33, Epsilon: 0.01
[INFO] model update: t: 581, loss: 242336.53125
[INFO] Global_t: 581, Episode_t: 5, Action: 24, Reward: 3.28, Epsilon: 0.01
[INFO] model update: t: 582, loss: 1713409.0
[INFO] Global_t: 582, Episode_t: 6, Action: 8, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 583, loss: 238293.03125
[INFO] Global_t: 583, Episode_t: 7, Action: 14, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 584, loss: 2237702.0
[INFO] Global_t: 584, Episode_t: 8, Action: 3, Reward: 3.00, Epsilon: 0.01
 29%|██▉       | 584/2000 [18:01<49:20,  2.09s/it]
[INFO] Global step: 584, Cumulative rewards: 27.185999999999996, Runtime (s): 1081.66
------------------------------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 585, loss: 402213.5625
[INFO] Global_t: 585, Episode_t: 1, Action: 2, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 586, loss: 1602288.25
[INFO] Global_t: 586, Episode_t: 2, Action: 1, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 587, loss: 3622632.75
[INFO] Global_t: 587, Episode_t: 3, Action: 7, Reward: 2.87, Epsilon: 0.01
[INFO] model update: t: 588, loss: 368525.28125
[INFO] Global_t: 588, Episode_t: 4, Action: 0, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 589, loss: 2773268.0
[INFO] Global_t: 589, Episode_t: 5, Action: 24, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 590, loss: 1044652.625
[INFO] Global_t: 590, Episode_t: 6, Action: 13, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 591, loss: 1120391.0
[INFO] Global_t: 591, Episode_t: 7, Action: 27, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 592, loss: 2383507.25
[INFO] Global_t: 592, Episode_t: 8, Action: 10, Reward: 1.86, Epsilon: 0.01
 30%|██▉       | 592/2000 [18:08<40:11,  1.71s/it]
[INFO] Global step: 592, Cumulative rewards: 21.758519999999997, Runtime (s): 1088.31
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.879303455352783
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8361775875091553
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9752025604248047
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.290878772735596
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.834972381591797
average cummulative reward vector is:  [0.13917526 0.1201588  0.1423235  0.13594229 0.14082392]
average cummulative reward is:  0.1356847542345519
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 593, loss: 160031.0625
[INFO] Global_t: 593, Episode_t: 1, Action: 4, Reward: 6.17, Epsilon: 0.01
[INFO] model update: t: 594, loss: 2374301.5
[INFO] Global_t: 594, Episode_t: 2, Action: 0, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 595, loss: 1637222.75
[INFO] Global_t: 595, Episode_t: 3, Action: 13, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 596, loss: 239568.71875
[INFO] Global_t: 596, Episode_t: 4, Action: 12, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 597, loss: 1505822.375
[INFO] Global_t: 597, Episode_t: 5, Action: 2, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 598, loss: 659826.5
[INFO] Global_t: 598, Episode_t: 6, Action: 18, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 599, loss: 529724.125
[INFO] Global_t: 599, Episode_t: 7, Action: 23, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 600, loss: 1584895.25
[INFO] Global_t: 600, Episode_t: 8, Action: 14, Reward: 1.98, Epsilon: 0.01
 30%|███       | 600/2000 [18:33<50:19,  2.16s/it]
[INFO] Global step: 600, Cumulative rewards: 25.150680000000005, Runtime (s): 1113.86
------------------------------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 601, loss: 173137.921875
[INFO] Global_t: 601, Episode_t: 1, Action: 4, Reward: 6.02, Epsilon: 0.01
[INFO] model update: t: 602, loss: 1235372.75
[INFO] Global_t: 602, Episode_t: 2, Action: 11, Reward: 5.33, Epsilon: 0.01
[INFO] model update: t: 603, loss: 2031743.125
[INFO] Global_t: 603, Episode_t: 3, Action: 8, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 604, loss: 142709.625
[INFO] Global_t: 604, Episode_t: 4, Action: 2, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 605, loss: 1091021.5
[INFO] Global_t: 605, Episode_t: 5, Action: 20, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 606, loss: 283087.59375
[INFO] Global_t: 606, Episode_t: 6, Action: 46, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 607, loss: 801865.875
[INFO] Global_t: 607, Episode_t: 7, Action: 22, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 608, loss: 592334.25
[INFO] Global_t: 608, Episode_t: 8, Action: 0, Reward: 3.49, Epsilon: 0.01
 30%|███       | 608/2000 [18:38<39:25,  1.70s/it]
[INFO] Global step: 608, Cumulative rewards: 28.09344, Runtime (s): 1118.91
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8771133422851562
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.0887131690979
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.355453729629517
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.87677001953125
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7085728645324707
average cummulative reward vector is:  [0.14073684 0.12810301 0.15677951 0.12386706 0.13742661]
average cummulative reward is:  0.13738260570784716
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 609, loss: 316270.4375
[INFO] Global_t: 609, Episode_t: 1, Action: 2, Reward: 6.13, Epsilon: 0.01
[INFO] model update: t: 610, loss: 902570.75
[INFO] Global_t: 610, Episode_t: 2, Action: 10, Reward: 3.28, Epsilon: 0.01
[INFO] model update: t: 611, loss: 403020.15625
[INFO] Global_t: 611, Episode_t: 3, Action: 14, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 612, loss: 156322.984375
[INFO] Global_t: 612, Episode_t: 4, Action: 6, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 613, loss: 476910.40625
[INFO] Global_t: 613, Episode_t: 5, Action: 12, Reward: 1.74, Epsilon: 0.01
[INFO] model update: t: 614, loss: 212258.171875
[INFO] Global_t: 614, Episode_t: 6, Action: 5, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 615, loss: 201931.78125
[INFO] Global_t: 615, Episode_t: 7, Action: 13, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 616, loss: 179315.359375
[INFO] Global_t: 616, Episode_t: 8, Action: 16, Reward: 1.86, Epsilon: 0.01
 31%|███       | 616/2000 [19:05<50:11,  2.18s/it]
[INFO] Global step: 616, Cumulative rewards: 21.546719999999997, Runtime (s): 1145.21
------------------------------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 617, loss: 126257.96875
[INFO] Global_t: 617, Episode_t: 1, Action: 5, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 618, loss: 97981.296875
[INFO] Global_t: 618, Episode_t: 2, Action: 18, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 619, loss: 159319.234375
[INFO] Global_t: 619, Episode_t: 3, Action: 12, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 620, loss: 138500.765625
[INFO] Global_t: 620, Episode_t: 4, Action: 11, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 621, loss: 160919.21875
[INFO] Global_t: 621, Episode_t: 5, Action: 10, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 622, loss: 171200.59375
[INFO] Global_t: 622, Episode_t: 6, Action: 2, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 623, loss: 209485.375
[INFO] Global_t: 623, Episode_t: 7, Action: 1, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 624, loss: 140837.0625
[INFO] Global_t: 624, Episode_t: 8, Action: 7, Reward: 1.92, Epsilon: 0.01
 31%|███       | 624/2000 [19:11<40:06,  1.75s/it]
[INFO] Global step: 624, Cumulative rewards: 24.366719999999997, Runtime (s): 1151.24
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8877971172332764
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.230867385864258
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.461306571960449
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9032979011535645
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.936264753341675
average cummulative reward vector is:  [0.14102711 0.13261065 0.12685847 0.12377921 0.14011102]
average cummulative reward is:  0.13287729009390284
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 625, loss: 132375.15625
[INFO] Global_t: 625, Episode_t: 1, Action: 9, Reward: 5.02, Epsilon: 0.01
[INFO] model update: t: 626, loss: 117787.9765625
[INFO] Global_t: 626, Episode_t: 2, Action: 75, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 627, loss: 67629.0
[INFO] Global_t: 627, Episode_t: 3, Action: 0, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 628, loss: 198205.546875
[INFO] Global_t: 628, Episode_t: 4, Action: 10, Reward: 5.18, Epsilon: 0.01
[INFO] model update: t: 629, loss: 161830.75
[INFO] Global_t: 629, Episode_t: 5, Action: 2, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 630, loss: 77072.328125
[INFO] Global_t: 630, Episode_t: 6, Action: 3, Reward: 3.13, Epsilon: 0.01
[INFO] model update: t: 631, loss: 150165.9375
[INFO] Global_t: 631, Episode_t: 7, Action: 4, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 632, loss: 186274.796875
[INFO] Global_t: 632, Episode_t: 8, Action: 16, Reward: 2.62, Epsilon: 0.01
 32%|███▏      | 632/2000 [19:34<47:38,  2.09s/it]
[INFO] Global step: 632, Cumulative rewards: 29.850000000000005, Runtime (s): 1174.32
------------------------------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 633, loss: 267323.3125
[INFO] Global_t: 633, Episode_t: 1, Action: 6, Reward: 5.95, Epsilon: 0.01
[INFO] model update: t: 634, loss: 238819.875
[INFO] Global_t: 634, Episode_t: 2, Action: 2, Reward: 5.79, Epsilon: 0.01
[INFO] model update: t: 635, loss: 135827.421875
[INFO] Global_t: 635, Episode_t: 3, Action: 1, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 636, loss: 112698.625
[INFO] Global_t: 636, Episode_t: 4, Action: 15, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 637, loss: 103158.8515625
[INFO] Global_t: 637, Episode_t: 5, Action: 5, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 638, loss: 256423.4375
[INFO] Global_t: 638, Episode_t: 6, Action: 17, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 639, loss: 389417.71875
[INFO] Global_t: 639, Episode_t: 7, Action: 0, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 640, loss: 187179.75
[INFO] Global_t: 640, Episode_t: 8, Action: 24, Reward: 2.12, Epsilon: 0.01
 32%|███▏      | 640/2000 [19:38<36:38,  1.62s/it]
[INFO] Global step: 640, Cumulative rewards: 30.906480000000002, Runtime (s): 1178.41
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.005865573883057
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.06970477104187
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.893662452697754
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.111332178115845
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7346227169036865
average cummulative reward vector is:  [0.13996789 0.12830509 0.14437049 0.12761145 0.1389207 ]
average cummulative reward is:  0.13583512533111505
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 641, loss: 189247.75
[INFO] Global_t: 641, Episode_t: 1, Action: 5, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 642, loss: 303155.34375
[INFO] Global_t: 642, Episode_t: 2, Action: 7, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 643, loss: 341219.125
[INFO] Global_t: 643, Episode_t: 3, Action: 32, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 644, loss: 248868.53125
[INFO] Global_t: 644, Episode_t: 4, Action: 2, Reward: 6.41, Epsilon: 0.01
[INFO] model update: t: 645, loss: 81309.9375
[INFO] Global_t: 645, Episode_t: 5, Action: 34, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 646, loss: 155662.78125
[INFO] Global_t: 646, Episode_t: 6, Action: 1, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 647, loss: 132236.0
[INFO] Global_t: 647, Episode_t: 7, Action: 8, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 648, loss: 127716.125
[INFO] Global_t: 648, Episode_t: 8, Action: 20, Reward: 2.77, Epsilon: 0.01
 32%|███▏      | 648/2000 [20:02<45:27,  2.02s/it]
[INFO] Global step: 648, Cumulative rewards: 36.71208, Runtime (s): 1202.04
------------------------------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 649, loss: 146736.28125
[INFO] Global_t: 649, Episode_t: 1, Action: 9, Reward: 5.23, Epsilon: 0.01
[INFO] model update: t: 650, loss: 114478.8046875
[INFO] Global_t: 650, Episode_t: 2, Action: 1, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 651, loss: 277028.34375
[INFO] Global_t: 651, Episode_t: 3, Action: 15, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 652, loss: 129588.5859375
[INFO] Global_t: 652, Episode_t: 4, Action: 8, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 653, loss: 96289.890625
[INFO] Global_t: 653, Episode_t: 5, Action: 16, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 654, loss: 269328.125
[INFO] Global_t: 654, Episode_t: 6, Action: 18, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 655, loss: 406542.75
[INFO] Global_t: 655, Episode_t: 7, Action: 24, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 656, loss: 113371.3828125
[INFO] Global_t: 656, Episode_t: 8, Action: 32, Reward: 2.14, Epsilon: 0.01

[INFO] Global step: 656, Cumulative rewards: 25.506119999999996, Runtime (s): 1206.70
------------------------------------------------------------
 
 33%|███▎      | 656/2000 [20:06<35:33,  1.59s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.083618402481079
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.141366958618164
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.670025110244751
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.200257062911987
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8512380123138428
average cummulative reward vector is:  [0.14134474 0.12716921 0.13905164 0.12837874 0.14358522]
average cummulative reward is:  0.1359059085041702
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
[INFO] model update: t: 657, loss: 313664.09375
[INFO] Global_t: 657, Episode_t: 1, Action: 3, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 658, loss: 127240.53125
[INFO] Global_t: 658, Episode_t: 2, Action: 2, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 659, loss: 176294.6875
[INFO] Global_t: 659, Episode_t: 3, Action: 5, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 660, loss: 126662.421875
[INFO] Global_t: 660, Episode_t: 4, Action: 4, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 661, loss: 241656.546875
[INFO] Global_t: 661, Episode_t: 5, Action: 9, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 662, loss: 177885.25
[INFO] Global_t: 662, Episode_t: 6, Action: 10, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 663, loss: 110464.53125
[INFO] Global_t: 663, Episode_t: 7, Action: 11, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 664, loss: 201694.84375
[INFO] Global_t: 664, Episode_t: 8, Action: 1, Reward: 2.65, Epsilon: 0.01
 33%|███▎      | 664/2000 [20:31<45:50,  2.06s/it]
[INFO] Global step: 664, Cumulative rewards: 22.29516, Runtime (s): 1231.98
------------------------------------------------------------
 
graph: 83, nodes: 198, edges: 584
[INFO] model update: t: 665, loss: 269184.625
[INFO] Global_t: 665, Episode_t: 1, Action: 4, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 666, loss: 164110.46875
[INFO] Global_t: 666, Episode_t: 2, Action: 7, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 667, loss: 130933.59375
[INFO] Global_t: 667, Episode_t: 3, Action: 6, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 668, loss: 122541.9140625
[INFO] Global_t: 668, Episode_t: 4, Action: 8, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 669, loss: 177016.96875
[INFO] Global_t: 669, Episode_t: 5, Action: 10, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 670, loss: 203434.171875
[INFO] Global_t: 670, Episode_t: 6, Action: 14, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 671, loss: 130905.6953125
[INFO] Global_t: 671, Episode_t: 7, Action: 1, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 672, loss: 118553.140625
[INFO] Global_t: 672, Episode_t: 8, Action: 30, Reward: 1.52, Epsilon: 0.01
 34%|███▎      | 672/2000 [20:37<36:32,  1.65s/it]
[INFO] Global step: 672, Cumulative rewards: 20.677319999999998, Runtime (s): 1237.58
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7246081829071045
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.224356412887573
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5512213706970215
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.470968246459961
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7428390979766846
average cummulative reward vector is:  [0.13522132 0.12517292 0.13335355 0.13281332 0.13878548]
average cummulative reward is:  0.13306931719933718
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 84, nodes: 205, edges: 606
[INFO] model update: t: 673, loss: 142410.8125
[INFO] Global_t: 673, Episode_t: 1, Action: 0, Reward: 5.52, Epsilon: 0.01
[INFO] model update: t: 674, loss: 84520.375
[INFO] Global_t: 674, Episode_t: 2, Action: 7, Reward: 4.89, Epsilon: 0.01
[INFO] model update: t: 675, loss: 247863.46875
[INFO] Global_t: 675, Episode_t: 3, Action: 3, Reward: 6.75, Epsilon: 0.01
[INFO] model update: t: 676, loss: 338472.1875
[INFO] Global_t: 676, Episode_t: 4, Action: 26, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 677, loss: 162285.34375
[INFO] Global_t: 677, Episode_t: 5, Action: 4, Reward: 4.72, Epsilon: 0.01
[INFO] model update: t: 678, loss: 241369.421875
[INFO] Global_t: 678, Episode_t: 6, Action: 27, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 679, loss: 130593.7578125
[INFO] Global_t: 679, Episode_t: 7, Action: 15, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 680, loss: 185463.25
[INFO] Global_t: 680, Episode_t: 8, Action: 10, Reward: 4.74, Epsilon: 0.01
 34%|███▍      | 680/2000 [21:00<44:08,  2.01s/it]
[INFO] Global step: 680, Cumulative rewards: 37.9308, Runtime (s): 1260.27
------------------------------------------------------------
 
graph: 85, nodes: 212, edges: 627
[INFO] model update: t: 681, loss: 354864.65625
[INFO] Global_t: 681, Episode_t: 1, Action: 0, Reward: 5.35, Epsilon: 0.01
[INFO] model update: t: 682, loss: 75742.34375
[INFO] Global_t: 682, Episode_t: 2, Action: 10, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 683, loss: 517807.125
[INFO] Global_t: 683, Episode_t: 3, Action: 165, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 684, loss: 114869.15625
[INFO] Global_t: 684, Episode_t: 4, Action: 2, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 685, loss: 642761.8125
[INFO] Global_t: 685, Episode_t: 5, Action: 5, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 686, loss: 1371283.375
[INFO] Global_t: 686, Episode_t: 6, Action: 12, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 687, loss: 915209.5
[INFO] Global_t: 687, Episode_t: 7, Action: 11, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 688, loss: 239313.578125
[INFO] Global_t: 688, Episode_t: 8, Action: 9, Reward: 1.65, Epsilon: 0.01
 34%|███▍      | 688/2000 [21:07<36:18,  1.66s/it]
[INFO] Global step: 688, Cumulative rewards: 22.363920000000004, Runtime (s): 1267.09
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.185286045074463
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.230950593948364
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6653709411621094
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.052311420440674
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8420510292053223
average cummulative reward vector is:  [0.15068947 0.12924167 0.13783689 0.12989112 0.13365081]
average cummulative reward is:  0.13626199070874376
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 86, nodes: 200, edges: 591
[INFO] model update: t: 689, loss: 1699044.0
[INFO] Global_t: 689, Episode_t: 1, Action: 3, Reward: 4.98, Epsilon: 0.01
[INFO] model update: t: 690, loss: 1152435.0
[INFO] Global_t: 690, Episode_t: 2, Action: 8, Reward: 4.54, Epsilon: 0.01
[INFO] model update: t: 691, loss: 693226.5
[INFO] Global_t: 691, Episode_t: 3, Action: 6, Reward: 3.14, Epsilon: 0.01
[INFO] model update: t: 692, loss: 4165361.5
[INFO] Global_t: 692, Episode_t: 4, Action: 0, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 693, loss: 773204.5625
[INFO] Global_t: 693, Episode_t: 5, Action: 11, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 694, loss: 2709101.25
[INFO] Global_t: 694, Episode_t: 6, Action: 5, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 695, loss: 1877130.125
[INFO] Global_t: 695, Episode_t: 7, Action: 24, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 696, loss: 206499.546875
[INFO] Global_t: 696, Episode_t: 8, Action: 12, Reward: 2.09, Epsilon: 0.01
 35%|███▍      | 696/2000 [21:32<45:56,  2.11s/it]
[INFO] Global step: 696, Cumulative rewards: 25.179479999999998, Runtime (s): 1292.46
------------------------------------------------------------
 
graph: 87, nodes: 218, edges: 645
[INFO] model update: t: 697, loss: 1826320.75
[INFO] Global_t: 697, Episode_t: 1, Action: 2, Reward: 5.05, Epsilon: 0.01
[INFO] model update: t: 698, loss: 147991.375
[INFO] Global_t: 698, Episode_t: 2, Action: 7, Reward: 5.01, Epsilon: 0.01
[INFO] model update: t: 699, loss: 1070701.75
[INFO] Global_t: 699, Episode_t: 3, Action: 9, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 700, loss: 480957.53125
[INFO] Global_t: 700, Episode_t: 4, Action: 12, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 701, loss: 492750.875
[INFO] Global_t: 701, Episode_t: 5, Action: 21, Reward: 2.90, Epsilon: 0.01
[INFO] model update: t: 702, loss: 1135068.125
[INFO] Global_t: 702, Episode_t: 6, Action: 11, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 703, loss: 101778.640625
[INFO] Global_t: 703, Episode_t: 7, Action: 16, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 704, loss: 925204.5
[INFO] Global_t: 704, Episode_t: 8, Action: 14, Reward: 3.21, Epsilon: 0.01
 35%|███▌      | 704/2000 [21:36<35:21,  1.64s/it]
[INFO] Global step: 704, Cumulative rewards: 31.00584, Runtime (s): 1296.65
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9214346408843994
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.954249143600464
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.616635799407959
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.306410312652588
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.930760622024536
average cummulative reward vector is:  [0.14153026 0.12129167 0.13770984 0.13679346 0.1383672 ]
average cummulative reward is:  0.13513848562702716
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 88, nodes: 204, edges: 603
[INFO] model update: t: 705, loss: 569632.0
[INFO] Global_t: 705, Episode_t: 1, Action: 3, Reward: 5.70, Epsilon: 0.01
[INFO] model update: t: 706, loss: 111264.09375
[INFO] Global_t: 706, Episode_t: 2, Action: 6, Reward: 5.83, Epsilon: 0.01
[INFO] model update: t: 707, loss: 577412.0
[INFO] Global_t: 707, Episode_t: 3, Action: 2, Reward: 5.27, Epsilon: 0.01
[INFO] model update: t: 708, loss: 832961.25
[INFO] Global_t: 708, Episode_t: 4, Action: 16, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 709, loss: 179203.34375
[INFO] Global_t: 709, Episode_t: 5, Action: 9, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 710, loss: 1205350.5
[INFO] Global_t: 710, Episode_t: 6, Action: 18, Reward: 3.02, Epsilon: 0.01
[INFO] model update: t: 711, loss: 384316.09375
[INFO] Global_t: 711, Episode_t: 7, Action: 4, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 712, loss: 385845.21875
[INFO] Global_t: 712, Episode_t: 8, Action: 17, Reward: 2.10, Epsilon: 0.01
 36%|███▌      | 712/2000 [22:00<43:49,  2.04s/it]
[INFO] Global step: 712, Cumulative rewards: 30.435599999999997, Runtime (s): 1320.53
------------------------------------------------------------
 
graph: 89, nodes: 199, edges: 588
[INFO] model update: t: 713, loss: 655210.625
[INFO] Global_t: 713, Episode_t: 1, Action: 5, Reward: 5.58, Epsilon: 0.01
[INFO] model update: t: 714, loss: 169038.0625
[INFO] Global_t: 714, Episode_t: 2, Action: 4, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 715, loss: 830202.875
[INFO] Global_t: 715, Episode_t: 3, Action: 0, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 716, loss: 63771.5859375
[INFO] Global_t: 716, Episode_t: 4, Action: 11, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 717, loss: 1000642.5625
[INFO] Global_t: 717, Episode_t: 5, Action: 14, Reward: 1.89, Epsilon: 0.01
[INFO] model update: t: 718, loss: 262824.4375
[INFO] Global_t: 718, Episode_t: 6, Action: 3, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 719, loss: 731836.6875
[INFO] Global_t: 719, Episode_t: 7, Action: 7, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 720, loss: 891386.375
[INFO] Global_t: 720, Episode_t: 8, Action: 9, Reward: 2.32, Epsilon: 0.01
 36%|███▌      | 720/2000 [22:05<34:35,  1.62s/it]
[INFO] Global step: 720, Cumulative rewards: 24.781679999999998, Runtime (s): 1325.66
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.825524091720581
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9163389205932617
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7257964611053467
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9342429637908936
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9638991355895996
average cummulative reward vector is:  [0.13759158 0.12376505 0.13211721 0.12523294 0.14571237]
average cummulative reward is:  0.13288382957501005
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 90, nodes: 207, edges: 612
[INFO] model update: t: 721, loss: 341246.34375
[INFO] Global_t: 721, Episode_t: 1, Action: 3, Reward: 5.47, Epsilon: 0.01
[INFO] model update: t: 722, loss: 1074315.375
[INFO] Global_t: 722, Episode_t: 2, Action: 7, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 723, loss: 94357.0234375
[INFO] Global_t: 723, Episode_t: 3, Action: 4, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 724, loss: 973706.0
[INFO] Global_t: 724, Episode_t: 4, Action: 12, Reward: 3.13, Epsilon: 0.01
[INFO] model update: t: 725, loss: 96276.75
[INFO] Global_t: 725, Episode_t: 5, Action: 16, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 726, loss: 879508.5625
[INFO] Global_t: 726, Episode_t: 6, Action: 5, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 727, loss: 543206.1875
[INFO] Global_t: 727, Episode_t: 7, Action: 1, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 728, loss: 101442.578125
[INFO] Global_t: 728, Episode_t: 8, Action: 15, Reward: 3.04, Epsilon: 0.01
 36%|███▋      | 728/2000 [22:30<43:44,  2.06s/it]
[INFO] Global step: 728, Cumulative rewards: 28.0104, Runtime (s): 1350.42
------------------------------------------------------------
 
graph: 91, nodes: 198, edges: 585
[INFO] model update: t: 729, loss: 549485.25
[INFO] Global_t: 729, Episode_t: 1, Action: 3, Reward: 6.11, Epsilon: 0.01
[INFO] model update: t: 730, loss: 407962.59375
[INFO] Global_t: 730, Episode_t: 2, Action: 9, Reward: 3.20, Epsilon: 0.01
[INFO] model update: t: 731, loss: 492680.25
[INFO] Global_t: 731, Episode_t: 3, Action: 15, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 732, loss: 1567232.25
[INFO] Global_t: 732, Episode_t: 4, Action: 5, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 733, loss: 491796.6875
[INFO] Global_t: 733, Episode_t: 5, Action: 0, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 734, loss: 460740.125
[INFO] Global_t: 734, Episode_t: 6, Action: 41, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 735, loss: 1042013.0
[INFO] Global_t: 735, Episode_t: 7, Action: 8, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 736, loss: 103626.0
[INFO] Global_t: 736, Episode_t: 8, Action: 1, Reward: 1.81, Epsilon: 0.01
 37%|███▋      | 736/2000 [22:36<35:28,  1.68s/it]
[INFO] Global step: 736, Cumulative rewards: 21.63924, Runtime (s): 1356.81
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.202239990234375
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.007017612457275
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.3257081508636475
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.821686267852783
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.126665353775024
average cummulative reward vector is:  [0.15145605 0.12422106 0.15006721 0.12138294 0.14156183]
average cummulative reward is:  0.13773782048867417
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 92, nodes: 183, edges: 539
[INFO] model update: t: 737, loss: 820630.3125
[INFO] Global_t: 737, Episode_t: 1, Action: 9, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 738, loss: 1229686.25
[INFO] Global_t: 738, Episode_t: 2, Action: 5, Reward: 4.92, Epsilon: 0.01
[INFO] model update: t: 739, loss: 424741.1875
[INFO] Global_t: 739, Episode_t: 3, Action: 16, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 740, loss: 595978.375
[INFO] Global_t: 740, Episode_t: 4, Action: 0, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 741, loss: 768735.0
[INFO] Global_t: 741, Episode_t: 5, Action: 10, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 742, loss: 134360.6875
[INFO] Global_t: 742, Episode_t: 6, Action: 12, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 743, loss: 498554.875
[INFO] Global_t: 743, Episode_t: 7, Action: 22, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 744, loss: 81745.328125
[INFO] Global_t: 744, Episode_t: 8, Action: 3, Reward: 2.19, Epsilon: 0.01
 37%|███▋      | 744/2000 [23:02<44:32,  2.13s/it]
[INFO] Global step: 744, Cumulative rewards: 26.664360000000002, Runtime (s): 1382.11
------------------------------------------------------------
 
graph: 93, nodes: 217, edges: 642
[INFO] model update: t: 745, loss: 627002.4375
[INFO] Global_t: 745, Episode_t: 1, Action: 4, Reward: 5.36, Epsilon: 0.01
[INFO] model update: t: 746, loss: 723413.4375
[INFO] Global_t: 746, Episode_t: 2, Action: 10, Reward: 4.80, Epsilon: 0.01
[INFO] model update: t: 747, loss: 129419.8671875
[INFO] Global_t: 747, Episode_t: 3, Action: 9, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 748, loss: 1230975.625
[INFO] Global_t: 748, Episode_t: 4, Action: 0, Reward: 5.86, Epsilon: 0.01
[INFO] model update: t: 749, loss: 388479.5
[INFO] Global_t: 749, Episode_t: 5, Action: 7, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 750, loss: 171299.875
[INFO] Global_t: 750, Episode_t: 6, Action: 20, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 751, loss: 274712.15625
[INFO] Global_t: 751, Episode_t: 7, Action: 19, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 752, loss: 83214.9609375
[INFO] Global_t: 752, Episode_t: 8, Action: 49, Reward: 1.86, Epsilon: 0.01
 38%|███▊      | 752/2000 [23:05<33:53,  1.63s/it]
[INFO] Global step: 752, Cumulative rewards: 33.02616, Runtime (s): 1385.86
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.831123113632202
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.192257881164551
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8648202419281006
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.077382326126099
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.735621929168701
average cummulative reward vector is:  [0.13340553 0.13100648 0.13499235 0.12761355 0.13801371]
average cummulative reward is:  0.13300632372066706
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 94, nodes: 198, edges: 585
[INFO] model update: t: 753, loss: 183742.3125
[INFO] Global_t: 753, Episode_t: 1, Action: 2, Reward: 6.26, Epsilon: 0.01
[INFO] model update: t: 754, loss: 150935.5
[INFO] Global_t: 754, Episode_t: 2, Action: 4, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 755, loss: 136589.921875
[INFO] Global_t: 755, Episode_t: 3, Action: 11, Reward: 2.90, Epsilon: 0.01
[INFO] model update: t: 756, loss: 147821.40625
[INFO] Global_t: 756, Episode_t: 4, Action: 15, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 757, loss: 87530.90625
[INFO] Global_t: 757, Episode_t: 5, Action: 5, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 758, loss: 150821.53125
[INFO] Global_t: 758, Episode_t: 6, Action: 6, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 759, loss: 325104.125
[INFO] Global_t: 759, Episode_t: 7, Action: 1, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 760, loss: 256677.4375
[INFO] Global_t: 760, Episode_t: 8, Action: 23, Reward: 1.44, Epsilon: 0.01
 38%|███▊      | 760/2000 [23:31<43:37,  2.11s/it]
[INFO] Global step: 760, Cumulative rewards: 23.196599999999997, Runtime (s): 1411.73
------------------------------------------------------------
 
graph: 95, nodes: 202, edges: 597
[INFO] model update: t: 761, loss: 63542.2578125
[INFO] Global_t: 761, Episode_t: 1, Action: 5, Reward: 6.22, Epsilon: 0.01
[INFO] model update: t: 762, loss: 281515.78125
[INFO] Global_t: 762, Episode_t: 2, Action: 8, Reward: 6.06, Epsilon: 0.01
[INFO] model update: t: 763, loss: 204713.8125
[INFO] Global_t: 763, Episode_t: 3, Action: 4, Reward: 4.44, Epsilon: 0.01
[INFO] model update: t: 764, loss: 68107.4375
[INFO] Global_t: 764, Episode_t: 4, Action: 6, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 765, loss: 322108.65625
[INFO] Global_t: 765, Episode_t: 5, Action: 10, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 766, loss: 220465.40625
[INFO] Global_t: 766, Episode_t: 6, Action: 17, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 767, loss: 101442.03125
[INFO] Global_t: 767, Episode_t: 7, Action: 9, Reward: 2.63, Epsilon: 0.01
[INFO] model update: t: 768, loss: 176442.9375
[INFO] Global_t: 768, Episode_t: 8, Action: 18, Reward: 1.64, Epsilon: 0.01
 38%|███▊      | 768/2000 [23:37<34:33,  1.68s/it]
[INFO] Global step: 768, Cumulative rewards: 30.597599999999996, Runtime (s): 1417.20
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6517817974090576
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.038991451263428
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7663400173187256
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.093834400177002
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4761300086975098
average cummulative reward vector is:  [0.12393368 0.12770231 0.13194508 0.12828621 0.12904032]
average cummulative reward is:  0.12818152370529406
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 96, nodes: 200, edges: 591
[INFO] model update: t: 769, loss: 184724.1875
[INFO] Global_t: 769, Episode_t: 1, Action: 5, Reward: 4.85, Epsilon: 0.01
[INFO] model update: t: 770, loss: 138692.5625
[INFO] Global_t: 770, Episode_t: 2, Action: 6, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 771, loss: 56557.015625
[INFO] Global_t: 771, Episode_t: 3, Action: 12, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 772, loss: 80102.828125
[INFO] Global_t: 772, Episode_t: 4, Action: 7, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 773, loss: 57803.6171875
[INFO] Global_t: 773, Episode_t: 5, Action: 0, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 774, loss: 61467.65234375
[INFO] Global_t: 774, Episode_t: 6, Action: 2, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 775, loss: 103966.3203125
[INFO] Global_t: 775, Episode_t: 7, Action: 4, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 776, loss: 96108.875
[INFO] Global_t: 776, Episode_t: 8, Action: 10, Reward: 2.91, Epsilon: 0.01
 39%|███▉      | 776/2000 [24:02<43:15,  2.12s/it]
[INFO] Global step: 776, Cumulative rewards: 25.91904, Runtime (s): 1442.33
------------------------------------------------------------
 
graph: 97, nodes: 206, edges: 609
[INFO] model update: t: 777, loss: 107453.453125
[INFO] Global_t: 777, Episode_t: 1, Action: 3, Reward: 5.46, Epsilon: 0.01
[INFO] model update: t: 778, loss: 59408.578125
[INFO] Global_t: 778, Episode_t: 2, Action: 8, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 779, loss: 130289.953125
[INFO] Global_t: 779, Episode_t: 3, Action: 2, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 780, loss: 350120.9375
[INFO] Global_t: 780, Episode_t: 4, Action: 7, Reward: 3.01, Epsilon: 0.01
[INFO] model update: t: 781, loss: 102867.015625
[INFO] Global_t: 781, Episode_t: 5, Action: 10, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 782, loss: 162764.375
[INFO] Global_t: 782, Episode_t: 6, Action: 13, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 783, loss: 187801.96875
[INFO] Global_t: 783, Episode_t: 7, Action: 4, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 784, loss: 72615.1484375
[INFO] Global_t: 784, Episode_t: 8, Action: 9, Reward: 2.19, Epsilon: 0.01
 39%|███▉      | 784/2000 [24:07<34:09,  1.69s/it]
[INFO] Global step: 784, Cumulative rewards: 25.72308, Runtime (s): 1447.69
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.070953130722046
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.202616214752197
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.100258827209473
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.0473713874816895
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.732482433319092
average cummulative reward vector is:  [0.13868211 0.13205741 0.14848962 0.12864977 0.13936667]
average cummulative reward is:  0.13744911263574217
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 98, nodes: 206, edges: 607
[INFO] model update: t: 785, loss: 82762.734375
[INFO] Global_t: 785, Episode_t: 1, Action: 3, Reward: 6.04, Epsilon: 0.01
[INFO] model update: t: 786, loss: 178328.25
[INFO] Global_t: 786, Episode_t: 2, Action: 12, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 787, loss: 76876.46875
[INFO] Global_t: 787, Episode_t: 3, Action: 5, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 788, loss: 108607.4375
[INFO] Global_t: 788, Episode_t: 4, Action: 16, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 789, loss: 192578.796875
[INFO] Global_t: 789, Episode_t: 5, Action: 17, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 790, loss: 134998.25
[INFO] Global_t: 790, Episode_t: 6, Action: 21, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 791, loss: 65670.296875
[INFO] Global_t: 791, Episode_t: 7, Action: 2, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 792, loss: 164487.078125
[INFO] Global_t: 792, Episode_t: 8, Action: 1, Reward: 1.82, Epsilon: 0.01
 40%|███▉      | 792/2000 [24:33<43:03,  2.14s/it]
[INFO] Global step: 792, Cumulative rewards: 22.651199999999996, Runtime (s): 1473.27
------------------------------------------------------------
 
graph: 99, nodes: 181, edges: 533
[INFO] model update: t: 793, loss: 81653.78125
[INFO] Global_t: 793, Episode_t: 1, Action: 5, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 794, loss: 99921.5859375
[INFO] Global_t: 794, Episode_t: 2, Action: 0, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 795, loss: 113441.15625
[INFO] Global_t: 795, Episode_t: 3, Action: 9, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 796, loss: 105048.9453125
[INFO] Global_t: 796, Episode_t: 4, Action: 11, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 797, loss: 79328.515625
[INFO] Global_t: 797, Episode_t: 5, Action: 19, Reward: 1.68, Epsilon: 0.01
[INFO] model update: t: 798, loss: 130109.0859375
[INFO] Global_t: 798, Episode_t: 6, Action: 10, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 799, loss: 287843.15625
[INFO] Global_t: 799, Episode_t: 7, Action: 1, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 800, loss: 99227.40625
[INFO] Global_t: 800, Episode_t: 8, Action: 34, Reward: 1.49, Epsilon: 0.01
 40%|████      | 800/2000 [24:39<34:26,  1.72s/it]
[INFO] Global step: 800, Cumulative rewards: 22.211399999999998, Runtime (s): 1479.27
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.010327100753784
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9516642093658447
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.28510308265686
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.229219675064087
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.91044020652771
average cummulative reward vector is:  [0.13825711 0.12507431 0.14507104 0.13354322 0.14357957]
average cummulative reward is:  0.1371050486523236
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 100, nodes: 188, edges: 555
[INFO] model update: t: 801, loss: 113315.453125
[INFO] Global_t: 801, Episode_t: 1, Action: 3, Reward: 5.49, Epsilon: 0.01
[INFO] model update: t: 802, loss: 112250.390625
[INFO] Global_t: 802, Episode_t: 2, Action: 6, Reward: 4.86, Epsilon: 0.01
[INFO] model update: t: 803, loss: 168339.234375
[INFO] Global_t: 803, Episode_t: 3, Action: 11, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 804, loss: 104735.0703125
[INFO] Global_t: 804, Episode_t: 4, Action: 10, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 805, loss: 160780.453125
[INFO] Global_t: 805, Episode_t: 5, Action: 4, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 806, loss: 227157.109375
[INFO] Global_t: 806, Episode_t: 6, Action: 9, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 807, loss: 74197.3671875
[INFO] Global_t: 807, Episode_t: 7, Action: 19, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 808, loss: 296214.6875
[INFO] Global_t: 808, Episode_t: 8, Action: 17, Reward: 2.18, Epsilon: 0.01
 40%|████      | 808/2000 [25:05<43:14,  2.18s/it]
[INFO] Global step: 808, Cumulative rewards: 25.688879999999997, Runtime (s): 1505.17
------------------------------------------------------------
 
graph: 101, nodes: 211, edges: 624
[INFO] model update: t: 809, loss: 129514.2265625
[INFO] Global_t: 809, Episode_t: 1, Action: 4, Reward: 5.24, Epsilon: 0.01
[INFO] model update: t: 810, loss: 101561.0078125
[INFO] Global_t: 810, Episode_t: 2, Action: 8, Reward: 4.78, Epsilon: 0.01
[INFO] model update: t: 811, loss: 99364.109375
[INFO] Global_t: 811, Episode_t: 3, Action: 6, Reward: 5.24, Epsilon: 0.01
[INFO] model update: t: 812, loss: 85185.8125
[INFO] Global_t: 812, Episode_t: 4, Action: 11, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 813, loss: 131454.375
[INFO] Global_t: 813, Episode_t: 5, Action: 2, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 814, loss: 120526.03125
[INFO] Global_t: 814, Episode_t: 6, Action: 16, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 815, loss: 88043.6875
[INFO] Global_t: 815, Episode_t: 7, Action: 12, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 816, loss: 170853.984375
[INFO] Global_t: 816, Episode_t: 8, Action: 25, Reward: 3.02, Epsilon: 0.01
 41%|████      | 816/2000 [25:09<33:23,  1.69s/it]
[INFO] Global step: 816, Cumulative rewards: 29.2902, Runtime (s): 1509.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.054056644439697
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.871497631072998
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9619240760803223
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.0398359298706055
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.681008815765381
average cummulative reward vector is:  [0.14208    0.12191852 0.14332596 0.12708715 0.13561909]
average cummulative reward is:  0.13400614207137745
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 102, nodes: 180, edges: 531
[INFO] model update: t: 817, loss: 48235.296875
[INFO] Global_t: 817, Episode_t: 1, Action: 7, Reward: 5.36, Epsilon: 0.01
[INFO] model update: t: 818, loss: 213680.25
[INFO] Global_t: 818, Episode_t: 2, Action: 2, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 819, loss: 80350.84375
[INFO] Global_t: 819, Episode_t: 3, Action: 4, Reward: 5.61, Epsilon: 0.01
[INFO] model update: t: 820, loss: 95692.9453125
[INFO] Global_t: 820, Episode_t: 4, Action: 10, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 821, loss: 183572.25
[INFO] Global_t: 821, Episode_t: 5, Action: 0, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 822, loss: 93765.875
[INFO] Global_t: 822, Episode_t: 6, Action: 178, Reward: 0.98, Epsilon: 0.01
[INFO] model update: t: 823, loss: 124774.015625
[INFO] Global_t: 823, Episode_t: 7, Action: 13, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 824, loss: 417588.875
[INFO] Global_t: 824, Episode_t: 8, Action: 8, Reward: 2.06, Epsilon: 0.01
 41%|████      | 824/2000 [25:33<40:56,  2.09s/it]
[INFO] Global step: 824, Cumulative rewards: 27.31284, Runtime (s): 1533.78
------------------------------------------------------------
 
graph: 103, nodes: 187, edges: 551
[INFO] model update: t: 825, loss: 64672.41015625
[INFO] Global_t: 825, Episode_t: 1, Action: 0, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 826, loss: 272429.40625
[INFO] Global_t: 826, Episode_t: 2, Action: 2, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 827, loss: 437080.0625
[INFO] Global_t: 827, Episode_t: 3, Action: 16, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 828, loss: 133101.140625
[INFO] Global_t: 828, Episode_t: 4, Action: 1, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 829, loss: 97067.484375
[INFO] Global_t: 829, Episode_t: 5, Action: 25, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 830, loss: 246092.78125
[INFO] Global_t: 830, Episode_t: 6, Action: 18, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 831, loss: 93119.5
[INFO] Global_t: 831, Episode_t: 7, Action: 13, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 832, loss: 137557.234375
[INFO] Global_t: 832, Episode_t: 8, Action: 17, Reward: 1.75, Epsilon: 0.01
 42%|████▏     | 832/2000 [25:39<32:25,  1.67s/it]
[INFO] Global step: 832, Cumulative rewards: 22.457639999999994, Runtime (s): 1539.19
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.230175733566284
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.046872854232788
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3897433280944824
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.418009519577026
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5205907821655273
average cummulative reward vector is:  [0.14225184 0.12751875 0.12856694 0.13340514 0.12851317]
average cummulative reward is:  0.13205116884518003
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 104, nodes: 185, edges: 546
[INFO] model update: t: 833, loss: 162338.90625
[INFO] Global_t: 833, Episode_t: 1, Action: 0, Reward: 5.38, Epsilon: 0.01
[INFO] model update: t: 834, loss: 120667.03125
[INFO] Global_t: 834, Episode_t: 2, Action: 4, Reward: 4.80, Epsilon: 0.01
[INFO] model update: t: 835, loss: 421464.75
[INFO] Global_t: 835, Episode_t: 3, Action: 11, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 836, loss: 382660.78125
[INFO] Global_t: 836, Episode_t: 4, Action: 33, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 837, loss: 76736.640625
[INFO] Global_t: 837, Episode_t: 5, Action: 17, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 838, loss: 551809.375
[INFO] Global_t: 838, Episode_t: 6, Action: 12, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 839, loss: 379649.28125
[INFO] Global_t: 839, Episode_t: 7, Action: 10, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 840, loss: 56745.7265625
[INFO] Global_t: 840, Episode_t: 8, Action: 5, Reward: 3.93, Epsilon: 0.01
 42%|████▏     | 840/2000 [26:03<39:49,  2.06s/it]
[INFO] Global step: 840, Cumulative rewards: 27.87936, Runtime (s): 1563.03
------------------------------------------------------------
 
graph: 105, nodes: 180, edges: 531
[INFO] model update: t: 841, loss: 381498.6875
[INFO] Global_t: 841, Episode_t: 1, Action: 2, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 842, loss: 342586.5625
[INFO] Global_t: 842, Episode_t: 2, Action: 1, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 843, loss: 47921.1640625
[INFO] Global_t: 843, Episode_t: 3, Action: 4, Reward: 2.10, Epsilon: 0.01
[INFO] model update: t: 844, loss: 178011.890625
[INFO] Global_t: 844, Episode_t: 4, Action: 18, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 845, loss: 180216.765625
[INFO] Global_t: 845, Episode_t: 5, Action: 3, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 846, loss: 156390.0625
[INFO] Global_t: 846, Episode_t: 6, Action: 5, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 847, loss: 611790.75
[INFO] Global_t: 847, Episode_t: 7, Action: 8, Reward: 2.94, Epsilon: 0.01
[INFO] model update: t: 848, loss: 313748.59375
[INFO] Global_t: 848, Episode_t: 8, Action: 6, Reward: 1.22, Epsilon: 0.01
 42%|████▏     | 848/2000 [26:07<31:11,  1.62s/it]
[INFO] Global step: 848, Cumulative rewards: 21.3486, Runtime (s): 1567.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.018799543380737
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.234571933746338
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.556715726852417
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.218478441238403
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.58293080329895
average cummulative reward vector is:  [0.14412    0.12916111 0.13377213 0.12817874 0.13082151]
average cummulative reward is:  0.13321069719055065
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 106, nodes: 206, edges: 608
[INFO] model update: t: 849, loss: 59826.640625
[INFO] Global_t: 849, Episode_t: 1, Action: 3, Reward: 6.44, Epsilon: 0.01
[INFO] model update: t: 850, loss: 212851.59375
[INFO] Global_t: 850, Episode_t: 2, Action: 1, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 851, loss: 149674.375
[INFO] Global_t: 851, Episode_t: 3, Action: 19, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 852, loss: 61920.828125
[INFO] Global_t: 852, Episode_t: 4, Action: 24, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 853, loss: 216245.78125
[INFO] Global_t: 853, Episode_t: 5, Action: 0, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 854, loss: 189716.984375
[INFO] Global_t: 854, Episode_t: 6, Action: 11, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 855, loss: 142941.9375
[INFO] Global_t: 855, Episode_t: 7, Action: 54, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 856, loss: 556341.6875
[INFO] Global_t: 856, Episode_t: 8, Action: 13, Reward: 3.42, Epsilon: 0.01
 43%|████▎     | 856/2000 [26:32<39:18,  2.06s/it]
[INFO] Global step: 856, Cumulative rewards: 29.663520000000002, Runtime (s): 1592.56
------------------------------------------------------------
 
graph: 107, nodes: 205, edges: 606
[INFO] model update: t: 857, loss: 337362.34375
[INFO] Global_t: 857, Episode_t: 1, Action: 10, Reward: 5.66, Epsilon: 0.01
[INFO] model update: t: 858, loss: 76076.484375
[INFO] Global_t: 858, Episode_t: 2, Action: 5, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 859, loss: 664918.8125
[INFO] Global_t: 859, Episode_t: 3, Action: 16, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 860, loss: 418322.5625
[INFO] Global_t: 860, Episode_t: 4, Action: 12, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 861, loss: 36068.125
[INFO] Global_t: 861, Episode_t: 5, Action: 49, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 862, loss: 320371.4375
[INFO] Global_t: 862, Episode_t: 6, Action: 26, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 863, loss: 286100.40625
[INFO] Global_t: 863, Episode_t: 7, Action: 11, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 864, loss: 37302.421875
[INFO] Global_t: 864, Episode_t: 8, Action: 0, Reward: 1.94, Epsilon: 0.01

[INFO] Global step: 864, Cumulative rewards: 22.261200000000002, Runtime (s): 1598.96
 43%|████▎     | 864/2000 [26:38<31:52,  1.68s/it]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.555206060409546
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.271024942398071
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.399069309234619
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.226596832275391
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6845414638519287
average cummulative reward vector is:  [0.12976789 0.12693773 0.12946257 0.13023762 0.13474113]
average cummulative reward is:  0.13022938807580448
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 108, nodes: 215, edges: 636
[INFO] model update: t: 865, loss: 306582.09375
[INFO] Global_t: 865, Episode_t: 1, Action: 5, Reward: 5.04, Epsilon: 0.01
[INFO] model update: t: 866, loss: 241304.703125
[INFO] Global_t: 866, Episode_t: 2, Action: 2, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 867, loss: 68273.640625
[INFO] Global_t: 867, Episode_t: 3, Action: 1, Reward: 3.52, Epsilon: 0.01
[INFO] model update: t: 868, loss: 72993.90625
[INFO] Global_t: 868, Episode_t: 4, Action: 9, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 869, loss: 242336.84375
[INFO] Global_t: 869, Episode_t: 5, Action: 10, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 870, loss: 279384.0625
[INFO] Global_t: 870, Episode_t: 6, Action: 14, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 871, loss: 116102.46875
[INFO] Global_t: 871, Episode_t: 7, Action: 25, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 872, loss: 45571.84765625
[INFO] Global_t: 872, Episode_t: 8, Action: 3, Reward: 1.84, Epsilon: 0.01
 44%|████▎     | 872/2000 [27:04<40:20,  2.15s/it]
[INFO] Global step: 872, Cumulative rewards: 23.429280000000002, Runtime (s): 1624.75
------------------------------------------------------------
 
graph: 109, nodes: 186, edges: 549
[INFO] model update: t: 873, loss: 138330.34375
[INFO] Global_t: 873, Episode_t: 1, Action: 3, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 874, loss: 400640.625
[INFO] Global_t: 874, Episode_t: 2, Action: 7, Reward: 4.83, Epsilon: 0.01
[INFO] model update: t: 875, loss: 546856.25
[INFO] Global_t: 875, Episode_t: 3, Action: 17, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 876, loss: 227220.71875
[INFO] Global_t: 876, Episode_t: 4, Action: 16, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 877, loss: 93601.0234375
[INFO] Global_t: 877, Episode_t: 5, Action: 9, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 878, loss: 304577.3125
[INFO] Global_t: 878, Episode_t: 6, Action: 8, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 879, loss: 50604.53125
[INFO] Global_t: 879, Episode_t: 7, Action: 2, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 880, loss: 273366.5
[INFO] Global_t: 880, Episode_t: 8, Action: 11, Reward: 1.31, Epsilon: 0.01
 44%|████▍     | 880/2000 [27:10<31:47,  1.70s/it]
[INFO] Global step: 880, Cumulative rewards: 24.504119999999997, Runtime (s): 1630.13
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.578338623046875
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.307514429092407
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.835662841796875
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.513613224029541
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5655200481414795
average cummulative reward vector is:  [0.13078579 0.12834931 0.14381858 0.13104019 0.13204731]
average cummulative reward is:  0.13320823460161146
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 110, nodes: 180, edges: 531
[INFO] model update: t: 881, loss: 122784.9921875
[INFO] Global_t: 881, Episode_t: 1, Action: 3, Reward: 6.03, Epsilon: 0.01
[INFO] model update: t: 882, loss: 96409.875
[INFO] Global_t: 882, Episode_t: 2, Action: 6, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 883, loss: 342776.5
[INFO] Global_t: 883, Episode_t: 3, Action: 2, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 884, loss: 486211.625
[INFO] Global_t: 884, Episode_t: 4, Action: 12, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 885, loss: 174677.65625
[INFO] Global_t: 885, Episode_t: 5, Action: 14, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 886, loss: 78003.484375
[INFO] Global_t: 886, Episode_t: 6, Action: 13, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 887, loss: 217333.75
[INFO] Global_t: 887, Episode_t: 7, Action: 1, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 888, loss: 155479.1875
[INFO] Global_t: 888, Episode_t: 8, Action: 0, Reward: 2.64, Epsilon: 0.01
 44%|████▍     | 888/2000 [27:34<39:05,  2.11s/it]
[INFO] Global step: 888, Cumulative rewards: 24.86172, Runtime (s): 1654.58
------------------------------------------------------------
 
graph: 111, nodes: 200, edges: 591
[INFO] model update: t: 889, loss: 61365.8828125
[INFO] Global_t: 889, Episode_t: 1, Action: 4, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 890, loss: 138904.90625
[INFO] Global_t: 890, Episode_t: 2, Action: 7, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 891, loss: 142413.53125
[INFO] Global_t: 891, Episode_t: 3, Action: 3, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 892, loss: 92499.71875
[INFO] Global_t: 892, Episode_t: 4, Action: 5, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 893, loss: 172826.515625
[INFO] Global_t: 893, Episode_t: 5, Action: 12, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 894, loss: 42983.01953125
[INFO] Global_t: 894, Episode_t: 6, Action: 24, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 895, loss: 304025.625
[INFO] Global_t: 895, Episode_t: 7, Action: 9, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 896, loss: 293616.28125
[INFO] Global_t: 896, Episode_t: 8, Action: 10, Reward: 2.38, Epsilon: 0.01
 45%|████▍     | 896/2000 [27:39<30:35,  1.66s/it]
[INFO] Global step: 896, Cumulative rewards: 26.090760000000003, Runtime (s): 1659.55
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4351389408111572
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.373569488525391
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8659403324127197
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.108131647109985
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8447489738464355
average cummulative reward vector is:  [0.12353474 0.12667546 0.14621339 0.13067009 0.13864328]
average cummulative reward is:  0.13314739216220936
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 112, nodes: 216, edges: 639
[INFO] model update: t: 897, loss: 33771.56640625
[INFO] Global_t: 897, Episode_t: 1, Action: 5, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 898, loss: 478426.9375
[INFO] Global_t: 898, Episode_t: 2, Action: 12, Reward: 5.08, Epsilon: 0.01
[INFO] model update: t: 899, loss: 771799.0
[INFO] Global_t: 899, Episode_t: 3, Action: 13, Reward: 4.63, Epsilon: 0.01
[INFO] model update: t: 900, loss: 421777.75
[INFO] Global_t: 900, Episode_t: 4, Action: 9, Reward: 4.89, Epsilon: 0.01
[INFO] model update: t: 901, loss: 41387.7421875
[INFO] Global_t: 901, Episode_t: 5, Action: 2, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 902, loss: 509168.78125
[INFO] Global_t: 902, Episode_t: 6, Action: 42, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 903, loss: 1185087.25
[INFO] Global_t: 903, Episode_t: 7, Action: 4, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 904, loss: 261030.734375
[INFO] Global_t: 904, Episode_t: 8, Action: 56, Reward: 2.46, Epsilon: 0.01
 45%|████▌     | 904/2000 [28:03<37:23,  2.05s/it]
[INFO] Global step: 904, Cumulative rewards: 32.03904, Runtime (s): 1683.09
------------------------------------------------------------
 
graph: 113, nodes: 217, edges: 642
[INFO] model update: t: 905, loss: 281158.4375
[INFO] Global_t: 905, Episode_t: 1, Action: 5, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 906, loss: 865474.5
[INFO] Global_t: 906, Episode_t: 2, Action: 6, Reward: 4.27, Epsilon: 0.01
[INFO] model update: t: 907, loss: 375172.8125
[INFO] Global_t: 907, Episode_t: 3, Action: 10, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 908, loss: 182809.15625
[INFO] Global_t: 908, Episode_t: 4, Action: 2, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 909, loss: 936625.8125
[INFO] Global_t: 909, Episode_t: 5, Action: 7, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 910, loss: 630718.4375
[INFO] Global_t: 910, Episode_t: 6, Action: 4, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 911, loss: 59844.3359375
[INFO] Global_t: 911, Episode_t: 7, Action: 24, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 912, loss: 460695.6875
[INFO] Global_t: 912, Episode_t: 8, Action: 11, Reward: 2.45, Epsilon: 0.01
 46%|████▌     | 912/2000 [28:08<29:32,  1.63s/it]
[INFO] Global step: 912, Cumulative rewards: 26.961, Runtime (s): 1688.34
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8999998569488525
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.935218095779419
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8472115993499756
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7317817211151123
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7227649688720703
average cummulative reward vector is:  [0.14194421 0.12508935 0.14023087 0.11823084 0.13792258]
average cummulative reward is:  0.13268357169235284
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 114, nodes: 190, edges: 561
[INFO] model update: t: 913, loss: 207501.03125
[INFO] Global_t: 913, Episode_t: 1, Action: 8, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 914, loss: 36398.41015625
[INFO] Global_t: 914, Episode_t: 2, Action: 3, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 915, loss: 117157.671875
[INFO] Global_t: 915, Episode_t: 3, Action: 18, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 916, loss: 134109.375
[INFO] Global_t: 916, Episode_t: 4, Action: 1, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 917, loss: 58345.9140625
[INFO] Global_t: 917, Episode_t: 5, Action: 5, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 918, loss: 338230.125
[INFO] Global_t: 918, Episode_t: 6, Action: 4, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 919, loss: 525560.5625
[INFO] Global_t: 919, Episode_t: 7, Action: 10, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 920, loss: 131206.90625
[INFO] Global_t: 920, Episode_t: 8, Action: 9, Reward: 2.47, Epsilon: 0.01
 46%|████▌     | 920/2000 [28:32<37:09,  2.06s/it]
[INFO] Global step: 920, Cumulative rewards: 26.531640000000003, Runtime (s): 1712.97
------------------------------------------------------------
 
graph: 115, nodes: 198, edges: 585
[INFO] model update: t: 921, loss: 139019.34375
[INFO] Global_t: 921, Episode_t: 1, Action: 6, Reward: 5.13, Epsilon: 0.01
[INFO] model update: t: 922, loss: 328506.6875
[INFO] Global_t: 922, Episode_t: 2, Action: 0, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 923, loss: 85195.453125
[INFO] Global_t: 923, Episode_t: 3, Action: 8, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 924, loss: 114826.421875
[INFO] Global_t: 924, Episode_t: 4, Action: 4, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 925, loss: 81952.75
[INFO] Global_t: 925, Episode_t: 5, Action: 22, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 926, loss: 73990.03125
[INFO] Global_t: 926, Episode_t: 6, Action: 3, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 927, loss: 199946.625
[INFO] Global_t: 927, Episode_t: 7, Action: 5, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 928, loss: 86806.6640625
[INFO] Global_t: 928, Episode_t: 8, Action: 11, Reward: 1.51, Epsilon: 0.01
 46%|████▋     | 928/2000 [28:38<29:42,  1.66s/it]
[INFO] Global step: 928, Cumulative rewards: 26.43876, Runtime (s): 1718.78
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6901001930236816
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.053315877914429
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.885782241821289
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.111932277679443
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6027519702911377
average cummulative reward vector is:  [0.13435263 0.12799907 0.13242678 0.13109813 0.13404677]
average cummulative reward is:  0.1319846773287951
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 116, nodes: 182, edges: 537
[INFO] model update: t: 929, loss: 82398.484375
[INFO] Global_t: 929, Episode_t: 1, Action: 0, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 930, loss: 136796.640625
[INFO] Global_t: 930, Episode_t: 2, Action: 8, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 931, loss: 99715.5234375
[INFO] Global_t: 931, Episode_t: 3, Action: 9, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 932, loss: 145743.765625
[INFO] Global_t: 932, Episode_t: 4, Action: 6, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 933, loss: 62901.8984375
[INFO] Global_t: 933, Episode_t: 5, Action: 18, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 934, loss: 111237.578125
[INFO] Global_t: 934, Episode_t: 6, Action: 5, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 935, loss: 295564.25
[INFO] Global_t: 935, Episode_t: 7, Action: 11, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 936, loss: 65929.5703125
[INFO] Global_t: 936, Episode_t: 8, Action: 26, Reward: 2.00, Epsilon: 0.01

[INFO] Global step: 936, Cumulative rewards: 20.42004, Runtime (s): 1743.69
------------------------------------------------------------
 
 47%|████▋     | 936/2000 [29:03<37:12,  2.10s/it]graph: 117, nodes: 196, edges: 579
[INFO] model update: t: 937, loss: 57975.0078125
[INFO] Global_t: 937, Episode_t: 1, Action: 0, Reward: 5.53, Epsilon: 0.01
[INFO] model update: t: 938, loss: 34035.6875
[INFO] Global_t: 938, Episode_t: 2, Action: 1, Reward: 5.68, Epsilon: 0.01
[INFO] model update: t: 939, loss: 41483.59375
[INFO] Global_t: 939, Episode_t: 3, Action: 8, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 940, loss: 55957.0703125
[INFO] Global_t: 940, Episode_t: 4, Action: 17, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 941, loss: 40923.3125
[INFO] Global_t: 941, Episode_t: 5, Action: 35, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 942, loss: 39662.06640625
[INFO] Global_t: 942, Episode_t: 6, Action: 4, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 943, loss: 82632.984375
[INFO] Global_t: 943, Episode_t: 7, Action: 7, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 944, loss: 245126.578125
[INFO] Global_t: 944, Episode_t: 8, Action: 6, Reward: 1.85, Epsilon: 0.01
 47%|████▋     | 944/2000 [29:08<29:07,  1.65s/it]
[INFO] Global step: 944, Cumulative rewards: 26.127719999999997, Runtime (s): 1748.65
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.022264003753662
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8881843090057373
graph: 100002, nodes: 183, edges: 540
