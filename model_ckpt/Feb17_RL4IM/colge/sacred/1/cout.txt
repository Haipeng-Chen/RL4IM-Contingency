[INFO 16:03:23] Experiments Running command 'my_main'
[INFO 16:03:23] Experiments Started run with ID "1"
[DEBUG 16:03:23] Experiments Starting Heartbeat
[DEBUG 16:03:23] my_main Started
Loading train graph:  powerlaw
train graphs in total:  200
Loading test graph:  powerlaw
merged graphs length:  205
/home/docker/app/src/agent/colge/utils/config.py:10: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  model_config = yaml.load(config_file)
  0%|          | 0/2000 [00:00<?, ?it/s]epoch:  0
graph: 0, nodes: 180, edges: 531
[INFO] Global_t: 1, Episode_t: 1, Action: 87, Reward: 1.17, Epsilon: 0.99
[INFO] Global_t: 2, Episode_t: 2, Action: 18, Reward: 2.93, Epsilon: 0.99
[INFO] Global_t: 3, Episode_t: 3, Action: 12, Reward: 3.99, Epsilon: 0.99
[INFO] Global_t: 4, Episode_t: 4, Action: 154, Reward: 1.40, Epsilon: 0.99
[INFO] Global_t: 5, Episode_t: 5, Action: 141, Reward: 1.14, Epsilon: 0.99
[INFO] Global_t: 6, Episode_t: 6, Action: 163, Reward: 1.08, Epsilon: 0.99
[INFO] Global_t: 7, Episode_t: 7, Action: 146, Reward: 1.07, Epsilon: 0.98
[INFO] Global_t: 8, Episode_t: 8, Action: 114, Reward: 1.34, Epsilon: 0.98
  0%|          | 8/2000 [00:03<16:09,  2.05it/s]
[INFO] Global step: 8, Cumulative rewards: 14.120519999999997, Runtime (s): 3.90
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] Global_t: 9, Episode_t: 1, Action: 205, Reward: 1.27, Epsilon: 0.98
[INFO] Global_t: 10, Episode_t: 2, Action: 89, Reward: 2.04, Epsilon: 0.98
[INFO] Global_t: 11, Episode_t: 3, Action: 173, Reward: 1.67, Epsilon: 0.98
[INFO] Global_t: 12, Episode_t: 4, Action: 105, Reward: 2.56, Epsilon: 0.98
[INFO] Global_t: 13, Episode_t: 5, Action: 84, Reward: 1.30, Epsilon: 0.98
[INFO] Global_t: 14, Episode_t: 6, Action: 10, Reward: 2.69, Epsilon: 0.98
[INFO] Global_t: 15, Episode_t: 7, Action: 53, Reward: 2.05, Epsilon: 0.98
[INFO] Global_t: 16, Episode_t: 8, Action: 144, Reward: 1.50, Epsilon: 0.98

[INFO] Global step: 16, Cumulative rewards: 15.079199999999997, Runtime (s): 7.29
  1%|          | 16/2000 [00:07<15:28,  2.14it/s]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.045709609985352
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.521084785461426
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9889426231384277
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.287263870239258
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.375717639923096
average cummulative reward vector is:  [0.14624053 0.14059931 0.15065874 0.13558481 0.15867957]
average cummulative reward is:  0.14635259160346586
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] Global_t: 17, Episode_t: 1, Action: 204, Reward: 1.52, Epsilon: 0.97
[INFO] Global_t: 18, Episode_t: 2, Action: 129, Reward: 2.06, Epsilon: 0.97
[INFO] Global_t: 19, Episode_t: 3, Action: 56, Reward: 2.43, Epsilon: 0.97
[INFO] Global_t: 20, Episode_t: 4, Action: 177, Reward: 1.25, Epsilon: 0.97
[INFO] Global_t: 21, Episode_t: 5, Action: 156, Reward: 1.29, Epsilon: 0.97
[INFO] Global_t: 22, Episode_t: 6, Action: 26, Reward: 2.62, Epsilon: 0.97
[INFO] Global_t: 23, Episode_t: 7, Action: 1, Reward: 6.85, Epsilon: 0.97
[INFO] Global_t: 24, Episode_t: 8, Action: 108, Reward: 1.81, Epsilon: 0.97
  1%|          | 24/2000 [00:32<41:26,  1.26s/it]
[INFO] Global step: 24, Cumulative rewards: 19.82148, Runtime (s): 32.10
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] Global_t: 25, Episode_t: 1, Action: 40, Reward: 2.20, Epsilon: 0.97
[INFO] Global_t: 26, Episode_t: 2, Action: 157, Reward: 1.54, Epsilon: 0.97
[INFO] Global_t: 27, Episode_t: 3, Action: 130, Reward: 1.91, Epsilon: 0.96
[INFO] Global_t: 28, Episode_t: 4, Action: 66, Reward: 1.87, Epsilon: 0.96
[INFO] Global_t: 29, Episode_t: 5, Action: 105, Reward: 1.49, Epsilon: 0.96
[INFO] Global_t: 30, Episode_t: 6, Action: 88, Reward: 1.39, Epsilon: 0.96
[INFO] Global_t: 31, Episode_t: 7, Action: 161, Reward: 0.85, Epsilon: 0.96
[INFO] Global_t: 32, Episode_t: 8, Action: 192, Reward: 1.21, Epsilon: 0.96
  2%|▏         | 32/2000 [00:34<31:23,  1.04it/s]
[INFO] Global step: 32, Cumulative rewards: 12.44964, Runtime (s): 34.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.035537958145142
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.418665885925293
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.066235065460205
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.405921697616577
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.992004871368408
average cummulative reward vector is:  [0.14216237 0.13327315 0.15415492 0.13756939 0.14512016]
average cummulative reward is:  0.14245599768313494
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] Global_t: 33, Episode_t: 1, Action: 151, Reward: 1.37, Epsilon: 0.96
[INFO] Global_t: 34, Episode_t: 2, Action: 83, Reward: 3.15, Epsilon: 0.96
[INFO] Global_t: 35, Episode_t: 3, Action: 16, Reward: 2.57, Epsilon: 0.96
[INFO] Global_t: 36, Episode_t: 4, Action: 14, Reward: 2.24, Epsilon: 0.96
[INFO] Global_t: 37, Episode_t: 5, Action: 26, Reward: 1.95, Epsilon: 0.95
[INFO] Global_t: 38, Episode_t: 6, Action: 147, Reward: 1.28, Epsilon: 0.95
[INFO] Global_t: 39, Episode_t: 7, Action: 146, Reward: 1.14, Epsilon: 0.95
[INFO] Global_t: 40, Episode_t: 8, Action: 11, Reward: 2.35, Epsilon: 0.95
  2%|▏         | 40/2000 [00:59<52:55,  1.62s/it]
[INFO] Global step: 40, Cumulative rewards: 16.068359999999995, Runtime (s): 59.47
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] Global_t: 41, Episode_t: 1, Action: 24, Reward: 3.21, Epsilon: 0.95
[INFO] Global_t: 42, Episode_t: 2, Action: 189, Reward: 1.34, Epsilon: 0.95
[INFO] Global_t: 43, Episode_t: 3, Action: 73, Reward: 1.90, Epsilon: 0.95
[INFO] Global_t: 44, Episode_t: 4, Action: 99, Reward: 1.88, Epsilon: 0.95
[INFO] Global_t: 45, Episode_t: 5, Action: 16, Reward: 2.88, Epsilon: 0.95
[INFO] Global_t: 46, Episode_t: 6, Action: 97, Reward: 1.96, Epsilon: 0.95
[INFO] Global_t: 47, Episode_t: 7, Action: 47, Reward: 1.82, Epsilon: 0.94
[INFO] Global_t: 48, Episode_t: 8, Action: 54, Reward: 2.04, Epsilon: 0.94

[INFO] Global step: 48, Cumulative rewards: 17.016959999999997, Runtime (s): 62.03
  2%|▏         | 48/2000 [01:02<40:00,  1.23s/it]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.362894773483276
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.614561557769775
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.890152931213379
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.527453184127808
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8717243671417236
average cummulative reward vector is:  [0.15307658 0.13803681 0.14647104 0.14159019 0.14185726]
average cummulative reward is:  0.14420637354693883
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 49, loss: 3660974592.0
[INFO] Global_t: 49, Episode_t: 1, Action: 101, Reward: 1.49, Epsilon: 0.94
[INFO] model update: t: 50, loss: 9744259481600.0
[INFO] Global_t: 50, Episode_t: 2, Action: 107, Reward: 1.92, Epsilon: 0.94
[INFO] model update: t: 51, loss: 440949538816.0
[INFO] Global_t: 51, Episode_t: 3, Action: 149, Reward: 1.44, Epsilon: 0.94
[INFO] model update: t: 52, loss: 378478067712.0
[INFO] Global_t: 52, Episode_t: 4, Action: 156, Reward: 1.56, Epsilon: 0.94
[INFO] model update: t: 53, loss: 506861486080.0
[INFO] Global_t: 53, Episode_t: 5, Action: 166, Reward: 1.52, Epsilon: 0.94
[INFO] model update: t: 54, loss: 364667338752.0
[INFO] Global_t: 54, Episode_t: 6, Action: 168, Reward: 1.50, Epsilon: 0.94
[INFO] model update: t: 55, loss: 205601308672.0
[INFO] Global_t: 55, Episode_t: 7, Action: 155, Reward: 1.19, Epsilon: 0.94
[INFO] model update: t: 56, loss: 265300672512.0
[INFO] Global_t: 56, Episode_t: 8, Action: 57, Reward: 1.41, Epsilon: 0.94
  3%|▎         | 56/2000 [01:27<58:20,  1.80s/it]
[INFO] Global step: 56, Cumulative rewards: 12.032399999999997, Runtime (s): 87.10
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 57, loss: 136477589504.0
[INFO] Global_t: 57, Episode_t: 1, Action: 173, Reward: 1.43, Epsilon: 0.94
[INFO] model update: t: 58, loss: 28204150784.0
[INFO] Global_t: 58, Episode_t: 2, Action: 134, Reward: 1.34, Epsilon: 0.93
[INFO] model update: t: 59, loss: 103571357696.0
[INFO] Global_t: 59, Episode_t: 3, Action: 117, Reward: 1.29, Epsilon: 0.93
[INFO] model update: t: 60, loss: 21422710784.0
[INFO] Global_t: 60, Episode_t: 4, Action: 38, Reward: 2.11, Epsilon: 0.93
[INFO] model update: t: 61, loss: 30647097344.0
[INFO] Global_t: 61, Episode_t: 5, Action: 71, Reward: 1.84, Epsilon: 0.93
[INFO] model update: t: 62, loss: 66009538560.0
[INFO] Global_t: 62, Episode_t: 6, Action: 30, Reward: 1.83, Epsilon: 0.93
[INFO] model update: t: 63, loss: 10653452288.0
[INFO] Global_t: 63, Episode_t: 7, Action: 106, Reward: 1.06, Epsilon: 0.93
[INFO] model update: t: 64, loss: 20958961664.0
[INFO] Global_t: 64, Episode_t: 8, Action: 84, Reward: 0.92, Epsilon: 0.93
  3%|▎         | 64/2000 [01:31<45:55,  1.42s/it]
[INFO] Global step: 64, Cumulative rewards: 11.805600000000002, Runtime (s): 91.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.728879690170288
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8187639713287354
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.0344324111938477
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.03835391998291
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.8077025413513184
average cummulative reward vector is:  [0.06397395 0.05724282 0.0800694  0.06771215 0.06890108]
average cummulative reward is:  0.06757987903022529
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 65, loss: 54786641920.0
[INFO] Global_t: 65, Episode_t: 1, Action: 56, Reward: 2.55, Epsilon: 0.93
[INFO] model update: t: 66, loss: 7110815232.0
[INFO] Global_t: 66, Episode_t: 2, Action: 100, Reward: 1.25, Epsilon: 0.93
[INFO] model update: t: 67, loss: 12192546816.0
[INFO] Global_t: 67, Episode_t: 3, Action: 181, Reward: 1.29, Epsilon: 0.93
[INFO] model update: t: 68, loss: 35694419968.0
[INFO] Global_t: 68, Episode_t: 4, Action: 98, Reward: 2.10, Epsilon: 0.92
[INFO] model update: t: 69, loss: 6570776576.0
[INFO] Global_t: 69, Episode_t: 5, Action: 11, Reward: 3.51, Epsilon: 0.92
[INFO] model update: t: 70, loss: 4326232064.0
[INFO] Global_t: 70, Episode_t: 6, Action: 43, Reward: 1.99, Epsilon: 0.92
[INFO] model update: t: 71, loss: 18694094848.0
[INFO] Global_t: 71, Episode_t: 7, Action: 37, Reward: 1.93, Epsilon: 0.92
[INFO] model update: t: 72, loss: 15981864960.0
[INFO] Global_t: 72, Episode_t: 8, Action: 81, Reward: 1.09, Epsilon: 0.92
  4%|▎         | 72/2000 [01:44<48:00,  1.49s/it]
[INFO] Global step: 72, Cumulative rewards: 15.722999999999999, Runtime (s): 104.70
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 73, loss: 935995264.0
[INFO] Global_t: 73, Episode_t: 1, Action: 51, Reward: 1.81, Epsilon: 0.92
[INFO] model update: t: 74, loss: 7603979264.0
[INFO] Global_t: 74, Episode_t: 2, Action: 144, Reward: 1.64, Epsilon: 0.92
[INFO] model update: t: 75, loss: 19840139264.0
[INFO] Global_t: 75, Episode_t: 3, Action: 8, Reward: 5.56, Epsilon: 0.92
[INFO] model update: t: 76, loss: 3292396544.0
[INFO] Global_t: 76, Episode_t: 4, Action: 44, Reward: 1.86, Epsilon: 0.92
[INFO] model update: t: 77, loss: 2535343872.0
[INFO] Global_t: 77, Episode_t: 5, Action: 41, Reward: 1.63, Epsilon: 0.92
[INFO] model update: t: 78, loss: 11251941376.0
[INFO] Global_t: 78, Episode_t: 6, Action: 35, Reward: 1.88, Epsilon: 0.91
[INFO] model update: t: 79, loss: 8260690944.0
[INFO] Global_t: 79, Episode_t: 7, Action: 28, Reward: 1.44, Epsilon: 0.91
[INFO] model update: t: 80, loss: 441409760.0
[INFO] Global_t: 80, Episode_t: 8, Action: 3, Reward: 3.71, Epsilon: 0.91
  4%|▍         | 80/2000 [01:49<39:18,  1.23s/it]
[INFO] Global step: 80, Cumulative rewards: 19.515959999999996, Runtime (s): 109.57
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.230708599090576
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.270559310913086
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.265260934829712
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2429380416870117
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2673826217651367
average cummulative reward vector is:  [0.08464579 0.07447106 0.08752896 0.07201098 0.08355699]
average cummulative reward is:  0.08044275731857119
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 81, loss: 3097888256.0
[INFO] Global_t: 81, Episode_t: 1, Action: 72, Reward: 1.26, Epsilon: 0.91
[INFO] model update: t: 82, loss: 7150654464.0
[INFO] Global_t: 82, Episode_t: 2, Action: 100, Reward: 1.50, Epsilon: 0.91
[INFO] model update: t: 83, loss: 5333709824.0
[INFO] Global_t: 83, Episode_t: 3, Action: 140, Reward: 1.23, Epsilon: 0.91
[INFO] model update: t: 84, loss: 6411788.0
[INFO] Global_t: 84, Episode_t: 4, Action: 161, Reward: 1.55, Epsilon: 0.91
[INFO] model update: t: 85, loss: 3317100544.0
[INFO] Global_t: 85, Episode_t: 5, Action: 20, Reward: 3.47, Epsilon: 0.91
[INFO] model update: t: 86, loss: 6545880064.0
[INFO] Global_t: 86, Episode_t: 6, Action: 146, Reward: 1.01, Epsilon: 0.91
[INFO] model update: t: 87, loss: 278535616.0
[INFO] Global_t: 87, Episode_t: 7, Action: 30, Reward: 1.59, Epsilon: 0.91
[INFO] model update: t: 88, loss: 5132573696.0
[INFO] Global_t: 88, Episode_t: 8, Action: 121, Reward: 1.50, Epsilon: 0.90
  4%|▍         | 88/2000 [02:04<45:13,  1.42s/it]
[INFO] Global step: 88, Cumulative rewards: 13.11672, Runtime (s): 124.49
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 89, loss: 625136896.0
[INFO] Global_t: 89, Episode_t: 1, Action: 150, Reward: 1.43, Epsilon: 0.90
[INFO] model update: t: 90, loss: 1540286720.0
[INFO] Global_t: 90, Episode_t: 2, Action: 37, Reward: 2.85, Epsilon: 0.90
[INFO] model update: t: 91, loss: 1118367616.0
[INFO] Global_t: 91, Episode_t: 3, Action: 46, Reward: 3.04, Epsilon: 0.90
[INFO] model update: t: 92, loss: 121418528.0
[INFO] Global_t: 92, Episode_t: 4, Action: 33, Reward: 3.14, Epsilon: 0.90
[INFO] model update: t: 93, loss: 305250368.0
[INFO] Global_t: 93, Episode_t: 5, Action: 48, Reward: 1.18, Epsilon: 0.90
[INFO] model update: t: 94, loss: 915219776.0
[INFO] Global_t: 94, Episode_t: 6, Action: 26, Reward: 1.13, Epsilon: 0.90
[INFO] model update: t: 95, loss: 832784128.0
[INFO] Global_t: 95, Episode_t: 7, Action: 15, Reward: 1.53, Epsilon: 0.90
[INFO] model update: t: 96, loss: 14579640.0
[INFO] Global_t: 96, Episode_t: 8, Action: 5, Reward: 4.99, Epsilon: 0.90
  5%|▍         | 96/2000 [02:10<38:14,  1.21s/it]
[INFO] Global step: 96, Cumulative rewards: 19.289279999999998, Runtime (s): 130.13
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.4719467163085938
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3162074089050293
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.308704137802124
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.436819076538086
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0516197681427
average cummulative reward vector is:  [0.08955658 0.07732106 0.0915541  0.07922547 0.07811613]
average cummulative reward is:  0.08315466768896333
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 97, loss: 490203072.0
[INFO] Global_t: 97, Episode_t: 1, Action: 93, Reward: 1.57, Epsilon: 0.90
[INFO] model update: t: 98, loss: 830499712.0
[INFO] Global_t: 98, Episode_t: 2, Action: 125, Reward: 1.90, Epsilon: 0.89
[INFO] model update: t: 99, loss: 299970624.0
[INFO] Global_t: 99, Episode_t: 3, Action: 130, Reward: 1.95, Epsilon: 0.89
[INFO] model update: t: 100, loss: 29913792.0
[INFO] Global_t: 100, Episode_t: 4, Action: 72, Reward: 1.73, Epsilon: 0.89
[INFO] model update: t: 101, loss: 454370080.0
[INFO] Global_t: 101, Episode_t: 5, Action: 33, Reward: 2.90, Epsilon: 0.89
[INFO] model update: t: 102, loss: 514702368.0
[INFO] Global_t: 102, Episode_t: 6, Action: 96, Reward: 1.97, Epsilon: 0.89
[INFO] model update: t: 103, loss: 61073344.0
[INFO] Global_t: 103, Episode_t: 7, Action: 66, Reward: 1.64, Epsilon: 0.89
[INFO] model update: t: 104, loss: 72786816.0
[INFO] Global_t: 104, Episode_t: 8, Action: 129, Reward: 1.39, Epsilon: 0.89
  5%|▌         | 104/2000 [02:25<44:45,  1.42s/it]
[INFO] Global step: 104, Cumulative rewards: 15.046199999999999, Runtime (s): 145.41
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 105, loss: 275225344.0
[INFO] Global_t: 105, Episode_t: 1, Action: 23, Reward: 2.86, Epsilon: 0.89
[INFO] model update: t: 106, loss: 232074528.0
[INFO] Global_t: 106, Episode_t: 2, Action: 26, Reward: 2.45, Epsilon: 0.89
[INFO] model update: t: 107, loss: 19587826.0
[INFO] Global_t: 107, Episode_t: 3, Action: 115, Reward: 1.51, Epsilon: 0.89
[INFO] model update: t: 108, loss: 60516592.0
[INFO] Global_t: 108, Episode_t: 4, Action: 162, Reward: 1.41, Epsilon: 0.89
[INFO] model update: t: 109, loss: 176106176.0
[INFO] Global_t: 109, Episode_t: 5, Action: 130, Reward: 1.69, Epsilon: 0.88
[INFO] model update: t: 110, loss: 162381280.0
[INFO] Global_t: 110, Episode_t: 6, Action: 140, Reward: 2.09, Epsilon: 0.88
[INFO] model update: t: 111, loss: 16211486.0
[INFO] Global_t: 111, Episode_t: 7, Action: 124, Reward: 1.31, Epsilon: 0.88
[INFO] model update: t: 112, loss: 66352732.0
[INFO] Global_t: 112, Episode_t: 8, Action: 45, Reward: 2.00, Epsilon: 0.88
  6%|▌         | 112/2000 [02:29<36:31,  1.16s/it]
[INFO] Global step: 112, Cumulative rewards: 15.3216, Runtime (s): 149.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.354600429534912
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.14640212059021
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3566064834594727
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3534977436065674
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1841609477996826
average cummulative reward vector is:  [0.08833684 0.07130671 0.08970683 0.07721285 0.08119194]
average cummulative reward is:  0.08155103432409594
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 113, loss: 171478816.0
[INFO] Global_t: 113, Episode_t: 1, Action: 93, Reward: 3.07, Epsilon: 0.88
[INFO] model update: t: 114, loss: 71059584.0
[INFO] Global_t: 114, Episode_t: 2, Action: 165, Reward: 1.00, Epsilon: 0.88
[INFO] model update: t: 115, loss: 2674718.0
[INFO] Global_t: 115, Episode_t: 3, Action: 151, Reward: 1.13, Epsilon: 0.88
[INFO] model update: t: 116, loss: 82954720.0
[INFO] Global_t: 116, Episode_t: 4, Action: 84, Reward: 1.46, Epsilon: 0.88
[INFO] model update: t: 117, loss: 102479712.0
[INFO] Global_t: 117, Episode_t: 5, Action: 10, Reward: 2.77, Epsilon: 0.88
[INFO] model update: t: 118, loss: 11708280.0
[INFO] Global_t: 118, Episode_t: 6, Action: 109, Reward: 1.58, Epsilon: 0.88
[INFO] model update: t: 119, loss: 21795940.0
[INFO] Global_t: 119, Episode_t: 7, Action: 0, Reward: 3.21, Epsilon: 0.87
[INFO] model update: t: 120, loss: 83767264.0
[INFO] Global_t: 120, Episode_t: 8, Action: 21, Reward: 1.62, Epsilon: 0.87
  6%|▌         | 120/2000 [02:45<44:06,  1.41s/it]
[INFO] Global step: 120, Cumulative rewards: 15.827879999999999, Runtime (s): 165.79
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 121, loss: 34838868.0
[INFO] Global_t: 121, Episode_t: 1, Action: 39, Reward: 2.14, Epsilon: 0.87
[INFO] model update: t: 122, loss: 2954452.0
[INFO] Global_t: 122, Episode_t: 2, Action: 151, Reward: 1.28, Epsilon: 0.87
[INFO] model update: t: 123, loss: 36722376.0
[INFO] Global_t: 123, Episode_t: 3, Action: 57, Reward: 1.83, Epsilon: 0.87
[INFO] model update: t: 124, loss: 52030096.0
[INFO] Global_t: 124, Episode_t: 4, Action: 43, Reward: 2.10, Epsilon: 0.87
[INFO] model update: t: 125, loss: 6845085.0
[INFO] Global_t: 125, Episode_t: 5, Action: 114, Reward: 1.64, Epsilon: 0.87
[INFO] model update: t: 126, loss: 14714956.0
[INFO] Global_t: 126, Episode_t: 6, Action: 89, Reward: 1.62, Epsilon: 0.87
[INFO] model update: t: 127, loss: 36453608.0
[INFO] Global_t: 127, Episode_t: 7, Action: 87, Reward: 1.75, Epsilon: 0.87
[INFO] model update: t: 128, loss: 13133099.0
[INFO] Global_t: 128, Episode_t: 8, Action: 119, Reward: 1.08, Epsilon: 0.87
  6%|▋         | 128/2000 [02:49<34:50,  1.12s/it]
[INFO] Global step: 128, Cumulative rewards: 13.45092, Runtime (s): 169.29
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.5005886554718018
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.214578866958618
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2187657356262207
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3937385082244873
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.259129047393799
average cummulative reward vector is:  [0.09261974 0.0691713  0.08461995 0.07749766 0.08621183]
average cummulative reward is:  0.08202409400039679
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 129, loss: 1991969.625
[INFO] Global_t: 129, Episode_t: 1, Action: 63, Reward: 1.35, Epsilon: 0.86
[INFO] model update: t: 130, loss: 21417264.0
[INFO] Global_t: 130, Episode_t: 2, Action: 47, Reward: 2.52, Epsilon: 0.86
[INFO] model update: t: 131, loss: 16383356.0
[INFO] Global_t: 131, Episode_t: 3, Action: 31, Reward: 1.91, Epsilon: 0.86
[INFO] model update: t: 132, loss: 1100555.25
[INFO] Global_t: 132, Episode_t: 4, Action: 149, Reward: 2.41, Epsilon: 0.86
[INFO] model update: t: 133, loss: 10597196.0
[INFO] Global_t: 133, Episode_t: 5, Action: 21, Reward: 3.03, Epsilon: 0.86
[INFO] model update: t: 134, loss: 11904709.0
[INFO] Global_t: 134, Episode_t: 6, Action: 15, Reward: 2.78, Epsilon: 0.86
[INFO] model update: t: 135, loss: 4804531.0
[INFO] Global_t: 135, Episode_t: 7, Action: 58, Reward: 1.89, Epsilon: 0.86
[INFO] model update: t: 136, loss: 1823920.25
[INFO] Global_t: 136, Episode_t: 8, Action: 46, Reward: 1.47, Epsilon: 0.86
  7%|▋         | 136/2000 [03:05<42:41,  1.37s/it]
[INFO] Global step: 136, Cumulative rewards: 17.35356, Runtime (s): 185.09
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 137, loss: 10069355.0
[INFO] Global_t: 137, Episode_t: 1, Action: 2, Reward: 3.29, Epsilon: 0.86
[INFO] model update: t: 138, loss: 8482610.0
[INFO] Global_t: 138, Episode_t: 2, Action: 57, Reward: 2.66, Epsilon: 0.86
[INFO] model update: t: 139, loss: 480729.1875
[INFO] Global_t: 139, Episode_t: 3, Action: 59, Reward: 2.04, Epsilon: 0.85
[INFO] model update: t: 140, loss: 7422971.5
[INFO] Global_t: 140, Episode_t: 4, Action: 15, Reward: 3.82, Epsilon: 0.85
[INFO] model update: t: 141, loss: 6690082.5
[INFO] Global_t: 141, Episode_t: 5, Action: 171, Reward: 1.16, Epsilon: 0.85
[INFO] model update: t: 142, loss: 108809.5703125
[INFO] Global_t: 142, Episode_t: 6, Action: 9, Reward: 2.44, Epsilon: 0.85
[INFO] model update: t: 143, loss: 3747752.5
[INFO] Global_t: 143, Episode_t: 7, Action: 80, Reward: 1.44, Epsilon: 0.85
[INFO] model update: t: 144, loss: 4592104.0
[INFO] Global_t: 144, Episode_t: 8, Action: 160, Reward: 1.06, Epsilon: 0.85
  7%|▋         | 144/2000 [03:09<34:18,  1.11s/it]
[INFO] Global step: 144, Cumulative rewards: 17.90352, Runtime (s): 189.01
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.3011603355407715
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.29765248298645
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.254728317260742
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.347118616104126
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3913700580596924
average cummulative reward vector is:  [0.08366132 0.07355949 0.08661421 0.07553808 0.08814274]
average cummulative reward is:  0.08150316804562421
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 145, loss: 1685765.25
[INFO] Global_t: 145, Episode_t: 1, Action: 43, Reward: 2.31, Epsilon: 0.85
[INFO] model update: t: 146, loss: 1547436.75
[INFO] Global_t: 146, Episode_t: 2, Action: 93, Reward: 1.45, Epsilon: 0.85
[INFO] model update: t: 147, loss: 4540246.0
[INFO] Global_t: 147, Episode_t: 3, Action: 13, Reward: 3.86, Epsilon: 0.85
[INFO] model update: t: 148, loss: 2625008.0
[INFO] Global_t: 148, Episode_t: 4, Action: 78, Reward: 1.68, Epsilon: 0.85
[INFO] model update: t: 149, loss: 179838.09375
[INFO] Global_t: 149, Episode_t: 5, Action: 1, Reward: 3.30, Epsilon: 0.84
[INFO] model update: t: 150, loss: 3174813.25
[INFO] Global_t: 150, Episode_t: 6, Action: 41, Reward: 2.14, Epsilon: 0.84
[INFO] model update: t: 151, loss: 2044143.0
[INFO] Global_t: 151, Episode_t: 7, Action: 104, Reward: 1.83, Epsilon: 0.84
[INFO] model update: t: 152, loss: 91390.5546875
[INFO] Global_t: 152, Episode_t: 8, Action: 174, Reward: 1.75, Epsilon: 0.84
  8%|▊         | 152/2000 [03:26<44:16,  1.44s/it]
[INFO] Global step: 152, Cumulative rewards: 18.31992, Runtime (s): 206.64
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 153, loss: 2316774.0
[INFO] Global_t: 153, Episode_t: 1, Action: 52, Reward: 1.77, Epsilon: 0.84
[INFO] model update: t: 154, loss: 1643780.0
[INFO] Global_t: 154, Episode_t: 2, Action: 135, Reward: 1.22, Epsilon: 0.84
[INFO] model update: t: 155, loss: 264885.8125
[INFO] Global_t: 155, Episode_t: 3, Action: 115, Reward: 1.17, Epsilon: 0.84
[INFO] model update: t: 156, loss: 1150471.125
[INFO] Global_t: 156, Episode_t: 4, Action: 5, Reward: 2.72, Epsilon: 0.84
[INFO] model update: t: 157, loss: 1437556.5
[INFO] Global_t: 157, Episode_t: 5, Action: 101, Reward: 1.32, Epsilon: 0.84
[INFO] model update: t: 158, loss: 412556.5
[INFO] Global_t: 158, Episode_t: 6, Action: 154, Reward: 1.27, Epsilon: 0.84
[INFO] model update: t: 159, loss: 451657.34375
[INFO] Global_t: 159, Episode_t: 7, Action: 184, Reward: 1.45, Epsilon: 0.84
[INFO] model update: t: 160, loss: 1057710.875
[INFO] Global_t: 160, Episode_t: 8, Action: 191, Reward: 1.56, Epsilon: 0.83
  8%|▊         | 160/2000 [03:30<35:01,  1.14s/it]
[INFO] Global step: 160, Cumulative rewards: 12.486479999999998, Runtime (s): 210.27
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.22591233253479
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2763187885284424
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1813809871673584
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4227421283721924
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.434215784072876
average cummulative reward vector is:  [0.08346105 0.07376644 0.08307049 0.07801028 0.091225  ]
average cummulative reward is:  0.08190665199877492
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 161, loss: 122150.40625
[INFO] Global_t: 161, Episode_t: 1, Action: 22, Reward: 4.31, Epsilon: 0.83
[INFO] model update: t: 162, loss: 279955.84375
[INFO] Global_t: 162, Episode_t: 2, Action: 95, Reward: 2.04, Epsilon: 0.83
[INFO] model update: t: 163, loss: 1388505.5
[INFO] Global_t: 163, Episode_t: 3, Action: 124, Reward: 1.78, Epsilon: 0.83
[INFO] model update: t: 164, loss: 57682.1484375
[INFO] Global_t: 164, Episode_t: 4, Action: 139, Reward: 1.06, Epsilon: 0.83
[INFO] model update: t: 165, loss: 409546.625
[INFO] Global_t: 165, Episode_t: 5, Action: 183, Reward: 0.89, Epsilon: 0.83
[INFO] model update: t: 166, loss: 759672.75
[INFO] Global_t: 166, Episode_t: 6, Action: 2, Reward: 5.16, Epsilon: 0.83
[INFO] model update: t: 167, loss: 266043.5625
[INFO] Global_t: 167, Episode_t: 7, Action: 184, Reward: 1.24, Epsilon: 0.83
[INFO] model update: t: 168, loss: 707917.0
[INFO] Global_t: 168, Episode_t: 8, Action: 112, Reward: 0.66, Epsilon: 0.83
  8%|▊         | 168/2000 [03:47<44:41,  1.46s/it]
[INFO] Global step: 168, Cumulative rewards: 17.141280000000005, Runtime (s): 227.98
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 169, loss: 854594.75
[INFO] Global_t: 169, Episode_t: 1, Action: 122, Reward: 1.40, Epsilon: 0.83
[INFO] model update: t: 170, loss: 88349.109375
[INFO] Global_t: 170, Episode_t: 2, Action: 170, Reward: 1.27, Epsilon: 0.82
[INFO] model update: t: 171, loss: 429348.6875
[INFO] Global_t: 171, Episode_t: 3, Action: 148, Reward: 1.97, Epsilon: 0.82
[INFO] model update: t: 172, loss: 454827.65625
[INFO] Global_t: 172, Episode_t: 4, Action: 105, Reward: 1.55, Epsilon: 0.82
[INFO] model update: t: 173, loss: 126468.34375
[INFO] Global_t: 173, Episode_t: 5, Action: 31, Reward: 1.75, Epsilon: 0.82
[INFO] model update: t: 174, loss: 549198.75
[INFO] Global_t: 174, Episode_t: 6, Action: 41, Reward: 1.87, Epsilon: 0.82
[INFO] model update: t: 175, loss: 566488.5
[INFO] Global_t: 175, Episode_t: 7, Action: 156, Reward: 1.79, Epsilon: 0.82
[INFO] model update: t: 176, loss: 198559.53125
[INFO] Global_t: 176, Episode_t: 8, Action: 112, Reward: 1.16, Epsilon: 0.82
  9%|▉         | 176/2000 [03:51<35:04,  1.15s/it]
[INFO] Global step: 176, Cumulative rewards: 12.75948, Runtime (s): 231.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.440189838409424
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.49194073677063
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.298551559448242
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.5105061531066895
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4007227420806885
average cummulative reward vector is:  [0.09021263 0.08176759 0.09056503 0.08361612 0.09352177]
average cummulative reward is:  0.08793662943656397
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 177, loss: 236700.5
[INFO] Global_t: 177, Episode_t: 1, Action: 17, Reward: 3.49, Epsilon: 0.82
[INFO] model update: t: 178, loss: 229783.78125
[INFO] Global_t: 178, Episode_t: 2, Action: 151, Reward: 2.07, Epsilon: 0.82
[INFO] model update: t: 179, loss: 64767.3125
[INFO] Global_t: 179, Episode_t: 3, Action: 47, Reward: 2.23, Epsilon: 0.82
[INFO] model update: t: 180, loss: 106291.0859375
[INFO] Global_t: 180, Episode_t: 4, Action: 146, Reward: 1.26, Epsilon: 0.81
[INFO] model update: t: 181, loss: 110245.28125
[INFO] Global_t: 181, Episode_t: 5, Action: 22, Reward: 2.04, Epsilon: 0.81
[INFO] model update: t: 182, loss: 283419.4375
[INFO] Global_t: 182, Episode_t: 6, Action: 149, Reward: 1.67, Epsilon: 0.81
[INFO] model update: t: 183, loss: 220893.390625
[INFO] Global_t: 183, Episode_t: 7, Action: 42, Reward: 2.79, Epsilon: 0.81
[INFO] model update: t: 184, loss: 127712.015625
[INFO] Global_t: 184, Episode_t: 8, Action: 182, Reward: 1.82, Epsilon: 0.81
  9%|▉         | 184/2000 [04:06<41:47,  1.38s/it]
[INFO] Global step: 184, Cumulative rewards: 17.3754, Runtime (s): 246.71
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 185, loss: 56856.34765625
[INFO] Global_t: 185, Episode_t: 1, Action: 38, Reward: 3.44, Epsilon: 0.81
[INFO] model update: t: 186, loss: 348250.1875
[INFO] Global_t: 186, Episode_t: 2, Action: 119, Reward: 2.17, Epsilon: 0.81
[INFO] model update: t: 187, loss: 90880.21875
[INFO] Global_t: 187, Episode_t: 3, Action: 169, Reward: 2.06, Epsilon: 0.81
[INFO] model update: t: 188, loss: 71210.171875
[INFO] Global_t: 188, Episode_t: 4, Action: 90, Reward: 1.49, Epsilon: 0.81
[INFO] model update: t: 189, loss: 35070.84375
[INFO] Global_t: 189, Episode_t: 5, Action: 24, Reward: 2.36, Epsilon: 0.81
[INFO] model update: t: 190, loss: 195917.5625
[INFO] Global_t: 190, Episode_t: 6, Action: 43, Reward: 1.49, Epsilon: 0.80
[INFO] model update: t: 191, loss: 29502.51953125
[INFO] Global_t: 191, Episode_t: 7, Action: 81, Reward: 1.59, Epsilon: 0.80
[INFO] model update: t: 192, loss: 54043.46875
[INFO] Global_t: 192, Episode_t: 8, Action: 113, Reward: 1.13, Epsilon: 0.80
 10%|▉         | 192/2000 [04:11<34:25,  1.14s/it]
[INFO] Global step: 192, Cumulative rewards: 15.7266, Runtime (s): 251.40
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.3250391483306885
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.4609649181365967
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.524142026901245
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.411564350128174
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2378039360046387
average cummulative reward vector is:  [0.08583605 0.07558218 0.09626639 0.07761075 0.08521505]
average cummulative reward is:  0.08410208468542402
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 193, loss: 103126.1875
[INFO] Global_t: 193, Episode_t: 1, Action: 47, Reward: 2.08, Epsilon: 0.80
[INFO] model update: t: 194, loss: 259870.015625
[INFO] Global_t: 194, Episode_t: 2, Action: 72, Reward: 1.87, Epsilon: 0.80
[INFO] model update: t: 195, loss: 282480.71875
[INFO] Global_t: 195, Episode_t: 3, Action: 143, Reward: 1.12, Epsilon: 0.80
[INFO] model update: t: 196, loss: 337215.40625
[INFO] Global_t: 196, Episode_t: 4, Action: 30, Reward: 2.32, Epsilon: 0.80
[INFO] model update: t: 197, loss: 87719.3125
[INFO] Global_t: 197, Episode_t: 5, Action: 46, Reward: 2.23, Epsilon: 0.80
[INFO] model update: t: 198, loss: 337780.34375
[INFO] Global_t: 198, Episode_t: 6, Action: 35, Reward: 1.80, Epsilon: 0.80
[INFO] model update: t: 199, loss: 90299.2421875
[INFO] Global_t: 199, Episode_t: 7, Action: 146, Reward: 1.01, Epsilon: 0.80
[INFO] model update: t: 200, loss: 260348.203125
[INFO] Global_t: 200, Episode_t: 8, Action: 24, Reward: 2.29, Epsilon: 0.79
 10%|█         | 200/2000 [04:27<41:46,  1.39s/it]
[INFO] Global step: 200, Cumulative rewards: 14.720759999999999, Runtime (s): 267.20
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 201, loss: 166678.265625
[INFO] Global_t: 201, Episode_t: 1, Action: 161, Reward: 1.33, Epsilon: 0.79
[INFO] model update: t: 202, loss: 218901.40625
[INFO] Global_t: 202, Episode_t: 2, Action: 112, Reward: 1.98, Epsilon: 0.79
[INFO] model update: t: 203, loss: 306597.03125
[INFO] Global_t: 203, Episode_t: 3, Action: 147, Reward: 1.54, Epsilon: 0.79
[INFO] model update: t: 204, loss: 96342.53125
[INFO] Global_t: 204, Episode_t: 4, Action: 7, Reward: 4.69, Epsilon: 0.79
[INFO] model update: t: 205, loss: 455850.4375
[INFO] Global_t: 205, Episode_t: 5, Action: 14, Reward: 4.52, Epsilon: 0.79
[INFO] model update: t: 206, loss: 192526.859375
[INFO] Global_t: 206, Episode_t: 6, Action: 37, Reward: 1.62, Epsilon: 0.79
[INFO] model update: t: 207, loss: 156575.34375
[INFO] Global_t: 207, Episode_t: 7, Action: 179, Reward: 1.89, Epsilon: 0.79
[INFO] model update: t: 208, loss: 187621.25
[INFO] Global_t: 208, Episode_t: 8, Action: 168, Reward: 1.60, Epsilon: 0.79
 10%|█         | 208/2000 [04:30<32:35,  1.09s/it]
[INFO] Global step: 208, Cumulative rewards: 19.16412, Runtime (s): 270.32
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.3018012046813965
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1981568336486816
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.160093069076538
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.30452299118042
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4200305938720703
average cummulative reward vector is:  [0.08226316 0.07292269 0.08520601 0.07531145 0.08826398]
average cummulative reward is:  0.08079345622032766
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 209, loss: 111320.8125
[INFO] Global_t: 209, Episode_t: 1, Action: 53, Reward: 2.06, Epsilon: 0.79
[INFO] model update: t: 210, loss: 332176.5
[INFO] Global_t: 210, Episode_t: 2, Action: 128, Reward: 1.12, Epsilon: 0.79
[INFO] model update: t: 211, loss: 152468.0625
[INFO] Global_t: 211, Episode_t: 3, Action: 42, Reward: 1.92, Epsilon: 0.78
[INFO] model update: t: 212, loss: 300934.59375
[INFO] Global_t: 212, Episode_t: 4, Action: 153, Reward: 1.09, Epsilon: 0.78
[INFO] model update: t: 213, loss: 181698.46875
[INFO] Global_t: 213, Episode_t: 5, Action: 70, Reward: 2.43, Epsilon: 0.78
[INFO] model update: t: 214, loss: 262143.734375
[INFO] Global_t: 214, Episode_t: 6, Action: 130, Reward: 1.33, Epsilon: 0.78
[INFO] model update: t: 215, loss: 474493.375
[INFO] Global_t: 215, Episode_t: 7, Action: 173, Reward: 1.21, Epsilon: 0.78
[INFO] model update: t: 216, loss: 71433.8046875
[INFO] Global_t: 216, Episode_t: 8, Action: 119, Reward: 1.83, Epsilon: 0.78
 11%|█         | 216/2000 [04:50<44:53,  1.51s/it]
[INFO] Global step: 216, Cumulative rewards: 12.99048, Runtime (s): 290.21
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 217, loss: 128255.0390625
[INFO] Global_t: 217, Episode_t: 1, Action: 132, Reward: 1.57, Epsilon: 0.78
[INFO] model update: t: 218, loss: 20605.640625
[INFO] Global_t: 218, Episode_t: 2, Action: 32, Reward: 2.11, Epsilon: 0.78
[INFO] model update: t: 219, loss: 105347.9921875
[INFO] Global_t: 219, Episode_t: 3, Action: 142, Reward: 1.45, Epsilon: 0.78
[INFO] model update: t: 220, loss: 305048.3125
[INFO] Global_t: 220, Episode_t: 4, Action: 68, Reward: 1.66, Epsilon: 0.78
[INFO] model update: t: 221, loss: 105626.59375
[INFO] Global_t: 221, Episode_t: 5, Action: 159, Reward: 1.11, Epsilon: 0.77
[INFO] model update: t: 222, loss: 223463.96875
[INFO] Global_t: 222, Episode_t: 6, Action: 69, Reward: 1.79, Epsilon: 0.77
[INFO] model update: t: 223, loss: 150841.46875
[INFO] Global_t: 223, Episode_t: 7, Action: 66, Reward: 1.54, Epsilon: 0.77
[INFO] model update: t: 224, loss: 87369.53125
[INFO] Global_t: 224, Episode_t: 8, Action: 40, Reward: 3.11, Epsilon: 0.77
 11%|█         | 224/2000 [04:53<34:44,  1.17s/it]
[INFO] Global step: 224, Cumulative rewards: 14.34084, Runtime (s): 293.32
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.12542986869812
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.217628002166748
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.4557223320007324
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3613648414611816
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.264878511428833
average cummulative reward vector is:  [0.08002263 0.07312685 0.09759153 0.07416822 0.08668441]
average cummulative reward is:  0.082318729277332
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 225, loss: 278146.1875
[INFO] Global_t: 225, Episode_t: 1, Action: 38, Reward: 2.62, Epsilon: 0.77
[INFO] model update: t: 226, loss: 237194.75
[INFO] Global_t: 226, Episode_t: 2, Action: 9, Reward: 2.51, Epsilon: 0.77
[INFO] model update: t: 227, loss: 235041.0625
[INFO] Global_t: 227, Episode_t: 3, Action: 173, Reward: 1.32, Epsilon: 0.77
[INFO] model update: t: 228, loss: 177745.125
[INFO] Global_t: 228, Episode_t: 4, Action: 75, Reward: 1.65, Epsilon: 0.77
[INFO] model update: t: 229, loss: 72662.71875
[INFO] Global_t: 229, Episode_t: 5, Action: 71, Reward: 2.32, Epsilon: 0.77
[INFO] model update: t: 230, loss: 268022.65625
[INFO] Global_t: 230, Episode_t: 6, Action: 167, Reward: 1.22, Epsilon: 0.77
[INFO] model update: t: 231, loss: 156083.484375
[INFO] Global_t: 231, Episode_t: 7, Action: 141, Reward: 1.37, Epsilon: 0.76
[INFO] model update: t: 232, loss: 225449.125
[INFO] Global_t: 232, Episode_t: 8, Action: 60, Reward: 1.84, Epsilon: 0.76
 12%|█▏        | 232/2000 [05:08<41:06,  1.40s/it]
[INFO] Global step: 232, Cumulative rewards: 14.836680000000001, Runtime (s): 308.61
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 233, loss: 146274.34375
[INFO] Global_t: 233, Episode_t: 1, Action: 186, Reward: 2.76, Epsilon: 0.76
[INFO] model update: t: 234, loss: 39667.921875
[INFO] Global_t: 234, Episode_t: 2, Action: 21, Reward: 3.37, Epsilon: 0.76
[INFO] model update: t: 235, loss: 123616.703125
[INFO] Global_t: 235, Episode_t: 3, Action: 42, Reward: 1.70, Epsilon: 0.76
[INFO] model update: t: 236, loss: 46029.8125
[INFO] Global_t: 236, Episode_t: 4, Action: 78, Reward: 1.13, Epsilon: 0.76
[INFO] model update: t: 237, loss: 57172.078125
[INFO] Global_t: 237, Episode_t: 5, Action: 56, Reward: 2.07, Epsilon: 0.76
[INFO] model update: t: 238, loss: 100319.2421875
[INFO] Global_t: 238, Episode_t: 6, Action: 85, Reward: 1.76, Epsilon: 0.76
[INFO] model update: t: 239, loss: 172358.6875
[INFO] Global_t: 239, Episode_t: 7, Action: 173, Reward: 1.19, Epsilon: 0.76
[INFO] model update: t: 240, loss: 14366.724609375
[INFO] Global_t: 240, Episode_t: 8, Action: 161, Reward: 1.76, Epsilon: 0.76
 12%|█▏        | 240/2000 [05:13<34:34,  1.18s/it]
[INFO] Global step: 240, Cumulative rewards: 15.735359999999998, Runtime (s): 314.00
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2510979175567627
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.452514886856079
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.237112283706665
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.350292921066284
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3445613384246826
average cummulative reward vector is:  [0.07507789 0.07438333 0.08471421 0.07357897 0.09126613]
average cummulative reward is:  0.0798041073430647
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 241, loss: 117438.21875
[INFO] Global_t: 241, Episode_t: 1, Action: 117, Reward: 2.26, Epsilon: 0.75
[INFO] model update: t: 242, loss: 108486.328125
[INFO] Global_t: 242, Episode_t: 2, Action: 75, Reward: 2.21, Epsilon: 0.75
[INFO] model update: t: 243, loss: 494633.6875
[INFO] Global_t: 243, Episode_t: 3, Action: 187, Reward: 1.11, Epsilon: 0.75
[INFO] model update: t: 244, loss: 216371.0
[INFO] Global_t: 244, Episode_t: 4, Action: 127, Reward: 0.94, Epsilon: 0.75
[INFO] model update: t: 245, loss: 225051.203125
[INFO] Global_t: 245, Episode_t: 5, Action: 82, Reward: 1.82, Epsilon: 0.75
[INFO] model update: t: 246, loss: 62426.828125
[INFO] Global_t: 246, Episode_t: 6, Action: 105, Reward: 1.82, Epsilon: 0.75
[INFO] model update: t: 247, loss: 241785.25
[INFO] Global_t: 247, Episode_t: 7, Action: 40, Reward: 2.00, Epsilon: 0.75
[INFO] model update: t: 248, loss: 81686.53125
[INFO] Global_t: 248, Episode_t: 8, Action: 57, Reward: 1.54, Epsilon: 0.75
 12%|█▏        | 248/2000 [05:29<41:18,  1.41s/it]
[INFO] Global step: 248, Cumulative rewards: 13.70004, Runtime (s): 329.72
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 249, loss: 77584.9765625
[INFO] Global_t: 249, Episode_t: 1, Action: 137, Reward: 1.50, Epsilon: 0.75
[INFO] model update: t: 250, loss: 9938.498046875
[INFO] Global_t: 250, Episode_t: 2, Action: 99, Reward: 2.42, Epsilon: 0.75
[INFO] model update: t: 251, loss: 148684.28125
[INFO] Global_t: 251, Episode_t: 3, Action: 2, Reward: 6.32, Epsilon: 0.74
[INFO] model update: t: 252, loss: 200950.4375
[INFO] Global_t: 252, Episode_t: 4, Action: 191, Reward: 1.04, Epsilon: 0.74
[INFO] model update: t: 253, loss: 115943.5
[INFO] Global_t: 253, Episode_t: 5, Action: 143, Reward: 0.88, Epsilon: 0.74
[INFO] model update: t: 254, loss: 273199.75
[INFO] Global_t: 254, Episode_t: 6, Action: 167, Reward: 1.30, Epsilon: 0.74
[INFO] model update: t: 255, loss: 104768.28125
[INFO] Global_t: 255, Episode_t: 7, Action: 124, Reward: 0.95, Epsilon: 0.74
[INFO] model update: t: 256, loss: 244970.59375
[INFO] Global_t: 256, Episode_t: 8, Action: 72, Reward: 1.31, Epsilon: 0.74
 13%|█▎        | 256/2000 [05:34<34:22,  1.18s/it]
[INFO] Global step: 256, Cumulative rewards: 15.72144, Runtime (s): 334.85
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.18705415725708
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3735625743865967
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.4602110385894775
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.345409631729126
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.171358823776245
average cummulative reward vector is:  [0.08159184 0.07638981 0.08843852 0.07398084 0.08290914]
average cummulative reward is:  0.0806620324833367
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 257, loss: 167100.4375
[INFO] Global_t: 257, Episode_t: 1, Action: 131, Reward: 1.42, Epsilon: 0.74
[INFO] model update: t: 258, loss: 195940.609375
[INFO] Global_t: 258, Episode_t: 2, Action: 126, Reward: 2.33, Epsilon: 0.74
[INFO] model update: t: 259, loss: 333566.9375
[INFO] Global_t: 259, Episode_t: 3, Action: 111, Reward: 2.08, Epsilon: 0.74
[INFO] model update: t: 260, loss: 209046.828125
[INFO] Global_t: 260, Episode_t: 4, Action: 0, Reward: 5.37, Epsilon: 0.74
[INFO] model update: t: 261, loss: 306037.3125
[INFO] Global_t: 261, Episode_t: 5, Action: 3, Reward: 4.22, Epsilon: 0.74
[INFO] model update: t: 262, loss: 490105.78125
[INFO] Global_t: 262, Episode_t: 6, Action: 103, Reward: 1.34, Epsilon: 0.73
[INFO] model update: t: 263, loss: 72197.8125
[INFO] Global_t: 263, Episode_t: 7, Action: 60, Reward: 1.70, Epsilon: 0.73
[INFO] model update: t: 264, loss: 454542.8125
[INFO] Global_t: 264, Episode_t: 8, Action: 189, Reward: 1.39, Epsilon: 0.73
 13%|█▎        | 264/2000 [05:52<42:37,  1.47s/it]
[INFO] Global step: 264, Cumulative rewards: 19.846680000000003, Runtime (s): 352.06
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 265, loss: 273946.125
[INFO] Global_t: 265, Episode_t: 1, Action: 59, Reward: 2.45, Epsilon: 0.73
[INFO] model update: t: 266, loss: 151451.796875
[INFO] Global_t: 266, Episode_t: 2, Action: 179, Reward: 1.29, Epsilon: 0.73
[INFO] model update: t: 267, loss: 460253.1875
[INFO] Global_t: 267, Episode_t: 3, Action: 28, Reward: 3.16, Epsilon: 0.73
[INFO] model update: t: 268, loss: 54460.4609375
[INFO] Global_t: 268, Episode_t: 4, Action: 117, Reward: 1.47, Epsilon: 0.73
[INFO] model update: t: 269, loss: 279116.71875
[INFO] Global_t: 269, Episode_t: 5, Action: 130, Reward: 1.54, Epsilon: 0.73
[INFO] model update: t: 270, loss: 198762.4375
[INFO] Global_t: 270, Episode_t: 6, Action: 27, Reward: 1.89, Epsilon: 0.73
[INFO] model update: t: 271, loss: 61852.80859375
[INFO] Global_t: 271, Episode_t: 7, Action: 183, Reward: 1.38, Epsilon: 0.73
[INFO] model update: t: 272, loss: 216267.53125
[INFO] Global_t: 272, Episode_t: 8, Action: 134, Reward: 1.29, Epsilon: 0.72
 14%|█▎        | 272/2000 [05:56<34:43,  1.21s/it]
[INFO] Global step: 272, Cumulative rewards: 14.470799999999999, Runtime (s): 356.71
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.20882248878479
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.0603890419006348
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.388850450515747
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2318115234375
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.211261034011841
average cummulative reward vector is:  [0.08299921 0.06655718 0.0885224  0.07379463 0.0849793 ]
average cummulative reward is:  0.0793705436134639
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 273, loss: 48175.05078125
[INFO] Global_t: 273, Episode_t: 1, Action: 105, Reward: 2.38, Epsilon: 0.72
[INFO] model update: t: 274, loss: 12546.4736328125
[INFO] Global_t: 274, Episode_t: 2, Action: 52, Reward: 2.15, Epsilon: 0.72
[INFO] model update: t: 275, loss: 97544.546875
[INFO] Global_t: 275, Episode_t: 3, Action: 189, Reward: 1.14, Epsilon: 0.72
[INFO] model update: t: 276, loss: 243886.875
[INFO] Global_t: 276, Episode_t: 4, Action: 57, Reward: 2.03, Epsilon: 0.72
[INFO] model update: t: 277, loss: 146121.125
[INFO] Global_t: 277, Episode_t: 5, Action: 46, Reward: 2.24, Epsilon: 0.72
[INFO] model update: t: 278, loss: 251311.046875
[INFO] Global_t: 278, Episode_t: 6, Action: 2, Reward: 3.74, Epsilon: 0.72
[INFO] model update: t: 279, loss: 294493.0625
[INFO] Global_t: 279, Episode_t: 7, Action: 125, Reward: 1.08, Epsilon: 0.72
[INFO] model update: t: 280, loss: 184544.71875
[INFO] Global_t: 280, Episode_t: 8, Action: 116, Reward: 1.78, Epsilon: 0.72
 14%|█▍        | 280/2000 [06:11<39:42,  1.38s/it]
[INFO] Global step: 280, Cumulative rewards: 16.5408, Runtime (s): 371.14
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 281, loss: 176070.71875
[INFO] Global_t: 281, Episode_t: 1, Action: 6, Reward: 3.46, Epsilon: 0.72
[INFO] model update: t: 282, loss: 216685.984375
[INFO] Global_t: 282, Episode_t: 2, Action: 89, Reward: 1.88, Epsilon: 0.71
[INFO] model update: t: 283, loss: 157808.84375
[INFO] Global_t: 283, Episode_t: 3, Action: 132, Reward: 1.48, Epsilon: 0.71
[INFO] model update: t: 284, loss: 300104.46875
[INFO] Global_t: 284, Episode_t: 4, Action: 0, Reward: 4.72, Epsilon: 0.71
[INFO] model update: t: 285, loss: 51880.8125
[INFO] Global_t: 285, Episode_t: 5, Action: 125, Reward: 1.21, Epsilon: 0.71
[INFO] model update: t: 286, loss: 199696.53125
[INFO] Global_t: 286, Episode_t: 6, Action: 46, Reward: 1.00, Epsilon: 0.71
[INFO] model update: t: 287, loss: 311598.875
[INFO] Global_t: 287, Episode_t: 7, Action: 1, Reward: 3.28, Epsilon: 0.71
[INFO] model update: t: 288, loss: 237454.09375
[INFO] Global_t: 288, Episode_t: 8, Action: 56, Reward: 1.16, Epsilon: 0.71
 14%|█▍        | 288/2000 [06:18<35:06,  1.23s/it]
[INFO] Global step: 288, Cumulative rewards: 18.198960000000003, Runtime (s): 378.10
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.024331569671631
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.5591607093811035
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1998403072357178
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2032899856567383
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2825419902801514
average cummulative reward vector is:  [0.07502132 0.0789625  0.08535847 0.06915047 0.08541317]
average cummulative reward is:  0.07878118501351186
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 289, loss: 241538.40625
[INFO] Global_t: 289, Episode_t: 1, Action: 54, Reward: 2.35, Epsilon: 0.71
[INFO] model update: t: 290, loss: 356571.5
[INFO] Global_t: 290, Episode_t: 2, Action: 107, Reward: 1.69, Epsilon: 0.71
[INFO] model update: t: 291, loss: 273105.625
[INFO] Global_t: 291, Episode_t: 3, Action: 108, Reward: 1.18, Epsilon: 0.71
[INFO] model update: t: 292, loss: 378918.75
[INFO] Global_t: 292, Episode_t: 4, Action: 22, Reward: 1.98, Epsilon: 0.70
[INFO] model update: t: 293, loss: 229441.3125
[INFO] Global_t: 293, Episode_t: 5, Action: 144, Reward: 1.67, Epsilon: 0.70
[INFO] model update: t: 294, loss: 219335.0
[INFO] Global_t: 294, Episode_t: 6, Action: 91, Reward: 1.12, Epsilon: 0.70
[INFO] model update: t: 295, loss: 137696.140625
[INFO] Global_t: 295, Episode_t: 7, Action: 92, Reward: 1.23, Epsilon: 0.70
[INFO] model update: t: 296, loss: 483923.6875
[INFO] Global_t: 296, Episode_t: 8, Action: 111, Reward: 1.49, Epsilon: 0.70
 15%|█▍        | 296/2000 [06:33<40:34,  1.43s/it]
[INFO] Global step: 296, Cumulative rewards: 12.70668, Runtime (s): 393.22
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 297, loss: 141049.734375
[INFO] Global_t: 297, Episode_t: 1, Action: 120, Reward: 1.91, Epsilon: 0.70
[INFO] model update: t: 298, loss: 316964.1875
[INFO] Global_t: 298, Episode_t: 2, Action: 51, Reward: 1.83, Epsilon: 0.70
[INFO] model update: t: 299, loss: 181741.78125
[INFO] Global_t: 299, Episode_t: 3, Action: 109, Reward: 2.42, Epsilon: 0.70
[INFO] model update: t: 300, loss: 155838.78125
[INFO] Global_t: 300, Episode_t: 4, Action: 169, Reward: 1.53, Epsilon: 0.70
[INFO] model update: t: 301, loss: 147070.796875
[INFO] Global_t: 301, Episode_t: 5, Action: 143, Reward: 1.75, Epsilon: 0.70
[INFO] model update: t: 302, loss: 164542.59375
[INFO] Global_t: 302, Episode_t: 6, Action: 194, Reward: 1.06, Epsilon: 0.70
[INFO] model update: t: 303, loss: 221120.21875
[INFO] Global_t: 303, Episode_t: 7, Action: 25, Reward: 1.65, Epsilon: 0.69
[INFO] model update: t: 304, loss: 205147.140625
[INFO] Global_t: 304, Episode_t: 8, Action: 28, Reward: 2.43, Epsilon: 0.69
 15%|█▌        | 304/2000 [06:36<31:53,  1.13s/it]
[INFO] Global step: 304, Cumulative rewards: 14.58372, Runtime (s): 396.64
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.154157876968384
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.41192364692688
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3665072917938232
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.437778949737549
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4456496238708496
average cummulative reward vector is:  [0.08007289 0.07739977 0.08412131 0.07921238 0.0933    ]
average cummulative reward is:  0.08282127158166812
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 305, loss: 95401.3984375
[INFO] Global_t: 305, Episode_t: 1, Action: 185, Reward: 1.75, Epsilon: 0.69
[INFO] model update: t: 306, loss: 165836.734375
[INFO] Global_t: 306, Episode_t: 2, Action: 201, Reward: 1.05, Epsilon: 0.69
[INFO] model update: t: 307, loss: 196802.84375
[INFO] Global_t: 307, Episode_t: 3, Action: 10, Reward: 2.89, Epsilon: 0.69
[INFO] model update: t: 308, loss: 136781.703125
[INFO] Global_t: 308, Episode_t: 4, Action: 37, Reward: 2.36, Epsilon: 0.69
[INFO] model update: t: 309, loss: 294016.375
[INFO] Global_t: 309, Episode_t: 5, Action: 66, Reward: 1.97, Epsilon: 0.69
[INFO] model update: t: 310, loss: 203169.765625
[INFO] Global_t: 310, Episode_t: 6, Action: 180, Reward: 1.63, Epsilon: 0.69
[INFO] model update: t: 311, loss: 84651.9375
[INFO] Global_t: 311, Episode_t: 7, Action: 163, Reward: 1.31, Epsilon: 0.69
[INFO] model update: t: 312, loss: 331188.125
[INFO] Global_t: 312, Episode_t: 8, Action: 151, Reward: 1.30, Epsilon: 0.69
 16%|█▌        | 312/2000 [06:52<38:48,  1.38s/it]
[INFO] Global step: 312, Cumulative rewards: 14.2722, Runtime (s): 412.37
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 313, loss: 148435.734375
[INFO] Global_t: 313, Episode_t: 1, Action: 44, Reward: 2.24, Epsilon: 0.68
[INFO] model update: t: 314, loss: 454475.6875
[INFO] Global_t: 314, Episode_t: 2, Action: 177, Reward: 1.74, Epsilon: 0.68
[INFO] model update: t: 315, loss: 275377.34375
[INFO] Global_t: 315, Episode_t: 3, Action: 117, Reward: 1.71, Epsilon: 0.68
[INFO] model update: t: 316, loss: 78762.9765625
[INFO] Global_t: 316, Episode_t: 4, Action: 112, Reward: 1.29, Epsilon: 0.68
[INFO] model update: t: 317, loss: 403817.25
[INFO] Global_t: 317, Episode_t: 5, Action: 106, Reward: 2.05, Epsilon: 0.68
[INFO] model update: t: 318, loss: 82325.703125
[INFO] Global_t: 318, Episode_t: 6, Action: 95, Reward: 1.99, Epsilon: 0.68
[INFO] model update: t: 319, loss: 301741.78125
[INFO] Global_t: 319, Episode_t: 7, Action: 19, Reward: 1.72, Epsilon: 0.68
[INFO] model update: t: 320, loss: 237015.953125
[INFO] Global_t: 320, Episode_t: 8, Action: 7, Reward: 3.21, Epsilon: 0.68
 16%|█▌        | 320/2000 [06:56<30:56,  1.11s/it]
[INFO] Global step: 320, Cumulative rewards: 15.95244, Runtime (s): 416.09
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0421016216278076
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2301061153411865
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.015099287033081
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3913118839263916
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2394275665283203
average cummulative reward vector is:  [0.07526263 0.07357454 0.07880956 0.07707664 0.08417231]
average cummulative reward is:  0.07777913575989803
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 321, loss: 98610.7578125
[INFO] Global_t: 321, Episode_t: 1, Action: 35, Reward: 2.11, Epsilon: 0.68
[INFO] model update: t: 322, loss: 170506.375
[INFO] Global_t: 322, Episode_t: 2, Action: 159, Reward: 1.25, Epsilon: 0.68
[INFO] model update: t: 323, loss: 99885.0625
[INFO] Global_t: 323, Episode_t: 3, Action: 26, Reward: 1.97, Epsilon: 0.67
[INFO] model update: t: 324, loss: 335836.21875
[INFO] Global_t: 324, Episode_t: 4, Action: 54, Reward: 2.41, Epsilon: 0.67
[INFO] model update: t: 325, loss: 84747.8828125
[INFO] Global_t: 325, Episode_t: 5, Action: 33, Reward: 2.15, Epsilon: 0.67
[INFO] model update: t: 326, loss: 209276.90625
[INFO] Global_t: 326, Episode_t: 6, Action: 111, Reward: 1.45, Epsilon: 0.67
[INFO] model update: t: 327, loss: 73009.359375
[INFO] Global_t: 327, Episode_t: 7, Action: 174, Reward: 1.77, Epsilon: 0.67
[INFO] model update: t: 328, loss: 234336.109375
[INFO] Global_t: 328, Episode_t: 8, Action: 55, Reward: 1.70, Epsilon: 0.67
 16%|█▋        | 328/2000 [07:09<35:43,  1.28s/it]
[INFO] Global step: 328, Cumulative rewards: 14.812319999999998, Runtime (s): 429.64
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 329, loss: 54487.15625
[INFO] Global_t: 329, Episode_t: 1, Action: 141, Reward: 2.19, Epsilon: 0.67
[INFO] model update: t: 330, loss: 150069.703125
[INFO] Global_t: 330, Episode_t: 2, Action: 94, Reward: 1.52, Epsilon: 0.67
[INFO] model update: t: 331, loss: 112357.515625
[INFO] Global_t: 331, Episode_t: 3, Action: 45, Reward: 1.94, Epsilon: 0.67
[INFO] model update: t: 332, loss: 201267.65625
[INFO] Global_t: 332, Episode_t: 4, Action: 31, Reward: 2.59, Epsilon: 0.67
[INFO] model update: t: 333, loss: 29152.2265625
[INFO] Global_t: 333, Episode_t: 5, Action: 14, Reward: 2.38, Epsilon: 0.66
[INFO] model update: t: 334, loss: 174356.78125
[INFO] Global_t: 334, Episode_t: 6, Action: 20, Reward: 1.68, Epsilon: 0.66
[INFO] model update: t: 335, loss: 237935.84375
[INFO] Global_t: 335, Episode_t: 7, Action: 66, Reward: 1.33, Epsilon: 0.66
[INFO] model update: t: 336, loss: 56275.03125
[INFO] Global_t: 336, Episode_t: 8, Action: 107, Reward: 1.45, Epsilon: 0.66
 17%|█▋        | 336/2000 [07:14<29:28,  1.06s/it]
[INFO] Global step: 336, Cumulative rewards: 15.071279999999998, Runtime (s): 434.06
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9983410835266113
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2085065841674805
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1192574501037598
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.124448537826538
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.493861675262451
average cummulative reward vector is:  [0.07171526 0.07089537 0.08018825 0.06779743 0.0873621 ]
average cummulative reward is:  0.0755916823150242
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 337, loss: 167180.109375
[INFO] Global_t: 337, Episode_t: 1, Action: 90, Reward: 2.03, Epsilon: 0.66
[INFO] model update: t: 338, loss: 93022.1875
[INFO] Global_t: 338, Episode_t: 2, Action: 88, Reward: 1.85, Epsilon: 0.66
[INFO] model update: t: 339, loss: 70239.484375
[INFO] Global_t: 339, Episode_t: 3, Action: 164, Reward: 2.23, Epsilon: 0.66
[INFO] model update: t: 340, loss: 179740.53125
[INFO] Global_t: 340, Episode_t: 4, Action: 102, Reward: 1.40, Epsilon: 0.66
[INFO] model update: t: 341, loss: 98634.34375
[INFO] Global_t: 341, Episode_t: 5, Action: 113, Reward: 2.46, Epsilon: 0.66
[INFO] model update: t: 342, loss: 194192.109375
[INFO] Global_t: 342, Episode_t: 6, Action: 185, Reward: 2.23, Epsilon: 0.66
[INFO] model update: t: 343, loss: 195482.828125
[INFO] Global_t: 343, Episode_t: 7, Action: 148, Reward: 1.21, Epsilon: 0.65
[INFO] model update: t: 344, loss: 180909.328125
[INFO] Global_t: 344, Episode_t: 8, Action: 141, Reward: 2.01, Epsilon: 0.65
 17%|█▋        | 344/2000 [07:28<34:59,  1.27s/it]
[INFO] Global step: 344, Cumulative rewards: 15.419639999999998, Runtime (s): 448.03
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 345, loss: 120678.5859375
[INFO] Global_t: 345, Episode_t: 1, Action: 74, Reward: 2.09, Epsilon: 0.65
[INFO] model update: t: 346, loss: 104706.46875
[INFO] Global_t: 346, Episode_t: 2, Action: 116, Reward: 1.81, Epsilon: 0.65
[INFO] model update: t: 347, loss: 268036.6875
[INFO] Global_t: 347, Episode_t: 3, Action: 73, Reward: 1.44, Epsilon: 0.65
[INFO] model update: t: 348, loss: 183320.9375
[INFO] Global_t: 348, Episode_t: 4, Action: 8, Reward: 4.39, Epsilon: 0.65
[INFO] model update: t: 349, loss: 140400.46875
[INFO] Global_t: 349, Episode_t: 5, Action: 66, Reward: 1.88, Epsilon: 0.65
[INFO] model update: t: 350, loss: 178855.09375
[INFO] Global_t: 350, Episode_t: 6, Action: 124, Reward: 0.91, Epsilon: 0.65
[INFO] model update: t: 351, loss: 262443.3125
[INFO] Global_t: 351, Episode_t: 7, Action: 18, Reward: 2.37, Epsilon: 0.65
[INFO] model update: t: 352, loss: 128143.8359375
[INFO] Global_t: 352, Episode_t: 8, Action: 56, Reward: 1.54, Epsilon: 0.65
 18%|█▊        | 352/2000 [07:31<28:26,  1.04s/it]
[INFO] Global step: 352, Cumulative rewards: 16.44384, Runtime (s): 451.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2721662521362305
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9640636444091797
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1668219566345215
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2806806564331055
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2064249515533447
average cummulative reward vector is:  [0.08243447 0.0637831  0.08491038 0.07426846 0.08407823]
average cummulative reward is:  0.0778949283600201
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 353, loss: 95019.3984375
[INFO] Global_t: 353, Episode_t: 1, Action: 194, Reward: 1.65, Epsilon: 0.65
[INFO] model update: t: 354, loss: 253404.96875
[INFO] Global_t: 354, Episode_t: 2, Action: 160, Reward: 1.38, Epsilon: 0.64
[INFO] model update: t: 355, loss: 47523.01171875
[INFO] Global_t: 355, Episode_t: 3, Action: 73, Reward: 1.80, Epsilon: 0.64
[INFO] model update: t: 356, loss: 48841.4375
[INFO] Global_t: 356, Episode_t: 4, Action: 22, Reward: 2.22, Epsilon: 0.64
[INFO] model update: t: 357, loss: 230647.671875
[INFO] Global_t: 357, Episode_t: 5, Action: 189, Reward: 2.22, Epsilon: 0.64
[INFO] model update: t: 358, loss: 140767.625
[INFO] Global_t: 358, Episode_t: 6, Action: 193, Reward: 0.99, Epsilon: 0.64
[INFO] model update: t: 359, loss: 172065.5
[INFO] Global_t: 359, Episode_t: 7, Action: 170, Reward: 1.35, Epsilon: 0.64
[INFO] model update: t: 360, loss: 281989.625
[INFO] Global_t: 360, Episode_t: 8, Action: 30, Reward: 2.00, Epsilon: 0.64
 18%|█▊        | 360/2000 [07:47<35:57,  1.32s/it]
[INFO] Global step: 360, Cumulative rewards: 13.608360000000001, Runtime (s): 467.72
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 361, loss: 113221.0234375
[INFO] Global_t: 361, Episode_t: 1, Action: 34, Reward: 2.67, Epsilon: 0.64
[INFO] model update: t: 362, loss: 72209.9296875
[INFO] Global_t: 362, Episode_t: 2, Action: 180, Reward: 1.96, Epsilon: 0.64
[INFO] model update: t: 363, loss: 234041.375
[INFO] Global_t: 363, Episode_t: 3, Action: 184, Reward: 1.48, Epsilon: 0.64
[INFO] model update: t: 364, loss: 68520.7421875
[INFO] Global_t: 364, Episode_t: 4, Action: 123, Reward: 1.71, Epsilon: 0.63
[INFO] model update: t: 365, loss: 116810.3125
[INFO] Global_t: 365, Episode_t: 5, Action: 69, Reward: 1.26, Epsilon: 0.63
[INFO] model update: t: 366, loss: 40737.015625
[INFO] Global_t: 366, Episode_t: 6, Action: 155, Reward: 1.01, Epsilon: 0.63
[INFO] model update: t: 367, loss: 21784.068359375
[INFO] Global_t: 367, Episode_t: 7, Action: 19, Reward: 2.55, Epsilon: 0.63
[INFO] model update: t: 368, loss: 220094.234375
[INFO] Global_t: 368, Episode_t: 8, Action: 129, Reward: 1.24, Epsilon: 0.63
 18%|█▊        | 368/2000 [07:55<33:05,  1.22s/it]
[INFO] Global step: 368, Cumulative rewards: 13.88016, Runtime (s): 475.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1861469745635986
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3537070751190186
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.0992298126220703
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.431415557861328
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.125192642211914
average cummulative reward vector is:  [0.07892605 0.07767917 0.0806735  0.07533995 0.08203011]
average cummulative reward is:  0.078929755472783
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 369, loss: 260100.5625
[INFO] Global_t: 369, Episode_t: 1, Action: 97, Reward: 2.38, Epsilon: 0.63
[INFO] model update: t: 370, loss: 435992.28125
[INFO] Global_t: 370, Episode_t: 2, Action: 77, Reward: 1.47, Epsilon: 0.63
[INFO] model update: t: 371, loss: 68022.546875
[INFO] Global_t: 371, Episode_t: 3, Action: 180, Reward: 2.45, Epsilon: 0.63
[INFO] model update: t: 372, loss: 502135.4375
[INFO] Global_t: 372, Episode_t: 4, Action: 9, Reward: 3.91, Epsilon: 0.63
[INFO] model update: t: 373, loss: 212405.734375
[INFO] Global_t: 373, Episode_t: 5, Action: 83, Reward: 1.32, Epsilon: 0.63
[INFO] model update: t: 374, loss: 740933.75
[INFO] Global_t: 374, Episode_t: 6, Action: 15, Reward: 1.46, Epsilon: 0.62
[INFO] model update: t: 375, loss: 212197.6875
[INFO] Global_t: 375, Episode_t: 7, Action: 162, Reward: 1.32, Epsilon: 0.62
[INFO] model update: t: 376, loss: 275481.71875
[INFO] Global_t: 376, Episode_t: 8, Action: 120, Reward: 1.05, Epsilon: 0.62
 19%|█▉        | 376/2000 [08:12<39:46,  1.47s/it]
[INFO] Global step: 376, Cumulative rewards: 15.35244, Runtime (s): 492.09
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 377, loss: 296693.625
[INFO] Global_t: 377, Episode_t: 1, Action: 81, Reward: 2.35, Epsilon: 0.62
[INFO] model update: t: 378, loss: 86159.296875
[INFO] Global_t: 378, Episode_t: 2, Action: 181, Reward: 1.17, Epsilon: 0.62
[INFO] model update: t: 379, loss: 473939.71875
[INFO] Global_t: 379, Episode_t: 3, Action: 166, Reward: 1.22, Epsilon: 0.62
[INFO] model update: t: 380, loss: 124308.8671875
[INFO] Global_t: 380, Episode_t: 4, Action: 79, Reward: 1.51, Epsilon: 0.62
[INFO] model update: t: 381, loss: 367917.78125
[INFO] Global_t: 381, Episode_t: 5, Action: 106, Reward: 1.77, Epsilon: 0.62
[INFO] model update: t: 382, loss: 148097.28125
[INFO] Global_t: 382, Episode_t: 6, Action: 174, Reward: 1.97, Epsilon: 0.62
[INFO] model update: t: 383, loss: 168600.921875
[INFO] Global_t: 383, Episode_t: 7, Action: 44, Reward: 1.13, Epsilon: 0.62
[INFO] model update: t: 384, loss: 272311.21875
[INFO] Global_t: 384, Episode_t: 8, Action: 154, Reward: 0.82, Epsilon: 0.61
 19%|█▉        | 384/2000 [08:15<30:48,  1.14s/it]
[INFO] Global step: 384, Cumulative rewards: 11.932920000000001, Runtime (s): 495.17
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.306413173675537
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.488417625427246
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.138486385345459
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2684946060180664
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2598915100097656
average cummulative reward vector is:  [0.08445763 0.08012708 0.08329754 0.07395047 0.08233172]
average cummulative reward is:  0.08083288872314287
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 385, loss: 99242.140625
[INFO] Global_t: 385, Episode_t: 1, Action: 115, Reward: 1.81, Epsilon: 0.61
[INFO] model update: t: 386, loss: 339216.21875
[INFO] Global_t: 386, Episode_t: 2, Action: 148, Reward: 1.25, Epsilon: 0.61
[INFO] model update: t: 387, loss: 214811.234375
[INFO] Global_t: 387, Episode_t: 3, Action: 77, Reward: 1.64, Epsilon: 0.61
[INFO] model update: t: 388, loss: 415677.0
[INFO] Global_t: 388, Episode_t: 4, Action: 149, Reward: 1.16, Epsilon: 0.61
[INFO] model update: t: 389, loss: 62809.15625
[INFO] Global_t: 389, Episode_t: 5, Action: 170, Reward: 1.31, Epsilon: 0.61
[INFO] model update: t: 390, loss: 131504.046875
[INFO] Global_t: 390, Episode_t: 6, Action: 56, Reward: 1.13, Epsilon: 0.61
[INFO] model update: t: 391, loss: 230431.65625
[INFO] Global_t: 391, Episode_t: 7, Action: 133, Reward: 1.52, Epsilon: 0.61
[INFO] model update: t: 392, loss: 174036.671875
[INFO] Global_t: 392, Episode_t: 8, Action: 35, Reward: 2.08, Epsilon: 0.61

[INFO] Global step: 392, Cumulative rewards: 11.90004, Runtime (s): 509.74
 20%|█▉        | 392/2000 [08:29<36:06,  1.35s/it]------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 393, loss: 110033.734375
[INFO] Global_t: 393, Episode_t: 1, Action: 211, Reward: 1.32, Epsilon: 0.61
[INFO] model update: t: 394, loss: 86016.9921875
[INFO] Global_t: 394, Episode_t: 2, Action: 78, Reward: 2.12, Epsilon: 0.60
[INFO] model update: t: 395, loss: 52629.4375
[INFO] Global_t: 395, Episode_t: 3, Action: 155, Reward: 2.16, Epsilon: 0.60
[INFO] model update: t: 396, loss: 48089.4296875
[INFO] Global_t: 396, Episode_t: 4, Action: 163, Reward: 1.82, Epsilon: 0.60
[INFO] model update: t: 397, loss: 121305.3828125
[INFO] Global_t: 397, Episode_t: 5, Action: 141, Reward: 1.43, Epsilon: 0.60
[INFO] model update: t: 398, loss: 63717.84765625
[INFO] Global_t: 398, Episode_t: 6, Action: 47, Reward: 1.58, Epsilon: 0.60
[INFO] model update: t: 399, loss: 109869.328125
[INFO] Global_t: 399, Episode_t: 7, Action: 196, Reward: 1.89, Epsilon: 0.60
[INFO] model update: t: 400, loss: 182787.21875
[INFO] Global_t: 400, Episode_t: 8, Action: 134, Reward: 1.57, Epsilon: 0.60
 20%|██        | 400/2000 [08:33<28:45,  1.08s/it]
[INFO] Global step: 400, Cumulative rewards: 13.886519999999997, Runtime (s): 513.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.254518747329712
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.459352493286133
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.437950611114502
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1152069568634033
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1651806831359863
average cummulative reward vector is:  [0.07888079 0.08171736 0.09271257 0.06996145 0.08228038]
average cummulative reward is:  0.08111050876660461
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 401, loss: 216057.5
[INFO] Global_t: 401, Episode_t: 1, Action: 6, Reward: 2.61, Epsilon: 0.60
[INFO] model update: t: 402, loss: 102413.640625
[INFO] Global_t: 402, Episode_t: 2, Action: 77, Reward: 1.47, Epsilon: 0.60
[INFO] model update: t: 403, loss: 122768.890625
[INFO] Global_t: 403, Episode_t: 3, Action: 182, Reward: 1.27, Epsilon: 0.60
[INFO] model update: t: 404, loss: 91653.3359375
[INFO] Global_t: 404, Episode_t: 4, Action: 129, Reward: 2.09, Epsilon: 0.60
[INFO] model update: t: 405, loss: 122142.671875
[INFO] Global_t: 405, Episode_t: 5, Action: 162, Reward: 1.85, Epsilon: 0.59
[INFO] model update: t: 406, loss: 123950.4453125
[INFO] Global_t: 406, Episode_t: 6, Action: 132, Reward: 1.72, Epsilon: 0.59
[INFO] model update: t: 407, loss: 66247.7265625
[INFO] Global_t: 407, Episode_t: 7, Action: 126, Reward: 1.53, Epsilon: 0.59
[INFO] model update: t: 408, loss: 102229.9921875
[INFO] Global_t: 408, Episode_t: 8, Action: 100, Reward: 1.45, Epsilon: 0.59
 20%|██        | 408/2000 [08:48<35:05,  1.32s/it]
[INFO] Global step: 408, Cumulative rewards: 13.9914, Runtime (s): 528.48
------------------------------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 409, loss: 95640.8828125
[INFO] Global_t: 409, Episode_t: 1, Action: 131, Reward: 2.42, Epsilon: 0.59
[INFO] model update: t: 410, loss: 97519.71875
[INFO] Global_t: 410, Episode_t: 2, Action: 136, Reward: 2.07, Epsilon: 0.59
[INFO] model update: t: 411, loss: 271379.53125
[INFO] Global_t: 411, Episode_t: 3, Action: 55, Reward: 1.81, Epsilon: 0.59
[INFO] model update: t: 412, loss: 247626.71875
[INFO] Global_t: 412, Episode_t: 4, Action: 15, Reward: 2.42, Epsilon: 0.59
[INFO] model update: t: 413, loss: 144155.71875
[INFO] Global_t: 413, Episode_t: 5, Action: 92, Reward: 1.56, Epsilon: 0.59
[INFO] model update: t: 414, loss: 67204.8203125
[INFO] Global_t: 414, Episode_t: 6, Action: 165, Reward: 1.37, Epsilon: 0.59
[INFO] model update: t: 415, loss: 176521.0
[INFO] Global_t: 415, Episode_t: 7, Action: 31, Reward: 1.70, Epsilon: 0.58
[INFO] model update: t: 416, loss: 163446.3125
[INFO] Global_t: 416, Episode_t: 8, Action: 168, Reward: 1.34, Epsilon: 0.58
 21%|██        | 416/2000 [08:52<28:19,  1.07s/it]
[INFO] Global step: 416, Cumulative rewards: 14.699160000000001, Runtime (s): 532.41
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2983222007751465
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.222196340560913
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.235215425491333
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1762216091156006
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.116264820098877
average cummulative reward vector is:  [0.08831763 0.06831829 0.08690355 0.07038458 0.07892392]
average cummulative reward is:  0.07856959493979758
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 417, loss: 108556.1796875
[INFO] Global_t: 417, Episode_t: 1, Action: 78, Reward: 2.74, Epsilon: 0.58
[INFO] model update: t: 418, loss: 156510.984375
[INFO] Global_t: 418, Episode_t: 2, Action: 206, Reward: 1.50, Epsilon: 0.58
[INFO] model update: t: 419, loss: 176556.875
[INFO] Global_t: 419, Episode_t: 3, Action: 118, Reward: 2.41, Epsilon: 0.58
[INFO] model update: t: 420, loss: 57218.51171875
[INFO] Global_t: 420, Episode_t: 4, Action: 108, Reward: 2.32, Epsilon: 0.58
[INFO] model update: t: 421, loss: 90190.203125
[INFO] Global_t: 421, Episode_t: 5, Action: 132, Reward: 1.63, Epsilon: 0.58
[INFO] model update: t: 422, loss: 203679.8125
[INFO] Global_t: 422, Episode_t: 6, Action: 154, Reward: 1.63, Epsilon: 0.58
[INFO] model update: t: 423, loss: 241858.09375
[INFO] Global_t: 423, Episode_t: 7, Action: 101, Reward: 2.23, Epsilon: 0.58
[INFO] model update: t: 424, loss: 106915.84375
[INFO] Global_t: 424, Episode_t: 8, Action: 131, Reward: 1.84, Epsilon: 0.58

[INFO] Global step: 424, Cumulative rewards: 16.29432, Runtime (s): 546.20
------------------------------------------------------------
 
 21%|██        | 424/2000 [09:06<33:18,  1.27s/it]graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 425, loss: 143270.8125
[INFO] Global_t: 425, Episode_t: 1, Action: 23, Reward: 2.38, Epsilon: 0.57
[INFO] model update: t: 426, loss: 100690.1875
[INFO] Global_t: 426, Episode_t: 2, Action: 40, Reward: 1.51, Epsilon: 0.57
[INFO] model update: t: 427, loss: 224725.65625
[INFO] Global_t: 427, Episode_t: 3, Action: 160, Reward: 1.97, Epsilon: 0.57
[INFO] model update: t: 428, loss: 52527.4296875
[INFO] Global_t: 428, Episode_t: 4, Action: 80, Reward: 1.78, Epsilon: 0.57
[INFO] model update: t: 429, loss: 251277.75
[INFO] Global_t: 429, Episode_t: 5, Action: 68, Reward: 1.98, Epsilon: 0.57
[INFO] model update: t: 430, loss: 108725.359375
[INFO] Global_t: 430, Episode_t: 6, Action: 12, Reward: 3.28, Epsilon: 0.57
[INFO] model update: t: 431, loss: 145866.65625
[INFO] Global_t: 431, Episode_t: 7, Action: 147, Reward: 2.01, Epsilon: 0.57
[INFO] model update: t: 432, loss: 184402.078125
[INFO] Global_t: 432, Episode_t: 8, Action: 142, Reward: 1.75, Epsilon: 0.57
 22%|██▏       | 432/2000 [09:09<26:38,  1.02s/it]
[INFO] Global step: 432, Cumulative rewards: 16.64436, Runtime (s): 549.72
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0755422115325928
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2307796478271484
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.15571665763855
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0177462100982666
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.158250331878662
average cummulative reward vector is:  [0.07729158 0.07284745 0.07700137 0.0675264  0.08221667]
average cummulative reward is:  0.07537669346142326
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 433, loss: 137718.765625
[INFO] Global_t: 433, Episode_t: 1, Action: 164, Reward: 2.31, Epsilon: 0.57
[INFO] model update: t: 434, loss: 186396.859375
[INFO] Global_t: 434, Episode_t: 2, Action: 177, Reward: 1.98, Epsilon: 0.57
[INFO] model update: t: 435, loss: 83091.40625
[INFO] Global_t: 435, Episode_t: 3, Action: 80, Reward: 2.07, Epsilon: 0.56
[INFO] model update: t: 436, loss: 50861.96875
[INFO] Global_t: 436, Episode_t: 4, Action: 33, Reward: 1.90, Epsilon: 0.56
[INFO] model update: t: 437, loss: 51279.5078125
[INFO] Global_t: 437, Episode_t: 5, Action: 132, Reward: 1.12, Epsilon: 0.56
[INFO] model update: t: 438, loss: 95839.53125
[INFO] Global_t: 438, Episode_t: 6, Action: 84, Reward: 1.46, Epsilon: 0.56
[INFO] model update: t: 439, loss: 77984.546875
[INFO] Global_t: 439, Episode_t: 7, Action: 32, Reward: 2.32, Epsilon: 0.56
[INFO] model update: t: 440, loss: 158515.640625
[INFO] Global_t: 440, Episode_t: 8, Action: 74, Reward: 1.66, Epsilon: 0.56
 22%|██▏       | 440/2000 [09:25<33:30,  1.29s/it]
[INFO] Global step: 440, Cumulative rewards: 14.83548, Runtime (s): 565.05
------------------------------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 441, loss: 169144.328125
[INFO] Global_t: 441, Episode_t: 1, Action: 150, Reward: 1.38, Epsilon: 0.56
[INFO] model update: t: 442, loss: 51419.1875
[INFO] Global_t: 442, Episode_t: 2, Action: 183, Reward: 1.89, Epsilon: 0.56
[INFO] model update: t: 443, loss: 114350.59375
[INFO] Global_t: 443, Episode_t: 3, Action: 61, Reward: 1.73, Epsilon: 0.56
[INFO] model update: t: 444, loss: 114382.2421875
[INFO] Global_t: 444, Episode_t: 4, Action: 156, Reward: 2.09, Epsilon: 0.56
[INFO] model update: t: 445, loss: 185546.671875
[INFO] Global_t: 445, Episode_t: 5, Action: 15, Reward: 2.15, Epsilon: 0.55
[INFO] model update: t: 446, loss: 85721.21875
[INFO] Global_t: 446, Episode_t: 6, Action: 28, Reward: 2.08, Epsilon: 0.55
[INFO] model update: t: 447, loss: 156434.46875
[INFO] Global_t: 447, Episode_t: 7, Action: 159, Reward: 1.94, Epsilon: 0.55
[INFO] model update: t: 448, loss: 139500.640625
[INFO] Global_t: 448, Episode_t: 8, Action: 81, Reward: 1.98, Epsilon: 0.55
 22%|██▏       | 448/2000 [09:27<25:58,  1.00s/it]
[INFO] Global step: 448, Cumulative rewards: 15.23964, Runtime (s): 567.78
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1646852493286133
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1831343173980713
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1980173587799072
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1820690631866455
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3778693675994873
average cummulative reward vector is:  [0.07971368 0.06905972 0.08376393 0.06963785 0.08768925]
average cummulative reward is:  0.07797288772761915
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 449, loss: 235576.875
[INFO] Global_t: 449, Episode_t: 1, Action: 150, Reward: 1.81, Epsilon: 0.55
[INFO] model update: t: 450, loss: 77934.8984375
[INFO] Global_t: 450, Episode_t: 2, Action: 39, Reward: 2.06, Epsilon: 0.55
[INFO] model update: t: 451, loss: 203080.03125
[INFO] Global_t: 451, Episode_t: 3, Action: 144, Reward: 1.64, Epsilon: 0.55
[INFO] model update: t: 452, loss: 169526.625
[INFO] Global_t: 452, Episode_t: 4, Action: 80, Reward: 1.55, Epsilon: 0.55
[INFO] model update: t: 453, loss: 162079.671875
[INFO] Global_t: 453, Episode_t: 5, Action: 110, Reward: 1.02, Epsilon: 0.55
[INFO] model update: t: 454, loss: 100698.9453125
[INFO] Global_t: 454, Episode_t: 6, Action: 116, Reward: 1.33, Epsilon: 0.55
[INFO] model update: t: 455, loss: 143511.78125
[INFO] Global_t: 455, Episode_t: 7, Action: 197, Reward: 0.96, Epsilon: 0.55
[INFO] model update: t: 456, loss: 65386.33203125
[INFO] Global_t: 456, Episode_t: 8, Action: 160, Reward: 0.87, Epsilon: 0.54

[INFO] Global step: 456, Cumulative rewards: 11.236800000000002, Runtime (s): 582.43
 23%|██▎       | 456/2000 [09:42<32:13,  1.25s/it]------------------------------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 457, loss: 120414.421875
[INFO] Global_t: 457, Episode_t: 1, Action: 146, Reward: 2.45, Epsilon: 0.54
[INFO] model update: t: 458, loss: 64572.703125
[INFO] Global_t: 458, Episode_t: 2, Action: 182, Reward: 1.69, Epsilon: 0.54
[INFO] model update: t: 459, loss: 98800.9765625
[INFO] Global_t: 459, Episode_t: 3, Action: 99, Reward: 1.77, Epsilon: 0.54
[INFO] model update: t: 460, loss: 169789.75
[INFO] Global_t: 460, Episode_t: 4, Action: 66, Reward: 1.63, Epsilon: 0.54
[INFO] model update: t: 461, loss: 24514.74609375
[INFO] Global_t: 461, Episode_t: 5, Action: 83, Reward: 1.58, Epsilon: 0.54
[INFO] model update: t: 462, loss: 130873.25
[INFO] Global_t: 462, Episode_t: 6, Action: 133, Reward: 1.82, Epsilon: 0.54
[INFO] model update: t: 463, loss: 19251.765625
[INFO] Global_t: 463, Episode_t: 7, Action: 95, Reward: 1.83, Epsilon: 0.54
[INFO] model update: t: 464, loss: 32145.955078125
[INFO] Global_t: 464, Episode_t: 8, Action: 15, Reward: 1.72, Epsilon: 0.54
 23%|██▎       | 464/2000 [09:45<25:03,  1.02it/s]
[INFO] Global step: 464, Cumulative rewards: 14.483160000000002, Runtime (s): 585.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2180373668670654
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.477038860321045
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.143672466278076
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.143101930618286
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.430820941925049
average cummulative reward vector is:  [0.08032211 0.0816419  0.0829153  0.06908364 0.08381667]
average cummulative reward is:  0.07955592309684675
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 465, loss: 31136.5546875
[INFO] Global_t: 465, Episode_t: 1, Action: 76, Reward: 1.47, Epsilon: 0.54
[INFO] model update: t: 466, loss: 15134.23046875
[INFO] Global_t: 466, Episode_t: 2, Action: 213, Reward: 2.18, Epsilon: 0.53
[INFO] model update: t: 467, loss: 163120.328125
[INFO] Global_t: 467, Episode_t: 3, Action: 198, Reward: 1.63, Epsilon: 0.53
[INFO] model update: t: 468, loss: 175990.03125
[INFO] Global_t: 468, Episode_t: 4, Action: 129, Reward: 1.97, Epsilon: 0.53
[INFO] model update: t: 469, loss: 78562.171875
[INFO] Global_t: 469, Episode_t: 5, Action: 26, Reward: 2.28, Epsilon: 0.53
[INFO] model update: t: 470, loss: 58825.25
[INFO] Global_t: 470, Episode_t: 6, Action: 56, Reward: 2.14, Epsilon: 0.53
[INFO] model update: t: 471, loss: 217369.671875
[INFO] Global_t: 471, Episode_t: 7, Action: 74, Reward: 2.71, Epsilon: 0.53
[INFO] model update: t: 472, loss: 43382.34375
[INFO] Global_t: 472, Episode_t: 8, Action: 96, Reward: 1.20, Epsilon: 0.53

[INFO] Global step: 472, Cumulative rewards: 15.588119999999996, Runtime (s): 601.28
------------------------------------------------------------
 
 24%|██▎       | 472/2000 [10:01<32:50,  1.29s/it]graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 473, loss: 158340.390625
[INFO] Global_t: 473, Episode_t: 1, Action: 120, Reward: 2.33, Epsilon: 0.53
[INFO] model update: t: 474, loss: 50750.3359375
[INFO] Global_t: 474, Episode_t: 2, Action: 125, Reward: 1.77, Epsilon: 0.53
[INFO] model update: t: 475, loss: 102178.984375
[INFO] Global_t: 475, Episode_t: 3, Action: 60, Reward: 1.78, Epsilon: 0.53
[INFO] model update: t: 476, loss: 105899.4921875
[INFO] Global_t: 476, Episode_t: 4, Action: 35, Reward: 1.78, Epsilon: 0.52
[INFO] model update: t: 477, loss: 104077.859375
[INFO] Global_t: 477, Episode_t: 5, Action: 41, Reward: 1.54, Epsilon: 0.52
[INFO] model update: t: 478, loss: 151098.53125
[INFO] Global_t: 478, Episode_t: 6, Action: 37, Reward: 1.94, Epsilon: 0.52
[INFO] model update: t: 479, loss: 95131.1171875
[INFO] Global_t: 479, Episode_t: 7, Action: 158, Reward: 1.47, Epsilon: 0.52
[INFO] model update: t: 480, loss: 129267.984375
[INFO] Global_t: 480, Episode_t: 8, Action: 101, Reward: 1.30, Epsilon: 0.52
 24%|██▍       | 480/2000 [10:07<28:59,  1.14s/it]
[INFO] Global step: 480, Cumulative rewards: 13.9056, Runtime (s): 607.72
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0895495414733887
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.34277606010437
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3104474544525146
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.365598201751709
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.313176393508911
average cummulative reward vector is:  [0.07696474 0.07723218 0.09084754 0.07324206 0.089575  ]
average cummulative reward is:  0.08157230196528083
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 481, loss: 116368.7578125
[INFO] Global_t: 481, Episode_t: 1, Action: 56, Reward: 2.01, Epsilon: 0.52
[INFO] model update: t: 482, loss: 217825.125
[INFO] Global_t: 482, Episode_t: 2, Action: 106, Reward: 1.79, Epsilon: 0.52
[INFO] model update: t: 483, loss: 45836.5625
[INFO] Global_t: 483, Episode_t: 3, Action: 184, Reward: 1.75, Epsilon: 0.52
[INFO] model update: t: 484, loss: 189348.21875
[INFO] Global_t: 484, Episode_t: 4, Action: 138, Reward: 1.64, Epsilon: 0.52
[INFO] model update: t: 485, loss: 105761.7734375
[INFO] Global_t: 485, Episode_t: 5, Action: 148, Reward: 1.68, Epsilon: 0.52
[INFO] model update: t: 486, loss: 252486.53125
[INFO] Global_t: 486, Episode_t: 6, Action: 91, Reward: 1.38, Epsilon: 0.51
[INFO] model update: t: 487, loss: 131072.625
[INFO] Global_t: 487, Episode_t: 7, Action: 149, Reward: 0.87, Epsilon: 0.51
[INFO] model update: t: 488, loss: 112521.046875
[INFO] Global_t: 488, Episode_t: 8, Action: 170, Reward: 1.53, Epsilon: 0.51
 24%|██▍       | 488/2000 [10:21<33:38,  1.34s/it]
[INFO] Global step: 488, Cumulative rewards: 12.66576, Runtime (s): 621.95
------------------------------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 489, loss: 160052.5625
[INFO] Global_t: 489, Episode_t: 1, Action: 13, Reward: 2.58, Epsilon: 0.51
[INFO] model update: t: 490, loss: 99584.03125
[INFO] Global_t: 490, Episode_t: 2, Action: 57, Reward: 2.60, Epsilon: 0.51
[INFO] model update: t: 491, loss: 173706.375
[INFO] Global_t: 491, Episode_t: 3, Action: 140, Reward: 2.58, Epsilon: 0.51
[INFO] model update: t: 492, loss: 95253.1875
[INFO] Global_t: 492, Episode_t: 4, Action: 191, Reward: 2.50, Epsilon: 0.51
[INFO] model update: t: 493, loss: 183523.1875
[INFO] Global_t: 493, Episode_t: 5, Action: 194, Reward: 1.62, Epsilon: 0.51
[INFO] model update: t: 494, loss: 16798.462890625
[INFO] Global_t: 494, Episode_t: 6, Action: 143, Reward: 1.80, Epsilon: 0.51
[INFO] model update: t: 495, loss: 174039.28125
[INFO] Global_t: 495, Episode_t: 7, Action: 206, Reward: 1.63, Epsilon: 0.51
[INFO] model update: t: 496, loss: 126416.9140625
[INFO] Global_t: 496, Episode_t: 8, Action: 29, Reward: 1.58, Epsilon: 0.50
 25%|██▍       | 496/2000 [10:25<27:04,  1.08s/it]
[INFO] Global step: 496, Cumulative rewards: 16.907639999999997, Runtime (s): 625.83
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.4157345294952393
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1915087699890137
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3699758052825928
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.162306785583496
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.229942560195923
average cummulative reward vector is:  [0.08637158 0.07059653 0.08761011 0.06898855 0.08028656]
average cummulative reward is:  0.07877066531128356
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 497, loss: 174129.234375
[INFO] Global_t: 497, Episode_t: 1, Action: 83, Reward: 1.96, Epsilon: 0.50
[INFO] model update: t: 498, loss: 26613.0
[INFO] Global_t: 498, Episode_t: 2, Action: 124, Reward: 2.01, Epsilon: 0.50
[INFO] model update: t: 499, loss: 120229.8359375
[INFO] Global_t: 499, Episode_t: 3, Action: 47, Reward: 2.01, Epsilon: 0.50
[INFO] model update: t: 500, loss: 93962.71875
[INFO] Global_t: 500, Episode_t: 4, Action: 144, Reward: 1.48, Epsilon: 0.50
[INFO] model update: t: 501, loss: 237795.03125
[INFO] Global_t: 501, Episode_t: 5, Action: 82, Reward: 1.94, Epsilon: 0.50
[INFO] model update: t: 502, loss: 147746.984375
[INFO] Global_t: 502, Episode_t: 6, Action: 36, Reward: 1.76, Epsilon: 0.50
[INFO] model update: t: 503, loss: 49472.0078125
[INFO] Global_t: 503, Episode_t: 7, Action: 73, Reward: 1.25, Epsilon: 0.50
[INFO] model update: t: 504, loss: 34398.734375
[INFO] Global_t: 504, Episode_t: 8, Action: 74, Reward: 1.57, Epsilon: 0.50
 25%|██▌       | 504/2000 [10:40<32:18,  1.30s/it]
[INFO] Global step: 504, Cumulative rewards: 13.987919999999999, Runtime (s): 640.24
------------------------------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 505, loss: 108746.4140625
[INFO] Global_t: 505, Episode_t: 1, Action: 22, Reward: 2.35, Epsilon: 0.50
[INFO] model update: t: 506, loss: 57828.1015625
[INFO] Global_t: 506, Episode_t: 2, Action: 86, Reward: 2.00, Epsilon: 0.50
[INFO] model update: t: 507, loss: 27289.087890625
[INFO] Global_t: 507, Episode_t: 3, Action: 117, Reward: 1.72, Epsilon: 0.49
[INFO] model update: t: 508, loss: 46846.609375
[INFO] Global_t: 508, Episode_t: 4, Action: 43, Reward: 1.79, Epsilon: 0.49
[INFO] model update: t: 509, loss: 121516.8046875
[INFO] Global_t: 509, Episode_t: 5, Action: 24, Reward: 1.71, Epsilon: 0.49
[INFO] model update: t: 510, loss: 94936.875
[INFO] Global_t: 510, Episode_t: 6, Action: 124, Reward: 1.66, Epsilon: 0.49
[INFO] model update: t: 511, loss: 85386.8203125
[INFO] Global_t: 511, Episode_t: 7, Action: 25, Reward: 1.68, Epsilon: 0.49
[INFO] model update: t: 512, loss: 71308.4375
[INFO] Global_t: 512, Episode_t: 8, Action: 50, Reward: 1.49, Epsilon: 0.49
 26%|██▌       | 512/2000 [10:43<25:51,  1.04s/it]
[INFO] Global step: 512, Cumulative rewards: 14.399999999999999, Runtime (s): 643.85
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1833910942077637
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3023722171783447
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.259227752685547
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2971203327178955
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.105583667755127
average cummulative reward vector is:  [0.08367132 0.06947477 0.08925847 0.07639159 0.08098333]
average cummulative reward is:  0.07995589527434548
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 513, loss: 70797.2421875
[INFO] Global_t: 513, Episode_t: 1, Action: 66, Reward: 2.73, Epsilon: 0.49
[INFO] model update: t: 514, loss: 62965.7109375
[INFO] Global_t: 514, Episode_t: 2, Action: 16, Reward: 2.67, Epsilon: 0.49
[INFO] model update: t: 515, loss: 91778.421875
[INFO] Global_t: 515, Episode_t: 3, Action: 106, Reward: 1.31, Epsilon: 0.49
[INFO] model update: t: 516, loss: 114874.078125
[INFO] Global_t: 516, Episode_t: 4, Action: 119, Reward: 1.66, Epsilon: 0.49
[INFO] model update: t: 517, loss: 164199.015625
[INFO] Global_t: 517, Episode_t: 5, Action: 183, Reward: 0.99, Epsilon: 0.48
[INFO] model update: t: 518, loss: 124067.34375
[INFO] Global_t: 518, Episode_t: 6, Action: 87, Reward: 1.06, Epsilon: 0.48
[INFO] model update: t: 519, loss: 28731.53515625
[INFO] Global_t: 519, Episode_t: 7, Action: 12, Reward: 1.43, Epsilon: 0.48
[INFO] model update: t: 520, loss: 95438.671875
[INFO] Global_t: 520, Episode_t: 8, Action: 35, Reward: 1.47, Epsilon: 0.48
 26%|██▌       | 520/2000 [11:05<37:43,  1.53s/it]
[INFO] Global step: 520, Cumulative rewards: 13.330079999999997, Runtime (s): 665.17
------------------------------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 521, loss: 81428.5625
[INFO] Global_t: 521, Episode_t: 1, Action: 128, Reward: 1.36, Epsilon: 0.48
[INFO] model update: t: 522, loss: 80985.71875
[INFO] Global_t: 522, Episode_t: 2, Action: 120, Reward: 2.62, Epsilon: 0.48
[INFO] model update: t: 523, loss: 215402.125
[INFO] Global_t: 523, Episode_t: 3, Action: 156, Reward: 1.68, Epsilon: 0.48
[INFO] model update: t: 524, loss: 113565.1875
[INFO] Global_t: 524, Episode_t: 4, Action: 7, Reward: 2.34, Epsilon: 0.48
[INFO] model update: t: 525, loss: 262380.71875
[INFO] Global_t: 525, Episode_t: 5, Action: 58, Reward: 2.42, Epsilon: 0.48
[INFO] model update: t: 526, loss: 211341.6875
[INFO] Global_t: 526, Episode_t: 6, Action: 26, Reward: 2.55, Epsilon: 0.48
[INFO] model update: t: 527, loss: 112396.1171875
[INFO] Global_t: 527, Episode_t: 7, Action: 124, Reward: 2.22, Epsilon: 0.47
[INFO] model update: t: 528, loss: 133249.46875
[INFO] Global_t: 528, Episode_t: 8, Action: 70, Reward: 2.20, Epsilon: 0.47
 26%|██▋       | 528/2000 [11:13<33:40,  1.37s/it]
[INFO] Global step: 528, Cumulative rewards: 17.38608, Runtime (s): 673.22
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0071022510528564
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.415066957473755
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.18670916557312
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2601559162139893
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4246277809143066
average cummulative reward vector is:  [0.07172579 0.0790294  0.08323142 0.07466682 0.09244167]
average cummulative reward is:  0.0802190194966866
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 529, loss: 143499.75
[INFO] Global_t: 529, Episode_t: 1, Action: 41, Reward: 2.37, Epsilon: 0.47
[INFO] model update: t: 530, loss: 110109.734375
[INFO] Global_t: 530, Episode_t: 2, Action: 80, Reward: 2.15, Epsilon: 0.47
[INFO] model update: t: 531, loss: 63887.78515625
[INFO] Global_t: 531, Episode_t: 3, Action: 3, Reward: 4.84, Epsilon: 0.47
[INFO] model update: t: 532, loss: 82135.59375
[INFO] Global_t: 532, Episode_t: 4, Action: 197, Reward: 1.56, Epsilon: 0.47
[INFO] model update: t: 533, loss: 113493.8125
[INFO] Global_t: 533, Episode_t: 5, Action: 114, Reward: 1.99, Epsilon: 0.47
[INFO] model update: t: 534, loss: 38726.0234375
[INFO] Global_t: 534, Episode_t: 6, Action: 136, Reward: 2.08, Epsilon: 0.47
[INFO] model update: t: 535, loss: 98107.0
[INFO] Global_t: 535, Episode_t: 7, Action: 95, Reward: 1.95, Epsilon: 0.47
[INFO] model update: t: 536, loss: 159922.4375
[INFO] Global_t: 536, Episode_t: 8, Action: 22, Reward: 2.17, Epsilon: 0.47
 27%|██▋       | 536/2000 [11:27<36:08,  1.48s/it]
[INFO] Global step: 536, Cumulative rewards: 19.101479999999995, Runtime (s): 687.09
------------------------------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 537, loss: 93834.71875
[INFO] Global_t: 537, Episode_t: 1, Action: 121, Reward: 1.25, Epsilon: 0.46
[INFO] model update: t: 538, loss: 75228.953125
[INFO] Global_t: 538, Episode_t: 2, Action: 44, Reward: 2.22, Epsilon: 0.46
[INFO] model update: t: 539, loss: 82853.2890625
[INFO] Global_t: 539, Episode_t: 3, Action: 92, Reward: 1.80, Epsilon: 0.46
[INFO] model update: t: 540, loss: 26700.3203125
[INFO] Global_t: 540, Episode_t: 4, Action: 31, Reward: 2.25, Epsilon: 0.46
[INFO] model update: t: 541, loss: 36682.921875
[INFO] Global_t: 541, Episode_t: 5, Action: 97, Reward: 1.21, Epsilon: 0.46
[INFO] model update: t: 542, loss: 53730.53515625
[INFO] Global_t: 542, Episode_t: 6, Action: 25, Reward: 2.27, Epsilon: 0.46
[INFO] model update: t: 543, loss: 53853.61328125
[INFO] Global_t: 543, Episode_t: 7, Action: 47, Reward: 2.18, Epsilon: 0.46
[INFO] model update: t: 544, loss: 72416.90625
[INFO] Global_t: 544, Episode_t: 8, Action: 61, Reward: 1.99, Epsilon: 0.46
 27%|██▋       | 544/2000 [11:29<27:44,  1.14s/it]
[INFO] Global step: 544, Cumulative rewards: 15.161159999999999, Runtime (s): 689.94
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8899457454681396
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.289214611053467
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.4030110836029053
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.744231939315796
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3451249599456787
average cummulative reward vector is:  [0.07132421 0.07465417 0.08772978 0.07565421 0.08757419]
average cummulative reward is:  0.07938731155392224
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 545, loss: 158799.59375
[INFO] Global_t: 545, Episode_t: 1, Action: 86, Reward: 1.39, Epsilon: 0.46
[INFO] model update: t: 546, loss: 51768.53515625
[INFO] Global_t: 546, Episode_t: 2, Action: 218, Reward: 2.54, Epsilon: 0.46
[INFO] model update: t: 547, loss: 42347.17578125
[INFO] Global_t: 547, Episode_t: 3, Action: 0, Reward: 2.65, Epsilon: 0.45
[INFO] model update: t: 548, loss: 51516.3203125
[INFO] Global_t: 548, Episode_t: 4, Action: 127, Reward: 2.24, Epsilon: 0.45
[INFO] model update: t: 549, loss: 53848.40625
[INFO] Global_t: 549, Episode_t: 5, Action: 110, Reward: 2.05, Epsilon: 0.45
[INFO] model update: t: 550, loss: 87798.8125
[INFO] Global_t: 550, Episode_t: 6, Action: 24, Reward: 2.17, Epsilon: 0.45
[INFO] model update: t: 551, loss: 18521.21484375
[INFO] Global_t: 551, Episode_t: 7, Action: 15, Reward: 2.10, Epsilon: 0.45
[INFO] model update: t: 552, loss: 176369.5625
[INFO] Global_t: 552, Episode_t: 8, Action: 201, Reward: 0.95, Epsilon: 0.45
 28%|██▊       | 552/2000 [11:45<33:38,  1.39s/it]
[INFO] Global step: 552, Cumulative rewards: 16.085639999999998, Runtime (s): 705.77
------------------------------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 553, loss: 125714.8125
[INFO] Global_t: 553, Episode_t: 1, Action: 37, Reward: 2.81, Epsilon: 0.45
[INFO] model update: t: 554, loss: 60437.32421875
[INFO] Global_t: 554, Episode_t: 2, Action: 170, Reward: 2.26, Epsilon: 0.45
[INFO] model update: t: 555, loss: 41711.65234375
[INFO] Global_t: 555, Episode_t: 3, Action: 163, Reward: 1.10, Epsilon: 0.45
[INFO] model update: t: 556, loss: 210120.859375
[INFO] Global_t: 556, Episode_t: 4, Action: 126, Reward: 2.23, Epsilon: 0.45
[INFO] model update: t: 557, loss: 32632.046875
[INFO] Global_t: 557, Episode_t: 5, Action: 4, Reward: 2.02, Epsilon: 0.45
[INFO] model update: t: 558, loss: 289787.03125
[INFO] Global_t: 558, Episode_t: 6, Action: 68, Reward: 1.58, Epsilon: 0.44
[INFO] model update: t: 559, loss: 77663.1015625
[INFO] Global_t: 559, Episode_t: 7, Action: 20, Reward: 1.80, Epsilon: 0.44
[INFO] model update: t: 560, loss: 24727.12109375
[INFO] Global_t: 560, Episode_t: 8, Action: 46, Reward: 1.38, Epsilon: 0.44
 28%|██▊       | 560/2000 [11:49<27:06,  1.13s/it]
[INFO] Global step: 560, Cumulative rewards: 15.18564, Runtime (s): 709.87
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.088745355606079
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1933510303497314
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.196174383163452
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1024045944213867
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1075496673583984
average cummulative reward vector is:  [0.07754816 0.07121667 0.08511831 0.06961121 0.07611586]
average cummulative reward is:  0.07592204114813146
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 561, loss: 123666.3046875
[INFO] Global_t: 561, Episode_t: 1, Action: 122, Reward: 1.18, Epsilon: 0.44
[INFO] model update: t: 562, loss: 132975.78125
[INFO] Global_t: 562, Episode_t: 2, Action: 133, Reward: 2.44, Epsilon: 0.44
[INFO] model update: t: 563, loss: 104710.9140625
[INFO] Global_t: 563, Episode_t: 3, Action: 92, Reward: 1.68, Epsilon: 0.44
[INFO] model update: t: 564, loss: 46004.98828125
[INFO] Global_t: 564, Episode_t: 4, Action: 170, Reward: 2.18, Epsilon: 0.44
[INFO] model update: t: 565, loss: 48182.3984375
[INFO] Global_t: 565, Episode_t: 5, Action: 165, Reward: 1.67, Epsilon: 0.44
[INFO] model update: t: 566, loss: 47144.515625
[INFO] Global_t: 566, Episode_t: 6, Action: 131, Reward: 1.99, Epsilon: 0.44
[INFO] model update: t: 567, loss: 79809.6171875
[INFO] Global_t: 567, Episode_t: 7, Action: 169, Reward: 1.34, Epsilon: 0.44
[INFO] model update: t: 568, loss: 31989.6640625
[INFO] Global_t: 568, Episode_t: 8, Action: 60, Reward: 2.20, Epsilon: 0.43
 28%|██▊       | 568/2000 [12:03<31:06,  1.30s/it]
[INFO] Global step: 568, Cumulative rewards: 14.67756, Runtime (s): 723.55
------------------------------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 569, loss: 154139.375
[INFO] Global_t: 569, Episode_t: 1, Action: 87, Reward: 1.42, Epsilon: 0.43
[INFO] model update: t: 570, loss: 134515.671875
[INFO] Global_t: 570, Episode_t: 2, Action: 185, Reward: 2.30, Epsilon: 0.43
[INFO] model update: t: 571, loss: 85577.9765625
[INFO] Global_t: 571, Episode_t: 3, Action: 164, Reward: 1.96, Epsilon: 0.43
[INFO] model update: t: 572, loss: 79449.5703125
[INFO] Global_t: 572, Episode_t: 4, Action: 125, Reward: 2.09, Epsilon: 0.43
[INFO] model update: t: 573, loss: 98985.296875
[INFO] Global_t: 573, Episode_t: 5, Action: 135, Reward: 2.08, Epsilon: 0.43
[INFO] model update: t: 574, loss: 104551.3671875
[INFO] Global_t: 574, Episode_t: 6, Action: 122, Reward: 1.36, Epsilon: 0.43
[INFO] model update: t: 575, loss: 115981.3046875
[INFO] Global_t: 575, Episode_t: 7, Action: 136, Reward: 1.45, Epsilon: 0.43
[INFO] model update: t: 576, loss: 48920.7734375
[INFO] Global_t: 576, Episode_t: 8, Action: 23, Reward: 2.51, Epsilon: 0.43
 29%|██▉       | 576/2000 [12:07<24:47,  1.04s/it]
[INFO] Global step: 576, Cumulative rewards: 15.183959999999999, Runtime (s): 727.07
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.316354513168335
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.4158406257629395
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1142780780792236
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.27036190032959
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.279721975326538
average cummulative reward vector is:  [0.07985368 0.07549722 0.07778852 0.06997921 0.08777097]
average cummulative reward is:  0.07817792087446493
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 577, loss: 153957.125
[INFO] Global_t: 577, Episode_t: 1, Action: 56, Reward: 2.29, Epsilon: 0.43
[INFO] model update: t: 578, loss: 23257.109375
[INFO] Global_t: 578, Episode_t: 2, Action: 72, Reward: 2.01, Epsilon: 0.42
[INFO] model update: t: 579, loss: 123367.328125
[INFO] Global_t: 579, Episode_t: 3, Action: 74, Reward: 1.59, Epsilon: 0.42
[INFO] model update: t: 580, loss: 42067.265625
[INFO] Global_t: 580, Episode_t: 4, Action: 89, Reward: 2.01, Epsilon: 0.42
[INFO] model update: t: 581, loss: 51208.3515625
[INFO] Global_t: 581, Episode_t: 5, Action: 124, Reward: 2.21, Epsilon: 0.42
[INFO] model update: t: 582, loss: 117104.1328125
[INFO] Global_t: 582, Episode_t: 6, Action: 55, Reward: 2.71, Epsilon: 0.42
[INFO] model update: t: 583, loss: 73423.59375
[INFO] Global_t: 583, Episode_t: 7, Action: 190, Reward: 2.16, Epsilon: 0.42
[INFO] model update: t: 584, loss: 109820.65625
[INFO] Global_t: 584, Episode_t: 8, Action: 169, Reward: 2.03, Epsilon: 0.42
 29%|██▉       | 584/2000 [12:20<29:16,  1.24s/it]
[INFO] Global step: 584, Cumulative rewards: 17.01588, Runtime (s): 740.65
------------------------------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 585, loss: 180571.75
[INFO] Global_t: 585, Episode_t: 1, Action: 158, Reward: 2.32, Epsilon: 0.42
[INFO] model update: t: 586, loss: 151701.84375
[INFO] Global_t: 586, Episode_t: 2, Action: 129, Reward: 1.49, Epsilon: 0.42
[INFO] model update: t: 587, loss: 84830.765625
[INFO] Global_t: 587, Episode_t: 3, Action: 84, Reward: 1.75, Epsilon: 0.42
[INFO] model update: t: 588, loss: 81518.984375
[INFO] Global_t: 588, Episode_t: 4, Action: 156, Reward: 1.34, Epsilon: 0.41
[INFO] model update: t: 589, loss: 38689.5390625
[INFO] Global_t: 589, Episode_t: 5, Action: 153, Reward: 1.23, Epsilon: 0.41
[INFO] model update: t: 590, loss: 111992.6484375
[INFO] Global_t: 590, Episode_t: 6, Action: 191, Reward: 2.15, Epsilon: 0.41
[INFO] model update: t: 591, loss: 110243.5
[INFO] Global_t: 591, Episode_t: 7, Action: 173, Reward: 1.48, Epsilon: 0.41
[INFO] model update: t: 592, loss: 134934.265625
[INFO] Global_t: 592, Episode_t: 8, Action: 80, Reward: 1.11, Epsilon: 0.41

[INFO] Global step: 592, Cumulative rewards: 12.879000000000001, Runtime (s): 743.56
------------------------------------------------------------
 
 30%|██▉       | 592/2000 [12:23<22:56,  1.02it/s]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.3233845233917236
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.193854331970215
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3119208812713623
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0886754989624023
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.321958065032959
average cummulative reward vector is:  [0.08930263 0.07135417 0.0791653  0.06891028 0.08695376]
average cummulative reward is:  0.07913722852135083
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 593, loss: 43725.7734375
[INFO] Global_t: 593, Episode_t: 1, Action: 175, Reward: 2.27, Epsilon: 0.41
[INFO] model update: t: 594, loss: 141466.78125
[INFO] Global_t: 594, Episode_t: 2, Action: 73, Reward: 2.22, Epsilon: 0.41
[INFO] model update: t: 595, loss: 40533.58203125
[INFO] Global_t: 595, Episode_t: 3, Action: 113, Reward: 2.31, Epsilon: 0.41
[INFO] model update: t: 596, loss: 176243.4375
[INFO] Global_t: 596, Episode_t: 4, Action: 54, Reward: 2.00, Epsilon: 0.41
[INFO] model update: t: 597, loss: 58571.40625
[INFO] Global_t: 597, Episode_t: 5, Action: 159, Reward: 1.68, Epsilon: 0.41
[INFO] model update: t: 598, loss: 123588.8828125
[INFO] Global_t: 598, Episode_t: 6, Action: 116, Reward: 1.65, Epsilon: 0.40
[INFO] model update: t: 599, loss: 122251.296875
[INFO] Global_t: 599, Episode_t: 7, Action: 118, Reward: 1.87, Epsilon: 0.40
[INFO] model update: t: 600, loss: 62901.0
[INFO] Global_t: 600, Episode_t: 8, Action: 69, Reward: 1.65, Epsilon: 0.40

[INFO] Global step: 600, Cumulative rewards: 15.65616, Runtime (s): 758.40
 30%|███       | 600/2000 [12:38<28:56,  1.24s/it]------------------------------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 601, loss: 216535.5
[INFO] Global_t: 601, Episode_t: 1, Action: 48, Reward: 2.38, Epsilon: 0.40
[INFO] model update: t: 602, loss: 96537.1796875
[INFO] Global_t: 602, Episode_t: 2, Action: 1, Reward: 6.36, Epsilon: 0.40
[INFO] model update: t: 603, loss: 130071.609375
[INFO] Global_t: 603, Episode_t: 3, Action: 107, Reward: 1.50, Epsilon: 0.40
[INFO] model update: t: 604, loss: 46602.890625
[INFO] Global_t: 604, Episode_t: 4, Action: 150, Reward: 0.87, Epsilon: 0.40
[INFO] model update: t: 605, loss: 215875.1875
[INFO] Global_t: 605, Episode_t: 5, Action: 83, Reward: 1.33, Epsilon: 0.40
[INFO] model update: t: 606, loss: 110966.234375
[INFO] Global_t: 606, Episode_t: 6, Action: 162, Reward: 1.56, Epsilon: 0.40
[INFO] model update: t: 607, loss: 157646.03125
[INFO] Global_t: 607, Episode_t: 7, Action: 100, Reward: 1.69, Epsilon: 0.40
[INFO] model update: t: 608, loss: 229115.078125
[INFO] Global_t: 608, Episode_t: 8, Action: 183, Reward: 0.64, Epsilon: 0.40
 30%|███       | 608/2000 [12:44<25:06,  1.08s/it]
[INFO] Global step: 608, Cumulative rewards: 16.3326, Runtime (s): 764.09
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.132148504257202
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.208139181137085
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1479642391204834
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.070991277694702
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2492318153381348
average cummulative reward vector is:  [0.07892711 0.07048588 0.07926995 0.06885047 0.08594167]
average cummulative reward is:  0.07669501284087302
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 609, loss: 352128.5625
[INFO] Global_t: 609, Episode_t: 1, Action: 122, Reward: 1.51, Epsilon: 0.39
[INFO] model update: t: 610, loss: 151186.0625
[INFO] Global_t: 610, Episode_t: 2, Action: 150, Reward: 1.44, Epsilon: 0.39
[INFO] model update: t: 611, loss: 205094.875
[INFO] Global_t: 611, Episode_t: 3, Action: 104, Reward: 2.06, Epsilon: 0.39
[INFO] model update: t: 612, loss: 139201.34375
[INFO] Global_t: 612, Episode_t: 4, Action: 143, Reward: 1.33, Epsilon: 0.39
[INFO] model update: t: 613, loss: 148668.953125
[INFO] Global_t: 613, Episode_t: 5, Action: 47, Reward: 2.45, Epsilon: 0.39
[INFO] model update: t: 614, loss: 53897.9296875
[INFO] Global_t: 614, Episode_t: 6, Action: 51, Reward: 2.41, Epsilon: 0.39
[INFO] model update: t: 615, loss: 132133.78125
[INFO] Global_t: 615, Episode_t: 7, Action: 18, Reward: 2.02, Epsilon: 0.39
[INFO] model update: t: 616, loss: 68511.734375
[INFO] Global_t: 616, Episode_t: 8, Action: 56, Reward: 1.49, Epsilon: 0.39
 31%|███       | 616/2000 [12:57<28:55,  1.25s/it]
[INFO] Global step: 616, Cumulative rewards: 14.71248, Runtime (s): 777.34
------------------------------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 617, loss: 203144.875
[INFO] Global_t: 617, Episode_t: 1, Action: 186, Reward: 1.41, Epsilon: 0.39
[INFO] model update: t: 618, loss: 8094.58837890625
[INFO] Global_t: 618, Episode_t: 2, Action: 120, Reward: 2.38, Epsilon: 0.39
[INFO] model update: t: 619, loss: 135810.0
[INFO] Global_t: 619, Episode_t: 3, Action: 86, Reward: 2.26, Epsilon: 0.38
[INFO] model update: t: 620, loss: 119088.5078125
[INFO] Global_t: 620, Episode_t: 4, Action: 46, Reward: 1.87, Epsilon: 0.38
[INFO] model update: t: 621, loss: 218423.125
[INFO] Global_t: 621, Episode_t: 5, Action: 59, Reward: 1.99, Epsilon: 0.38
[INFO] model update: t: 622, loss: 96756.265625
[INFO] Global_t: 622, Episode_t: 6, Action: 108, Reward: 1.40, Epsilon: 0.38
[INFO] model update: t: 623, loss: 105318.2421875
[INFO] Global_t: 623, Episode_t: 7, Action: 118, Reward: 1.68, Epsilon: 0.38
[INFO] model update: t: 624, loss: 30017.30078125
[INFO] Global_t: 624, Episode_t: 8, Action: 141, Reward: 1.50, Epsilon: 0.38
 31%|███       | 624/2000 [13:00<22:29,  1.02it/s]
[INFO] Global step: 624, Cumulative rewards: 14.499719999999996, Runtime (s): 780.08
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1779637336730957
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.20463490486145
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3588767051696777
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2942726612091064
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.133155345916748
average cummulative reward vector is:  [0.07685158 0.07092153 0.08830546 0.07575444 0.07618118]
average cummulative reward is:  0.07760283865081118
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 625, loss: 131224.0
[INFO] Global_t: 625, Episode_t: 1, Action: 20, Reward: 3.39, Epsilon: 0.38
[INFO] model update: t: 626, loss: 104599.3828125
[INFO] Global_t: 626, Episode_t: 2, Action: 114, Reward: 1.40, Epsilon: 0.38
[INFO] model update: t: 627, loss: 92134.609375
[INFO] Global_t: 627, Episode_t: 3, Action: 181, Reward: 1.36, Epsilon: 0.38
[INFO] model update: t: 628, loss: 108091.171875
[INFO] Global_t: 628, Episode_t: 4, Action: 49, Reward: 1.74, Epsilon: 0.38
[INFO] model update: t: 629, loss: 113009.71875
[INFO] Global_t: 629, Episode_t: 5, Action: 14, Reward: 1.91, Epsilon: 0.37
[INFO] model update: t: 630, loss: 120768.6953125
[INFO] Global_t: 630, Episode_t: 6, Action: 8, Reward: 4.42, Epsilon: 0.37
[INFO] model update: t: 631, loss: 215084.8125
[INFO] Global_t: 631, Episode_t: 7, Action: 146, Reward: 0.82, Epsilon: 0.37
[INFO] model update: t: 632, loss: 56761.46875
[INFO] Global_t: 632, Episode_t: 8, Action: 45, Reward: 1.31, Epsilon: 0.37
 32%|███▏      | 632/2000 [13:15<28:42,  1.26s/it]
[INFO] Global step: 632, Cumulative rewards: 16.3512, Runtime (s): 795.36
------------------------------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 633, loss: 98498.0625
[INFO] Global_t: 633, Episode_t: 1, Action: 174, Reward: 2.17, Epsilon: 0.37
[INFO] model update: t: 634, loss: 75903.8203125
[INFO] Global_t: 634, Episode_t: 2, Action: 78, Reward: 2.24, Epsilon: 0.37
[INFO] model update: t: 635, loss: 51478.234375
[INFO] Global_t: 635, Episode_t: 3, Action: 159, Reward: 1.99, Epsilon: 0.37
[INFO] model update: t: 636, loss: 46973.0234375
[INFO] Global_t: 636, Episode_t: 4, Action: 118, Reward: 1.97, Epsilon: 0.37
[INFO] model update: t: 637, loss: 78614.4921875
[INFO] Global_t: 637, Episode_t: 5, Action: 68, Reward: 1.74, Epsilon: 0.37
[INFO] model update: t: 638, loss: 80420.375
[INFO] Global_t: 638, Episode_t: 6, Action: 92, Reward: 1.76, Epsilon: 0.37
[INFO] model update: t: 639, loss: 152951.109375
[INFO] Global_t: 639, Episode_t: 7, Action: 190, Reward: 0.95, Epsilon: 0.36
[INFO] model update: t: 640, loss: 189057.546875
[INFO] Global_t: 640, Episode_t: 8, Action: 77, Reward: 1.40, Epsilon: 0.36
 32%|███▏      | 640/2000 [13:18<22:51,  1.01s/it]
[INFO] Global step: 640, Cumulative rewards: 14.219039999999998, Runtime (s): 798.75
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.3063318729400635
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3289496898651123
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2071754932403564
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1386187076568604
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3748507499694824
average cummulative reward vector is:  [0.08345947 0.0763081  0.08642978 0.07086963 0.09004866]
average cummulative reward is:  0.08142312780780606
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 641, loss: 70137.125
[INFO] Global_t: 641, Episode_t: 1, Action: 129, Reward: 2.56, Epsilon: 0.36
[INFO] model update: t: 642, loss: 129336.0625
[INFO] Global_t: 642, Episode_t: 2, Action: 147, Reward: 1.80, Epsilon: 0.36
[INFO] model update: t: 643, loss: 19714.576171875
[INFO] Global_t: 643, Episode_t: 3, Action: 93, Reward: 2.38, Epsilon: 0.36
[INFO] model update: t: 644, loss: 132717.453125
[INFO] Global_t: 644, Episode_t: 4, Action: 67, Reward: 1.89, Epsilon: 0.36
[INFO] model update: t: 645, loss: 33640.22265625
[INFO] Global_t: 645, Episode_t: 5, Action: 48, Reward: 2.07, Epsilon: 0.36
[INFO] model update: t: 646, loss: 151495.1875
[INFO] Global_t: 646, Episode_t: 6, Action: 160, Reward: 1.66, Epsilon: 0.36
[INFO] model update: t: 647, loss: 45128.421875
[INFO] Global_t: 647, Episode_t: 7, Action: 154, Reward: 1.81, Epsilon: 0.36
[INFO] model update: t: 648, loss: 60173.6875
[INFO] Global_t: 648, Episode_t: 8, Action: 100, Reward: 1.88, Epsilon: 0.36
 32%|███▏      | 648/2000 [13:34<29:08,  1.29s/it]
[INFO] Global step: 648, Cumulative rewards: 16.053240000000002, Runtime (s): 814.40
------------------------------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 649, loss: 61793.21875
[INFO] Global_t: 649, Episode_t: 1, Action: 159, Reward: 1.34, Epsilon: 0.35
[INFO] model update: t: 650, loss: 33658.8515625
[INFO] Global_t: 650, Episode_t: 2, Action: 38, Reward: 2.43, Epsilon: 0.35
[INFO] model update: t: 651, loss: 56223.79296875
[INFO] Global_t: 651, Episode_t: 3, Action: 103, Reward: 2.00, Epsilon: 0.35
[INFO] model update: t: 652, loss: 39718.3203125
[INFO] Global_t: 652, Episode_t: 4, Action: 6, Reward: 6.23, Epsilon: 0.35
[INFO] model update: t: 653, loss: 54297.4453125
[INFO] Global_t: 653, Episode_t: 5, Action: 107, Reward: 1.76, Epsilon: 0.35
[INFO] model update: t: 654, loss: 119961.8828125
[INFO] Global_t: 654, Episode_t: 6, Action: 47, Reward: 1.76, Epsilon: 0.35
[INFO] model update: t: 655, loss: 92151.25
[INFO] Global_t: 655, Episode_t: 7, Action: 37, Reward: 1.89, Epsilon: 0.35
[INFO] model update: t: 656, loss: 93986.4375
[INFO] Global_t: 656, Episode_t: 8, Action: 72, Reward: 2.15, Epsilon: 0.35
 33%|███▎      | 656/2000 [13:37<22:42,  1.01s/it]
[INFO] Global step: 656, Cumulative rewards: 19.550040000000003, Runtime (s): 817.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.389514923095703
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2441816329956055
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.0726747512817383
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2865514755249023
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3859567642211914
average cummulative reward vector is:  [0.08563053 0.06713495 0.07990847 0.07314579 0.08950618]
average cummulative reward is:  0.07906518543061411
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
[INFO] model update: t: 657, loss: 136404.390625
[INFO] Global_t: 657, Episode_t: 1, Action: 118, Reward: 1.06, Epsilon: 0.35
[INFO] model update: t: 658, loss: 75205.984375
[INFO] Global_t: 658, Episode_t: 2, Action: 33, Reward: 2.03, Epsilon: 0.35
[INFO] model update: t: 659, loss: 210108.203125
[INFO] Global_t: 659, Episode_t: 3, Action: 161, Reward: 1.74, Epsilon: 0.35
[INFO] model update: t: 660, loss: 105567.46875
[INFO] Global_t: 660, Episode_t: 4, Action: 45, Reward: 1.65, Epsilon: 0.34
[INFO] model update: t: 661, loss: 137372.3125
[INFO] Global_t: 661, Episode_t: 5, Action: 57, Reward: 1.80, Epsilon: 0.34
[INFO] model update: t: 662, loss: 37547.12890625
[INFO] Global_t: 662, Episode_t: 6, Action: 82, Reward: 1.52, Epsilon: 0.34
[INFO] model update: t: 663, loss: 48880.71875
[INFO] Global_t: 663, Episode_t: 7, Action: 19, Reward: 1.99, Epsilon: 0.34
[INFO] model update: t: 664, loss: 190791.984375
[INFO] Global_t: 664, Episode_t: 8, Action: 49, Reward: 1.37, Epsilon: 0.34
 33%|███▎      | 664/2000 [13:52<28:06,  1.26s/it]
[INFO] Global step: 664, Cumulative rewards: 13.15788, Runtime (s): 832.03
------------------------------------------------------------
 
graph: 83, nodes: 198, edges: 584
[INFO] model update: t: 665, loss: 116999.609375
[INFO] Global_t: 665, Episode_t: 1, Action: 155, Reward: 2.47, Epsilon: 0.34
[INFO] model update: t: 666, loss: 37544.5546875
[INFO] Global_t: 666, Episode_t: 2, Action: 140, Reward: 1.85, Epsilon: 0.34
[INFO] model update: t: 667, loss: 93123.9375
[INFO] Global_t: 667, Episode_t: 3, Action: 26, Reward: 1.99, Epsilon: 0.34
[INFO] model update: t: 668, loss: 34196.91015625
[INFO] Global_t: 668, Episode_t: 4, Action: 16, Reward: 2.34, Epsilon: 0.34
[INFO] model update: t: 669, loss: 54504.1015625
[INFO] Global_t: 669, Episode_t: 5, Action: 83, Reward: 1.50, Epsilon: 0.34
[INFO] model update: t: 670, loss: 45630.91015625
[INFO] Global_t: 670, Episode_t: 6, Action: 78, Reward: 1.38, Epsilon: 0.33
[INFO] model update: t: 671, loss: 97910.4296875
[INFO] Global_t: 671, Episode_t: 7, Action: 186, Reward: 1.30, Epsilon: 0.33
[INFO] model update: t: 672, loss: 100439.96875
[INFO] Global_t: 672, Episode_t: 8, Action: 32, Reward: 1.33, Epsilon: 0.33
 34%|███▎      | 672/2000 [13:56<22:56,  1.04s/it]
[INFO] Global step: 672, Cumulative rewards: 14.166359999999997, Runtime (s): 836.11
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.976682186126709
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.137664794921875
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3071343898773193
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.207791805267334
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.385422706604004
average cummulative reward vector is:  [0.07250579 0.06996204 0.07844344 0.07257664 0.09001855]
average cummulative reward is:  0.0767012906069575
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 84, nodes: 205, edges: 606
[INFO] model update: t: 673, loss: 57633.3828125
[INFO] Global_t: 673, Episode_t: 1, Action: 101, Reward: 2.21, Epsilon: 0.33
[INFO] model update: t: 674, loss: 16083.421875
[INFO] Global_t: 674, Episode_t: 2, Action: 78, Reward: 1.80, Epsilon: 0.33
[INFO] model update: t: 675, loss: 148186.78125
[INFO] Global_t: 675, Episode_t: 3, Action: 53, Reward: 1.85, Epsilon: 0.33
[INFO] model update: t: 676, loss: 75114.734375
[INFO] Global_t: 676, Episode_t: 4, Action: 129, Reward: 1.20, Epsilon: 0.33
[INFO] model update: t: 677, loss: 54974.2734375
[INFO] Global_t: 677, Episode_t: 5, Action: 58, Reward: 1.68, Epsilon: 0.33
[INFO] model update: t: 678, loss: 31352.130859375
[INFO] Global_t: 678, Episode_t: 6, Action: 111, Reward: 1.00, Epsilon: 0.33
[INFO] model update: t: 679, loss: 80001.359375
[INFO] Global_t: 679, Episode_t: 7, Action: 166, Reward: 1.82, Epsilon: 0.33
[INFO] model update: t: 680, loss: 103114.4765625
[INFO] Global_t: 680, Episode_t: 8, Action: 68, Reward: 1.34, Epsilon: 0.32
 34%|███▍      | 680/2000 [14:10<28:09,  1.28s/it]
[INFO] Global step: 680, Cumulative rewards: 12.89844, Runtime (s): 850.88
------------------------------------------------------------
 
graph: 85, nodes: 212, edges: 627
[INFO] model update: t: 681, loss: 95303.140625
[INFO] Global_t: 681, Episode_t: 1, Action: 6, Reward: 4.69, Epsilon: 0.32
[INFO] model update: t: 682, loss: 122862.9375
[INFO] Global_t: 682, Episode_t: 2, Action: 107, Reward: 1.41, Epsilon: 0.32
[INFO] model update: t: 683, loss: 17697.9921875
[INFO] Global_t: 683, Episode_t: 3, Action: 29, Reward: 1.64, Epsilon: 0.32
[INFO] model update: t: 684, loss: 78297.1015625
[INFO] Global_t: 684, Episode_t: 4, Action: 73, Reward: 1.21, Epsilon: 0.32
[INFO] model update: t: 685, loss: 22238.083984375
[INFO] Global_t: 685, Episode_t: 5, Action: 113, Reward: 1.81, Epsilon: 0.32
[INFO] model update: t: 686, loss: 67028.2265625
[INFO] Global_t: 686, Episode_t: 6, Action: 158, Reward: 1.61, Epsilon: 0.32
[INFO] model update: t: 687, loss: 96112.2265625
[INFO] Global_t: 687, Episode_t: 7, Action: 39, Reward: 1.57, Epsilon: 0.32
[INFO] model update: t: 688, loss: 118015.734375
[INFO] Global_t: 688, Episode_t: 8, Action: 93, Reward: 1.74, Epsilon: 0.32
 34%|███▍      | 688/2000 [14:15<23:43,  1.08s/it]
[INFO] Global step: 688, Cumulative rewards: 15.67992, Runtime (s): 855.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.96992826461792
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.083712100982666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3999366760253906
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.170778274536133
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.162539482116699
average cummulative reward vector is:  [0.07194974 0.06680301 0.08584317 0.07166986 0.07931398]
average cummulative reward is:  0.07511595076159587
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 86, nodes: 200, edges: 591
[INFO] model update: t: 689, loss: 102377.6328125
[INFO] Global_t: 689, Episode_t: 1, Action: 61, Reward: 2.13, Epsilon: 0.32
[INFO] model update: t: 690, loss: 106075.109375
[INFO] Global_t: 690, Episode_t: 2, Action: 190, Reward: 1.94, Epsilon: 0.31
[INFO] model update: t: 691, loss: 99532.9765625
[INFO] Global_t: 691, Episode_t: 3, Action: 177, Reward: 2.03, Epsilon: 0.31
[INFO] model update: t: 692, loss: 91178.6796875
[INFO] Global_t: 692, Episode_t: 4, Action: 100, Reward: 1.65, Epsilon: 0.31
[INFO] model update: t: 693, loss: 74998.0625
[INFO] Global_t: 693, Episode_t: 5, Action: 77, Reward: 1.84, Epsilon: 0.31
[INFO] model update: t: 694, loss: 29549.6640625
[INFO] Global_t: 694, Episode_t: 6, Action: 19, Reward: 2.66, Epsilon: 0.31
[INFO] model update: t: 695, loss: 71494.03125
[INFO] Global_t: 695, Episode_t: 7, Action: 155, Reward: 1.76, Epsilon: 0.31
[INFO] model update: t: 696, loss: 98355.890625
[INFO] Global_t: 696, Episode_t: 8, Action: 74, Reward: 1.60, Epsilon: 0.31
 35%|███▍      | 696/2000 [14:29<27:56,  1.29s/it]
[INFO] Global step: 696, Cumulative rewards: 15.614519999999995, Runtime (s): 869.97
------------------------------------------------------------
 
graph: 87, nodes: 218, edges: 645
[INFO] model update: t: 697, loss: 16018.8759765625
[INFO] Global_t: 697, Episode_t: 1, Action: 209, Reward: 2.34, Epsilon: 0.31
[INFO] model update: t: 698, loss: 89469.453125
[INFO] Global_t: 698, Episode_t: 2, Action: 59, Reward: 2.49, Epsilon: 0.31
[INFO] model update: t: 699, loss: 71797.65625
[INFO] Global_t: 699, Episode_t: 3, Action: 154, Reward: 2.23, Epsilon: 0.31
[INFO] model update: t: 700, loss: 60703.5625
[INFO] Global_t: 700, Episode_t: 4, Action: 84, Reward: 1.38, Epsilon: 0.30
[INFO] model update: t: 701, loss: 66806.5234375
[INFO] Global_t: 701, Episode_t: 5, Action: 77, Reward: 1.79, Epsilon: 0.30
[INFO] model update: t: 702, loss: 61505.37890625
[INFO] Global_t: 702, Episode_t: 6, Action: 182, Reward: 1.44, Epsilon: 0.30
[INFO] model update: t: 703, loss: 18535.943359375
[INFO] Global_t: 703, Episode_t: 7, Action: 106, Reward: 1.58, Epsilon: 0.30
[INFO] model update: t: 704, loss: 65283.94140625
[INFO] Global_t: 704, Episode_t: 8, Action: 213, Reward: 1.29, Epsilon: 0.30
 35%|███▌      | 704/2000 [14:34<22:44,  1.05s/it]
[INFO] Global step: 704, Cumulative rewards: 14.5374, Runtime (s): 874.03
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1019043922424316
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.323183298110962
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.250356912612915
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.338181734085083
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.347972869873047
average cummulative reward vector is:  [0.07837289 0.07586574 0.08727951 0.07133925 0.09067097]
average cummulative reward is:  0.08070567275053764
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 88, nodes: 204, edges: 603
[INFO] model update: t: 705, loss: 127912.5625
[INFO] Global_t: 705, Episode_t: 1, Action: 132, Reward: 1.94, Epsilon: 0.30
[INFO] model update: t: 706, loss: 79742.4921875
[INFO] Global_t: 706, Episode_t: 2, Action: 38, Reward: 1.77, Epsilon: 0.30
[INFO] model update: t: 707, loss: 178105.671875
[INFO] Global_t: 707, Episode_t: 3, Action: 0, Reward: 1.39, Epsilon: 0.30
[INFO] model update: t: 708, loss: 223182.359375
[INFO] Global_t: 708, Episode_t: 4, Action: 10, Reward: 1.82, Epsilon: 0.30
[INFO] model update: t: 709, loss: 51910.9140625
[INFO] Global_t: 709, Episode_t: 5, Action: 165, Reward: 1.17, Epsilon: 0.30
[INFO] model update: t: 710, loss: 152172.40625
[INFO] Global_t: 710, Episode_t: 6, Action: 100, Reward: 1.37, Epsilon: 0.30
[INFO] model update: t: 711, loss: 30073.85546875
[INFO] Global_t: 711, Episode_t: 7, Action: 160, Reward: 1.27, Epsilon: 0.29
[INFO] model update: t: 712, loss: 134407.15625
[INFO] Global_t: 712, Episode_t: 8, Action: 112, Reward: 1.51, Epsilon: 0.29
 36%|███▌      | 712/2000 [14:49<27:58,  1.30s/it]
[INFO] Global step: 712, Cumulative rewards: 12.23604, Runtime (s): 889.13
------------------------------------------------------------
 
graph: 89, nodes: 199, edges: 588
[INFO] model update: t: 713, loss: 191265.65625
[INFO] Global_t: 713, Episode_t: 1, Action: 61, Reward: 2.24, Epsilon: 0.29
[INFO] model update: t: 714, loss: 96486.734375
[INFO] Global_t: 714, Episode_t: 2, Action: 144, Reward: 1.45, Epsilon: 0.29
[INFO] model update: t: 715, loss: 128914.1328125
[INFO] Global_t: 715, Episode_t: 3, Action: 44, Reward: 2.05, Epsilon: 0.29
[INFO] model update: t: 716, loss: 20426.921875
[INFO] Global_t: 716, Episode_t: 4, Action: 53, Reward: 1.75, Epsilon: 0.29
[INFO] model update: t: 717, loss: 91656.203125
[INFO] Global_t: 717, Episode_t: 5, Action: 51, Reward: 1.73, Epsilon: 0.29
[INFO] model update: t: 718, loss: 72356.96875
[INFO] Global_t: 718, Episode_t: 6, Action: 25, Reward: 2.22, Epsilon: 0.29
[INFO] model update: t: 719, loss: 116771.3671875
[INFO] Global_t: 719, Episode_t: 7, Action: 16, Reward: 1.79, Epsilon: 0.29
[INFO] model update: t: 720, loss: 60420.09375
[INFO] Global_t: 720, Episode_t: 8, Action: 26, Reward: 0.94, Epsilon: 0.29
 36%|███▌      | 720/2000 [14:53<22:37,  1.06s/it]
[INFO] Global step: 720, Cumulative rewards: 14.174399999999999, Runtime (s): 893.09
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2779266834259033
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.288388729095459
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.9876708984375
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2341511249542236
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.418470859527588
average cummulative reward vector is:  [0.08449579 0.0745206  0.07464317 0.07291028 0.08396478]
average cummulative reward is:  0.0781069252089023
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 90, nodes: 207, edges: 612
[INFO] model update: t: 721, loss: 59072.609375
[INFO] Global_t: 721, Episode_t: 1, Action: 54, Reward: 2.20, Epsilon: 0.28
[INFO] model update: t: 722, loss: 58694.83203125
[INFO] Global_t: 722, Episode_t: 2, Action: 83, Reward: 1.76, Epsilon: 0.28
[INFO] model update: t: 723, loss: 51338.35546875
[INFO] Global_t: 723, Episode_t: 3, Action: 149, Reward: 1.74, Epsilon: 0.28
[INFO] model update: t: 724, loss: 84170.0390625
[INFO] Global_t: 724, Episode_t: 4, Action: 106, Reward: 1.96, Epsilon: 0.28
[INFO] model update: t: 725, loss: 38084.4921875
[INFO] Global_t: 725, Episode_t: 5, Action: 132, Reward: 1.27, Epsilon: 0.28
[INFO] model update: t: 726, loss: 68166.40625
[INFO] Global_t: 726, Episode_t: 6, Action: 156, Reward: 1.31, Epsilon: 0.28
[INFO] model update: t: 727, loss: 54044.8203125
[INFO] Global_t: 727, Episode_t: 7, Action: 45, Reward: 1.77, Epsilon: 0.28
[INFO] model update: t: 728, loss: 82433.921875
[INFO] Global_t: 728, Episode_t: 8, Action: 195, Reward: 1.73, Epsilon: 0.28
 36%|███▋      | 728/2000 [15:07<27:04,  1.28s/it]
[INFO] Global step: 728, Cumulative rewards: 13.725719999999999, Runtime (s): 907.34
------------------------------------------------------------
 
graph: 91, nodes: 198, edges: 585
[INFO] model update: t: 729, loss: 39955.15625
[INFO] Global_t: 729, Episode_t: 1, Action: 197, Reward: 2.44, Epsilon: 0.28
[INFO] model update: t: 730, loss: 83097.8515625
[INFO] Global_t: 730, Episode_t: 2, Action: 161, Reward: 0.97, Epsilon: 0.28
[INFO] model update: t: 731, loss: 50896.87109375
[INFO] Global_t: 731, Episode_t: 3, Action: 165, Reward: 0.90, Epsilon: 0.27
[INFO] model update: t: 732, loss: 50950.328125
[INFO] Global_t: 732, Episode_t: 4, Action: 130, Reward: 2.04, Epsilon: 0.27
[INFO] model update: t: 733, loss: 51959.72265625
[INFO] Global_t: 733, Episode_t: 5, Action: 158, Reward: 2.02, Epsilon: 0.27
[INFO] model update: t: 734, loss: 97451.53125
[INFO] Global_t: 734, Episode_t: 6, Action: 149, Reward: 1.52, Epsilon: 0.27
[INFO] model update: t: 735, loss: 54080.4296875
[INFO] Global_t: 735, Episode_t: 7, Action: 145, Reward: 0.94, Epsilon: 0.27
[INFO] model update: t: 736, loss: 123821.03125
[INFO] Global_t: 736, Episode_t: 8, Action: 16, Reward: 1.86, Epsilon: 0.27
 37%|███▋      | 736/2000 [15:10<21:19,  1.01s/it]
[INFO] Global step: 736, Cumulative rewards: 12.68196, Runtime (s): 910.50
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.04622483253479
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.536129951477051
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2070634365081787
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4135496616363525
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0321173667907715
average cummulative reward vector is:  [0.07783263 0.07636181 0.08423169 0.07814953 0.07316344]
average cummulative reward is:  0.07794782093881389
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 92, nodes: 183, edges: 539
[INFO] model update: t: 737, loss: 111415.625
[INFO] Global_t: 737, Episode_t: 1, Action: 57, Reward: 1.93, Epsilon: 0.27
[INFO] model update: t: 738, loss: 27167.58984375
[INFO] Global_t: 738, Episode_t: 2, Action: 141, Reward: 1.57, Epsilon: 0.27
[INFO] model update: t: 739, loss: 95145.7109375
[INFO] Global_t: 739, Episode_t: 3, Action: 69, Reward: 2.42, Epsilon: 0.27
[INFO] model update: t: 740, loss: 58605.9453125
[INFO] Global_t: 740, Episode_t: 4, Action: 66, Reward: 2.33, Epsilon: 0.27
[INFO] model update: t: 741, loss: 182434.859375
[INFO] Global_t: 741, Episode_t: 5, Action: 18, Reward: 2.45, Epsilon: 0.26
[INFO] model update: t: 742, loss: 344206.34375
[INFO] Global_t: 742, Episode_t: 6, Action: 90, Reward: 1.96, Epsilon: 0.26
[INFO] model update: t: 743, loss: 37081.953125
[INFO] Global_t: 743, Episode_t: 7, Action: 111, Reward: 1.56, Epsilon: 0.26
[INFO] model update: t: 744, loss: 150149.6875
[INFO] Global_t: 744, Episode_t: 8, Action: 128, Reward: 1.39, Epsilon: 0.26
 37%|███▋      | 744/2000 [15:24<25:50,  1.23s/it]
[INFO] Global step: 744, Cumulative rewards: 15.614279999999999, Runtime (s): 924.53
------------------------------------------------------------
 
graph: 93, nodes: 217, edges: 642
[INFO] model update: t: 745, loss: 181540.375
[INFO] Global_t: 745, Episode_t: 1, Action: 195, Reward: 1.75, Epsilon: 0.26
[INFO] model update: t: 746, loss: 482633.125
[INFO] Global_t: 746, Episode_t: 2, Action: 170, Reward: 2.45, Epsilon: 0.26
[INFO] model update: t: 747, loss: 62802.87890625
[INFO] Global_t: 747, Episode_t: 3, Action: 207, Reward: 1.92, Epsilon: 0.26
[INFO] model update: t: 748, loss: 489099.6875
[INFO] Global_t: 748, Episode_t: 4, Action: 182, Reward: 1.86, Epsilon: 0.26
[INFO] model update: t: 749, loss: 53238.38671875
[INFO] Global_t: 749, Episode_t: 5, Action: 132, Reward: 1.76, Epsilon: 0.26
[INFO] model update: t: 750, loss: 260575.09375
[INFO] Global_t: 750, Episode_t: 6, Action: 106, Reward: 1.86, Epsilon: 0.26
[INFO] model update: t: 751, loss: 44420.16015625
[INFO] Global_t: 751, Episode_t: 7, Action: 107, Reward: 1.99, Epsilon: 0.26
[INFO] model update: t: 752, loss: 420212.71875
[INFO] Global_t: 752, Episode_t: 8, Action: 79, Reward: 1.75, Epsilon: 0.25
 38%|███▊      | 752/2000 [15:27<20:10,  1.03it/s]
[INFO] Global step: 752, Cumulative rewards: 15.34416, Runtime (s): 927.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0980353355407715
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.358011484146118
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.371196985244751
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.156872510910034
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1226916313171387
average cummulative reward vector is:  [0.07944553 0.07685625 0.08706366 0.07188084 0.08231909]
average cummulative reward is:  0.07951307293219519
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 94, nodes: 198, edges: 585
[INFO] model update: t: 753, loss: 155896.109375
[INFO] Global_t: 753, Episode_t: 1, Action: 173, Reward: 1.42, Epsilon: 0.25
[INFO] model update: t: 754, loss: 424340.5625
[INFO] Global_t: 754, Episode_t: 2, Action: 20, Reward: 2.27, Epsilon: 0.25
[INFO] model update: t: 755, loss: 259822.21875
[INFO] Global_t: 755, Episode_t: 3, Action: 109, Reward: 2.06, Epsilon: 0.25
[INFO] model update: t: 756, loss: 292383.8125
[INFO] Global_t: 756, Episode_t: 4, Action: 132, Reward: 2.01, Epsilon: 0.25
[INFO] model update: t: 757, loss: 113005.1875
[INFO] Global_t: 757, Episode_t: 5, Action: 128, Reward: 1.78, Epsilon: 0.25
[INFO] model update: t: 758, loss: 369085.15625
[INFO] Global_t: 758, Episode_t: 6, Action: 77, Reward: 2.24, Epsilon: 0.25
[INFO] model update: t: 759, loss: 273335.28125
[INFO] Global_t: 759, Episode_t: 7, Action: 119, Reward: 2.21, Epsilon: 0.25
[INFO] model update: t: 760, loss: 117453.1484375
[INFO] Global_t: 760, Episode_t: 8, Action: 70, Reward: 1.92, Epsilon: 0.25
 38%|███▊      | 760/2000 [15:40<24:31,  1.19s/it]
[INFO] Global step: 760, Cumulative rewards: 15.911999999999999, Runtime (s): 940.90
------------------------------------------------------------
 
graph: 95, nodes: 202, edges: 597
[INFO] model update: t: 761, loss: 308146.21875
[INFO] Global_t: 761, Episode_t: 1, Action: 117, Reward: 2.16, Epsilon: 0.25
[INFO] model update: t: 762, loss: 62672.3125
[INFO] Global_t: 762, Episode_t: 2, Action: 57, Reward: 2.34, Epsilon: 0.24
[INFO] model update: t: 763, loss: 359661.875
[INFO] Global_t: 763, Episode_t: 3, Action: 46, Reward: 2.24, Epsilon: 0.24
[INFO] model update: t: 764, loss: 113256.71875
[INFO] Global_t: 764, Episode_t: 4, Action: 101, Reward: 1.94, Epsilon: 0.24
[INFO] model update: t: 765, loss: 73682.8828125
[INFO] Global_t: 765, Episode_t: 5, Action: 191, Reward: 1.61, Epsilon: 0.24
[INFO] model update: t: 766, loss: 58238.234375
[INFO] Global_t: 766, Episode_t: 6, Action: 107, Reward: 1.68, Epsilon: 0.24
[INFO] model update: t: 767, loss: 134440.53125
[INFO] Global_t: 767, Episode_t: 7, Action: 75, Reward: 1.69, Epsilon: 0.24
[INFO] model update: t: 768, loss: 81869.78125
[INFO] Global_t: 768, Episode_t: 8, Action: 72, Reward: 2.16, Epsilon: 0.24
 38%|███▊      | 768/2000 [15:44<20:03,  1.02it/s]
[INFO] Global step: 768, Cumulative rewards: 15.808679999999999, Runtime (s): 944.79
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0623385906219482
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.299013376235962
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.091339349746704
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1844589710235596
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.296980142593384
average cummulative reward vector is:  [0.07633605 0.07322431 0.08143306 0.07154393 0.08312285]
average cummulative reward is:  0.07713203859848691
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 96, nodes: 200, edges: 591
[INFO] model update: t: 769, loss: 104151.359375
[INFO] Global_t: 769, Episode_t: 1, Action: 177, Reward: 1.98, Epsilon: 0.24
[INFO] model update: t: 770, loss: 60999.3203125
[INFO] Global_t: 770, Episode_t: 2, Action: 183, Reward: 2.42, Epsilon: 0.24
[INFO] model update: t: 771, loss: 235811.3125
[INFO] Global_t: 771, Episode_t: 3, Action: 104, Reward: 2.07, Epsilon: 0.24
[INFO] model update: t: 772, loss: 148365.0
[INFO] Global_t: 772, Episode_t: 4, Action: 197, Reward: 0.71, Epsilon: 0.23
[INFO] model update: t: 773, loss: 206948.78125
[INFO] Global_t: 773, Episode_t: 5, Action: 67, Reward: 1.68, Epsilon: 0.23
[INFO] model update: t: 774, loss: 181819.484375
[INFO] Global_t: 774, Episode_t: 6, Action: 158, Reward: 1.75, Epsilon: 0.23
[INFO] model update: t: 775, loss: 180004.609375
[INFO] Global_t: 775, Episode_t: 7, Action: 95, Reward: 1.77, Epsilon: 0.23
[INFO] model update: t: 776, loss: 451053.375
[INFO] Global_t: 776, Episode_t: 8, Action: 59, Reward: 1.62, Epsilon: 0.23
 39%|███▉      | 776/2000 [15:58<24:21,  1.19s/it]
[INFO] Global step: 776, Cumulative rewards: 14.011199999999999, Runtime (s): 958.39
------------------------------------------------------------
 
graph: 97, nodes: 206, edges: 609
[INFO] model update: t: 777, loss: 118973.65625
[INFO] Global_t: 777, Episode_t: 1, Action: 12, Reward: 2.11, Epsilon: 0.23
[INFO] model update: t: 778, loss: 355174.875
[INFO] Global_t: 778, Episode_t: 2, Action: 117, Reward: 1.16, Epsilon: 0.23
[INFO] model update: t: 779, loss: 42706.56640625
[INFO] Global_t: 779, Episode_t: 3, Action: 38, Reward: 2.20, Epsilon: 0.23
[INFO] model update: t: 780, loss: 241882.578125
[INFO] Global_t: 780, Episode_t: 4, Action: 110, Reward: 1.65, Epsilon: 0.23
[INFO] model update: t: 781, loss: 40943.7578125
[INFO] Global_t: 781, Episode_t: 5, Action: 166, Reward: 1.88, Epsilon: 0.23
[INFO] model update: t: 782, loss: 401230.25
[INFO] Global_t: 782, Episode_t: 6, Action: 71, Reward: 1.72, Epsilon: 0.22
[INFO] model update: t: 783, loss: 209600.796875
[INFO] Global_t: 783, Episode_t: 7, Action: 194, Reward: 0.93, Epsilon: 0.22
[INFO] model update: t: 784, loss: 126561.546875
[INFO] Global_t: 784, Episode_t: 8, Action: 88, Reward: 1.90, Epsilon: 0.22
 39%|███▉      | 784/2000 [16:02<19:56,  1.02it/s]
[INFO] Global step: 784, Cumulative rewards: 13.541519999999998, Runtime (s): 962.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.156583547592163
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.324603796005249
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.174621343612671
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.143812656402588
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1548640727996826
average cummulative reward vector is:  [0.07544763 0.07426343 0.08563224 0.07122009 0.08068038]
average cummulative reward is:  0.07744875354881234
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 98, nodes: 206, edges: 607
[INFO] model update: t: 785, loss: 171014.125
[INFO] Global_t: 785, Episode_t: 1, Action: 24, Reward: 2.12, Epsilon: 0.22
[INFO] model update: t: 786, loss: 52955.18359375
[INFO] Global_t: 786, Episode_t: 2, Action: 71, Reward: 1.78, Epsilon: 0.22
[INFO] model update: t: 787, loss: 87872.2578125
[INFO] Global_t: 787, Episode_t: 3, Action: 52, Reward: 1.89, Epsilon: 0.22
[INFO] model update: t: 788, loss: 69088.1953125
[INFO] Global_t: 788, Episode_t: 4, Action: 55, Reward: 1.51, Epsilon: 0.22
[INFO] model update: t: 789, loss: 70862.796875
[INFO] Global_t: 789, Episode_t: 5, Action: 49, Reward: 1.80, Epsilon: 0.22
[INFO] model update: t: 790, loss: 53595.65625
[INFO] Global_t: 790, Episode_t: 6, Action: 26, Reward: 1.78, Epsilon: 0.22
[INFO] model update: t: 791, loss: 61643.8046875
[INFO] Global_t: 791, Episode_t: 7, Action: 166, Reward: 1.40, Epsilon: 0.22
[INFO] model update: t: 792, loss: 69910.328125
[INFO] Global_t: 792, Episode_t: 8, Action: 153, Reward: 1.24, Epsilon: 0.21
 40%|███▉      | 792/2000 [16:16<24:53,  1.24s/it]
[INFO] Global step: 792, Cumulative rewards: 13.529399999999999, Runtime (s): 976.95
------------------------------------------------------------
 
graph: 99, nodes: 181, edges: 533
[INFO] model update: t: 793, loss: 44226.92578125
[INFO] Global_t: 793, Episode_t: 1, Action: 59, Reward: 2.41, Epsilon: 0.21
[INFO] model update: t: 794, loss: 47925.890625
[INFO] Global_t: 794, Episode_t: 2, Action: 150, Reward: 2.18, Epsilon: 0.21
[INFO] model update: t: 795, loss: 44940.24609375
[INFO] Global_t: 795, Episode_t: 3, Action: 98, Reward: 1.68, Epsilon: 0.21
[INFO] model update: t: 796, loss: 82229.03125
[INFO] Global_t: 796, Episode_t: 4, Action: 143, Reward: 1.45, Epsilon: 0.21
[INFO] model update: t: 797, loss: 74977.265625
[INFO] Global_t: 797, Episode_t: 5, Action: 148, Reward: 1.46, Epsilon: 0.21
[INFO] model update: t: 798, loss: 29115.18359375
[INFO] Global_t: 798, Episode_t: 6, Action: 154, Reward: 1.77, Epsilon: 0.21
[INFO] model update: t: 799, loss: 84605.53125
[INFO] Global_t: 799, Episode_t: 7, Action: 79, Reward: 1.71, Epsilon: 0.21
[INFO] model update: t: 800, loss: 58115.90625
[INFO] Global_t: 800, Episode_t: 8, Action: 155, Reward: 1.66, Epsilon: 0.21
 40%|████      | 800/2000 [16:20<20:11,  1.01s/it]
[INFO] Global step: 800, Cumulative rewards: 14.31384, Runtime (s): 980.78
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1425929069519043
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.5413146018981934
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2652602195739746
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.075742244720459
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3571105003356934
average cummulative reward vector is:  [0.07969158 0.07337986 0.08592678 0.06728972 0.08903548]
average cummulative reward is:  0.07906468390237993
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 100, nodes: 188, edges: 555
[INFO] model update: t: 801, loss: 16717.375
[INFO] Global_t: 801, Episode_t: 1, Action: 73, Reward: 2.40, Epsilon: 0.21
[INFO] model update: t: 802, loss: 51626.21875
[INFO] Global_t: 802, Episode_t: 2, Action: 32, Reward: 2.38, Epsilon: 0.21
[INFO] model update: t: 803, loss: 106143.28125
[INFO] Global_t: 803, Episode_t: 3, Action: 171, Reward: 1.68, Epsilon: 0.20
[INFO] model update: t: 804, loss: 78482.7734375
[INFO] Global_t: 804, Episode_t: 4, Action: 119, Reward: 1.57, Epsilon: 0.20
[INFO] model update: t: 805, loss: 58075.22265625
[INFO] Global_t: 805, Episode_t: 5, Action: 69, Reward: 2.32, Epsilon: 0.20
[INFO] model update: t: 806, loss: 43919.5078125
[INFO] Global_t: 806, Episode_t: 6, Action: 33, Reward: 2.13, Epsilon: 0.20
[INFO] model update: t: 807, loss: 91587.9453125
[INFO] Global_t: 807, Episode_t: 7, Action: 158, Reward: 1.30, Epsilon: 0.20
[INFO] model update: t: 808, loss: 157748.59375
[INFO] Global_t: 808, Episode_t: 8, Action: 187, Reward: 1.25, Epsilon: 0.20
 40%|████      | 808/2000 [16:36<25:35,  1.29s/it]
[INFO] Global step: 808, Cumulative rewards: 15.039359999999999, Runtime (s): 996.29
------------------------------------------------------------
 
graph: 101, nodes: 211, edges: 624
[INFO] model update: t: 809, loss: 46387.6953125
[INFO] Global_t: 809, Episode_t: 1, Action: 119, Reward: 2.42, Epsilon: 0.20
[INFO] model update: t: 810, loss: 137056.859375
[INFO] Global_t: 810, Episode_t: 2, Action: 171, Reward: 2.37, Epsilon: 0.20
[INFO] model update: t: 811, loss: 182367.703125
[INFO] Global_t: 811, Episode_t: 3, Action: 113, Reward: 2.32, Epsilon: 0.20
[INFO] model update: t: 812, loss: 25488.26171875
[INFO] Global_t: 812, Episode_t: 4, Action: 101, Reward: 2.03, Epsilon: 0.20
[INFO] model update: t: 813, loss: 241803.546875
[INFO] Global_t: 813, Episode_t: 5, Action: 85, Reward: 2.06, Epsilon: 0.19
[INFO] model update: t: 814, loss: 126398.046875
[INFO] Global_t: 814, Episode_t: 6, Action: 92, Reward: 1.87, Epsilon: 0.19
[INFO] model update: t: 815, loss: 70183.421875
[INFO] Global_t: 815, Episode_t: 7, Action: 76, Reward: 1.98, Epsilon: 0.19
[INFO] model update: t: 816, loss: 137759.796875
[INFO] Global_t: 816, Episode_t: 8, Action: 117, Reward: 2.03, Epsilon: 0.19
 41%|████      | 816/2000 [16:39<19:59,  1.01s/it]
[INFO] Global step: 816, Cumulative rewards: 17.08308, Runtime (s): 999.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2565643787384033
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.4006447792053223
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.224679470062256
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2140324115753174
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2446413040161133
average cummulative reward vector is:  [0.08673079 0.07632824 0.08012432 0.07312266 0.08573011]
average cummulative reward is:  0.08040722364651984
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 102, nodes: 180, edges: 531
[INFO] model update: t: 817, loss: 61810.0625
[INFO] Global_t: 817, Episode_t: 1, Action: 123, Reward: 2.65, Epsilon: 0.19
[INFO] model update: t: 818, loss: 62538.78125
[INFO] Global_t: 818, Episode_t: 2, Action: 24, Reward: 2.02, Epsilon: 0.19
[INFO] model update: t: 819, loss: 131597.140625
[INFO] Global_t: 819, Episode_t: 3, Action: 26, Reward: 1.67, Epsilon: 0.19
[INFO] model update: t: 820, loss: 245779.78125
[INFO] Global_t: 820, Episode_t: 4, Action: 106, Reward: 1.50, Epsilon: 0.19
[INFO] model update: t: 821, loss: 43886.6875
[INFO] Global_t: 821, Episode_t: 5, Action: 42, Reward: 1.20, Epsilon: 0.19
[INFO] model update: t: 822, loss: 80511.296875
[INFO] Global_t: 822, Episode_t: 6, Action: 144, Reward: 1.42, Epsilon: 0.19
[INFO] model update: t: 823, loss: 35842.4453125
[INFO] Global_t: 823, Episode_t: 7, Action: 103, Reward: 1.40, Epsilon: 0.18
[INFO] model update: t: 824, loss: 68198.8359375
[INFO] Global_t: 824, Episode_t: 8, Action: 99, Reward: 1.64, Epsilon: 0.18
 41%|████      | 824/2000 [16:54<24:56,  1.27s/it]
[INFO] Global step: 824, Cumulative rewards: 13.491000000000003, Runtime (s): 1014.29
------------------------------------------------------------
 
graph: 103, nodes: 187, edges: 551
[INFO] model update: t: 825, loss: 99533.0078125
[INFO] Global_t: 825, Episode_t: 1, Action: 36, Reward: 2.00, Epsilon: 0.18
[INFO] model update: t: 826, loss: 91171.515625
[INFO] Global_t: 826, Episode_t: 2, Action: 145, Reward: 1.74, Epsilon: 0.18
[INFO] model update: t: 827, loss: 77935.671875
[INFO] Global_t: 827, Episode_t: 3, Action: 121, Reward: 1.78, Epsilon: 0.18
[INFO] model update: t: 828, loss: 69709.71875
[INFO] Global_t: 828, Episode_t: 4, Action: 42, Reward: 1.68, Epsilon: 0.18
[INFO] model update: t: 829, loss: 55210.2109375
[INFO] Global_t: 829, Episode_t: 5, Action: 136, Reward: 1.62, Epsilon: 0.18
[INFO] model update: t: 830, loss: 66012.421875
[INFO] Global_t: 830, Episode_t: 6, Action: 23, Reward: 1.88, Epsilon: 0.18
[INFO] model update: t: 831, loss: 144911.3125
[INFO] Global_t: 831, Episode_t: 7, Action: 75, Reward: 1.70, Epsilon: 0.18
[INFO] model update: t: 832, loss: 54388.44140625
[INFO] Global_t: 832, Episode_t: 8, Action: 47, Reward: 1.38, Epsilon: 0.18
 42%|████▏     | 832/2000 [16:58<20:40,  1.06s/it]
[INFO] Global step: 832, Cumulative rewards: 13.78056, Runtime (s): 1018.86
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.053023338317871
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.11260724067688
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.239218235015869
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2034475803375244
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.256167411804199
average cummulative reward vector is:  [0.07499421 0.06914606 0.08874372 0.06682991 0.08756263]
average cummulative reward is:  0.07745530642775666
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 104, nodes: 185, edges: 546
[INFO] model update: t: 833, loss: 154746.375
[INFO] Global_t: 833, Episode_t: 1, Action: 135, Reward: 2.02, Epsilon: 0.17
[INFO] model update: t: 834, loss: 220253.609375
[INFO] Global_t: 834, Episode_t: 2, Action: 79, Reward: 2.06, Epsilon: 0.17
[INFO] model update: t: 835, loss: 128462.953125
[INFO] Global_t: 835, Episode_t: 3, Action: 57, Reward: 1.91, Epsilon: 0.17
[INFO] model update: t: 836, loss: 425066.84375
[INFO] Global_t: 836, Episode_t: 4, Action: 89, Reward: 1.83, Epsilon: 0.17
[INFO] model update: t: 837, loss: 134662.125
[INFO] Global_t: 837, Episode_t: 5, Action: 165, Reward: 1.67, Epsilon: 0.17
[INFO] model update: t: 838, loss: 154399.46875
[INFO] Global_t: 838, Episode_t: 6, Action: 40, Reward: 1.66, Epsilon: 0.17
[INFO] model update: t: 839, loss: 403594.21875
[INFO] Global_t: 839, Episode_t: 7, Action: 21, Reward: 1.48, Epsilon: 0.17
[INFO] model update: t: 840, loss: 98156.15625
[INFO] Global_t: 840, Episode_t: 8, Action: 32, Reward: 1.63, Epsilon: 0.17
 42%|████▏     | 840/2000 [17:12<24:21,  1.26s/it]
[INFO] Global step: 840, Cumulative rewards: 14.25348, Runtime (s): 1032.63
------------------------------------------------------------
 
graph: 105, nodes: 180, edges: 531
[INFO] model update: t: 841, loss: 182170.421875
[INFO] Global_t: 841, Episode_t: 1, Action: 131, Reward: 1.87, Epsilon: 0.17
[INFO] model update: t: 842, loss: 219881.953125
[INFO] Global_t: 842, Episode_t: 2, Action: 37, Reward: 1.68, Epsilon: 0.17
[INFO] model update: t: 843, loss: 99509.71875
[INFO] Global_t: 843, Episode_t: 3, Action: 24, Reward: 1.80, Epsilon: 0.16
[INFO] model update: t: 844, loss: 368088.5625
[INFO] Global_t: 844, Episode_t: 4, Action: 72, Reward: 1.58, Epsilon: 0.16
[INFO] model update: t: 845, loss: 18068.421875
[INFO] Global_t: 845, Episode_t: 5, Action: 100, Reward: 1.22, Epsilon: 0.16
[INFO] model update: t: 846, loss: 313579.875
[INFO] Global_t: 846, Episode_t: 6, Action: 92, Reward: 1.41, Epsilon: 0.16
[INFO] model update: t: 847, loss: 82721.9453125
[INFO] Global_t: 847, Episode_t: 7, Action: 33, Reward: 0.92, Epsilon: 0.16
[INFO] model update: t: 848, loss: 234571.1875
[INFO] Global_t: 848, Episode_t: 8, Action: 134, Reward: 1.02, Epsilon: 0.16
 42%|████▏     | 848/2000 [17:15<19:16,  1.00s/it]
[INFO] Global step: 848, Cumulative rewards: 11.51448, Runtime (s): 1035.88
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.282691717147827
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2403435707092285
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.238468885421753
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.266111135482788
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4579505920410156
average cummulative reward vector is:  [0.08144474 0.07447986 0.08702623 0.07694579 0.08680457]
average cummulative reward is:  0.08134023834928192
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 106, nodes: 206, edges: 608
[INFO] model update: t: 849, loss: 229146.875
[INFO] Global_t: 849, Episode_t: 1, Action: 15, Reward: 2.17, Epsilon: 0.16
[INFO] model update: t: 850, loss: 117154.5625
[INFO] Global_t: 850, Episode_t: 2, Action: 113, Reward: 2.30, Epsilon: 0.16
[INFO] model update: t: 851, loss: 357342.5
[INFO] Global_t: 851, Episode_t: 3, Action: 128, Reward: 1.55, Epsilon: 0.16
[INFO] model update: t: 852, loss: 25826.833984375
[INFO] Global_t: 852, Episode_t: 4, Action: 203, Reward: 1.97, Epsilon: 0.16
[INFO] model update: t: 853, loss: 264412.9375
[INFO] Global_t: 853, Episode_t: 5, Action: 83, Reward: 1.63, Epsilon: 0.16
[INFO] model update: t: 854, loss: 66559.09375
[INFO] Global_t: 854, Episode_t: 6, Action: 57, Reward: 1.40, Epsilon: 0.15
[INFO] model update: t: 855, loss: 151623.71875
[INFO] Global_t: 855, Episode_t: 7, Action: 31, Reward: 1.92, Epsilon: 0.15
[INFO] model update: t: 856, loss: 76925.2578125
[INFO] Global_t: 856, Episode_t: 8, Action: 117, Reward: 1.23, Epsilon: 0.15
 43%|████▎     | 856/2000 [17:31<24:23,  1.28s/it]
[INFO] Global step: 856, Cumulative rewards: 14.185799999999999, Runtime (s): 1051.26
------------------------------------------------------------
 
graph: 107, nodes: 205, edges: 606
[INFO] model update: t: 857, loss: 78334.734375
[INFO] Global_t: 857, Episode_t: 1, Action: 183, Reward: 2.20, Epsilon: 0.15
[INFO] model update: t: 858, loss: 178258.921875
[INFO] Global_t: 858, Episode_t: 2, Action: 34, Reward: 2.28, Epsilon: 0.15
[INFO] model update: t: 859, loss: 55380.70703125
[INFO] Global_t: 859, Episode_t: 3, Action: 23, Reward: 1.94, Epsilon: 0.15
[INFO] model update: t: 860, loss: 88346.03125
[INFO] Global_t: 860, Episode_t: 4, Action: 135, Reward: 1.67, Epsilon: 0.15
[INFO] model update: t: 861, loss: 124634.3046875
[INFO] Global_t: 861, Episode_t: 5, Action: 194, Reward: 1.39, Epsilon: 0.15
[INFO] model update: t: 862, loss: 35500.3984375
[INFO] Global_t: 862, Episode_t: 6, Action: 35, Reward: 1.63, Epsilon: 0.15
[INFO] model update: t: 863, loss: 50211.140625
[INFO] Global_t: 863, Episode_t: 7, Action: 65, Reward: 1.96, Epsilon: 0.15
[INFO] model update: t: 864, loss: 59278.0625
[INFO] Global_t: 864, Episode_t: 8, Action: 105, Reward: 1.18, Epsilon: 0.14
 43%|████▎     | 864/2000 [17:34<19:36,  1.04s/it]
[INFO] Global step: 864, Cumulative rewards: 14.236440000000004, Runtime (s): 1054.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.421201705932617
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.017991542816162
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.178956985473633
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.330343723297119
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2803659439086914
average cummulative reward vector is:  [0.08264658 0.06479051 0.08295574 0.07840701 0.0839371 ]
average cummulative reward is:  0.07854738640630674
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 108, nodes: 215, edges: 636
[INFO] model update: t: 865, loss: 19036.822265625
[INFO] Global_t: 865, Episode_t: 1, Action: 181, Reward: 2.28, Epsilon: 0.14
[INFO] model update: t: 866, loss: 82701.828125
[INFO] Global_t: 866, Episode_t: 2, Action: 207, Reward: 1.96, Epsilon: 0.14
[INFO] model update: t: 867, loss: 8481.4462890625
[INFO] Global_t: 867, Episode_t: 3, Action: 6, Reward: 3.82, Epsilon: 0.14
[INFO] model update: t: 868, loss: 94642.4375
[INFO] Global_t: 868, Episode_t: 4, Action: 31, Reward: 1.44, Epsilon: 0.14
[INFO] model update: t: 869, loss: 45595.99609375
[INFO] Global_t: 869, Episode_t: 5, Action: 97, Reward: 1.64, Epsilon: 0.14
[INFO] model update: t: 870, loss: 25567.5546875
[INFO] Global_t: 870, Episode_t: 6, Action: 82, Reward: 1.63, Epsilon: 0.14
[INFO] model update: t: 871, loss: 23104.1953125
[INFO] Global_t: 871, Episode_t: 7, Action: 98, Reward: 1.62, Epsilon: 0.14
[INFO] model update: t: 872, loss: 63875.94140625
[INFO] Global_t: 872, Episode_t: 8, Action: 190, Reward: 1.75, Epsilon: 0.14
 44%|████▎     | 872/2000 [17:50<24:42,  1.31s/it]
[INFO] Global step: 872, Cumulative rewards: 16.13364, Runtime (s): 1070.71
------------------------------------------------------------
 
graph: 109, nodes: 186, edges: 549
[INFO] model update: t: 873, loss: 219696.90625
[INFO] Global_t: 873, Episode_t: 1, Action: 151, Reward: 2.76, Epsilon: 0.14
[INFO] model update: t: 874, loss: 237925.96875
[INFO] Global_t: 874, Episode_t: 2, Action: 62, Reward: 1.83, Epsilon: 0.13
[INFO] model update: t: 875, loss: 16909.650390625
[INFO] Global_t: 875, Episode_t: 3, Action: 40, Reward: 1.78, Epsilon: 0.13
[INFO] model update: t: 876, loss: 131170.125
[INFO] Global_t: 876, Episode_t: 4, Action: 48, Reward: 3.01, Epsilon: 0.13
[INFO] model update: t: 877, loss: 50895.578125
[INFO] Global_t: 877, Episode_t: 5, Action: 69, Reward: 1.65, Epsilon: 0.13
[INFO] model update: t: 878, loss: 61803.7109375
[INFO] Global_t: 878, Episode_t: 6, Action: 82, Reward: 1.45, Epsilon: 0.13
[INFO] model update: t: 879, loss: 123260.4375
[INFO] Global_t: 879, Episode_t: 7, Action: 100, Reward: 1.04, Epsilon: 0.13
[INFO] model update: t: 880, loss: 31191.583984375
[INFO] Global_t: 880, Episode_t: 8, Action: 145, Reward: 1.22, Epsilon: 0.13
 44%|████▍     | 880/2000 [17:54<20:03,  1.07s/it]
[INFO] Global step: 880, Cumulative rewards: 14.7426, Runtime (s): 1074.84
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.292858362197876
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.281552791595459
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3760626316070557
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3340229988098145
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1796114444732666
average cummulative reward vector is:  [0.08354921 0.06688194 0.08959399 0.07268107 0.08163898]
average cummulative reward is:  0.07886903946055546
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 110, nodes: 180, edges: 531
[INFO] model update: t: 881, loss: 173705.84375
[INFO] Global_t: 881, Episode_t: 1, Action: 58, Reward: 2.46, Epsilon: 0.13
[INFO] model update: t: 882, loss: 53697.0859375
[INFO] Global_t: 882, Episode_t: 2, Action: 64, Reward: 1.85, Epsilon: 0.13
[INFO] model update: t: 883, loss: 204169.0625
[INFO] Global_t: 883, Episode_t: 3, Action: 69, Reward: 1.63, Epsilon: 0.13
[INFO] model update: t: 884, loss: 376259.53125
[INFO] Global_t: 884, Episode_t: 4, Action: 93, Reward: 1.98, Epsilon: 0.12
[INFO] model update: t: 885, loss: 133288.78125
[INFO] Global_t: 885, Episode_t: 5, Action: 114, Reward: 1.76, Epsilon: 0.12
[INFO] model update: t: 886, loss: 98986.4140625
[INFO] Global_t: 886, Episode_t: 6, Action: 27, Reward: 2.18, Epsilon: 0.12
[INFO] model update: t: 887, loss: 77097.8828125
[INFO] Global_t: 887, Episode_t: 7, Action: 115, Reward: 2.37, Epsilon: 0.12
[INFO] model update: t: 888, loss: 66569.109375
[INFO] Global_t: 888, Episode_t: 8, Action: 101, Reward: 1.75, Epsilon: 0.12
 44%|████▍     | 888/2000 [18:08<23:31,  1.27s/it]
[INFO] Global step: 888, Cumulative rewards: 15.9708, Runtime (s): 1088.63
------------------------------------------------------------
 
graph: 111, nodes: 200, edges: 591
[INFO] model update: t: 889, loss: 235859.265625
[INFO] Global_t: 889, Episode_t: 1, Action: 163, Reward: 1.76, Epsilon: 0.12
[INFO] model update: t: 890, loss: 50171.11328125
[INFO] Global_t: 890, Episode_t: 2, Action: 92, Reward: 2.37, Epsilon: 0.12
[INFO] model update: t: 891, loss: 92398.796875
[INFO] Global_t: 891, Episode_t: 3, Action: 150, Reward: 2.29, Epsilon: 0.12
[INFO] model update: t: 892, loss: 50396.9453125
[INFO] Global_t: 892, Episode_t: 4, Action: 110, Reward: 1.66, Epsilon: 0.12
[INFO] model update: t: 893, loss: 62961.375
[INFO] Global_t: 893, Episode_t: 5, Action: 155, Reward: 1.62, Epsilon: 0.12
[INFO] model update: t: 894, loss: 134861.90625
[INFO] Global_t: 894, Episode_t: 6, Action: 81, Reward: 1.60, Epsilon: 0.11
[INFO] model update: t: 895, loss: 44654.1328125
[INFO] Global_t: 895, Episode_t: 7, Action: 78, Reward: 1.61, Epsilon: 0.11
[INFO] model update: t: 896, loss: 165360.09375
[INFO] Global_t: 896, Episode_t: 8, Action: 162, Reward: 1.16, Epsilon: 0.11
 45%|████▍     | 896/2000 [18:11<18:25,  1.00s/it]
[INFO] Global step: 896, Cumulative rewards: 14.08152, Runtime (s): 1091.62
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.229029655456543
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1975905895233154
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.430832624435425
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0155298709869385
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2241921424865723
average cummulative reward vector is:  [0.08570289 0.07242338 0.08906858 0.06521706 0.08599462]
average cummulative reward is:  0.07968130666642495
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 112, nodes: 216, edges: 639
[INFO] model update: t: 897, loss: 181584.59375
[INFO] Global_t: 897, Episode_t: 1, Action: 31, Reward: 2.28, Epsilon: 0.11
[INFO] model update: t: 898, loss: 38263.24609375
[INFO] Global_t: 898, Episode_t: 2, Action: 16, Reward: 2.61, Epsilon: 0.11
[INFO] model update: t: 899, loss: 207351.671875
[INFO] Global_t: 899, Episode_t: 3, Action: 182, Reward: 2.24, Epsilon: 0.11
[INFO] model update: t: 900, loss: 21280.3359375
[INFO] Global_t: 900, Episode_t: 4, Action: 98, Reward: 2.06, Epsilon: 0.11
[INFO] model update: t: 901, loss: 138413.59375
[INFO] Global_t: 901, Episode_t: 5, Action: 181, Reward: 1.59, Epsilon: 0.11
[INFO] model update: t: 902, loss: 54375.96875
[INFO] Global_t: 902, Episode_t: 6, Action: 108, Reward: 1.48, Epsilon: 0.11
[INFO] model update: t: 903, loss: 74721.796875
[INFO] Global_t: 903, Episode_t: 7, Action: 138, Reward: 1.62, Epsilon: 0.11
[INFO] model update: t: 904, loss: 127004.5078125
[INFO] Global_t: 904, Episode_t: 8, Action: 145, Reward: 1.82, Epsilon: 0.11
 45%|████▌     | 904/2000 [18:25<22:27,  1.23s/it]
[INFO] Global step: 904, Cumulative rewards: 15.693959999999997, Runtime (s): 1105.74
------------------------------------------------------------
 
graph: 113, nodes: 217, edges: 642
[INFO] model update: t: 905, loss: 108979.09375
[INFO] Global_t: 905, Episode_t: 1, Action: 175, Reward: 2.41, Epsilon: 0.10
[INFO] model update: t: 906, loss: 374626.0625
[INFO] Global_t: 906, Episode_t: 2, Action: 196, Reward: 2.32, Epsilon: 0.10
[INFO] model update: t: 907, loss: 32902.5078125
[INFO] Global_t: 907, Episode_t: 3, Action: 166, Reward: 1.94, Epsilon: 0.10
[INFO] model update: t: 908, loss: 366917.1875
[INFO] Global_t: 908, Episode_t: 4, Action: 107, Reward: 1.72, Epsilon: 0.10
[INFO] model update: t: 909, loss: 425299.75
[INFO] Global_t: 909, Episode_t: 5, Action: 155, Reward: 1.45, Epsilon: 0.10
[INFO] model update: t: 910, loss: 102844.140625
[INFO] Global_t: 910, Episode_t: 6, Action: 142, Reward: 1.74, Epsilon: 0.10
[INFO] model update: t: 911, loss: 514978.21875
[INFO] Global_t: 911, Episode_t: 7, Action: 203, Reward: 1.22, Epsilon: 0.10
[INFO] model update: t: 912, loss: 26159.57421875
[INFO] Global_t: 912, Episode_t: 8, Action: 39, Reward: 1.91, Epsilon: 0.10
 46%|████▌     | 912/2000 [18:29<18:07,  1.00it/s]
[INFO] Global step: 912, Cumulative rewards: 14.715480000000001, Runtime (s): 1109.44
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.831613302230835
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1088643074035645
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1751081943511963
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.485726833343506
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4152109622955322
average cummulative reward vector is:  [0.06825895 0.06713472 0.08441202 0.08196168 0.08818145]
average cummulative reward is:  0.07798976506089213
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 114, nodes: 190, edges: 561
[INFO] model update: t: 913, loss: 640422.25
[INFO] Global_t: 913, Episode_t: 1, Action: 187, Reward: 2.32, Epsilon: 0.10
[INFO] model update: t: 914, loss: 92424.875
[INFO] Global_t: 914, Episode_t: 2, Action: 127, Reward: 1.61, Epsilon: 0.10
[INFO] model update: t: 915, loss: 513777.84375
[INFO] Global_t: 915, Episode_t: 3, Action: 94, Reward: 2.28, Epsilon: 0.09
[INFO] model update: t: 916, loss: 634544.1875
[INFO] Global_t: 916, Episode_t: 4, Action: 72, Reward: 1.89, Epsilon: 0.09
[INFO] model update: t: 917, loss: 14846.0234375
[INFO] Global_t: 917, Episode_t: 5, Action: 160, Reward: 1.86, Epsilon: 0.09
[INFO] model update: t: 918, loss: 461371.25
[INFO] Global_t: 918, Episode_t: 6, Action: 66, Reward: 1.75, Epsilon: 0.09
[INFO] model update: t: 919, loss: 95529.859375
[INFO] Global_t: 919, Episode_t: 7, Action: 67, Reward: 1.83, Epsilon: 0.09
[INFO] model update: t: 920, loss: 347646.78125
[INFO] Global_t: 920, Episode_t: 8, Action: 100, Reward: 1.52, Epsilon: 0.09
 46%|████▌     | 920/2000 [18:43<21:57,  1.22s/it]
[INFO] Global step: 920, Cumulative rewards: 15.05796, Runtime (s): 1123.31
------------------------------------------------------------
 
graph: 115, nodes: 198, edges: 585
[INFO] model update: t: 921, loss: 167813.03125
[INFO] Global_t: 921, Episode_t: 1, Action: 46, Reward: 2.45, Epsilon: 0.09
[INFO] model update: t: 922, loss: 108450.90625
[INFO] Global_t: 922, Episode_t: 2, Action: 63, Reward: 2.25, Epsilon: 0.09
[INFO] model update: t: 923, loss: 159826.5
[INFO] Global_t: 923, Episode_t: 3, Action: 146, Reward: 1.65, Epsilon: 0.09
[INFO] model update: t: 924, loss: 70580.15625
[INFO] Global_t: 924, Episode_t: 4, Action: 19, Reward: 2.07, Epsilon: 0.09
[INFO] model update: t: 925, loss: 439134.34375
[INFO] Global_t: 925, Episode_t: 5, Action: 23, Reward: 2.03, Epsilon: 0.08
[INFO] model update: t: 926, loss: 307284.375
[INFO] Global_t: 926, Episode_t: 6, Action: 184, Reward: 1.73, Epsilon: 0.08
[INFO] model update: t: 927, loss: 106973.296875
[INFO] Global_t: 927, Episode_t: 7, Action: 173, Reward: 1.74, Epsilon: 0.08
[INFO] model update: t: 928, loss: 460780.5
[INFO] Global_t: 928, Episode_t: 8, Action: 103, Reward: 1.85, Epsilon: 0.08

[INFO] Global step: 928, Cumulative rewards: 15.771, Runtime (s): 1125.84
------------------------------------------------------------
 
 46%|████▋     | 928/2000 [18:45<16:57,  1.05it/s]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.118572235107422
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.451881170272827
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.368640899658203
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2590856552124023
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2813005447387695
average cummulative reward vector is:  [0.08066921 0.07180417 0.09046749 0.0736722  0.08819919]
average cummulative reward is:  0.08096245066836992
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 116, nodes: 182, edges: 537
[INFO] model update: t: 929, loss: 14468.5703125
[INFO] Global_t: 929, Episode_t: 1, Action: 89, Reward: 2.25, Epsilon: 0.08
[INFO] model update: t: 930, loss: 534919.0625
[INFO] Global_t: 930, Episode_t: 2, Action: 150, Reward: 2.08, Epsilon: 0.08
[INFO] model update: t: 931, loss: 573082.3125
[INFO] Global_t: 931, Episode_t: 3, Action: 17, Reward: 1.61, Epsilon: 0.08
[INFO] model update: t: 932, loss: 53621.3203125
[INFO] Global_t: 932, Episode_t: 4, Action: 128, Reward: 1.78, Epsilon: 0.08
[INFO] model update: t: 933, loss: 310726.875
[INFO] Global_t: 933, Episode_t: 5, Action: 12, Reward: 1.67, Epsilon: 0.08
[INFO] model update: t: 934, loss: 125864.828125
[INFO] Global_t: 934, Episode_t: 6, Action: 70, Reward: 1.34, Epsilon: 0.08
[INFO] model update: t: 935, loss: 105481.1875
[INFO] Global_t: 935, Episode_t: 7, Action: 38, Reward: 1.38, Epsilon: 0.07
[INFO] model update: t: 936, loss: 118460.96875
[INFO] Global_t: 936, Episode_t: 8, Action: 58, Reward: 1.05, Epsilon: 0.07
 47%|████▋     | 936/2000 [19:01<21:56,  1.24s/it]
[INFO] Global step: 936, Cumulative rewards: 13.156560000000002, Runtime (s): 1141.12
------------------------------------------------------------
 
graph: 117, nodes: 196, edges: 579
[INFO] model update: t: 937, loss: 66772.765625
[INFO] Global_t: 937, Episode_t: 1, Action: 128, Reward: 1.36, Epsilon: 0.07
[INFO] model update: t: 938, loss: 314992.5625
[INFO] Global_t: 938, Episode_t: 2, Action: 106, Reward: 2.24, Epsilon: 0.07
[INFO] model update: t: 939, loss: 90203.953125
[INFO] Global_t: 939, Episode_t: 3, Action: 70, Reward: 2.70, Epsilon: 0.07
[INFO] model update: t: 940, loss: 185935.875
[INFO] Global_t: 940, Episode_t: 4, Action: 98, Reward: 1.79, Epsilon: 0.07
[INFO] model update: t: 941, loss: 349159.0625
[INFO] Global_t: 941, Episode_t: 5, Action: 67, Reward: 1.98, Epsilon: 0.07
[INFO] model update: t: 942, loss: 24819.1875
[INFO] Global_t: 942, Episode_t: 6, Action: 157, Reward: 2.09, Epsilon: 0.07
[INFO] model update: t: 943, loss: 221582.875
[INFO] Global_t: 943, Episode_t: 7, Action: 27, Reward: 2.24, Epsilon: 0.07
[INFO] model update: t: 944, loss: 116419.328125
[INFO] Global_t: 944, Episode_t: 8, Action: 29, Reward: 1.51, Epsilon: 0.07
 47%|████▋     | 944/2000 [19:04<17:28,  1.01it/s]
[INFO] Global step: 944, Cumulative rewards: 15.931439999999997, Runtime (s): 1144.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.16558575630188
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.4215009212493896
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.0262651443481445
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1740007400512695
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.167954206466675
average cummulative reward vector is:  [0.08082237 0.07165532 0.07846093 0.07011332 0.08247473]
average cummulative reward is:  0.07670533407933608
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 118, nodes: 180, edges: 531
[INFO] model update: t: 945, loss: 109463.0234375
[INFO] Global_t: 945, Episode_t: 1, Action: 9, Reward: 2.07, Epsilon: 0.06
[INFO] model update: t: 946, loss: 214205.0625
[INFO] Global_t: 946, Episode_t: 2, Action: 160, Reward: 1.90, Epsilon: 0.06
[INFO] model update: t: 947, loss: 49042.6796875
[INFO] Global_t: 947, Episode_t: 3, Action: 155, Reward: 1.69, Epsilon: 0.06
[INFO] model update: t: 948, loss: 85390.3359375
[INFO] Global_t: 948, Episode_t: 4, Action: 96, Reward: 1.69, Epsilon: 0.06
[INFO] model update: t: 949, loss: 231289.34375
[INFO] Global_t: 949, Episode_t: 5, Action: 61, Reward: 1.38, Epsilon: 0.06
[INFO] model update: t: 950, loss: 114978.78125
[INFO] Global_t: 950, Episode_t: 6, Action: 15, Reward: 1.15, Epsilon: 0.06
[INFO] model update: t: 951, loss: 37493.96875
[INFO] Global_t: 951, Episode_t: 7, Action: 118, Reward: 1.52, Epsilon: 0.06
[INFO] model update: t: 952, loss: 211755.46875
[INFO] Global_t: 952, Episode_t: 8, Action: 32, Reward: 1.39, Epsilon: 0.06
 48%|████▊     | 952/2000 [19:18<21:11,  1.21s/it]
[INFO] Global step: 952, Cumulative rewards: 12.78936, Runtime (s): 1158.33
------------------------------------------------------------
 
graph: 119, nodes: 182, edges: 537
[INFO] model update: t: 953, loss: 32430.07421875
[INFO] Global_t: 953, Episode_t: 1, Action: 155, Reward: 2.52, Epsilon: 0.06
[INFO] model update: t: 954, loss: 120772.3515625
[INFO] Global_t: 954, Episode_t: 2, Action: 95, Reward: 1.90, Epsilon: 0.06
[INFO] model update: t: 955, loss: 157838.703125
[INFO] Global_t: 955, Episode_t: 3, Action: 106, Reward: 1.96, Epsilon: 0.06
[INFO] model update: t: 956, loss: 8552.345703125
[INFO] Global_t: 956, Episode_t: 4, Action: 128, Reward: 2.03, Epsilon: 0.05
[INFO] model update: t: 957, loss: 120039.3984375
[INFO] Global_t: 957, Episode_t: 5, Action: 147, Reward: 1.83, Epsilon: 0.05
[INFO] model update: t: 958, loss: 45770.92578125
[INFO] Global_t: 958, Episode_t: 6, Action: 22, Reward: 1.73, Epsilon: 0.05
[INFO] model update: t: 959, loss: 88328.6328125
[INFO] Global_t: 959, Episode_t: 7, Action: 97, Reward: 1.27, Epsilon: 0.05
[INFO] model update: t: 960, loss: 161482.125
[INFO] Global_t: 960, Episode_t: 8, Action: 71, Reward: 1.49, Epsilon: 0.05
 48%|████▊     | 960/2000 [19:21<16:59,  1.02it/s]
[INFO] Global step: 960, Cumulative rewards: 14.716079999999998, Runtime (s): 1161.82
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1348254680633545
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1642966270446777
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.295665740966797
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.481773853302002
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.631596803665161
average cummulative reward vector is:  [0.08174447 0.06951157 0.0893265  0.0737771  0.09904301]
average cummulative reward is:  0.0826805328093903
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 120, nodes: 219, edges: 648
[INFO] model update: t: 961, loss: 47586.390625
[INFO] Global_t: 961, Episode_t: 1, Action: 175, Reward: 2.08, Epsilon: 0.05
[INFO] model update: t: 962, loss: 85180.390625
[INFO] Global_t: 962, Episode_t: 2, Action: 69, Reward: 1.87, Epsilon: 0.05
[INFO] model update: t: 963, loss: 235429.03125
[INFO] Global_t: 963, Episode_t: 3, Action: 18, Reward: 2.26, Epsilon: 0.05
[INFO] model update: t: 964, loss: 99894.6484375
[INFO] Global_t: 964, Episode_t: 4, Action: 86, Reward: 1.78, Epsilon: 0.05
[INFO] model update: t: 965, loss: 109544.21875
[INFO] Global_t: 965, Episode_t: 5, Action: 187, Reward: 1.63, Epsilon: 0.05
[INFO] model update: t: 966, loss: 420195.8125
[INFO] Global_t: 966, Episode_t: 6, Action: 99, Reward: 1.73, Epsilon: 0.04
[INFO] model update: t: 967, loss: 287154.90625
[INFO] Global_t: 967, Episode_t: 7, Action: 51, Reward: 1.29, Epsilon: 0.04
[INFO] model update: t: 968, loss: 10836.3583984375
[INFO] Global_t: 968, Episode_t: 8, Action: 38, Reward: 1.78, Epsilon: 0.04
 48%|████▊     | 968/2000 [19:36<21:18,  1.24s/it]
[INFO] Global step: 968, Cumulative rewards: 14.425799999999999, Runtime (s): 1176.55
------------------------------------------------------------
 
graph: 121, nodes: 182, edges: 536
[INFO] model update: t: 969, loss: 176072.25
[INFO] Global_t: 969, Episode_t: 1, Action: 15, Reward: 2.27, Epsilon: 0.04
[INFO] model update: t: 970, loss: 53735.49609375
[INFO] Global_t: 970, Episode_t: 2, Action: 44, Reward: 2.08, Epsilon: 0.04
[INFO] model update: t: 971, loss: 110184.90625
[INFO] Global_t: 971, Episode_t: 3, Action: 98, Reward: 1.77, Epsilon: 0.04
[INFO] model update: t: 972, loss: 191732.640625
[INFO] Global_t: 972, Episode_t: 4, Action: 173, Reward: 2.00, Epsilon: 0.04
[INFO] model update: t: 973, loss: 52789.6796875
[INFO] Global_t: 973, Episode_t: 5, Action: 144, Reward: 1.84, Epsilon: 0.04
[INFO] model update: t: 974, loss: 292215.84375
[INFO] Global_t: 974, Episode_t: 6, Action: 96, Reward: 1.81, Epsilon: 0.04
[INFO] model update: t: 975, loss: 363966.3125
[INFO] Global_t: 975, Episode_t: 7, Action: 161, Reward: 1.32, Epsilon: 0.04
[INFO] model update: t: 976, loss: 77875.4453125
[INFO] Global_t: 976, Episode_t: 8, Action: 21, Reward: 1.65, Epsilon: 0.03
 49%|████▉     | 976/2000 [19:39<16:40,  1.02it/s]
[INFO] Global step: 976, Cumulative rewards: 14.74152, Runtime (s): 1179.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0296928882598877
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.124424934387207
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.0965657234191895
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1477184295654297
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.418893337249756
average cummulative reward vector is:  [0.07580842 0.06976343 0.08028279 0.07166355 0.08509597]
average cummulative reward is:  0.07652283060152161
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 122, nodes: 206, edges: 609
[INFO] model update: t: 977, loss: 162672.59375
[INFO] Global_t: 977, Episode_t: 1, Action: 15, Reward: 2.24, Epsilon: 0.03
[INFO] model update: t: 978, loss: 120926.25
[INFO] Global_t: 978, Episode_t: 2, Action: 46, Reward: 2.23, Epsilon: 0.03
[INFO] model update: t: 979, loss: 84957.671875
[INFO] Global_t: 979, Episode_t: 3, Action: 65, Reward: 2.07, Epsilon: 0.03
[INFO] model update: t: 980, loss: 407338.1875
[INFO] Global_t: 980, Episode_t: 4, Action: 149, Reward: 1.80, Epsilon: 0.03
[INFO] model update: t: 981, loss: 110175.15625
[INFO] Global_t: 981, Episode_t: 5, Action: 84, Reward: 1.51, Epsilon: 0.03
[INFO] model update: t: 982, loss: 203798.15625
[INFO] Global_t: 982, Episode_t: 6, Action: 74, Reward: 1.39, Epsilon: 0.03
[INFO] model update: t: 983, loss: 94105.5625
[INFO] Global_t: 983, Episode_t: 7, Action: 16, Reward: 1.90, Epsilon: 0.03
[INFO] model update: t: 984, loss: 93332.46875
[INFO] Global_t: 984, Episode_t: 8, Action: 175, Reward: 1.11, Epsilon: 0.03
 49%|████▉     | 984/2000 [19:53<20:36,  1.22s/it]
[INFO] Global step: 984, Cumulative rewards: 14.23872, Runtime (s): 1193.70
------------------------------------------------------------
 
graph: 123, nodes: 182, edges: 537
[INFO] model update: t: 985, loss: 219624.1875
[INFO] Global_t: 985, Episode_t: 1, Action: 103, Reward: 2.06, Epsilon: 0.03
[INFO] model update: t: 986, loss: 30414.796875
[INFO] Global_t: 986, Episode_t: 2, Action: 150, Reward: 1.89, Epsilon: 0.02
[INFO] model update: t: 987, loss: 239976.09375
[INFO] Global_t: 987, Episode_t: 3, Action: 118, Reward: 1.75, Epsilon: 0.02
[INFO] model update: t: 988, loss: 181708.765625
[INFO] Global_t: 988, Episode_t: 4, Action: 86, Reward: 1.23, Epsilon: 0.02
[INFO] model update: t: 989, loss: 26273.345703125
[INFO] Global_t: 989, Episode_t: 5, Action: 74, Reward: 1.65, Epsilon: 0.02
[INFO] model update: t: 990, loss: 173417.78125
[INFO] Global_t: 990, Episode_t: 6, Action: 164, Reward: 1.19, Epsilon: 0.02
[INFO] model update: t: 991, loss: 44053.8125
[INFO] Global_t: 991, Episode_t: 7, Action: 122, Reward: 0.90, Epsilon: 0.02
[INFO] model update: t: 992, loss: 87581.765625
[INFO] Global_t: 992, Episode_t: 8, Action: 8, Reward: 2.81, Epsilon: 0.02
 50%|████▉     | 992/2000 [19:57<16:27,  1.02it/s]
[INFO] Global step: 992, Cumulative rewards: 13.472759999999997, Runtime (s): 1197.10
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1207902431488037
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.5124120712280273
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1392135620117188
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.253997802734375
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.228783369064331
average cummulative reward vector is:  [0.07663947 0.07506435 0.08119399 0.07439579 0.08379543]
average cummulative reward is:  0.07821780782143017
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 124, nodes: 194, edges: 573
[INFO] model update: t: 993, loss: 323179.71875
[INFO] Global_t: 993, Episode_t: 1, Action: 101, Reward: 2.45, Epsilon: 0.02
[INFO] model update: t: 994, loss: 197701.8125
[INFO] Global_t: 994, Episode_t: 2, Action: 57, Reward: 2.33, Epsilon: 0.02
[INFO] model update: t: 995, loss: 58358.0234375
[INFO] Global_t: 995, Episode_t: 3, Action: 63, Reward: 2.40, Epsilon: 0.02
[INFO] model update: t: 996, loss: 124474.859375
[INFO] Global_t: 996, Episode_t: 4, Action: 125, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 997, loss: 53121.3359375
[INFO] Global_t: 997, Episode_t: 5, Action: 179, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 998, loss: 295693.0625
[INFO] Global_t: 998, Episode_t: 6, Action: 68, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 999, loss: 69222.359375
[INFO] Global_t: 999, Episode_t: 7, Action: 105, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1000, loss: 355659.28125
[INFO] Global_t: 1000, Episode_t: 8, Action: 120, Reward: 1.47, Epsilon: 0.01
 50%|█████     | 1000/2000 [20:11<20:31,  1.23s/it]
[INFO] Global step: 1000, Cumulative rewards: 15.88272, Runtime (s): 1211.67
------------------------------------------------------------
 
graph: 125, nodes: 209, edges: 617
[INFO] model update: t: 1001, loss: 235756.875
[INFO] Global_t: 1001, Episode_t: 1, Action: 11, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 1002, loss: 38205.80078125
[INFO] Global_t: 1002, Episode_t: 2, Action: 133, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1003, loss: 206705.84375
[INFO] Global_t: 1003, Episode_t: 3, Action: 97, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1004, loss: 42994.5
[INFO] Global_t: 1004, Episode_t: 4, Action: 134, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1005, loss: 46353.578125
[INFO] Global_t: 1005, Episode_t: 5, Action: 196, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1006, loss: 128297.625
[INFO] Global_t: 1006, Episode_t: 6, Action: 143, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1007, loss: 89872.2265625
[INFO] Global_t: 1007, Episode_t: 7, Action: 124, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1008, loss: 40404.53125
[INFO] Global_t: 1008, Episode_t: 8, Action: 65, Reward: 0.99, Epsilon: 0.01
 50%|█████     | 1008/2000 [20:15<16:47,  1.02s/it]
[INFO] Global step: 1008, Cumulative rewards: 16.32024, Runtime (s): 1215.77
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2861580848693848
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2774698734283447
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.4476282596588135
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.221135139465332
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.340949296951294
average cummulative reward vector is:  [0.08488763 0.07455903 0.08546585 0.07169743 0.08929946]
average cummulative reward is:  0.08118187972467882
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 126, nodes: 218, edges: 645
[INFO] model update: t: 1009, loss: 39033.9765625
[INFO] Global_t: 1009, Episode_t: 1, Action: 145, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1010, loss: 173752.75
[INFO] Global_t: 1010, Episode_t: 2, Action: 165, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1011, loss: 123976.96875
[INFO] Global_t: 1011, Episode_t: 3, Action: 76, Reward: 1.48, Epsilon: 0.01
[INFO] model update: t: 1012, loss: 16190.59375
[INFO] Global_t: 1012, Episode_t: 4, Action: 127, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1013, loss: 144940.8125
[INFO] Global_t: 1013, Episode_t: 5, Action: 208, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1014, loss: 92249.140625
[INFO] Global_t: 1014, Episode_t: 6, Action: 166, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1015, loss: 34061.51171875
[INFO] Global_t: 1015, Episode_t: 7, Action: 214, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 1016, loss: 102903.03125
[INFO] Global_t: 1016, Episode_t: 8, Action: 51, Reward: 1.85, Epsilon: 0.01
 51%|█████     | 1016/2000 [20:29<20:19,  1.24s/it]
[INFO] Global step: 1016, Cumulative rewards: 15.213119999999996, Runtime (s): 1229.85
------------------------------------------------------------
 
graph: 127, nodes: 189, edges: 558
[INFO] model update: t: 1017, loss: 31542.162109375
[INFO] Global_t: 1017, Episode_t: 1, Action: 38, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1018, loss: 382121.96875
[INFO] Global_t: 1018, Episode_t: 2, Action: 111, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1019, loss: 585274.8125
[INFO] Global_t: 1019, Episode_t: 3, Action: 149, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1020, loss: 61985.47265625
[INFO] Global_t: 1020, Episode_t: 4, Action: 53, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1021, loss: 191809.328125
[INFO] Global_t: 1021, Episode_t: 5, Action: 161, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 1022, loss: 294149.3125
[INFO] Global_t: 1022, Episode_t: 6, Action: 105, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1023, loss: 32413.466796875
[INFO] Global_t: 1023, Episode_t: 7, Action: 156, Reward: 1.63, Epsilon: 0.01
[INFO] model update: t: 1024, loss: 515443.15625
[INFO] Global_t: 1024, Episode_t: 8, Action: 52, Reward: 1.60, Epsilon: 0.01
 51%|█████     | 1024/2000 [20:32<15:46,  1.03it/s]
[INFO] Global step: 1024, Cumulative rewards: 15.31356, Runtime (s): 1232.57
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9879372119903564
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2477660179138184
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2932140827178955
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.432980537414551
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3876137733459473
average cummulative reward vector is:  [0.07379868 0.0724706  0.08914098 0.07278645 0.09165833]
average cummulative reward is:  0.07997101032007994
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 128, nodes: 198, edges: 585
[INFO] model update: t: 1025, loss: 53830.515625
[INFO] Global_t: 1025, Episode_t: 1, Action: 63, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1026, loss: 548904.25
[INFO] Global_t: 1026, Episode_t: 2, Action: 99, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 1027, loss: 1083633.375
[INFO] Global_t: 1027, Episode_t: 3, Action: 189, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 1028, loss: 64374.984375
[INFO] Global_t: 1028, Episode_t: 4, Action: 43, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1029, loss: 709220.9375
[INFO] Global_t: 1029, Episode_t: 5, Action: 161, Reward: 1.11, Epsilon: 0.01
[INFO] model update: t: 1030, loss: 472977.46875
[INFO] Global_t: 1030, Episode_t: 6, Action: 148, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1031, loss: 37053.3984375
[INFO] Global_t: 1031, Episode_t: 7, Action: 15, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1032, loss: 633056.0625
[INFO] Global_t: 1032, Episode_t: 8, Action: 136, Reward: 1.24, Epsilon: 0.01
 52%|█████▏    | 1032/2000 [20:48<20:27,  1.27s/it]
[INFO] Global step: 1032, Cumulative rewards: 13.431840000000003, Runtime (s): 1248.29
------------------------------------------------------------
 
graph: 129, nodes: 211, edges: 624
[INFO] model update: t: 1033, loss: 840656.375
[INFO] Global_t: 1033, Episode_t: 1, Action: 115, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1034, loss: 324218.6875
[INFO] Global_t: 1034, Episode_t: 2, Action: 94, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1035, loss: 134833.90625
[INFO] Global_t: 1035, Episode_t: 3, Action: 163, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 1036, loss: 549819.25
[INFO] Global_t: 1036, Episode_t: 4, Action: 82, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 1037, loss: 159058.9375
[INFO] Global_t: 1037, Episode_t: 5, Action: 39, Reward: 2.08, Epsilon: 0.01
[INFO] model update: t: 1038, loss: 113704.5078125
[INFO] Global_t: 1038, Episode_t: 6, Action: 132, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1039, loss: 377456.75
[INFO] Global_t: 1039, Episode_t: 7, Action: 154, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1040, loss: 28913.47265625
[INFO] Global_t: 1040, Episode_t: 8, Action: 157, Reward: 1.55, Epsilon: 0.01
 52%|█████▏    | 1040/2000 [20:50<15:49,  1.01it/s]
[INFO] Global step: 1040, Cumulative rewards: 15.479399999999998, Runtime (s): 1250.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.334465503692627
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.335850477218628
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.349879264831543
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1975746154785156
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.441202402114868
average cummulative reward vector is:  [0.08099    0.07592176 0.09411694 0.07277757 0.08762581]
average cummulative reward is:  0.0822864151390081
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 130, nodes: 205, edges: 606
[INFO] model update: t: 1041, loss: 88329.453125
[INFO] Global_t: 1041, Episode_t: 1, Action: 20, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1042, loss: 61180.52734375
[INFO] Global_t: 1042, Episode_t: 2, Action: 191, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 1043, loss: 65809.8359375
[INFO] Global_t: 1043, Episode_t: 3, Action: 36, Reward: 2.85, Epsilon: 0.01
[INFO] model update: t: 1044, loss: 123684.0
[INFO] Global_t: 1044, Episode_t: 4, Action: 75, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1045, loss: 32432.2265625
[INFO] Global_t: 1045, Episode_t: 5, Action: 198, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 1046, loss: 121142.15625
[INFO] Global_t: 1046, Episode_t: 6, Action: 51, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1047, loss: 126200.421875
[INFO] Global_t: 1047, Episode_t: 7, Action: 143, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 1048, loss: 46895.8046875
[INFO] Global_t: 1048, Episode_t: 8, Action: 153, Reward: 1.98, Epsilon: 0.01
 52%|█████▏    | 1048/2000 [21:04<19:15,  1.21s/it]
[INFO] Global step: 1048, Cumulative rewards: 19.70376, Runtime (s): 1264.91
------------------------------------------------------------
 
graph: 131, nodes: 210, edges: 620
[INFO] model update: t: 1049, loss: 27516.091796875
[INFO] Global_t: 1049, Episode_t: 1, Action: 22, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1050, loss: 57223.296875
[INFO] Global_t: 1050, Episode_t: 2, Action: 37, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1051, loss: 24707.42578125
[INFO] Global_t: 1051, Episode_t: 3, Action: 208, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1052, loss: 12429.4306640625
[INFO] Global_t: 1052, Episode_t: 4, Action: 184, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1053, loss: 21488.734375
[INFO] Global_t: 1053, Episode_t: 5, Action: 143, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1054, loss: 39460.18359375
[INFO] Global_t: 1054, Episode_t: 6, Action: 201, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 1055, loss: 53886.15625
[INFO] Global_t: 1055, Episode_t: 7, Action: 15, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1056, loss: 18694.541015625
[INFO] Global_t: 1056, Episode_t: 8, Action: 160, Reward: 1.27, Epsilon: 0.01
 53%|█████▎    | 1056/2000 [21:07<15:02,  1.05it/s]
[INFO] Global step: 1056, Cumulative rewards: 16.61076, Runtime (s): 1267.75
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.193607807159424
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.434396505355835
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.379706382751465
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.129714012145996
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2227725982666016
average cummulative reward vector is:  [0.081275   0.06992176 0.08943825 0.06969813 0.08169086]
average cummulative reward is:  0.07840480033631095
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 132, nodes: 213, edges: 630
[INFO] model update: t: 1057, loss: 150194.90625
[INFO] Global_t: 1057, Episode_t: 1, Action: 23, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1058, loss: 98198.34375
[INFO] Global_t: 1058, Episode_t: 2, Action: 86, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1059, loss: 48179.33203125
[INFO] Global_t: 1059, Episode_t: 3, Action: 156, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1060, loss: 153387.5
[INFO] Global_t: 1060, Episode_t: 4, Action: 157, Reward: 1.89, Epsilon: 0.01
[INFO] model update: t: 1061, loss: 67627.3671875
[INFO] Global_t: 1061, Episode_t: 5, Action: 109, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1062, loss: 62013.12890625
[INFO] Global_t: 1062, Episode_t: 6, Action: 105, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1063, loss: 260987.578125
[INFO] Global_t: 1063, Episode_t: 7, Action: 165, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 1064, loss: 372745.84375
[INFO] Global_t: 1064, Episode_t: 8, Action: 202, Reward: 1.61, Epsilon: 0.01
 53%|█████▎    | 1064/2000 [21:22<19:05,  1.22s/it]
[INFO] Global step: 1064, Cumulative rewards: 14.8632, Runtime (s): 1282.53
------------------------------------------------------------
 
graph: 133, nodes: 213, edges: 630
[INFO] model update: t: 1065, loss: 153548.34375
[INFO] Global_t: 1065, Episode_t: 1, Action: 172, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1066, loss: 12291.830078125
[INFO] Global_t: 1066, Episode_t: 2, Action: 78, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1067, loss: 54324.6015625
[INFO] Global_t: 1067, Episode_t: 3, Action: 173, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1068, loss: 46540.41015625
[INFO] Global_t: 1068, Episode_t: 4, Action: 128, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1069, loss: 50765.2421875
[INFO] Global_t: 1069, Episode_t: 5, Action: 158, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1070, loss: 40711.97265625
[INFO] Global_t: 1070, Episode_t: 6, Action: 184, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1071, loss: 171630.28125
[INFO] Global_t: 1071, Episode_t: 7, Action: 10, Reward: 1.60, Epsilon: 0.01
[INFO] model update: t: 1072, loss: 62975.9609375
[INFO] Global_t: 1072, Episode_t: 8, Action: 23, Reward: 1.77, Epsilon: 0.01
 54%|█████▎    | 1072/2000 [21:25<15:07,  1.02it/s]
[INFO] Global step: 1072, Cumulative rewards: 16.28616, Runtime (s): 1285.77
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1378583908081055
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.0426292419433594
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.443565607070923
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1296496391296387
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.27941632270813
average cummulative reward vector is:  [0.07951711 0.06733727 0.08794699 0.06928855 0.0873172 ]
average cummulative reward is:  0.078281424804028
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 134, nodes: 215, edges: 635
[INFO] model update: t: 1073, loss: 14329.55078125
[INFO] Global_t: 1073, Episode_t: 1, Action: 148, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 1074, loss: 59282.828125
[INFO] Global_t: 1074, Episode_t: 2, Action: 132, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 1075, loss: 62519.87890625
[INFO] Global_t: 1075, Episode_t: 3, Action: 163, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1076, loss: 69677.484375
[INFO] Global_t: 1076, Episode_t: 4, Action: 180, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 1077, loss: 49297.484375
[INFO] Global_t: 1077, Episode_t: 5, Action: 144, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1078, loss: 95504.609375
[INFO] Global_t: 1078, Episode_t: 6, Action: 140, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1079, loss: 30856.57421875
[INFO] Global_t: 1079, Episode_t: 7, Action: 162, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1080, loss: 81953.0546875
[INFO] Global_t: 1080, Episode_t: 8, Action: 147, Reward: 1.62, Epsilon: 0.01

[INFO] Global step: 1080, Cumulative rewards: 15.791400000000001, Runtime (s): 1302.45
------------------------------------------------------------
 
 54%|█████▍    | 1080/2000 [21:42<20:05,  1.31s/it]graph: 135, nodes: 211, edges: 624
[INFO] model update: t: 1081, loss: 51351.5234375
[INFO] Global_t: 1081, Episode_t: 1, Action: 190, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1082, loss: 94200.203125
[INFO] Global_t: 1082, Episode_t: 2, Action: 63, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 1083, loss: 421526.53125
[INFO] Global_t: 1083, Episode_t: 3, Action: 176, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1084, loss: 406040.6875
[INFO] Global_t: 1084, Episode_t: 4, Action: 120, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 1085, loss: 261117.671875
[INFO] Global_t: 1085, Episode_t: 5, Action: 92, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1086, loss: 11125.58203125
[INFO] Global_t: 1086, Episode_t: 6, Action: 178, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1087, loss: 338335.53125
[INFO] Global_t: 1087, Episode_t: 7, Action: 202, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1088, loss: 173202.28125
[INFO] Global_t: 1088, Episode_t: 8, Action: 27, Reward: 1.51, Epsilon: 0.01
 54%|█████▍    | 1088/2000 [21:52<19:29,  1.28s/it]
[INFO] Global step: 1088, Cumulative rewards: 13.581479999999997, Runtime (s): 1312.18
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2285499572753906
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.184638261795044
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.9575238227844238
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1415863037109375
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.736150026321411
average cummulative reward vector is:  [0.07614158 0.07181481 0.07545765 0.07030958 0.09194247]
average cummulative reward is:  0.07713321931858784
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 136, nodes: 211, edges: 624
[INFO] model update: t: 1089, loss: 225492.75
[INFO] Global_t: 1089, Episode_t: 1, Action: 144, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1090, loss: 872684.125
[INFO] Global_t: 1090, Episode_t: 2, Action: 153, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1091, loss: 697707.875
[INFO] Global_t: 1091, Episode_t: 3, Action: 105, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 1092, loss: 379909.65625
[INFO] Global_t: 1092, Episode_t: 4, Action: 185, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1093, loss: 95186.71875
[INFO] Global_t: 1093, Episode_t: 5, Action: 72, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1094, loss: 66347.203125
[INFO] Global_t: 1094, Episode_t: 6, Action: 171, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1095, loss: 212320.15625
[INFO] Global_t: 1095, Episode_t: 7, Action: 39, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1096, loss: 41667.2109375
[INFO] Global_t: 1096, Episode_t: 8, Action: 60, Reward: 1.66, Epsilon: 0.01
 55%|█████▍    | 1096/2000 [22:05<21:05,  1.40s/it]
[INFO] Global step: 1096, Cumulative rewards: 16.090919999999997, Runtime (s): 1325.57
------------------------------------------------------------
 
graph: 137, nodes: 210, edges: 621
[INFO] model update: t: 1097, loss: 90999.578125
[INFO] Global_t: 1097, Episode_t: 1, Action: 151, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 1098, loss: 67107.5
[INFO] Global_t: 1098, Episode_t: 2, Action: 172, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1099, loss: 52262.70703125
[INFO] Global_t: 1099, Episode_t: 3, Action: 122, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1100, loss: 210457.328125
[INFO] Global_t: 1100, Episode_t: 4, Action: 71, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1101, loss: 218125.0
[INFO] Global_t: 1101, Episode_t: 5, Action: 117, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1102, loss: 54307.0390625
[INFO] Global_t: 1102, Episode_t: 6, Action: 149, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1103, loss: 107431.0625
[INFO] Global_t: 1103, Episode_t: 7, Action: 105, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 1104, loss: 170856.1875
[INFO] Global_t: 1104, Episode_t: 8, Action: 108, Reward: 1.24, Epsilon: 0.01
 55%|█████▌    | 1104/2000 [22:08<16:30,  1.11s/it]
[INFO] Global step: 1104, Cumulative rewards: 16.52616, Runtime (s): 1328.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0110912322998047
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.635833978652954
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.0974013805389404
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3063347339630127
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2343013286590576
average cummulative reward vector is:  [0.07573132 0.07641389 0.07951366 0.0722757  0.07932823]
average cummulative reward is:  0.07665255852431588
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 138, nodes: 185, edges: 545
[INFO] model update: t: 1105, loss: 48535.58203125
[INFO] Global_t: 1105, Episode_t: 1, Action: 164, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 1106, loss: 14172.412109375
[INFO] Global_t: 1106, Episode_t: 2, Action: 30, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1107, loss: 28009.263671875
[INFO] Global_t: 1107, Episode_t: 3, Action: 23, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1108, loss: 9843.091796875
[INFO] Global_t: 1108, Episode_t: 4, Action: 82, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 1109, loss: 64041.484375
[INFO] Global_t: 1109, Episode_t: 5, Action: 142, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1110, loss: 19078.5
[INFO] Global_t: 1110, Episode_t: 6, Action: 54, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1111, loss: 54019.02734375
[INFO] Global_t: 1111, Episode_t: 7, Action: 144, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 1112, loss: 18947.564453125
[INFO] Global_t: 1112, Episode_t: 8, Action: 45, Reward: 1.40, Epsilon: 0.01
 56%|█████▌    | 1112/2000 [22:25<20:36,  1.39s/it]
[INFO] Global step: 1112, Cumulative rewards: 15.0492, Runtime (s): 1345.42
------------------------------------------------------------
 
graph: 139, nodes: 184, edges: 543
[INFO] model update: t: 1113, loss: 67998.5078125
[INFO] Global_t: 1113, Episode_t: 1, Action: 40, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1114, loss: 76697.15625
[INFO] Global_t: 1114, Episode_t: 2, Action: 55, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 1115, loss: 36375.046875
[INFO] Global_t: 1115, Episode_t: 3, Action: 49, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1116, loss: 28585.9453125
[INFO] Global_t: 1116, Episode_t: 4, Action: 148, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1117, loss: 22356.4375
[INFO] Global_t: 1117, Episode_t: 5, Action: 119, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1118, loss: 9824.67578125
[INFO] Global_t: 1118, Episode_t: 6, Action: 110, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 1119, loss: 27054.40625
[INFO] Global_t: 1119, Episode_t: 7, Action: 15, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 1120, loss: 12466.9169921875
[INFO] Global_t: 1120, Episode_t: 8, Action: 60, Reward: 1.26, Epsilon: 0.01
 56%|█████▌    | 1120/2000 [22:28<16:09,  1.10s/it]
[INFO] Global step: 1120, Cumulative rewards: 13.089120000000001, Runtime (s): 1348.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9683480262756348
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9212725162506104
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3226356506347656
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.292423963546753
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3256325721740723
average cummulative reward vector is:  [0.07371316 0.06109306 0.08377404 0.07786542 0.08908737]
average cummulative reward is:  0.077106608663657
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 140, nodes: 220, edges: 651
[INFO] model update: t: 1121, loss: 15929.794921875
[INFO] Global_t: 1121, Episode_t: 1, Action: 89, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1122, loss: 77698.46875
[INFO] Global_t: 1122, Episode_t: 2, Action: 57, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 1123, loss: 141861.953125
[INFO] Global_t: 1123, Episode_t: 3, Action: 174, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 1124, loss: 96285.609375
[INFO] Global_t: 1124, Episode_t: 4, Action: 48, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 1125, loss: 26921.359375
[INFO] Global_t: 1125, Episode_t: 5, Action: 200, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1126, loss: 25497.6796875
[INFO] Global_t: 1126, Episode_t: 6, Action: 78, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1127, loss: 18456.990234375
[INFO] Global_t: 1127, Episode_t: 7, Action: 158, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1128, loss: 23668.486328125
[INFO] Global_t: 1128, Episode_t: 8, Action: 44, Reward: 1.38, Epsilon: 0.01
 56%|█████▋    | 1128/2000 [22:42<18:50,  1.30s/it]
[INFO] Global step: 1128, Cumulative rewards: 17.4864, Runtime (s): 1362.81
------------------------------------------------------------
 
graph: 141, nodes: 205, edges: 606
[INFO] model update: t: 1129, loss: 13086.837890625
[INFO] Global_t: 1129, Episode_t: 1, Action: 194, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1130, loss: 28271.72265625
[INFO] Global_t: 1130, Episode_t: 2, Action: 133, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 1131, loss: 19937.96875
[INFO] Global_t: 1131, Episode_t: 3, Action: 175, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1132, loss: 58594.62109375
[INFO] Global_t: 1132, Episode_t: 4, Action: 94, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1133, loss: 120934.3671875
[INFO] Global_t: 1133, Episode_t: 5, Action: 151, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1134, loss: 156394.1875
[INFO] Global_t: 1134, Episode_t: 6, Action: 15, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1135, loss: 150093.65625
[INFO] Global_t: 1135, Episode_t: 7, Action: 118, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1136, loss: 19433.43359375
[INFO] Global_t: 1136, Episode_t: 8, Action: 197, Reward: 1.26, Epsilon: 0.01
 57%|█████▋    | 1136/2000 [22:45<14:39,  1.02s/it]
[INFO] Global step: 1136, Cumulative rewards: 16.1358, Runtime (s): 1365.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.262004852294922
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.341736078262329
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2941861152648926
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.6003077030181885
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.273247003555298
average cummulative reward vector is:  [0.08328579 0.07637546 0.08641011 0.08083925 0.08478575]
average cummulative reward is:  0.08233927335017706
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 142, nodes: 201, edges: 593
[INFO] model update: t: 1137, loss: 88163.65625
[INFO] Global_t: 1137, Episode_t: 1, Action: 87, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1138, loss: 87565.390625
[INFO] Global_t: 1138, Episode_t: 2, Action: 26, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1139, loss: 39357.39453125
[INFO] Global_t: 1139, Episode_t: 3, Action: 56, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 1140, loss: 37737.3828125
[INFO] Global_t: 1140, Episode_t: 4, Action: 119, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 1141, loss: 135476.234375
[INFO] Global_t: 1141, Episode_t: 5, Action: 79, Reward: 1.88, Epsilon: 0.01
[INFO] model update: t: 1142, loss: 184125.46875
[INFO] Global_t: 1142, Episode_t: 6, Action: 135, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 1143, loss: 41601.78125
[INFO] Global_t: 1143, Episode_t: 7, Action: 104, Reward: 1.88, Epsilon: 0.01
[INFO] model update: t: 1144, loss: 38512.6171875
[INFO] Global_t: 1144, Episode_t: 8, Action: 137, Reward: 1.68, Epsilon: 0.01
 57%|█████▋    | 1144/2000 [23:00<18:07,  1.27s/it]
[INFO] Global step: 1144, Cumulative rewards: 17.13312, Runtime (s): 1380.64
------------------------------------------------------------
 
graph: 143, nodes: 194, edges: 573
[INFO] model update: t: 1145, loss: 90892.3828125
[INFO] Global_t: 1145, Episode_t: 1, Action: 143, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1146, loss: 36444.87109375
[INFO] Global_t: 1146, Episode_t: 2, Action: 120, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 1147, loss: 20546.26953125
[INFO] Global_t: 1147, Episode_t: 3, Action: 162, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1148, loss: 75784.796875
[INFO] Global_t: 1148, Episode_t: 4, Action: 53, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1149, loss: 93704.9140625
[INFO] Global_t: 1149, Episode_t: 5, Action: 187, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1150, loss: 129361.546875
[INFO] Global_t: 1150, Episode_t: 6, Action: 58, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1151, loss: 27215.29296875
[INFO] Global_t: 1151, Episode_t: 7, Action: 32, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1152, loss: 341653.03125
[INFO] Global_t: 1152, Episode_t: 8, Action: 132, Reward: 1.38, Epsilon: 0.01

[INFO] Global step: 1152, Cumulative rewards: 13.42848, Runtime (s): 1383.74
------------------------------------------------------------
 
 58%|█████▊    | 1152/2000 [23:03<14:13,  1.01s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.372530698776245
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.05020809173584
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3634495735168457
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4289023876190186
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3856024742126465
average cummulative reward vector is:  [0.08412289 0.06565046 0.09399918 0.07817734 0.08174704]
average cummulative reward is:  0.08073938349740496
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 144, nodes: 219, edges: 648
[INFO] model update: t: 1153, loss: 230606.203125
[INFO] Global_t: 1153, Episode_t: 1, Action: 91, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1154, loss: 116990.4375
[INFO] Global_t: 1154, Episode_t: 2, Action: 180, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1155, loss: 432048.0
[INFO] Global_t: 1155, Episode_t: 3, Action: 106, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1156, loss: 48028.2734375
[INFO] Global_t: 1156, Episode_t: 4, Action: 164, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1157, loss: 179317.65625
[INFO] Global_t: 1157, Episode_t: 5, Action: 27, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1158, loss: 34781.4921875
[INFO] Global_t: 1158, Episode_t: 6, Action: 136, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 1159, loss: 103943.171875
[INFO] Global_t: 1159, Episode_t: 7, Action: 198, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 1160, loss: 273274.0625
[INFO] Global_t: 1160, Episode_t: 8, Action: 194, Reward: 1.64, Epsilon: 0.01
 58%|█████▊    | 1160/2000 [23:18<17:45,  1.27s/it]
[INFO] Global step: 1160, Cumulative rewards: 14.245199999999999, Runtime (s): 1398.80
------------------------------------------------------------
 
graph: 145, nodes: 217, edges: 642
[INFO] model update: t: 1161, loss: 51422.4375
[INFO] Global_t: 1161, Episode_t: 1, Action: 41, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1162, loss: 217196.34375
[INFO] Global_t: 1162, Episode_t: 2, Action: 16, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 1163, loss: 453928.625
[INFO] Global_t: 1163, Episode_t: 3, Action: 47, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1164, loss: 229186.8125
[INFO] Global_t: 1164, Episode_t: 4, Action: 180, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1165, loss: 27221.52734375
[INFO] Global_t: 1165, Episode_t: 5, Action: 165, Reward: 2.59, Epsilon: 0.01
[INFO] model update: t: 1166, loss: 312365.75
[INFO] Global_t: 1166, Episode_t: 6, Action: 156, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1167, loss: 212528.953125
[INFO] Global_t: 1167, Episode_t: 7, Action: 112, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1168, loss: 24793.888671875
[INFO] Global_t: 1168, Episode_t: 8, Action: 126, Reward: 1.95, Epsilon: 0.01
 58%|█████▊    | 1168/2000 [23:21<13:38,  1.02it/s]
[INFO] Global step: 1168, Cumulative rewards: 18.98796, Runtime (s): 1401.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.3332438468933105
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2807276248931885
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2229936122894287
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2384793758392334
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.339132070541382
average cummulative reward vector is:  [0.08262237 0.06677083 0.08476885 0.07508925 0.08919839]
average cummulative reward is:  0.07968993872932503
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 146, nodes: 207, edges: 612
[INFO] model update: t: 1169, loss: 41644.453125
[INFO] Global_t: 1169, Episode_t: 1, Action: 145, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1170, loss: 55837.75
[INFO] Global_t: 1170, Episode_t: 2, Action: 12, Reward: 3.02, Epsilon: 0.01
[INFO] model update: t: 1171, loss: 28247.380859375
[INFO] Global_t: 1171, Episode_t: 3, Action: 72, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1172, loss: 7796.1328125
[INFO] Global_t: 1172, Episode_t: 4, Action: 46, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1173, loss: 45044.8828125
[INFO] Global_t: 1173, Episode_t: 5, Action: 103, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1174, loss: 16472.046875
[INFO] Global_t: 1174, Episode_t: 6, Action: 63, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1175, loss: 21383.5
[INFO] Global_t: 1175, Episode_t: 7, Action: 96, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1176, loss: 45633.0546875
[INFO] Global_t: 1176, Episode_t: 8, Action: 149, Reward: 1.55, Epsilon: 0.01
 59%|█████▉    | 1176/2000 [23:35<16:43,  1.22s/it]
[INFO] Global step: 1176, Cumulative rewards: 17.32176, Runtime (s): 1415.46
------------------------------------------------------------
 
graph: 147, nodes: 202, edges: 597
[INFO] model update: t: 1177, loss: 23034.46484375
[INFO] Global_t: 1177, Episode_t: 1, Action: 134, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 1178, loss: 13640.376953125
[INFO] Global_t: 1178, Episode_t: 2, Action: 128, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 1179, loss: 39412.0859375
[INFO] Global_t: 1179, Episode_t: 3, Action: 198, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 1180, loss: 21609.75
[INFO] Global_t: 1180, Episode_t: 4, Action: 21, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1181, loss: 119307.1875
[INFO] Global_t: 1181, Episode_t: 5, Action: 108, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 1182, loss: 118895.421875
[INFO] Global_t: 1182, Episode_t: 6, Action: 101, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1183, loss: 43039.83984375
[INFO] Global_t: 1183, Episode_t: 7, Action: 63, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1184, loss: 10775.517578125
[INFO] Global_t: 1184, Episode_t: 8, Action: 98, Reward: 1.39, Epsilon: 0.01
 59%|█████▉    | 1184/2000 [23:38<13:10,  1.03it/s]
[INFO] Global step: 1184, Cumulative rewards: 14.741040000000002, Runtime (s): 1418.55
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.116401195526123
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2265756130218506
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1779210567474365
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.6697230339050293
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.191951274871826
average cummulative reward vector is:  [0.07801947 0.07343542 0.0851847  0.07597383 0.08368468]
average cummulative reward is:  0.07925961979989697
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 148, nodes: 199, edges: 587
[INFO] model update: t: 1185, loss: 43142.9765625
[INFO] Global_t: 1185, Episode_t: 1, Action: 121, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1186, loss: 28266.24609375
[INFO] Global_t: 1186, Episode_t: 2, Action: 88, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1187, loss: 28759.11328125
[INFO] Global_t: 1187, Episode_t: 3, Action: 196, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 1188, loss: 85029.546875
[INFO] Global_t: 1188, Episode_t: 4, Action: 72, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1189, loss: 103555.578125
[INFO] Global_t: 1189, Episode_t: 5, Action: 44, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 1190, loss: 28266.078125
[INFO] Global_t: 1190, Episode_t: 6, Action: 144, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1191, loss: 47489.1328125
[INFO] Global_t: 1191, Episode_t: 7, Action: 76, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 1192, loss: 96617.390625
[INFO] Global_t: 1192, Episode_t: 8, Action: 75, Reward: 1.60, Epsilon: 0.01
 60%|█████▉    | 1192/2000 [23:54<17:19,  1.29s/it]
[INFO] Global step: 1192, Cumulative rewards: 13.58616, Runtime (s): 1434.80
------------------------------------------------------------
 
graph: 149, nodes: 208, edges: 615
[INFO] model update: t: 1193, loss: 38520.65625
[INFO] Global_t: 1193, Episode_t: 1, Action: 31, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1194, loss: 9272.6328125
[INFO] Global_t: 1194, Episode_t: 2, Action: 51, Reward: 3.01, Epsilon: 0.01
[INFO] model update: t: 1195, loss: 37706.6875
[INFO] Global_t: 1195, Episode_t: 3, Action: 22, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1196, loss: 29779.37890625
[INFO] Global_t: 1196, Episode_t: 4, Action: 122, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1197, loss: 51959.578125
[INFO] Global_t: 1197, Episode_t: 5, Action: 200, Reward: 2.10, Epsilon: 0.01
[INFO] model update: t: 1198, loss: 23288.90625
[INFO] Global_t: 1198, Episode_t: 6, Action: 147, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1199, loss: 44511.78515625
[INFO] Global_t: 1199, Episode_t: 7, Action: 191, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1200, loss: 158540.96875
[INFO] Global_t: 1200, Episode_t: 8, Action: 16, Reward: 2.28, Epsilon: 0.01
 60%|██████    | 1200/2000 [23:58<13:43,  1.03s/it]
[INFO] Global step: 1200, Cumulative rewards: 19.43232, Runtime (s): 1438.21
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9739830493927002
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.388395309448242
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.192357301712036
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.295212984085083
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0296754837036133
average cummulative reward vector is:  [0.07257974 0.07657755 0.08205164 0.06926729 0.07748656]
average cummulative reward is:  0.075592554268415
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 150, nodes: 216, edges: 639
[INFO] model update: t: 1201, loss: 303304.71875
[INFO] Global_t: 1201, Episode_t: 1, Action: 53, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1202, loss: 232369.734375
[INFO] Global_t: 1202, Episode_t: 2, Action: 35, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1203, loss: 20772.6328125
[INFO] Global_t: 1203, Episode_t: 3, Action: 118, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 1204, loss: 112381.8359375
[INFO] Global_t: 1204, Episode_t: 4, Action: 75, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1205, loss: 145309.0
[INFO] Global_t: 1205, Episode_t: 5, Action: 34, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1206, loss: 22040.8828125
[INFO] Global_t: 1206, Episode_t: 6, Action: 55, Reward: 1.71, Epsilon: 0.01
[INFO] model update: t: 1207, loss: 195290.328125
[INFO] Global_t: 1207, Episode_t: 7, Action: 93, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1208, loss: 72355.9140625
[INFO] Global_t: 1208, Episode_t: 8, Action: 54, Reward: 1.71, Epsilon: 0.01
 60%|██████    | 1208/2000 [24:11<16:19,  1.24s/it]
[INFO] Global step: 1208, Cumulative rewards: 13.90308, Runtime (s): 1451.98
------------------------------------------------------------
 
graph: 151, nodes: 204, edges: 601
[INFO] model update: t: 1209, loss: 73570.6796875
[INFO] Global_t: 1209, Episode_t: 1, Action: 189, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1210, loss: 344999.25
[INFO] Global_t: 1210, Episode_t: 2, Action: 100, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1211, loss: 408804.21875
[INFO] Global_t: 1211, Episode_t: 3, Action: 137, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1212, loss: 96689.53125
[INFO] Global_t: 1212, Episode_t: 4, Action: 136, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1213, loss: 81522.0
[INFO] Global_t: 1213, Episode_t: 5, Action: 195, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1214, loss: 242844.09375
[INFO] Global_t: 1214, Episode_t: 6, Action: 41, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 1215, loss: 32840.6171875
[INFO] Global_t: 1215, Episode_t: 7, Action: 22, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 1216, loss: 248263.78125
[INFO] Global_t: 1216, Episode_t: 8, Action: 69, Reward: 1.95, Epsilon: 0.01
 61%|██████    | 1216/2000 [24:15<12:48,  1.02it/s]
[INFO] Global step: 1216, Cumulative rewards: 16.00416, Runtime (s): 1455.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.229071617126465
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.297725200653076
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1760191917419434
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3178975582122803
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3658101558685303
average cummulative reward vector is:  [0.07514526 0.07519722 0.08455273 0.07338972 0.08714624]
average cummulative reward is:  0.07908623476117242
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 152, nodes: 208, edges: 615
[INFO] model update: t: 1217, loss: 105606.046875
[INFO] Global_t: 1217, Episode_t: 1, Action: 11, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1218, loss: 38729.66015625
[INFO] Global_t: 1218, Episode_t: 2, Action: 29, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1219, loss: 152457.546875
[INFO] Global_t: 1219, Episode_t: 3, Action: 24, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 1220, loss: 225981.9375
[INFO] Global_t: 1220, Episode_t: 4, Action: 143, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1221, loss: 85417.8828125
[INFO] Global_t: 1221, Episode_t: 5, Action: 43, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1222, loss: 41463.28125
[INFO] Global_t: 1222, Episode_t: 6, Action: 185, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 1223, loss: 378284.75
[INFO] Global_t: 1223, Episode_t: 7, Action: 111, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1224, loss: 1002878.8125
[INFO] Global_t: 1224, Episode_t: 8, Action: 36, Reward: 1.53, Epsilon: 0.01
 61%|██████    | 1224/2000 [24:30<16:35,  1.28s/it]
[INFO] Global step: 1224, Cumulative rewards: 15.60792, Runtime (s): 1470.95
------------------------------------------------------------
 
graph: 153, nodes: 211, edges: 623
[INFO] model update: t: 1225, loss: 386587.6875
[INFO] Global_t: 1225, Episode_t: 1, Action: 59, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1226, loss: 10392.794921875
[INFO] Global_t: 1226, Episode_t: 2, Action: 26, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 1227, loss: 224353.1875
[INFO] Global_t: 1227, Episode_t: 3, Action: 21, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1228, loss: 513703.46875
[INFO] Global_t: 1228, Episode_t: 4, Action: 116, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 1229, loss: 151147.84375
[INFO] Global_t: 1229, Episode_t: 5, Action: 42, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1230, loss: 47011.2265625
[INFO] Global_t: 1230, Episode_t: 6, Action: 41, Reward: 1.34, Epsilon: 0.01
[INFO] model update: t: 1231, loss: 441343.8125
[INFO] Global_t: 1231, Episode_t: 7, Action: 193, Reward: 1.57, Epsilon: 0.01
[INFO] model update: t: 1232, loss: 808795.0
[INFO] Global_t: 1232, Episode_t: 8, Action: 118, Reward: 1.72, Epsilon: 0.01
 62%|██████▏   | 1232/2000 [24:35<13:51,  1.08s/it]
[INFO] Global step: 1232, Cumulative rewards: 15.17256, Runtime (s): 1475.88
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.4595892429351807
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1772854328155518
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2036259174346924
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0702314376831055
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1206085681915283
average cummulative reward vector is:  [0.07964105 0.07084884 0.08704071 0.06878762 0.08240269]
average cummulative reward is:  0.07774418212023163
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 154, nodes: 189, edges: 558
[INFO] model update: t: 1233, loss: 323205.53125
[INFO] Global_t: 1233, Episode_t: 1, Action: 177, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1234, loss: 22990.998046875
[INFO] Global_t: 1234, Episode_t: 2, Action: 115, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 1235, loss: 188270.703125
[INFO] Global_t: 1235, Episode_t: 3, Action: 90, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1236, loss: 498422.46875
[INFO] Global_t: 1236, Episode_t: 4, Action: 185, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1237, loss: 267383.8125
[INFO] Global_t: 1237, Episode_t: 5, Action: 100, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 1238, loss: 32457.75390625
[INFO] Global_t: 1238, Episode_t: 6, Action: 31, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 1239, loss: 505046.5
[INFO] Global_t: 1239, Episode_t: 7, Action: 164, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1240, loss: 700263.125
[INFO] Global_t: 1240, Episode_t: 8, Action: 43, Reward: 2.02, Epsilon: 0.01
 62%|██████▏   | 1240/2000 [24:49<16:08,  1.27s/it]
[INFO] Global step: 1240, Cumulative rewards: 17.36808, Runtime (s): 1489.64
------------------------------------------------------------
 
graph: 155, nodes: 203, edges: 599
[INFO] model update: t: 1241, loss: 24965.537109375
[INFO] Global_t: 1241, Episode_t: 1, Action: 130, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 1242, loss: 462675.25
[INFO] Global_t: 1242, Episode_t: 2, Action: 88, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1243, loss: 589280.75
[INFO] Global_t: 1243, Episode_t: 3, Action: 150, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1244, loss: 25891.16015625
[INFO] Global_t: 1244, Episode_t: 4, Action: 108, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1245, loss: 439714.5625
[INFO] Global_t: 1245, Episode_t: 5, Action: 69, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1246, loss: 703357.375
[INFO] Global_t: 1246, Episode_t: 6, Action: 30, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1247, loss: 505151.5
[INFO] Global_t: 1247, Episode_t: 7, Action: 174, Reward: 0.99, Epsilon: 0.01
[INFO] model update: t: 1248, loss: 65266.01171875
[INFO] Global_t: 1248, Episode_t: 8, Action: 47, Reward: 0.78, Epsilon: 0.01
 62%|██████▏   | 1248/2000 [24:53<12:59,  1.04s/it]
[INFO] Global step: 1248, Cumulative rewards: 14.30052, Runtime (s): 1493.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.118786573410034
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2132253646850586
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.5125560760498047
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.163466691970825
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2784907817840576
average cummulative reward vector is:  [0.07493553 0.07039421 0.08791913 0.07178271 0.08783602]
average cummulative reward is:  0.07857351934951254
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 156, nodes: 192, edges: 567
[INFO] model update: t: 1249, loss: 321006.8125
[INFO] Global_t: 1249, Episode_t: 1, Action: 123, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 1250, loss: 809693.0
[INFO] Global_t: 1250, Episode_t: 2, Action: 133, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1251, loss: 855243.625
[INFO] Global_t: 1251, Episode_t: 3, Action: 12, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1252, loss: 463417.5625
[INFO] Global_t: 1252, Episode_t: 4, Action: 144, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1253, loss: 75056.46875
[INFO] Global_t: 1253, Episode_t: 5, Action: 162, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1254, loss: 108369.5
[INFO] Global_t: 1254, Episode_t: 6, Action: 152, Reward: 1.63, Epsilon: 0.01
[INFO] model update: t: 1255, loss: 482489.90625
[INFO] Global_t: 1255, Episode_t: 7, Action: 91, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1256, loss: 226652.875
[INFO] Global_t: 1256, Episode_t: 8, Action: 109, Reward: 1.39, Epsilon: 0.01
 63%|██████▎   | 1256/2000 [25:07<15:39,  1.26s/it]
[INFO] Global step: 1256, Cumulative rewards: 13.90848, Runtime (s): 1507.81
------------------------------------------------------------
 
graph: 157, nodes: 220, edges: 651
[INFO] model update: t: 1257, loss: 67890.75
[INFO] Global_t: 1257, Episode_t: 1, Action: 185, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 1258, loss: 591310.875
[INFO] Global_t: 1258, Episode_t: 2, Action: 130, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1259, loss: 251258.65625
[INFO] Global_t: 1259, Episode_t: 3, Action: 219, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1260, loss: 10285.7626953125
[INFO] Global_t: 1260, Episode_t: 4, Action: 80, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1261, loss: 87013.453125
[INFO] Global_t: 1261, Episode_t: 5, Action: 82, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 1262, loss: 60697.56640625
[INFO] Global_t: 1262, Episode_t: 6, Action: 79, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 1263, loss: 12735.46875
[INFO] Global_t: 1263, Episode_t: 7, Action: 166, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1264, loss: 122401.53125
[INFO] Global_t: 1264, Episode_t: 8, Action: 67, Reward: 1.67, Epsilon: 0.01
 63%|██████▎   | 1264/2000 [25:10<12:05,  1.01it/s]
[INFO] Global step: 1264, Cumulative rewards: 16.17384, Runtime (s): 1510.54
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9737443923950195
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.354965925216675
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1897590160369873
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.490715742111206
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2528634071350098
average cummulative reward vector is:  [0.07472684 0.07833495 0.08598033 0.07418551 0.0849793 ]
average cummulative reward is:  0.07964138775435595
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 158, nodes: 209, edges: 618
[INFO] model update: t: 1265, loss: 211013.53125
[INFO] Global_t: 1265, Episode_t: 1, Action: 57, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1266, loss: 48431.25
[INFO] Global_t: 1266, Episode_t: 2, Action: 141, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1267, loss: 90830.4375
[INFO] Global_t: 1267, Episode_t: 3, Action: 39, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1268, loss: 171287.296875
[INFO] Global_t: 1268, Episode_t: 4, Action: 145, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1269, loss: 92604.046875
[INFO] Global_t: 1269, Episode_t: 5, Action: 196, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1270, loss: 9449.015625
[INFO] Global_t: 1270, Episode_t: 6, Action: 135, Reward: 1.74, Epsilon: 0.01
[INFO] model update: t: 1271, loss: 94973.96875
[INFO] Global_t: 1271, Episode_t: 7, Action: 55, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1272, loss: 233659.359375
[INFO] Global_t: 1272, Episode_t: 8, Action: 94, Reward: 1.60, Epsilon: 0.01
 64%|██████▎   | 1272/2000 [25:25<15:10,  1.25s/it]
[INFO] Global step: 1272, Cumulative rewards: 17.427239999999998, Runtime (s): 1525.48
------------------------------------------------------------
 
graph: 159, nodes: 191, edges: 564
[INFO] model update: t: 1273, loss: 26587.966796875
[INFO] Global_t: 1273, Episode_t: 1, Action: 157, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 1274, loss: 144312.65625
[INFO] Global_t: 1274, Episode_t: 2, Action: 93, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1275, loss: 464951.4375
[INFO] Global_t: 1275, Episode_t: 3, Action: 167, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1276, loss: 467671.65625
[INFO] Global_t: 1276, Episode_t: 4, Action: 29, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1277, loss: 469581.15625
[INFO] Global_t: 1277, Episode_t: 5, Action: 44, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1278, loss: 393505.40625
[INFO] Global_t: 1278, Episode_t: 6, Action: 52, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1279, loss: 225265.0625
[INFO] Global_t: 1279, Episode_t: 7, Action: 24, Reward: 1.27, Epsilon: 0.01
[INFO] model update: t: 1280, loss: 26374.919921875
[INFO] Global_t: 1280, Episode_t: 8, Action: 27, Reward: 1.21, Epsilon: 0.01
 64%|██████▍   | 1280/2000 [25:28<11:54,  1.01it/s]
[INFO] Global step: 1280, Cumulative rewards: 13.595399999999998, Runtime (s): 1528.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.419940948486328
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2550060749053955
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.246380090713501
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1551051139831543
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.301867961883545
average cummulative reward vector is:  [0.07803921 0.0728669  0.08771038 0.07133458 0.08107124]
average cummulative reward is:  0.07820446143730345
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 160, nodes: 220, edges: 650
[INFO] model update: t: 1281, loss: 235957.53125
[INFO] Global_t: 1281, Episode_t: 1, Action: 186, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1282, loss: 686957.875
[INFO] Global_t: 1282, Episode_t: 2, Action: 197, Reward: 1.89, Epsilon: 0.01
[INFO] model update: t: 1283, loss: 1361620.25
[INFO] Global_t: 1283, Episode_t: 3, Action: 131, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1284, loss: 1004113.125
[INFO] Global_t: 1284, Episode_t: 4, Action: 219, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1285, loss: 223086.0
[INFO] Global_t: 1285, Episode_t: 5, Action: 132, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 1286, loss: 42564.6875
[INFO] Global_t: 1286, Episode_t: 6, Action: 79, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 1287, loss: 289124.5
[INFO] Global_t: 1287, Episode_t: 7, Action: 204, Reward: 1.19, Epsilon: 0.01
[INFO] model update: t: 1288, loss: 457185.5
[INFO] Global_t: 1288, Episode_t: 8, Action: 66, Reward: 1.27, Epsilon: 0.01
 64%|██████▍   | 1288/2000 [25:43<15:03,  1.27s/it]
[INFO] Global step: 1288, Cumulative rewards: 14.565599999999998, Runtime (s): 1543.91
------------------------------------------------------------
 
graph: 161, nodes: 194, edges: 573
[INFO] model update: t: 1289, loss: 215949.578125
[INFO] Global_t: 1289, Episode_t: 1, Action: 162, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 1290, loss: 70524.09375
[INFO] Global_t: 1290, Episode_t: 2, Action: 44, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1291, loss: 619036.5625
[INFO] Global_t: 1291, Episode_t: 3, Action: 24, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1292, loss: 522741.0
[INFO] Global_t: 1292, Episode_t: 4, Action: 16, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1293, loss: 185840.9375
[INFO] Global_t: 1293, Episode_t: 5, Action: 75, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 1294, loss: 37831.0625
[INFO] Global_t: 1294, Episode_t: 6, Action: 90, Reward: 1.74, Epsilon: 0.01
[INFO] model update: t: 1295, loss: 267719.03125
[INFO] Global_t: 1295, Episode_t: 7, Action: 38, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1296, loss: 38795.203125
[INFO] Global_t: 1296, Episode_t: 8, Action: 40, Reward: 1.57, Epsilon: 0.01
 65%|██████▍   | 1296/2000 [25:46<11:37,  1.01it/s]
[INFO] Global step: 1296, Cumulative rewards: 14.21112, Runtime (s): 1546.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.33949613571167
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.616939067840576
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.244670867919922
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0987002849578857
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2024147510528564
average cummulative reward vector is:  [0.08480053 0.0728044  0.08808962 0.06778224 0.0852086 ]
average cummulative reward is:  0.07973707741829364
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 162, nodes: 191, edges: 564
[INFO] model update: t: 1297, loss: 127953.046875
[INFO] Global_t: 1297, Episode_t: 1, Action: 8, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1298, loss: 713856.375
[INFO] Global_t: 1298, Episode_t: 2, Action: 69, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1299, loss: 2024922.875
[INFO] Global_t: 1299, Episode_t: 3, Action: 57, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1300, loss: 3557425.75
[INFO] Global_t: 1300, Episode_t: 4, Action: 143, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 1301, loss: 3755457.5
[INFO] Global_t: 1301, Episode_t: 5, Action: 37, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1302, loss: 411887.28125
[INFO] Global_t: 1302, Episode_t: 6, Action: 46, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1303, loss: 1581256.25
[INFO] Global_t: 1303, Episode_t: 7, Action: 65, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1304, loss: 6603424.0
[INFO] Global_t: 1304, Episode_t: 8, Action: 52, Reward: 1.31, Epsilon: 0.01
 65%|██████▌   | 1304/2000 [26:01<14:19,  1.23s/it]
[INFO] Global step: 1304, Cumulative rewards: 16.266479999999998, Runtime (s): 1561.08
------------------------------------------------------------
 
graph: 163, nodes: 213, edges: 629
[INFO] model update: t: 1305, loss: 1295029.75
[INFO] Global_t: 1305, Episode_t: 1, Action: 174, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1306, loss: 1422337.0
[INFO] Global_t: 1306, Episode_t: 2, Action: 29, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 1307, loss: 7426888.0
[INFO] Global_t: 1307, Episode_t: 3, Action: 161, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1308, loss: 5531473.5
[INFO] Global_t: 1308, Episode_t: 4, Action: 134, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1309, loss: 83313.1328125
[INFO] Global_t: 1309, Episode_t: 5, Action: 192, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1310, loss: 2887859.0
[INFO] Global_t: 1310, Episode_t: 6, Action: 132, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1311, loss: 4158392.0
[INFO] Global_t: 1311, Episode_t: 7, Action: 67, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1312, loss: 1612006.625
[INFO] Global_t: 1312, Episode_t: 8, Action: 78, Reward: 1.58, Epsilon: 0.01
 66%|██████▌   | 1312/2000 [26:04<11:17,  1.02it/s]
[INFO] Global step: 1312, Cumulative rewards: 14.484359999999995, Runtime (s): 1564.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2538862228393555
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.179824113845825
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.359278440475464
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.123173236846924
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.082545042037964
average cummulative reward vector is:  [0.08559237 0.07155394 0.08371749 0.06990514 0.07853468]
average cummulative reward is:  0.07786072151026127
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 164, nodes: 182, edges: 537
[INFO] model update: t: 1313, loss: 35446.07421875
[INFO] Global_t: 1313, Episode_t: 1, Action: 21, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1314, loss: 703759.5
[INFO] Global_t: 1314, Episode_t: 2, Action: 86, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1315, loss: 885304.5625
[INFO] Global_t: 1315, Episode_t: 3, Action: 82, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 1316, loss: 1654711.875
[INFO] Global_t: 1316, Episode_t: 4, Action: 77, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1317, loss: 659510.375
[INFO] Global_t: 1317, Episode_t: 5, Action: 40, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1318, loss: 515741.59375
[INFO] Global_t: 1318, Episode_t: 6, Action: 20, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1319, loss: 3077831.0
[INFO] Global_t: 1319, Episode_t: 7, Action: 173, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 1320, loss: 5139730.5
[INFO] Global_t: 1320, Episode_t: 8, Action: 157, Reward: 1.53, Epsilon: 0.01
 66%|██████▌   | 1320/2000 [26:18<14:02,  1.24s/it]
[INFO] Global step: 1320, Cumulative rewards: 13.751999999999999, Runtime (s): 1578.95
------------------------------------------------------------
 
graph: 165, nodes: 180, edges: 531
[INFO] model update: t: 1321, loss: 7433412.5
[INFO] Global_t: 1321, Episode_t: 1, Action: 136, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 1322, loss: 9593362.0
[INFO] Global_t: 1322, Episode_t: 2, Action: 141, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1323, loss: 2225586.25
[INFO] Global_t: 1323, Episode_t: 3, Action: 35, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1324, loss: 100461.546875
[INFO] Global_t: 1324, Episode_t: 4, Action: 29, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1325, loss: 2854850.5
[INFO] Global_t: 1325, Episode_t: 5, Action: 46, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1326, loss: 4300967.5
[INFO] Global_t: 1326, Episode_t: 6, Action: 145, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 1327, loss: 64602.328125
[INFO] Global_t: 1327, Episode_t: 7, Action: 66, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1328, loss: 3573272.75
[INFO] Global_t: 1328, Episode_t: 8, Action: 58, Reward: 1.42, Epsilon: 0.01
 66%|██████▋   | 1328/2000 [26:22<11:02,  1.01it/s]
[INFO] Global step: 1328, Cumulative rewards: 14.971319999999999, Runtime (s): 1582.10
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.17155385017395
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1673285961151123
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.21401309967041
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.399806261062622
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3376550674438477
average cummulative reward vector is:  [0.08156395 0.06771181 0.0860265  0.07220981 0.08288978]
average cummulative reward is:  0.07808037073731315
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 166, nodes: 185, edges: 544
[INFO] model update: t: 1329, loss: 11452466.0
[INFO] Global_t: 1329, Episode_t: 1, Action: 95, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 1330, loss: 8979229.0
[INFO] Global_t: 1330, Episode_t: 2, Action: 59, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1331, loss: 75874.4921875
[INFO] Global_t: 1331, Episode_t: 3, Action: 60, Reward: 1.48, Epsilon: 0.01
[INFO] model update: t: 1332, loss: 5915614.5
[INFO] Global_t: 1332, Episode_t: 4, Action: 41, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1333, loss: 13126746.0
[INFO] Global_t: 1333, Episode_t: 5, Action: 115, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1334, loss: 11233441.0
[INFO] Global_t: 1334, Episode_t: 6, Action: 92, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 1335, loss: 403749.125
[INFO] Global_t: 1335, Episode_t: 7, Action: 56, Reward: 1.60, Epsilon: 0.01
[INFO] model update: t: 1336, loss: 3715457.75
[INFO] Global_t: 1336, Episode_t: 8, Action: 121, Reward: 1.51, Epsilon: 0.01
 67%|██████▋   | 1336/2000 [26:36<13:39,  1.23s/it]
[INFO] Global step: 1336, Cumulative rewards: 12.86232, Runtime (s): 1596.63
------------------------------------------------------------
 
graph: 167, nodes: 181, edges: 533
[INFO] model update: t: 1337, loss: 2582443.5
[INFO] Global_t: 1337, Episode_t: 1, Action: 15, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 1338, loss: 20889.072265625
[INFO] Global_t: 1338, Episode_t: 2, Action: 95, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1339, loss: 2112235.0
[INFO] Global_t: 1339, Episode_t: 3, Action: 42, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 1340, loss: 1596903.125
[INFO] Global_t: 1340, Episode_t: 4, Action: 29, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 1341, loss: 604139.75
[INFO] Global_t: 1341, Episode_t: 5, Action: 135, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1342, loss: 56794.328125
[INFO] Global_t: 1342, Episode_t: 6, Action: 70, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1343, loss: 844648.0625
[INFO] Global_t: 1343, Episode_t: 7, Action: 71, Reward: 1.63, Epsilon: 0.01
[INFO] model update: t: 1344, loss: 970451.3125
[INFO] Global_t: 1344, Episode_t: 8, Action: 100, Reward: 1.17, Epsilon: 0.01
 67%|██████▋   | 1344/2000 [26:39<10:34,  1.03it/s]
[INFO] Global step: 1344, Cumulative rewards: 14.63412, Runtime (s): 1599.36
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2132039070129395
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3177804946899414
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1971755027770996
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3514246940612793
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.456812620162964
average cummulative reward vector is:  [0.07462763 0.07233264 0.08499617 0.07685327 0.08969731]
average cummulative reward is:  0.07970140563744371
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 168, nodes: 201, edges: 594
[INFO] model update: t: 1345, loss: 179781.078125
[INFO] Global_t: 1345, Episode_t: 1, Action: 95, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1346, loss: 54053.53125
[INFO] Global_t: 1346, Episode_t: 2, Action: 49, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1347, loss: 552244.4375
[INFO] Global_t: 1347, Episode_t: 3, Action: 87, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1348, loss: 1299841.25
[INFO] Global_t: 1348, Episode_t: 4, Action: 109, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1349, loss: 1327891.125
[INFO] Global_t: 1349, Episode_t: 5, Action: 89, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1350, loss: 40853.3046875
[INFO] Global_t: 1350, Episode_t: 6, Action: 142, Reward: 1.18, Epsilon: 0.01
[INFO] model update: t: 1351, loss: 764100.0
[INFO] Global_t: 1351, Episode_t: 7, Action: 92, Reward: 1.89, Epsilon: 0.01
[INFO] model update: t: 1352, loss: 689953.25
[INFO] Global_t: 1352, Episode_t: 8, Action: 162, Reward: 2.11, Epsilon: 0.01
 68%|██████▊   | 1352/2000 [26:53<13:04,  1.21s/it]
[INFO] Global step: 1352, Cumulative rewards: 15.32124, Runtime (s): 1613.60
------------------------------------------------------------
 
graph: 169, nodes: 215, edges: 635
[INFO] model update: t: 1353, loss: 51162.3828125
[INFO] Global_t: 1353, Episode_t: 1, Action: 195, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 1354, loss: 77125.4375
[INFO] Global_t: 1354, Episode_t: 2, Action: 213, Reward: 2.56, Epsilon: 0.01
[INFO] model update: t: 1355, loss: 228991.21875
[INFO] Global_t: 1355, Episode_t: 3, Action: 30, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1356, loss: 121453.765625
[INFO] Global_t: 1356, Episode_t: 4, Action: 57, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1357, loss: 59174.4765625
[INFO] Global_t: 1357, Episode_t: 5, Action: 197, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1358, loss: 10711.0078125
[INFO] Global_t: 1358, Episode_t: 6, Action: 82, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1359, loss: 86874.34375
[INFO] Global_t: 1359, Episode_t: 7, Action: 187, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1360, loss: 170739.921875
[INFO] Global_t: 1360, Episode_t: 8, Action: 145, Reward: 1.58, Epsilon: 0.01
 68%|██████▊   | 1360/2000 [26:56<10:12,  1.05it/s]
[INFO] Global step: 1360, Cumulative rewards: 16.770719999999997, Runtime (s): 1616.52
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1906933784484863
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2916719913482666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.471752643585205
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4076385498046875
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1567800045013428
average cummulative reward vector is:  [0.08338    0.07577245 0.08825055 0.07953341 0.08058978]
average cummulative reward is:  0.08150523926259619
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 170, nodes: 206, edges: 609
[INFO] model update: t: 1361, loss: 211117.53125
[INFO] Global_t: 1361, Episode_t: 1, Action: 25, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1362, loss: 109872.03125
[INFO] Global_t: 1362, Episode_t: 2, Action: 75, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 1363, loss: 10487.9130859375
[INFO] Global_t: 1363, Episode_t: 3, Action: 15, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1364, loss: 39501.9921875
[INFO] Global_t: 1364, Episode_t: 4, Action: 24, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1365, loss: 24099.9921875
[INFO] Global_t: 1365, Episode_t: 5, Action: 34, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1366, loss: 37238.15625
[INFO] Global_t: 1366, Episode_t: 6, Action: 31, Reward: 1.32, Epsilon: 0.01
[INFO] model update: t: 1367, loss: 50744.5703125
[INFO] Global_t: 1367, Episode_t: 7, Action: 148, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 1368, loss: 10817.7607421875
[INFO] Global_t: 1368, Episode_t: 8, Action: 181, Reward: 1.24, Epsilon: 0.01
 68%|██████▊   | 1368/2000 [27:11<13:05,  1.24s/it]
[INFO] Global step: 1368, Cumulative rewards: 14.264759999999997, Runtime (s): 1631.80
------------------------------------------------------------
 
graph: 171, nodes: 202, edges: 597
[INFO] model update: t: 1369, loss: 19951.11328125
[INFO] Global_t: 1369, Episode_t: 1, Action: 160, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1370, loss: 21330.890625
[INFO] Global_t: 1370, Episode_t: 2, Action: 144, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1371, loss: 21745.5
[INFO] Global_t: 1371, Episode_t: 3, Action: 187, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1372, loss: 12775.50390625
[INFO] Global_t: 1372, Episode_t: 4, Action: 43, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 1373, loss: 29879.025390625
[INFO] Global_t: 1373, Episode_t: 5, Action: 111, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1374, loss: 27518.171875
[INFO] Global_t: 1374, Episode_t: 6, Action: 27, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1375, loss: 22870.87890625
[INFO] Global_t: 1375, Episode_t: 7, Action: 153, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1376, loss: 9186.71484375
[INFO] Global_t: 1376, Episode_t: 8, Action: 96, Reward: 1.47, Epsilon: 0.01
 69%|██████▉   | 1376/2000 [27:16<10:53,  1.05s/it]
[INFO] Global step: 1376, Cumulative rewards: 13.992719999999998, Runtime (s): 1636.53
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0924651622772217
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.251026153564453
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3903791904449463
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1557724475860596
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0511345863342285
average cummulative reward vector is:  [0.07879632 0.07309074 0.08462869 0.07151799 0.07737231]
average cummulative reward is:  0.07708120950739343
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 172, nodes: 206, edges: 609
[INFO] model update: t: 1377, loss: 57714.55078125
[INFO] Global_t: 1377, Episode_t: 1, Action: 67, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 1378, loss: 23658.341796875
[INFO] Global_t: 1378, Episode_t: 2, Action: 25, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 1379, loss: 18864.359375
[INFO] Global_t: 1379, Episode_t: 3, Action: 187, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 1380, loss: 44270.7109375
[INFO] Global_t: 1380, Episode_t: 4, Action: 63, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1381, loss: 34056.05859375
[INFO] Global_t: 1381, Episode_t: 5, Action: 38, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1382, loss: 14865.97265625
[INFO] Global_t: 1382, Episode_t: 6, Action: 65, Reward: 1.67, Epsilon: 0.01
[INFO] model update: t: 1383, loss: 19664.75
[INFO] Global_t: 1383, Episode_t: 7, Action: 77, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 1384, loss: 52590.921875
[INFO] Global_t: 1384, Episode_t: 8, Action: 62, Reward: 1.38, Epsilon: 0.01
 69%|██████▉   | 1384/2000 [27:30<12:54,  1.26s/it]
[INFO] Global step: 1384, Cumulative rewards: 15.936840000000002, Runtime (s): 1650.52
------------------------------------------------------------
 
graph: 173, nodes: 217, edges: 641
[INFO] model update: t: 1385, loss: 101158.671875
[INFO] Global_t: 1385, Episode_t: 1, Action: 193, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 1386, loss: 72348.4921875
[INFO] Global_t: 1386, Episode_t: 2, Action: 114, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1387, loss: 66565.9765625
[INFO] Global_t: 1387, Episode_t: 3, Action: 96, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1388, loss: 52349.19921875
[INFO] Global_t: 1388, Episode_t: 4, Action: 95, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1389, loss: 110948.6015625
[INFO] Global_t: 1389, Episode_t: 5, Action: 135, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1390, loss: 361772.09375
[INFO] Global_t: 1390, Episode_t: 6, Action: 166, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1391, loss: 711407.8125
[INFO] Global_t: 1391, Episode_t: 7, Action: 118, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1392, loss: 171903.015625
[INFO] Global_t: 1392, Episode_t: 8, Action: 170, Reward: 1.24, Epsilon: 0.01
 70%|██████▉   | 1392/2000 [27:34<10:31,  1.04s/it]
[INFO] Global step: 1392, Cumulative rewards: 17.467680000000005, Runtime (s): 1654.75
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0520448684692383
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.269775390625
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1062910556793213
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.6597790718078613
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.300246477127075
average cummulative reward vector is:  [0.07578368 0.07246597 0.08042213 0.06948411 0.08707419]
average cummulative reward is:  0.07704601865564185
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 174, nodes: 217, edges: 640
[INFO] model update: t: 1393, loss: 177949.125
[INFO] Global_t: 1393, Episode_t: 1, Action: 65, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1394, loss: 1431277.125
[INFO] Global_t: 1394, Episode_t: 2, Action: 162, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1395, loss: 3053548.0
[INFO] Global_t: 1395, Episode_t: 3, Action: 159, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1396, loss: 3103731.5
[INFO] Global_t: 1396, Episode_t: 4, Action: 95, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1397, loss: 30562.306640625
[INFO] Global_t: 1397, Episode_t: 5, Action: 83, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1398, loss: 2845522.0
[INFO] Global_t: 1398, Episode_t: 6, Action: 27, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1399, loss: 9641660.0
[INFO] Global_t: 1399, Episode_t: 7, Action: 160, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1400, loss: 24675892.0
[INFO] Global_t: 1400, Episode_t: 8, Action: 47, Reward: 1.14, Epsilon: 0.01

 70%|███████   | 1400/2000 [27:49<12:42,  1.27s/it]6839999999999, Runtime (s): 1669.23
------------------------------------------------------------
 
graph: 175, nodes: 200, edges: 591
[INFO] model update: t: 1401, loss: 59623932.0
[INFO] Global_t: 1401, Episode_t: 1, Action: 91, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 1402, loss: 128527880.0
[INFO] Global_t: 1402, Episode_t: 2, Action: 168, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 1403, loss: 121631264.0
[INFO] Global_t: 1403, Episode_t: 3, Action: 39, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1404, loss: 55914608.0
[INFO] Global_t: 1404, Episode_t: 4, Action: 113, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1405, loss: 12253207.0
[INFO] Global_t: 1405, Episode_t: 5, Action: 174, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1406, loss: 1837636.5
[INFO] Global_t: 1406, Episode_t: 6, Action: 170, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1407, loss: 26610136.0
[INFO] Global_t: 1407, Episode_t: 7, Action: 195, Reward: 1.57, Epsilon: 0.01
[INFO] model update: t: 1408, loss: 39654192.0
[INFO] Global_t: 1408, Episode_t: 8, Action: 75, Reward: 1.71, Epsilon: 0.01
 70%|███████   | 1408/2000 [27:52<09:51,  1.00it/s]
[INFO] Global step: 1408, Cumulative rewards: 15.9312, Runtime (s): 1672.18
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.342637538909912
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3307478427886963
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1206514835357666
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.100344181060791
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0526392459869385
average cummulative reward vector is:  [0.08150974 0.07750301 0.08264454 0.0700715  0.07872419]
average cummulative reward is:  0.07809059409919603
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 176, nodes: 180, edges: 531
[INFO] model update: t: 1409, loss: 81603712.0
[INFO] Global_t: 1409, Episode_t: 1, Action: 129, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1410, loss: 89401008.0
[INFO] Global_t: 1410, Episode_t: 2, Action: 35, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1411, loss: 72559304.0
[INFO] Global_t: 1411, Episode_t: 3, Action: 23, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1412, loss: 22441868.0
[INFO] Global_t: 1412, Episode_t: 4, Action: 168, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1413, loss: 4845571.5
[INFO] Global_t: 1413, Episode_t: 5, Action: 7, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 1414, loss: 60166928.0
[INFO] Global_t: 1414, Episode_t: 6, Action: 36, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 1415, loss: 109047208.0
[INFO] Global_t: 1415, Episode_t: 7, Action: 144, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1416, loss: 167757536.0
[INFO] Global_t: 1416, Episode_t: 8, Action: 57, Reward: 1.36, Epsilon: 0.01
 71%|███████   | 1416/2000 [28:07<12:18,  1.26s/it]
[INFO] Global step: 1416, Cumulative rewards: 12.640920000000001, Runtime (s): 1687.23
------------------------------------------------------------
 
graph: 177, nodes: 192, edges: 567
[INFO] model update: t: 1417, loss: 190007808.0
[INFO] Global_t: 1417, Episode_t: 1, Action: 26, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 1418, loss: 136907792.0
[INFO] Global_t: 1418, Episode_t: 2, Action: 173, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1419, loss: 8513414.0
[INFO] Global_t: 1419, Episode_t: 3, Action: 31, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1420, loss: 37602368.0
[INFO] Global_t: 1420, Episode_t: 4, Action: 165, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 1421, loss: 151673728.0
[INFO] Global_t: 1421, Episode_t: 5, Action: 42, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1422, loss: 308621184.0
[INFO] Global_t: 1422, Episode_t: 6, Action: 53, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 1423, loss: 572971392.0
[INFO] Global_t: 1423, Episode_t: 7, Action: 133, Reward: 1.14, Epsilon: 0.01
[INFO] model update: t: 1424, loss: 281464896.0
[INFO] Global_t: 1424, Episode_t: 8, Action: 56, Reward: 1.67, Epsilon: 0.01
 71%|███████   | 1424/2000 [28:10<09:35,  1.00it/s]
[INFO] Global step: 1424, Cumulative rewards: 14.41656, Runtime (s): 1690.27
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2837977409362793
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.552652597427368
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.334806442260742
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.974785327911377
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.208645820617676
average cummulative reward vector is:  [0.08340263 0.07414583 0.08843333 0.06543505 0.08387903]
average cummulative reward is:  0.0790591754465301
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 178, nodes: 209, edges: 618
[INFO] model update: t: 1425, loss: 22219072.0
[INFO] Global_t: 1425, Episode_t: 1, Action: 102, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 1426, loss: 538815808.0
[INFO] Global_t: 1426, Episode_t: 2, Action: 96, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 1427, loss: 859490240.0
[INFO] Global_t: 1427, Episode_t: 3, Action: 51, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1428, loss: 1309488384.0
[INFO] Global_t: 1428, Episode_t: 4, Action: 112, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 1429, loss: 1142812672.0
[INFO] Global_t: 1429, Episode_t: 5, Action: 111, Reward: 1.34, Epsilon: 0.01
[INFO] model update: t: 1430, loss: 96438976.0
[INFO] Global_t: 1430, Episode_t: 6, Action: 196, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1431, loss: 2566314496.0
[INFO] Global_t: 1431, Episode_t: 7, Action: 13, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1432, loss: 4004564224.0
[INFO] Global_t: 1432, Episode_t: 8, Action: 108, Reward: 1.65, Epsilon: 0.01
 72%|███████▏  | 1432/2000 [28:25<12:00,  1.27s/it]
[INFO] Global step: 1432, Cumulative rewards: 13.908479999999997, Runtime (s): 1705.43
------------------------------------------------------------
 
graph: 179, nodes: 205, edges: 606
[INFO] model update: t: 1433, loss: 916671360.0
[INFO] Global_t: 1433, Episode_t: 1, Action: 151, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1434, loss: 790858496.0
[INFO] Global_t: 1434, Episode_t: 2, Action: 46, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1435, loss: 3751580160.0
[INFO] Global_t: 1435, Episode_t: 3, Action: 67, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1436, loss: 1854142976.0
[INFO] Global_t: 1436, Episode_t: 4, Action: 156, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1437, loss: 162345888.0
[INFO] Global_t: 1437, Episode_t: 5, Action: 85, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1438, loss: 2154545152.0
[INFO] Global_t: 1438, Episode_t: 6, Action: 134, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 1439, loss: 575354240.0
[INFO] Global_t: 1439, Episode_t: 7, Action: 169, Reward: 1.67, Epsilon: 0.01
[INFO] model update: t: 1440, loss: 296272096.0
[INFO] Global_t: 1440, Episode_t: 8, Action: 99, Reward: 1.97, Epsilon: 0.01
 72%|███████▏  | 1440/2000 [28:27<09:03,  1.03it/s]
[INFO] Global step: 1440, Cumulative rewards: 17.20932, Runtime (s): 1707.66
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.140885829925537
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9214797019958496
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.24870228767395
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.5442054271698
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.95841383934021
average cummulative reward vector is:  [0.08118316 0.06260787 0.08662295 0.07414089 0.07229086]
average cummulative reward is:  0.0753691454300601
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 180, nodes: 202, edges: 596
[INFO] model update: t: 1441, loss: 422147680.0
[INFO] Global_t: 1441, Episode_t: 1, Action: 163, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1442, loss: 35622964.0
[INFO] Global_t: 1442, Episode_t: 2, Action: 51, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1443, loss: 438162560.0
[INFO] Global_t: 1443, Episode_t: 3, Action: 66, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 1444, loss: 9163230.0
[INFO] Global_t: 1444, Episode_t: 4, Action: 160, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1445, loss: 361802624.0
[INFO] Global_t: 1445, Episode_t: 5, Action: 46, Reward: 1.57, Epsilon: 0.01
[INFO] model update: t: 1446, loss: 169479472.0
[INFO] Global_t: 1446, Episode_t: 6, Action: 162, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1447, loss: 85594080.0
[INFO] Global_t: 1447, Episode_t: 7, Action: 88, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1448, loss: 87934369792.0
[INFO] Global_t: 1448, Episode_t: 8, Action: 97, Reward: 1.30, Epsilon: 0.01
 72%|███████▏  | 1448/2000 [28:43<11:33,  1.26s/it]
[INFO] Global step: 1448, Cumulative rewards: 14.854559999999998, Runtime (s): 1723.02
------------------------------------------------------------
 
graph: 181, nodes: 205, edges: 606
[INFO] model update: t: 1449, loss: 166981730304.0
[INFO] Global_t: 1449, Episode_t: 1, Action: 139, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1450, loss: 190120935424.0
[INFO] Global_t: 1450, Episode_t: 2, Action: 148, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 1451, loss: 5240978432.0
[INFO] Global_t: 1451, Episode_t: 3, Action: 134, Reward: 1.74, Epsilon: 0.01
[INFO] model update: t: 1452, loss: 25989771264.0
[INFO] Global_t: 1452, Episode_t: 4, Action: 196, Reward: 1.71, Epsilon: 0.01
[INFO] model update: t: 1453, loss: 30863949824.0
[INFO] Global_t: 1453, Episode_t: 5, Action: 166, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1454, loss: 6185315840.0
[INFO] Global_t: 1454, Episode_t: 6, Action: 179, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1455, loss: 22829754368.0
[INFO] Global_t: 1455, Episode_t: 7, Action: 181, Reward: 1.04, Epsilon: 0.01
[INFO] model update: t: 1456, loss: 10452314112.0
[INFO] Global_t: 1456, Episode_t: 8, Action: 118, Reward: 0.89, Epsilon: 0.01
 73%|███████▎  | 1456/2000 [28:47<09:32,  1.05s/it]
[INFO] Global step: 1456, Cumulative rewards: 12.984119999999997, Runtime (s): 1727.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.548079013824463
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6005859375
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5051133632659912
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4776802062988281
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.6945180892944336
average cummulative reward vector is:  [0.05474658 0.05239653 0.06084536 0.04922897 0.05927097]
average cummulative reward is:  0.055297680324191065
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 182, nodes: 205, edges: 606
[INFO] model update: t: 1457, loss: 1303840000.0
[INFO] Global_t: 1457, Episode_t: 1, Action: 187, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 1458, loss: 7872429056.0
[INFO] Global_t: 1458, Episode_t: 2, Action: 162, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1459, loss: 1637655808.0
[INFO] Global_t: 1459, Episode_t: 3, Action: 107, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1460, loss: 915027392.0
[INFO] Global_t: 1460, Episode_t: 4, Action: 191, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1461, loss: 513475872.0
[INFO] Global_t: 1461, Episode_t: 5, Action: 181, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1462, loss: 177986672.0
[INFO] Global_t: 1462, Episode_t: 6, Action: 71, Reward: 1.05, Epsilon: 0.01
[INFO] model update: t: 1463, loss: 4170770.75
[INFO] Global_t: 1463, Episode_t: 7, Action: 83, Reward: 0.97, Epsilon: 0.01
[INFO] model update: t: 1464, loss: 73674336.0
[INFO] Global_t: 1464, Episode_t: 8, Action: 136, Reward: 0.89, Epsilon: 0.01
 73%|███████▎  | 1464/2000 [28:58<10:07,  1.13s/it]
[INFO] Global step: 1464, Cumulative rewards: 9.965519999999998, Runtime (s): 1738.25
------------------------------------------------------------
 
graph: 183, nodes: 217, edges: 642
[INFO] model update: t: 1465, loss: 203571680.0
[INFO] Global_t: 1465, Episode_t: 1, Action: 182, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1466, loss: 308929344.0
[INFO] Global_t: 1466, Episode_t: 2, Action: 181, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1467, loss: 179981968.0
[INFO] Global_t: 1467, Episode_t: 3, Action: 93, Reward: 1.57, Epsilon: 0.01
[INFO] model update: t: 1468, loss: 43253100.0
[INFO] Global_t: 1468, Episode_t: 4, Action: 154, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1469, loss: 6210891.5
[INFO] Global_t: 1469, Episode_t: 5, Action: 213, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1470, loss: 39580148.0
[INFO] Global_t: 1470, Episode_t: 6, Action: 205, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1471, loss: 126905808.0
[INFO] Global_t: 1471, Episode_t: 7, Action: 171, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 1472, loss: 203042832.0
[INFO] Global_t: 1472, Episode_t: 8, Action: 212, Reward: 1.45, Epsilon: 0.01
 74%|███████▎  | 1472/2000 [29:01<07:56,  1.11it/s]
[INFO] Global step: 1472, Cumulative rewards: 12.013440000000001, Runtime (s): 1741.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.756714105606079
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9624338150024414
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.9610612392425537
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8814024925231934
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.7582271099090576
average cummulative reward vector is:  [0.06551263 0.06413912 0.0678877  0.06334089 0.06729355]
average cummulative reward is:  0.06563477862098291
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 184, nodes: 196, edges: 579
[INFO] model update: t: 1473, loss: 87285360.0
[INFO] Global_t: 1473, Episode_t: 1, Action: 124, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 1474, loss: 29850158.0
[INFO] Global_t: 1474, Episode_t: 2, Action: 7, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 1475, loss: 6767604.0
[INFO] Global_t: 1475, Episode_t: 3, Action: 23, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 1476, loss: 18055474.0
[INFO] Global_t: 1476, Episode_t: 4, Action: 191, Reward: 0.98, Epsilon: 0.01
[INFO] model update: t: 1477, loss: 44993376.0
[INFO] Global_t: 1477, Episode_t: 5, Action: 50, Reward: 1.27, Epsilon: 0.01
[INFO] model update: t: 1478, loss: 53825608.0
[INFO] Global_t: 1478, Episode_t: 6, Action: 132, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1479, loss: 49264336.0
[INFO] Global_t: 1479, Episode_t: 7, Action: 137, Reward: 1.28, Epsilon: 0.01
[INFO] model update: t: 1480, loss: 38852448.0
[INFO] Global_t: 1480, Episode_t: 8, Action: 83, Reward: 0.87, Epsilon: 0.01
 74%|███████▍  | 1480/2000 [29:14<09:45,  1.13s/it]
[INFO] Global step: 1480, Cumulative rewards: 12.706800000000005, Runtime (s): 1754.32
------------------------------------------------------------
 
graph: 185, nodes: 180, edges: 530
[INFO] model update: t: 1481, loss: 8458222.0
[INFO] Global_t: 1481, Episode_t: 1, Action: 4, Reward: 5.14, Epsilon: 0.01
[INFO] model update: t: 1482, loss: 4655888.0
[INFO] Global_t: 1482, Episode_t: 2, Action: 82, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1483, loss: 8879283.0
[INFO] Global_t: 1483, Episode_t: 3, Action: 113, Reward: 1.04, Epsilon: 0.01
[INFO] model update: t: 1484, loss: 38127064.0
[INFO] Global_t: 1484, Episode_t: 4, Action: 107, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 1485, loss: 30515104.0
[INFO] Global_t: 1485, Episode_t: 5, Action: 149, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1486, loss: 32133992.0
[INFO] Global_t: 1486, Episode_t: 6, Action: 128, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1487, loss: 14067202.0
[INFO] Global_t: 1487, Episode_t: 7, Action: 66, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1488, loss: 2594926.5
[INFO] Global_t: 1488, Episode_t: 8, Action: 165, Reward: 1.34, Epsilon: 0.01
 74%|███████▍  | 1488/2000 [29:18<08:11,  1.04it/s]
[INFO] Global step: 1488, Cumulative rewards: 14.399159999999998, Runtime (s): 1758.90
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1930766105651855
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.5093698501586914
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.459932804107666
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4957592487335205
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0072357654571533
average cummulative reward vector is:  [0.07997684 0.08034074 0.08699344 0.08309696 0.07634247]
average cummulative reward is:  0.08135009224081133
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 186, nodes: 210, edges: 621
[INFO] model update: t: 1489, loss: 2971766.25
[INFO] Global_t: 1489, Episode_t: 1, Action: 8, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1490, loss: 19331036.0
[INFO] Global_t: 1490, Episode_t: 2, Action: 12, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1491, loss: 19610016.0
[INFO] Global_t: 1491, Episode_t: 3, Action: 13, Reward: 4.43, Epsilon: 0.01
[INFO] model update: t: 1492, loss: 21042930.0
[INFO] Global_t: 1492, Episode_t: 4, Action: 138, Reward: 1.68, Epsilon: 0.01
[INFO] model update: t: 1493, loss: 837416960.0
[INFO] Global_t: 1493, Episode_t: 5, Action: 107, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 1494, loss: 8395738.0
[INFO] Global_t: 1494, Episode_t: 6, Action: 170, Reward: 0.89, Epsilon: 0.01
[INFO] model update: t: 1495, loss: 71784768.0
[INFO] Global_t: 1495, Episode_t: 7, Action: 141, Reward: 1.01, Epsilon: 0.01
[INFO] model update: t: 1496, loss: 111921800.0
[INFO] Global_t: 1496, Episode_t: 8, Action: 183, Reward: 0.72, Epsilon: 0.01
 75%|███████▍  | 1496/2000 [29:34<10:26,  1.24s/it]
[INFO] Global step: 1496, Cumulative rewards: 19.704479999999997, Runtime (s): 1774.11
------------------------------------------------------------
 
graph: 187, nodes: 210, edges: 621
[INFO] model update: t: 1497, loss: 124481672.0
[INFO] Global_t: 1497, Episode_t: 1, Action: 150, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1498, loss: 100867728.0
[INFO] Global_t: 1498, Episode_t: 2, Action: 6, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 1499, loss: 56014320.0
[INFO] Global_t: 1499, Episode_t: 3, Action: 79, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1500, loss: 2933424.75
[INFO] Global_t: 1500, Episode_t: 4, Action: 156, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1501, loss: 23675376.0
[INFO] Global_t: 1501, Episode_t: 5, Action: 126, Reward: 1.14, Epsilon: 0.01
[INFO] model update: t: 1502, loss: 59834696.0
[INFO] Global_t: 1502, Episode_t: 6, Action: 117, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1503, loss: 68185136.0
[INFO] Global_t: 1503, Episode_t: 7, Action: 119, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1504, loss: 69912512.0
[INFO] Global_t: 1504, Episode_t: 8, Action: 73, Reward: 1.14, Epsilon: 0.01
 75%|███████▌  | 1504/2000 [29:38<08:37,  1.04s/it]
[INFO] Global step: 1504, Cumulative rewards: 13.465080000000002, Runtime (s): 1778.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.116255760192871
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2753920555114746
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.299445867538452
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.6663787364959717
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3570284843444824
average cummulative reward vector is:  [0.07575737 0.07218056 0.08694344 0.07909907 0.09009919]
average cummulative reward is:  0.08081592511370136
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 188, nodes: 198, edges: 585
[INFO] model update: t: 1505, loss: 42561860.0
[INFO] Global_t: 1505, Episode_t: 1, Action: 8, Reward: 5.11, Epsilon: 0.01
[INFO] model update: t: 1506, loss: 8154979.0
[INFO] Global_t: 1506, Episode_t: 2, Action: 168, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1507, loss: 5989823.0
[INFO] Global_t: 1507, Episode_t: 3, Action: 95, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1508, loss: 32991472.0
[INFO] Global_t: 1508, Episode_t: 4, Action: 124, Reward: 0.99, Epsilon: 0.01
[INFO] model update: t: 1509, loss: 29653920.0
[INFO] Global_t: 1509, Episode_t: 5, Action: 163, Reward: 1.34, Epsilon: 0.01
[INFO] model update: t: 1510, loss: 44428900.0
[INFO] Global_t: 1510, Episode_t: 6, Action: 83, Reward: 0.98, Epsilon: 0.01
[INFO] model update: t: 1511, loss: 20529958.0
[INFO] Global_t: 1511, Episode_t: 7, Action: 140, Reward: 0.63, Epsilon: 0.01
[INFO] model update: t: 1512, loss: 17077806.0
[INFO] Global_t: 1512, Episode_t: 8, Action: 180, Reward: 1.06, Epsilon: 0.01
 76%|███████▌  | 1512/2000 [29:54<10:42,  1.32s/it]
[INFO] Global step: 1512, Cumulative rewards: 12.800519999999999, Runtime (s): 1794.40
------------------------------------------------------------
 
graph: 189, nodes: 180, edges: 531
[INFO] model update: t: 1513, loss: 8817338.0
[INFO] Global_t: 1513, Episode_t: 1, Action: 9, Reward: 4.63, Epsilon: 0.01
[INFO] model update: t: 1514, loss: 5505172.0
[INFO] Global_t: 1514, Episode_t: 2, Action: 8, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1515, loss: 16929528.0
[INFO] Global_t: 1515, Episode_t: 3, Action: 5, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1516, loss: 21929748.0
[INFO] Global_t: 1516, Episode_t: 4, Action: 86, Reward: 0.81, Epsilon: 0.01
[INFO] model update: t: 1517, loss: 21471864.0
[INFO] Global_t: 1517, Episode_t: 5, Action: 144, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1518, loss: 14354863.0
[INFO] Global_t: 1518, Episode_t: 6, Action: 65, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1519, loss: 5381170.5
[INFO] Global_t: 1519, Episode_t: 7, Action: 130, Reward: 0.94, Epsilon: 0.01
[INFO] model update: t: 1520, loss: 113707.40625
[INFO] Global_t: 1520, Episode_t: 8, Action: 167, Reward: 1.26, Epsilon: 0.01
 76%|███████▌  | 1520/2000 [29:57<08:17,  1.04s/it]
[INFO] Global step: 1520, Cumulative rewards: 18.59052, Runtime (s): 1797.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.299107789993286
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.0524017810821533
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.255200147628784
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2150750160217285
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3462347984313965
average cummulative reward vector is:  [0.08650947 0.06847407 0.08724891 0.07043481 0.0824043 ]
average cummulative reward is:  0.07901431380429813
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 190, nodes: 194, edges: 573
[INFO] model update: t: 1521, loss: 3381332.0
[INFO] Global_t: 1521, Episode_t: 1, Action: 3, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1522, loss: 6285148.0
[INFO] Global_t: 1522, Episode_t: 2, Action: 16, Reward: 4.72, Epsilon: 0.01
[INFO] model update: t: 1523, loss: 19687078.0
[INFO] Global_t: 1523, Episode_t: 3, Action: 144, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1524, loss: 6693671.0
[INFO] Global_t: 1524, Episode_t: 4, Action: 193, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1525, loss: 4179582.0
[INFO] Global_t: 1525, Episode_t: 5, Action: 169, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1526, loss: 560648.6875
[INFO] Global_t: 1526, Episode_t: 6, Action: 167, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1527, loss: 1889206.75
[INFO] Global_t: 1527, Episode_t: 7, Action: 139, Reward: 1.09, Epsilon: 0.01
[INFO] model update: t: 1528, loss: 2350925.5
[INFO] Global_t: 1528, Episode_t: 8, Action: 127, Reward: 0.98, Epsilon: 0.01
 76%|███████▋  | 1528/2000 [30:11<09:58,  1.27s/it]
[INFO] Global step: 1528, Cumulative rewards: 17.025959999999998, Runtime (s): 1811.92
------------------------------------------------------------
 
graph: 191, nodes: 183, edges: 539
[INFO] model update: t: 1529, loss: 3347741.25
[INFO] Global_t: 1529, Episode_t: 1, Action: 17, Reward: 4.75, Epsilon: 0.01
[INFO] model update: t: 1530, loss: 7268131.0
[INFO] Global_t: 1530, Episode_t: 2, Action: 121, Reward: 1.27, Epsilon: 0.01
[INFO] model update: t: 1531, loss: 6829283.5
[INFO] Global_t: 1531, Episode_t: 3, Action: 116, Reward: 0.87, Epsilon: 0.01
[INFO] model update: t: 1532, loss: 4963741.5
[INFO] Global_t: 1532, Episode_t: 4, Action: 144, Reward: 1.04, Epsilon: 0.01
[INFO] model update: t: 1533, loss: 2119478.5
[INFO] Global_t: 1533, Episode_t: 5, Action: 110, Reward: 0.81, Epsilon: 0.01
[INFO] model update: t: 1534, loss: 4171748.0
[INFO] Global_t: 1534, Episode_t: 6, Action: 95, Reward: 0.82, Epsilon: 0.01
[INFO] model update: t: 1535, loss: 7545532.5
[INFO] Global_t: 1535, Episode_t: 7, Action: 139, Reward: 0.96, Epsilon: 0.01
[INFO] model update: t: 1536, loss: 3517192.25
[INFO] Global_t: 1536, Episode_t: 8, Action: 176, Reward: 0.74, Epsilon: 0.01
 77%|███████▋  | 1536/2000 [30:15<07:59,  1.03s/it]
[INFO] Global step: 1536, Cumulative rewards: 11.265479999999998, Runtime (s): 1815.79
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.4377429485321045
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.0540359020233154
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.514479160308838
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.313901901245117
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2861828804016113
average cummulative reward vector is:  [0.08327105 0.06536435 0.09779044 0.07682593 0.08771505]
average cummulative reward is:  0.08219336599695617
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 192, nodes: 214, edges: 633
[INFO] model update: t: 1537, loss: 11333660.0
[INFO] Global_t: 1537, Episode_t: 1, Action: 15, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1538, loss: 6449998.0
[INFO] Global_t: 1538, Episode_t: 2, Action: 8, Reward: 5.13, Epsilon: 0.01
[INFO] model update: t: 1539, loss: 12382278.0
[INFO] Global_t: 1539, Episode_t: 3, Action: 2, Reward: 4.85, Epsilon: 0.01
[INFO] model update: t: 1540, loss: 10504145.0
[INFO] Global_t: 1540, Episode_t: 4, Action: 162, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1541, loss: 2919988.25
[INFO] Global_t: 1541, Episode_t: 5, Action: 158, Reward: 1.15, Epsilon: 0.01
[INFO] model update: t: 1542, loss: 5334467.5
[INFO] Global_t: 1542, Episode_t: 6, Action: 151, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1543, loss: 4486256.5
[INFO] Global_t: 1543, Episode_t: 7, Action: 165, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 1544, loss: 3562744.25
[INFO] Global_t: 1544, Episode_t: 8, Action: 92, Reward: 1.32, Epsilon: 0.01
 77%|███████▋  | 1544/2000 [30:30<09:45,  1.28s/it]
[INFO] Global step: 1544, Cumulative rewards: 21.3552, Runtime (s): 1830.76
------------------------------------------------------------
 
graph: 193, nodes: 218, edges: 645
[INFO] model update: t: 1545, loss: 3310492.0
[INFO] Global_t: 1545, Episode_t: 1, Action: 11, Reward: 5.03, Epsilon: 0.01
[INFO] model update: t: 1546, loss: 6137151.0
[INFO] Global_t: 1546, Episode_t: 2, Action: 6, Reward: 4.96, Epsilon: 0.01
[INFO] model update: t: 1547, loss: 2379304.5
[INFO] Global_t: 1547, Episode_t: 3, Action: 206, Reward: 0.84, Epsilon: 0.01
[INFO] model update: t: 1548, loss: 8804048.0
[INFO] Global_t: 1548, Episode_t: 4, Action: 179, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1549, loss: 1363982.25
[INFO] Global_t: 1549, Episode_t: 5, Action: 153, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 1550, loss: 1182707.75
[INFO] Global_t: 1550, Episode_t: 6, Action: 171, Reward: 1.17, Epsilon: 0.01
[INFO] model update: t: 1551, loss: 1203964.875
[INFO] Global_t: 1551, Episode_t: 7, Action: 73, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1552, loss: 6537310.0
[INFO] Global_t: 1552, Episode_t: 8, Action: 215, Reward: 1.42, Epsilon: 0.01
 78%|███████▊  | 1552/2000 [30:34<07:43,  1.04s/it]
[INFO] Global step: 1552, Cumulative rewards: 17.878200000000003, Runtime (s): 1834.39
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.26086688041687
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.429149627685547
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3521170616149902
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.290872097015381
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1326611042022705
average cummulative reward vector is:  [0.0825     0.06720556 0.08979754 0.07506846 0.08082473]
average cummulative reward is:  0.07907925713317662
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 194, nodes: 213, edges: 630
[INFO] model update: t: 1553, loss: 2006636.0
[INFO] Global_t: 1553, Episode_t: 1, Action: 10, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 1554, loss: 2280859.5
[INFO] Global_t: 1554, Episode_t: 2, Action: 72, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1555, loss: 1864065.75
[INFO] Global_t: 1555, Episode_t: 3, Action: 200, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1556, loss: 3018237.0
[INFO] Global_t: 1556, Episode_t: 4, Action: 127, Reward: 1.01, Epsilon: 0.01
[INFO] model update: t: 1557, loss: 1837414.75
[INFO] Global_t: 1557, Episode_t: 5, Action: 163, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1558, loss: 1978069.75
[INFO] Global_t: 1558, Episode_t: 6, Action: 181, Reward: 0.77, Epsilon: 0.01
[INFO] model update: t: 1559, loss: 564539.4375
[INFO] Global_t: 1559, Episode_t: 7, Action: 175, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1560, loss: 5276392.0
[INFO] Global_t: 1560, Episode_t: 8, Action: 92, Reward: 1.16, Epsilon: 0.01
 78%|███████▊  | 1560/2000 [30:51<09:53,  1.35s/it]
[INFO] Global step: 1560, Cumulative rewards: 13.988999999999999, Runtime (s): 1851.05
------------------------------------------------------------
 
graph: 195, nodes: 189, edges: 558
[INFO] model update: t: 1561, loss: 2157550.75
[INFO] Global_t: 1561, Episode_t: 1, Action: 9, Reward: 4.89, Epsilon: 0.01
[INFO] model update: t: 1562, loss: 7087743.0
[INFO] Global_t: 1562, Episode_t: 2, Action: 155, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1563, loss: 1399538.625
[INFO] Global_t: 1563, Episode_t: 3, Action: 170, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1564, loss: 1845678.125
[INFO] Global_t: 1564, Episode_t: 4, Action: 134, Reward: 1.48, Epsilon: 0.01
[INFO] model update: t: 1565, loss: 1872142.625
[INFO] Global_t: 1565, Episode_t: 5, Action: 116, Reward: 0.65, Epsilon: 0.01
[INFO] model update: t: 1566, loss: 2679260.75
[INFO] Global_t: 1566, Episode_t: 6, Action: 113, Reward: 1.28, Epsilon: 0.01
[INFO] model update: t: 1567, loss: 2019458.0
[INFO] Global_t: 1567, Episode_t: 7, Action: 171, Reward: 1.03, Epsilon: 0.01
[INFO] model update: t: 1568, loss: 1870168.125
[INFO] Global_t: 1568, Episode_t: 8, Action: 108, Reward: 0.95, Epsilon: 0.01
 78%|███████▊  | 1568/2000 [30:55<08:00,  1.11s/it]
[INFO] Global step: 1568, Cumulative rewards: 13.109879999999997, Runtime (s): 1855.50
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1835551261901855
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.709524154663086
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1384224891662598
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2226405143737793
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.187437057495117
average cummulative reward vector is:  [0.08033447 0.08186204 0.08199672 0.07260491 0.08550565]
average cummulative reward is:  0.08046075674721388
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 196, nodes: 208, edges: 615
[INFO] model update: t: 1569, loss: 2433789.25
[INFO] Global_t: 1569, Episode_t: 1, Action: 5, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1570, loss: 1384208.75
[INFO] Global_t: 1570, Episode_t: 2, Action: 1, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1571, loss: 2097593.25
[INFO] Global_t: 1571, Episode_t: 3, Action: 71, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1572, loss: 1748817.25
[INFO] Global_t: 1572, Episode_t: 4, Action: 155, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 1573, loss: 1934283.0
[INFO] Global_t: 1573, Episode_t: 5, Action: 158, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1574, loss: 1841145.875
[INFO] Global_t: 1574, Episode_t: 6, Action: 168, Reward: 0.92, Epsilon: 0.01
[INFO] model update: t: 1575, loss: 1004994.1875
[INFO] Global_t: 1575, Episode_t: 7, Action: 199, Reward: 0.72, Epsilon: 0.01
[INFO] model update: t: 1576, loss: 3627560.75
[INFO] Global_t: 1576, Episode_t: 8, Action: 122, Reward: 1.44, Epsilon: 0.01
 79%|███████▉  | 1576/2000 [31:11<09:38,  1.37s/it]
[INFO] Global step: 1576, Cumulative rewards: 16.48668, Runtime (s): 1871.16
------------------------------------------------------------
 
graph: 197, nodes: 197, edges: 582
[INFO] model update: t: 1577, loss: 3650294.0
[INFO] Global_t: 1577, Episode_t: 1, Action: 2, Reward: 4.84, Epsilon: 0.01
[INFO] model update: t: 1578, loss: 1729021.375
[INFO] Global_t: 1578, Episode_t: 2, Action: 97, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1579, loss: 1507681.5
[INFO] Global_t: 1579, Episode_t: 3, Action: 194, Reward: 1.34, Epsilon: 0.01
[INFO] model update: t: 1580, loss: 2885265.5
[INFO] Global_t: 1580, Episode_t: 4, Action: 180, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1581, loss: 1315273.5
[INFO] Global_t: 1581, Episode_t: 5, Action: 139, Reward: 1.04, Epsilon: 0.01
[INFO] model update: t: 1582, loss: 3104399.0
[INFO] Global_t: 1582, Episode_t: 6, Action: 67, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1583, loss: 1570657.5
[INFO] Global_t: 1583, Episode_t: 7, Action: 104, Reward: 0.92, Epsilon: 0.01
[INFO] model update: t: 1584, loss: 1820349.75
[INFO] Global_t: 1584, Episode_t: 8, Action: 141, Reward: 1.26, Epsilon: 0.01
 79%|███████▉  | 1584/2000 [31:14<07:32,  1.09s/it]
[INFO] Global step: 1584, Cumulative rewards: 13.716720000000002, Runtime (s): 1874.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.336724042892456
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3597934246063232
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.677151679992676
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.431169271469116
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.7622439861297607
average cummulative reward vector is:  [0.08548868 0.07624653 0.09371585 0.07792991 0.10288387]
average cummulative reward is:  0.08725296729852752
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 198, nodes: 187, edges: 552
[INFO] model update: t: 1585, loss: 1326467.625
[INFO] Global_t: 1585, Episode_t: 1, Action: 5, Reward: 5.18, Epsilon: 0.01
[INFO] model update: t: 1586, loss: 2929993.75
[INFO] Global_t: 1586, Episode_t: 2, Action: 7, Reward: 5.21, Epsilon: 0.01
[INFO] model update: t: 1587, loss: 1762891.5
[INFO] Global_t: 1587, Episode_t: 3, Action: 40, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 1588, loss: 704369.0
[INFO] Global_t: 1588, Episode_t: 4, Action: 105, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1589, loss: 253853.59375
[INFO] Global_t: 1589, Episode_t: 5, Action: 166, Reward: 1.00, Epsilon: 0.01
[INFO] model update: t: 1590, loss: 2224862.75
[INFO] Global_t: 1590, Episode_t: 6, Action: 112, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1591, loss: 668159.5
[INFO] Global_t: 1591, Episode_t: 7, Action: 137, Reward: 0.96, Epsilon: 0.01
[INFO] model update: t: 1592, loss: 1062690.75
[INFO] Global_t: 1592, Episode_t: 8, Action: 95, Reward: 1.03, Epsilon: 0.01
 80%|███████▉  | 1592/2000 [31:31<09:33,  1.40s/it]
[INFO] Global step: 1592, Cumulative rewards: 17.93856, Runtime (s): 1891.83
------------------------------------------------------------
 
graph: 199, nodes: 216, edges: 638
[INFO] model update: t: 1593, loss: 3472453.75
[INFO] Global_t: 1593, Episode_t: 1, Action: 8, Reward: 5.29, Epsilon: 0.01
[INFO] model update: t: 1594, loss: 1411308.875
[INFO] Global_t: 1594, Episode_t: 2, Action: 25, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1595, loss: 1973487.0
[INFO] Global_t: 1595, Episode_t: 3, Action: 14, Reward: 4.96, Epsilon: 0.01
[INFO] model update: t: 1596, loss: 1373198.625
[INFO] Global_t: 1596, Episode_t: 4, Action: 215, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1597, loss: 3226801.75
[INFO] Global_t: 1597, Episode_t: 5, Action: 119, Reward: 0.99, Epsilon: 0.01
[INFO] model update: t: 1598, loss: 700512.375
[INFO] Global_t: 1598, Episode_t: 6, Action: 139, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1599, loss: 1020417.125
[INFO] Global_t: 1599, Episode_t: 7, Action: 186, Reward: 1.01, Epsilon: 0.01
[INFO] model update: t: 1600, loss: 1793074.75
[INFO] Global_t: 1600, Episode_t: 8, Action: 66, Reward: 1.29, Epsilon: 0.01
 80%|████████  | 1600/2000 [31:35<07:23,  1.11s/it]
[INFO] Global step: 1600, Cumulative rewards: 20.838839999999998, Runtime (s): 1895.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.4810397624969482
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.594968557357788
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3152403831481934
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.120659112930298
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.1009769439697266
average cummulative reward vector is:  [0.09266342 0.08433495 0.08201011 0.06951495 0.08140618]
average cummulative reward is:  0.08198592402253595
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  1
graph: 0, nodes: 180, edges: 531
[INFO] model update: t: 1601, loss: 1406543.5
[INFO] Global_t: 1601, Episode_t: 1, Action: 9, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1602, loss: 6027036.0
[INFO] Global_t: 1602, Episode_t: 2, Action: 12, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1603, loss: 3499082.0
[INFO] Global_t: 1603, Episode_t: 3, Action: 176, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 1604, loss: 5605164.0
[INFO] Global_t: 1604, Episode_t: 4, Action: 100, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1605, loss: 1523422.75
[INFO] Global_t: 1605, Episode_t: 5, Action: 131, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1606, loss: 1910893.5
[INFO] Global_t: 1606, Episode_t: 6, Action: 107, Reward: 1.11, Epsilon: 0.01
[INFO] model update: t: 1607, loss: 3822269.0
[INFO] Global_t: 1607, Episode_t: 7, Action: 149, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 1608, loss: 2835998.5
[INFO] Global_t: 1608, Episode_t: 8, Action: 154, Reward: 0.87, Epsilon: 0.01
 80%|████████  | 1608/2000 [31:50<08:46,  1.34s/it]
[INFO] Global step: 1608, Cumulative rewards: 17.190000000000005, Runtime (s): 1910.32
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] model update: t: 1609, loss: 1294950.25
[INFO] Global_t: 1609, Episode_t: 1, Action: 12, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1610, loss: 993215.25
[INFO] Global_t: 1610, Episode_t: 2, Action: 6, Reward: 4.85, Epsilon: 0.01
[INFO] model update: t: 1611, loss: 1731759.125
[INFO] Global_t: 1611, Episode_t: 3, Action: 69, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1612, loss: 3841015.75
[INFO] Global_t: 1612, Episode_t: 4, Action: 185, Reward: 0.84, Epsilon: 0.01
[INFO] model update: t: 1613, loss: 1573288.125
[INFO] Global_t: 1613, Episode_t: 5, Action: 116, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1614, loss: 1006197.375
[INFO] Global_t: 1614, Episode_t: 6, Action: 178, Reward: 1.60, Epsilon: 0.01
[INFO] model update: t: 1615, loss: 3832261.5
[INFO] Global_t: 1615, Episode_t: 7, Action: 180, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1616, loss: 1056644.875
[INFO] Global_t: 1616, Episode_t: 8, Action: 183, Reward: 1.51, Epsilon: 0.01
 81%|████████  | 1616/2000 [31:54<07:08,  1.12s/it]
[INFO] Global step: 1616, Cumulative rewards: 18.357599999999998, Runtime (s): 1914.96
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.5650157928466797
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.186812162399292
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.547098398208618
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1586596965789795
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3760123252868652
average cummulative reward vector is:  [0.09165632 0.0710331  0.08725847 0.07103738 0.09338065]
average cummulative reward is:  0.08287318318510824
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] model update: t: 1617, loss: 1050577.625
[INFO] Global_t: 1617, Episode_t: 1, Action: 6, Reward: 5.34, Epsilon: 0.01
[INFO] model update: t: 1618, loss: 2261341.75
[INFO] Global_t: 1618, Episode_t: 2, Action: 191, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1619, loss: 1477032.375
[INFO] Global_t: 1619, Episode_t: 3, Action: 166, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1620, loss: 4090974.75
[INFO] Global_t: 1620, Episode_t: 4, Action: 167, Reward: 1.00, Epsilon: 0.01
[INFO] model update: t: 1621, loss: 2864068.25
[INFO] Global_t: 1621, Episode_t: 5, Action: 122, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1622, loss: 2193549.5
[INFO] Global_t: 1622, Episode_t: 6, Action: 138, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1623, loss: 2658084.0
[INFO] Global_t: 1623, Episode_t: 7, Action: 164, Reward: 1.48, Epsilon: 0.01
[INFO] model update: t: 1624, loss: 625970.0
[INFO] Global_t: 1624, Episode_t: 8, Action: 213, Reward: 1.61, Epsilon: 0.01
 81%|████████  | 1624/2000 [32:10<08:36,  1.37s/it]
[INFO] Global step: 1624, Cumulative rewards: 14.64132, Runtime (s): 1930.81
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] model update: t: 1625, loss: 830109.875
[INFO] Global_t: 1625, Episode_t: 1, Action: 1, Reward: 4.97, Epsilon: 0.01
[INFO] model update: t: 1626, loss: 812732.5
[INFO] Global_t: 1626, Episode_t: 2, Action: 136, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1627, loss: 1606630.25
[INFO] Global_t: 1627, Episode_t: 3, Action: 159, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 1628, loss: 1124495.625
[INFO] Global_t: 1628, Episode_t: 4, Action: 125, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1629, loss: 6823151.5
[INFO] Global_t: 1629, Episode_t: 5, Action: 195, Reward: 1.48, Epsilon: 0.01
[INFO] model update: t: 1630, loss: 454435.5625
[INFO] Global_t: 1630, Episode_t: 6, Action: 132, Reward: 0.96, Epsilon: 0.01
[INFO] model update: t: 1631, loss: 1000524.0
[INFO] Global_t: 1631, Episode_t: 7, Action: 174, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1632, loss: 1115918.75
[INFO] Global_t: 1632, Episode_t: 8, Action: 144, Reward: 1.36, Epsilon: 0.01
 82%|████████▏ | 1632/2000 [32:15<06:57,  1.13s/it]
[INFO] Global step: 1632, Cumulative rewards: 14.61372, Runtime (s): 1935.41
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.3542299270629883
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.356482982635498
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.9604830741882324
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4967732429504395
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.997441291809082
average cummulative reward vector is:  [0.08805632 0.07780463 0.07438169 0.07482009 0.07567554]
average cummulative reward is:  0.07814765410010537
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] model update: t: 1633, loss: 3374111.25
[INFO] Global_t: 1633, Episode_t: 1, Action: 10, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1634, loss: 1419557.125
[INFO] Global_t: 1634, Episode_t: 2, Action: 127, Reward: 0.60, Epsilon: 0.01
[INFO] model update: t: 1635, loss: 1467675.125
[INFO] Global_t: 1635, Episode_t: 3, Action: 173, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1636, loss: 1794806.5
[INFO] Global_t: 1636, Episode_t: 4, Action: 161, Reward: 0.78, Epsilon: 0.01
[INFO] model update: t: 1637, loss: 2452885.75
[INFO] Global_t: 1637, Episode_t: 5, Action: 139, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1638, loss: 3100933.5
[INFO] Global_t: 1638, Episode_t: 6, Action: 87, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1639, loss: 2556707.0
[INFO] Global_t: 1639, Episode_t: 7, Action: 115, Reward: 1.08, Epsilon: 0.01
[INFO] model update: t: 1640, loss: 1690520.0
[INFO] Global_t: 1640, Episode_t: 8, Action: 152, Reward: 1.01, Epsilon: 0.01
 82%|████████▏ | 1640/2000 [32:29<08:01,  1.34s/it]
[INFO] Global step: 1640, Cumulative rewards: 12.479879999999998, Runtime (s): 1949.93
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] model update: t: 1641, loss: 3252695.0
[INFO] Global_t: 1641, Episode_t: 1, Action: 6, Reward: 5.03, Epsilon: 0.01
[INFO] model update: t: 1642, loss: 1440173.75
[INFO] Global_t: 1642, Episode_t: 2, Action: 163, Reward: 0.91, Epsilon: 0.01
[INFO] model update: t: 1643, loss: 3283488.0
[INFO] Global_t: 1643, Episode_t: 3, Action: 86, Reward: 0.87, Epsilon: 0.01
[INFO] model update: t: 1644, loss: 2991043.5
[INFO] Global_t: 1644, Episode_t: 4, Action: 180, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1645, loss: 1535784.25
[INFO] Global_t: 1645, Episode_t: 5, Action: 115, Reward: 1.34, Epsilon: 0.01
[INFO] model update: t: 1646, loss: 1211444.75
[INFO] Global_t: 1646, Episode_t: 6, Action: 124, Reward: 1.30, Epsilon: 0.01
[INFO] model update: t: 1647, loss: 1469408.25
[INFO] Global_t: 1647, Episode_t: 7, Action: 114, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1648, loss: 2045016.25
[INFO] Global_t: 1648, Episode_t: 8, Action: 166, Reward: 0.99, Epsilon: 0.01
 82%|████████▏ | 1648/2000 [32:33<06:21,  1.08s/it]
[INFO] Global step: 1648, Cumulative rewards: 13.451160000000002, Runtime (s): 1953.84
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0488011837005615
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.6192357540130615
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1852941513061523
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0457570552825928
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.7681093215942383
average cummulative reward vector is:  [0.07566658 0.0844713  0.08459126 0.06588318 0.09413145]
average cummulative reward is:  0.08094875225145251
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 1649, loss: 2120695.75
[INFO] Global_t: 1649, Episode_t: 1, Action: 17, Reward: 5.05, Epsilon: 0.01
[INFO] model update: t: 1650, loss: 1941555.125
[INFO] Global_t: 1650, Episode_t: 2, Action: 89, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1651, loss: 1016517.75
[INFO] Global_t: 1651, Episode_t: 3, Action: 149, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1652, loss: 3043583.25
[INFO] Global_t: 1652, Episode_t: 4, Action: 178, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1653, loss: 868283.9375
[INFO] Global_t: 1653, Episode_t: 5, Action: 148, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1654, loss: 4180570.75
[INFO] Global_t: 1654, Episode_t: 6, Action: 54, Reward: 1.18, Epsilon: 0.01
[INFO] model update: t: 1655, loss: 917355.6875
[INFO] Global_t: 1655, Episode_t: 7, Action: 138, Reward: 1.14, Epsilon: 0.01
[INFO] model update: t: 1656, loss: 321595.125
[INFO] Global_t: 1656, Episode_t: 8, Action: 108, Reward: 1.29, Epsilon: 0.01
 83%|████████▎ | 1656/2000 [32:49<07:46,  1.36s/it]
[INFO] Global step: 1656, Cumulative rewards: 13.726199999999999, Runtime (s): 1969.74
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 1657, loss: 166309.609375
[INFO] Global_t: 1657, Episode_t: 1, Action: 3, Reward: 4.78, Epsilon: 0.01
[INFO] model update: t: 1658, loss: 614549.0
[INFO] Global_t: 1658, Episode_t: 2, Action: 159, Reward: 0.80, Epsilon: 0.01
[INFO] model update: t: 1659, loss: 956195.125
[INFO] Global_t: 1659, Episode_t: 3, Action: 163, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1660, loss: 716811.9375
[INFO] Global_t: 1660, Episode_t: 4, Action: 170, Reward: 1.05, Epsilon: 0.01
[INFO] model update: t: 1661, loss: 1438377.25
[INFO] Global_t: 1661, Episode_t: 5, Action: 173, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1662, loss: 2083029.0
[INFO] Global_t: 1662, Episode_t: 6, Action: 127, Reward: 0.87, Epsilon: 0.01
[INFO] model update: t: 1663, loss: 1751426.5
[INFO] Global_t: 1663, Episode_t: 7, Action: 131, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1664, loss: 1580145.0
[INFO] Global_t: 1664, Episode_t: 8, Action: 162, Reward: 1.00, Epsilon: 0.01
 83%|████████▎ | 1664/2000 [32:53<06:05,  1.09s/it]
[INFO] Global step: 1664, Cumulative rewards: 12.56988, Runtime (s): 1973.44
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.53106427192688
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.450718641281128
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.399672031402588
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.372069835662842
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.400240421295166
average cummulative reward vector is:  [0.084785   0.07974815 0.09162404 0.07900771 0.08112177]
average cummulative reward is:  0.08325733526758347
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 1665, loss: 1596551.5
[INFO] Global_t: 1665, Episode_t: 1, Action: 8, Reward: 5.05, Epsilon: 0.01
[INFO] model update: t: 1666, loss: 1844044.0
[INFO] Global_t: 1666, Episode_t: 2, Action: 146, Reward: 0.85, Epsilon: 0.01
[INFO] model update: t: 1667, loss: 883228.0
[INFO] Global_t: 1667, Episode_t: 3, Action: 97, Reward: 0.82, Epsilon: 0.01
[INFO] model update: t: 1668, loss: 922328.4375
[INFO] Global_t: 1668, Episode_t: 4, Action: 79, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1669, loss: 1237647.25
[INFO] Global_t: 1669, Episode_t: 5, Action: 93, Reward: 1.06, Epsilon: 0.01
[INFO] model update: t: 1670, loss: 2030641.375
[INFO] Global_t: 1670, Episode_t: 6, Action: 129, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1671, loss: 1074660.625
[INFO] Global_t: 1671, Episode_t: 7, Action: 30, Reward: 1.11, Epsilon: 0.01
[INFO] model update: t: 1672, loss: 726438.375
[INFO] Global_t: 1672, Episode_t: 8, Action: 32, Reward: 1.25, Epsilon: 0.01
 84%|████████▎ | 1672/2000 [33:08<07:20,  1.34s/it]
[INFO] Global step: 1672, Cumulative rewards: 12.847079999999998, Runtime (s): 1988.99
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 1673, loss: 1140630.0
[INFO] Global_t: 1673, Episode_t: 1, Action: 0, Reward: 5.36, Epsilon: 0.01
[INFO] model update: t: 1674, loss: 1469004.0
[INFO] Global_t: 1674, Episode_t: 2, Action: 145, Reward: 1.32, Epsilon: 0.01
[INFO] model update: t: 1675, loss: 789510.5
[INFO] Global_t: 1675, Episode_t: 3, Action: 38, Reward: 1.18, Epsilon: 0.01
[INFO] model update: t: 1676, loss: 2325627.25
[INFO] Global_t: 1676, Episode_t: 4, Action: 143, Reward: 1.14, Epsilon: 0.01
[INFO] model update: t: 1677, loss: 2872244.25
[INFO] Global_t: 1677, Episode_t: 5, Action: 159, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1678, loss: 968984.875
[INFO] Global_t: 1678, Episode_t: 6, Action: 206, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1679, loss: 1044023.875
[INFO] Global_t: 1679, Episode_t: 7, Action: 141, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1680, loss: 1110068.75
[INFO] Global_t: 1680, Episode_t: 8, Action: 201, Reward: 1.14, Epsilon: 0.01
 84%|████████▍ | 1680/2000 [33:13<05:50,  1.10s/it]
[INFO] Global step: 1680, Cumulative rewards: 14.305799999999998, Runtime (s): 1993.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.9920918941497803
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.48720383644104
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.394383430480957
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1444284915924072
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.6497128009796143
average cummulative reward vector is:  [0.09641632 0.0829206  0.09392705 0.06948785 0.08949892]
average cummulative reward is:  0.08645014840402518
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 1681, loss: 692325.5
[INFO] Global_t: 1681, Episode_t: 1, Action: 1, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1682, loss: 581780.625
[INFO] Global_t: 1682, Episode_t: 2, Action: 148, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1683, loss: 459984.90625
[INFO] Global_t: 1683, Episode_t: 3, Action: 131, Reward: 1.27, Epsilon: 0.01
[INFO] model update: t: 1684, loss: 1199522.5
[INFO] Global_t: 1684, Episode_t: 4, Action: 155, Reward: 1.07, Epsilon: 0.01
[INFO] model update: t: 1685, loss: 765962.125
[INFO] Global_t: 1685, Episode_t: 5, Action: 29, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1686, loss: 1435718.625
[INFO] Global_t: 1686, Episode_t: 6, Action: 108, Reward: 1.06, Epsilon: 0.01
[INFO] model update: t: 1687, loss: 1219282.75
[INFO] Global_t: 1687, Episode_t: 7, Action: 175, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1688, loss: 305939.6875
[INFO] Global_t: 1688, Episode_t: 8, Action: 147, Reward: 1.13, Epsilon: 0.01
 84%|████████▍ | 1688/2000 [33:29<07:10,  1.38s/it]
[INFO] Global step: 1688, Cumulative rewards: 13.57536, Runtime (s): 2009.49
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 1689, loss: 700299.0
[INFO] Global_t: 1689, Episode_t: 1, Action: 7, Reward: 5.14, Epsilon: 0.01
[INFO] model update: t: 1690, loss: 2960228.75
[INFO] Global_t: 1690, Episode_t: 2, Action: 168, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1691, loss: 1201681.25
[INFO] Global_t: 1691, Episode_t: 3, Action: 85, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1692, loss: 712631.125
[INFO] Global_t: 1692, Episode_t: 4, Action: 179, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1693, loss: 1695070.875
[INFO] Global_t: 1693, Episode_t: 5, Action: 203, Reward: 1.04, Epsilon: 0.01
[INFO] model update: t: 1694, loss: 560008.6875
[INFO] Global_t: 1694, Episode_t: 6, Action: 81, Reward: 0.97, Epsilon: 0.01
[INFO] model update: t: 1695, loss: 945458.3125
[INFO] Global_t: 1695, Episode_t: 7, Action: 196, Reward: 1.10, Epsilon: 0.01
[INFO] model update: t: 1696, loss: 974455.875
[INFO] Global_t: 1696, Episode_t: 8, Action: 188, Reward: 1.30, Epsilon: 0.01
 85%|████████▍ | 1696/2000 [33:33<05:43,  1.13s/it]
[INFO] Global step: 1696, Cumulative rewards: 13.333440000000001, Runtime (s): 2013.82
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.850635051727295
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.146615982055664
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.2102880477905273
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.547752857208252
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.876335620880127
average cummulative reward vector is:  [0.09133316 0.06810556 0.08187951 0.08313318 0.0899086 ]
average cummulative reward is:  0.08287200027352896
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 1697, loss: 1915997.75
[INFO] Global_t: 1697, Episode_t: 1, Action: 6, Reward: 5.31, Epsilon: 0.01
[INFO] model update: t: 1698, loss: 2041426.5
[INFO] Global_t: 1698, Episode_t: 2, Action: 164, Reward: 1.14, Epsilon: 0.01
[INFO] model update: t: 1699, loss: 881835.375
[INFO] Global_t: 1699, Episode_t: 3, Action: 111, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1700, loss: 1032091.4375
[INFO] Global_t: 1700, Episode_t: 4, Action: 174, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 1701, loss: 1800360.0
[INFO] Global_t: 1701, Episode_t: 5, Action: 42, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1702, loss: 1330747.25
[INFO] Global_t: 1702, Episode_t: 6, Action: 126, Reward: 1.15, Epsilon: 0.01
[INFO] model update: t: 1703, loss: 724903.3125
[INFO] Global_t: 1703, Episode_t: 7, Action: 120, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1704, loss: 916466.8125
[INFO] Global_t: 1704, Episode_t: 8, Action: 157, Reward: 0.62, Epsilon: 0.01
 85%|████████▌ | 1704/2000 [33:50<06:57,  1.41s/it]
[INFO] Global step: 1704, Cumulative rewards: 13.743839999999999, Runtime (s): 2030.35
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 1705, loss: 817788.25
[INFO] Global_t: 1705, Episode_t: 1, Action: 5, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 1706, loss: 1543352.875
[INFO] Global_t: 1706, Episode_t: 2, Action: 162, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1707, loss: 468105.65625
[INFO] Global_t: 1707, Episode_t: 3, Action: 144, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 1708, loss: 2665757.5
[INFO] Global_t: 1708, Episode_t: 4, Action: 147, Reward: 1.01, Epsilon: 0.01
[INFO] model update: t: 1709, loss: 825653.9375
[INFO] Global_t: 1709, Episode_t: 5, Action: 152, Reward: 1.36, Epsilon: 0.01
[INFO] model update: t: 1710, loss: 987605.3125
[INFO] Global_t: 1710, Episode_t: 6, Action: 112, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 1711, loss: 920780.125
[INFO] Global_t: 1711, Episode_t: 7, Action: 65, Reward: 0.88, Epsilon: 0.01
[INFO] model update: t: 1712, loss: 386859.0625
[INFO] Global_t: 1712, Episode_t: 8, Action: 190, Reward: 0.68, Epsilon: 0.01

[INFO] Global step: 1712, Cumulative rewards: 12.97044, Runtime (s): 2034.04
------------------------------------------------------------
 
 86%|████████▌ | 1712/2000 [33:54<05:24,  1.13s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.6028106212615967
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.416001796722412
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.222395420074463
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.596756935119629
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.478679656982422
average cummulative reward vector is:  [0.08546579 0.07820394 0.08733142 0.08015561 0.08726317]
average cummulative reward is:  0.08368398498870859
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 1713, loss: 1382372.5
[INFO] Global_t: 1713, Episode_t: 1, Action: 11, Reward: 4.63, Epsilon: 0.01
[INFO] model update: t: 1714, loss: 2216789.5
[INFO] Global_t: 1714, Episode_t: 2, Action: 40, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1715, loss: 1104551.875
[INFO] Global_t: 1715, Episode_t: 3, Action: 131, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1716, loss: 789373.5
[INFO] Global_t: 1716, Episode_t: 4, Action: 73, Reward: 1.18, Epsilon: 0.01
[INFO] model update: t: 1717, loss: 419220.1875
[INFO] Global_t: 1717, Episode_t: 5, Action: 171, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1718, loss: 858408.875
[INFO] Global_t: 1718, Episode_t: 6, Action: 202, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1719, loss: 223663.90625
[INFO] Global_t: 1719, Episode_t: 7, Action: 175, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1720, loss: 399122.0
[INFO] Global_t: 1720, Episode_t: 8, Action: 170, Reward: 1.14, Epsilon: 0.01
 86%|████████▌ | 1720/2000 [34:12<06:56,  1.49s/it]
[INFO] Global step: 1720, Cumulative rewards: 13.582680000000003, Runtime (s): 2052.74
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 1721, loss: 596925.375
[INFO] Global_t: 1721, Episode_t: 1, Action: 7, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1722, loss: 1008987.5625
[INFO] Global_t: 1722, Episode_t: 2, Action: 184, Reward: 1.17, Epsilon: 0.01
[INFO] model update: t: 1723, loss: 161848.828125
[INFO] Global_t: 1723, Episode_t: 3, Action: 173, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1724, loss: 806611.0625
[INFO] Global_t: 1724, Episode_t: 4, Action: 85, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1725, loss: 896356.0
[INFO] Global_t: 1725, Episode_t: 5, Action: 89, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1726, loss: 979109.1875
[INFO] Global_t: 1726, Episode_t: 6, Action: 128, Reward: 0.61, Epsilon: 0.01
[INFO] model update: t: 1727, loss: 792709.25
[INFO] Global_t: 1727, Episode_t: 7, Action: 124, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1728, loss: 1243242.625
[INFO] Global_t: 1728, Episode_t: 8, Action: 126, Reward: 0.98, Epsilon: 0.01
 86%|████████▋ | 1728/2000 [34:16<05:20,  1.18s/it]
[INFO] Global step: 1728, Cumulative rewards: 11.928119999999998, Runtime (s): 2056.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.8387956619262695
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.506890296936035
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1060681343078613
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4009289741516113
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.166412591934204
average cummulative reward vector is:  [0.09439974 0.08308403 0.08232104 0.08042407 0.07277392]
average cummulative reward is:  0.08260055860459853
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 1729, loss: 1767151.625
[INFO] Global_t: 1729, Episode_t: 1, Action: 3, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1730, loss: 1657017.5
[INFO] Global_t: 1730, Episode_t: 2, Action: 157, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1731, loss: 1300179.25
[INFO] Global_t: 1731, Episode_t: 3, Action: 140, Reward: 0.96, Epsilon: 0.01
[INFO] model update: t: 1732, loss: 520419.1875
[INFO] Global_t: 1732, Episode_t: 4, Action: 101, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1733, loss: 539032.125
[INFO] Global_t: 1733, Episode_t: 5, Action: 84, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1734, loss: 353288.5
[INFO] Global_t: 1734, Episode_t: 6, Action: 79, Reward: 1.32, Epsilon: 0.01
[INFO] model update: t: 1735, loss: 539519.625
[INFO] Global_t: 1735, Episode_t: 7, Action: 121, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1736, loss: 1404852.875
[INFO] Global_t: 1736, Episode_t: 8, Action: 142, Reward: 1.26, Epsilon: 0.01
 87%|████████▋ | 1736/2000 [34:31<06:09,  1.40s/it]
[INFO] Global step: 1736, Cumulative rewards: 13.7556, Runtime (s): 2071.65
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 1737, loss: 602916.1875
[INFO] Global_t: 1737, Episode_t: 1, Action: 1, Reward: 4.86, Epsilon: 0.01
[INFO] model update: t: 1738, loss: 663066.6875
[INFO] Global_t: 1738, Episode_t: 2, Action: 6, Reward: 4.81, Epsilon: 0.01
[INFO] model update: t: 1739, loss: 338869.75
[INFO] Global_t: 1739, Episode_t: 3, Action: 161, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1740, loss: 1690190.625
[INFO] Global_t: 1740, Episode_t: 4, Action: 178, Reward: 1.00, Epsilon: 0.01
[INFO] model update: t: 1741, loss: 1497923.5
[INFO] Global_t: 1741, Episode_t: 5, Action: 164, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1742, loss: 819948.375
[INFO] Global_t: 1742, Episode_t: 6, Action: 189, Reward: 1.18, Epsilon: 0.01
[INFO] model update: t: 1743, loss: 589371.0625
[INFO] Global_t: 1743, Episode_t: 7, Action: 94, Reward: 0.76, Epsilon: 0.01
[INFO] model update: t: 1744, loss: 714277.25
[INFO] Global_t: 1744, Episode_t: 8, Action: 175, Reward: 0.90, Epsilon: 0.01
 87%|████████▋ | 1744/2000 [34:36<04:56,  1.16s/it]
[INFO] Global step: 1744, Cumulative rewards: 15.952200000000001, Runtime (s): 2076.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.77764892578125
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.6062710285186768
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3063762187957764
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2781612873077393
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4132912158966064
average cummulative reward vector is:  [0.09106237 0.08149259 0.0871082  0.07504977 0.08227177]
average cummulative reward is:  0.08339693965672905
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 1745, loss: 901637.0625
[INFO] Global_t: 1745, Episode_t: 1, Action: 4, Reward: 5.14, Epsilon: 0.01
[INFO] model update: t: 1746, loss: 804677.625
[INFO] Global_t: 1746, Episode_t: 2, Action: 20, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 1747, loss: 330266.53125
[INFO] Global_t: 1747, Episode_t: 3, Action: 8, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1748, loss: 976461.75
[INFO] Global_t: 1748, Episode_t: 4, Action: 1, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1749, loss: 1447798.5
[INFO] Global_t: 1749, Episode_t: 5, Action: 61, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1750, loss: 876126.25
[INFO] Global_t: 1750, Episode_t: 6, Action: 112, Reward: 0.87, Epsilon: 0.01
[INFO] model update: t: 1751, loss: 1988931.25
[INFO] Global_t: 1751, Episode_t: 7, Action: 84, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1752, loss: 1012607.6875
[INFO] Global_t: 1752, Episode_t: 8, Action: 68, Reward: 1.59, Epsilon: 0.01
 88%|████████▊ | 1752/2000 [34:51<05:44,  1.39s/it]
[INFO] Global step: 1752, Cumulative rewards: 24.931079999999994, Runtime (s): 2091.90
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 1753, loss: 512729.6875
[INFO] Global_t: 1753, Episode_t: 1, Action: 10, Reward: 4.95, Epsilon: 0.01
[INFO] model update: t: 1754, loss: 616899.125
[INFO] Global_t: 1754, Episode_t: 2, Action: 4, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1755, loss: 623803.25
[INFO] Global_t: 1755, Episode_t: 3, Action: 8, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 1756, loss: 924477.8125
[INFO] Global_t: 1756, Episode_t: 4, Action: 145, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1757, loss: 217553.453125
[INFO] Global_t: 1757, Episode_t: 5, Action: 179, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1758, loss: 422791.84375
[INFO] Global_t: 1758, Episode_t: 6, Action: 203, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1759, loss: 1117745.75
[INFO] Global_t: 1759, Episode_t: 7, Action: 198, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 1760, loss: 1402053.75
[INFO] Global_t: 1760, Episode_t: 8, Action: 156, Reward: 1.23, Epsilon: 0.01
 88%|████████▊ | 1760/2000 [34:55<04:23,  1.10s/it]
[INFO] Global step: 1760, Cumulative rewards: 21.85176, Runtime (s): 2095.25
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.968780517578125
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.7334864139556885
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3496761322021484
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1357171535491943
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.191768169403076
average cummulative reward vector is:  [0.07419579 0.08132569 0.09390546 0.06648715 0.0832586 ]
average cummulative reward is:  0.07983454001645018
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 1761, loss: 661762.75
[INFO] Global_t: 1761, Episode_t: 1, Action: 14, Reward: 4.96, Epsilon: 0.01
[INFO] model update: t: 1762, loss: 410165.9375
[INFO] Global_t: 1762, Episode_t: 2, Action: 13, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1763, loss: 437366.28125
[INFO] Global_t: 1763, Episode_t: 3, Action: 135, Reward: 1.19, Epsilon: 0.01
[INFO] model update: t: 1764, loss: 439504.96875
[INFO] Global_t: 1764, Episode_t: 4, Action: 211, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1765, loss: 772749.5625
[INFO] Global_t: 1765, Episode_t: 5, Action: 125, Reward: 0.88, Epsilon: 0.01
[INFO] model update: t: 1766, loss: 523900.875
[INFO] Global_t: 1766, Episode_t: 6, Action: 201, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1767, loss: 315375.84375
[INFO] Global_t: 1767, Episode_t: 7, Action: 72, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1768, loss: 913050.25
[INFO] Global_t: 1768, Episode_t: 8, Action: 140, Reward: 1.79, Epsilon: 0.01
 88%|████████▊ | 1768/2000 [35:15<05:50,  1.51s/it]
[INFO] Global step: 1768, Cumulative rewards: 17.95644, Runtime (s): 2115.03
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 1769, loss: 628803.5625
[INFO] Global_t: 1769, Episode_t: 1, Action: 7, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1770, loss: 1333262.75
[INFO] Global_t: 1770, Episode_t: 2, Action: 130, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 1771, loss: 758574.625
[INFO] Global_t: 1771, Episode_t: 3, Action: 140, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1772, loss: 750099.25
[INFO] Global_t: 1772, Episode_t: 4, Action: 48, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1773, loss: 650016.9375
[INFO] Global_t: 1773, Episode_t: 5, Action: 136, Reward: 1.18, Epsilon: 0.01
[INFO] model update: t: 1774, loss: 412897.46875
[INFO] Global_t: 1774, Episode_t: 6, Action: 132, Reward: 0.57, Epsilon: 0.01
[INFO] model update: t: 1775, loss: 562480.375
[INFO] Global_t: 1775, Episode_t: 7, Action: 106, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1776, loss: 741481.1875
[INFO] Global_t: 1776, Episode_t: 8, Action: 125, Reward: 1.15, Epsilon: 0.01
 89%|████████▉ | 1776/2000 [35:20<04:41,  1.26s/it]
[INFO] Global step: 1776, Cumulative rewards: 12.852479999999998, Runtime (s): 2120.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9668159484863281
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.24629282951355
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.077019453048706
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.282113790512085
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.281451940536499
average cummulative reward vector is:  [0.07165184 0.07322407 0.08175792 0.07545023 0.07745403]
average cummulative reward is:  0.07590762111590586
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 1777, loss: 408506.21875
[INFO] Global_t: 1777, Episode_t: 1, Action: 8, Reward: 4.86, Epsilon: 0.01
[INFO] model update: t: 1778, loss: 459690.28125
[INFO] Global_t: 1778, Episode_t: 2, Action: 96, Reward: 1.57, Epsilon: 0.01
[INFO] model update: t: 1779, loss: 484962.25
[INFO] Global_t: 1779, Episode_t: 3, Action: 69, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1780, loss: 793068.125
[INFO] Global_t: 1780, Episode_t: 4, Action: 131, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1781, loss: 459670.375
[INFO] Global_t: 1781, Episode_t: 5, Action: 117, Reward: 0.77, Epsilon: 0.01
[INFO] model update: t: 1782, loss: 496366.65625
[INFO] Global_t: 1782, Episode_t: 6, Action: 150, Reward: 1.11, Epsilon: 0.01
[INFO] model update: t: 1783, loss: 187202.109375
[INFO] Global_t: 1783, Episode_t: 7, Action: 100, Reward: 1.27, Epsilon: 0.01
[INFO] model update: t: 1784, loss: 682458.875
[INFO] Global_t: 1784, Episode_t: 8, Action: 167, Reward: 1.06, Epsilon: 0.01
 89%|████████▉ | 1784/2000 [35:35<05:10,  1.44s/it]
[INFO] Global step: 1784, Cumulative rewards: 13.48908, Runtime (s): 2135.17
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 1785, loss: 2013854.375
[INFO] Global_t: 1785, Episode_t: 1, Action: 13, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1786, loss: 918461.875
[INFO] Global_t: 1786, Episode_t: 2, Action: 155, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1787, loss: 560770.5
[INFO] Global_t: 1787, Episode_t: 3, Action: 171, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1788, loss: 477389.8125
[INFO] Global_t: 1788, Episode_t: 4, Action: 126, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1789, loss: 465510.125
[INFO] Global_t: 1789, Episode_t: 5, Action: 147, Reward: 1.13, Epsilon: 0.01
[INFO] model update: t: 1790, loss: 519951.25
[INFO] Global_t: 1790, Episode_t: 6, Action: 176, Reward: 0.91, Epsilon: 0.01
[INFO] model update: t: 1791, loss: 957885.9375
[INFO] Global_t: 1791, Episode_t: 7, Action: 101, Reward: 1.10, Epsilon: 0.01
[INFO] model update: t: 1792, loss: 379612.6875
[INFO] Global_t: 1792, Episode_t: 8, Action: 98, Reward: 1.30, Epsilon: 0.01
 90%|████████▉ | 1792/2000 [35:39<04:02,  1.17s/it]
[INFO] Global step: 1792, Cumulative rewards: 13.766399999999997, Runtime (s): 2139.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.696208953857422
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1921613216400146
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3720507621765137
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.160175323486328
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2032387256622314
average cummulative reward vector is:  [0.09140526 0.07095903 0.08698798 0.07115047 0.07321371]
average cummulative reward is:  0.0787432892089776
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 1793, loss: 493395.0
[INFO] Global_t: 1793, Episode_t: 1, Action: 0, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1794, loss: 1237341.25
[INFO] Global_t: 1794, Episode_t: 2, Action: 164, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1795, loss: 789317.8125
[INFO] Global_t: 1795, Episode_t: 3, Action: 141, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1796, loss: 236892.78125
[INFO] Global_t: 1796, Episode_t: 4, Action: 191, Reward: 1.02, Epsilon: 0.01
[INFO] model update: t: 1797, loss: 513331.9375
[INFO] Global_t: 1797, Episode_t: 5, Action: 83, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1798, loss: 302074.09375
[INFO] Global_t: 1798, Episode_t: 6, Action: 134, Reward: 1.08, Epsilon: 0.01
[INFO] model update: t: 1799, loss: 351999.21875
[INFO] Global_t: 1799, Episode_t: 7, Action: 86, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1800, loss: 432751.5625
[INFO] Global_t: 1800, Episode_t: 8, Action: 90, Reward: 0.96, Epsilon: 0.01
 90%|█████████ | 1800/2000 [35:55<04:41,  1.41s/it]
[INFO] Global step: 1800, Cumulative rewards: 12.6978, Runtime (s): 2155.26
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 1801, loss: 648873.3125
[INFO] Global_t: 1801, Episode_t: 1, Action: 10, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1802, loss: 323933.9375
[INFO] Global_t: 1802, Episode_t: 2, Action: 155, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 1803, loss: 223203.984375
[INFO] Global_t: 1803, Episode_t: 3, Action: 151, Reward: 0.85, Epsilon: 0.01
[INFO] model update: t: 1804, loss: 230853.546875
[INFO] Global_t: 1804, Episode_t: 4, Action: 132, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1805, loss: 444209.09375
[INFO] Global_t: 1805, Episode_t: 5, Action: 117, Reward: 1.31, Epsilon: 0.01
[INFO] model update: t: 1806, loss: 433889.96875
[INFO] Global_t: 1806, Episode_t: 6, Action: 152, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1807, loss: 464841.1875
[INFO] Global_t: 1807, Episode_t: 7, Action: 153, Reward: 1.18, Epsilon: 0.01
[INFO] model update: t: 1808, loss: 1251034.625
[INFO] Global_t: 1808, Episode_t: 8, Action: 95, Reward: 1.06, Epsilon: 0.01
 90%|█████████ | 1808/2000 [35:59<03:38,  1.14s/it]
[INFO] Global step: 1808, Cumulative rewards: 13.871759999999998, Runtime (s): 2159.37
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.571403980255127
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.415743350982666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.368968963623047
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.449885368347168
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.7357850074768066
average cummulative reward vector is:  [0.08614526 0.07797546 0.08868443 0.0779729  0.09493522]
average cummulative reward is:  0.08514265292007821
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 1809, loss: 481205.4375
[INFO] Global_t: 1809, Episode_t: 1, Action: 0, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1810, loss: 692641.75
[INFO] Global_t: 1810, Episode_t: 2, Action: 8, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1811, loss: 479408.34375
[INFO] Global_t: 1811, Episode_t: 3, Action: 24, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1812, loss: 557646.4375
[INFO] Global_t: 1812, Episode_t: 4, Action: 1, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1813, loss: 596610.3125
[INFO] Global_t: 1813, Episode_t: 5, Action: 11, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1814, loss: 177847.671875
[INFO] Global_t: 1814, Episode_t: 6, Action: 184, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1815, loss: 355863.96875
[INFO] Global_t: 1815, Episode_t: 7, Action: 71, Reward: 1.05, Epsilon: 0.01
[INFO] model update: t: 1816, loss: 919821.5
[INFO] Global_t: 1816, Episode_t: 8, Action: 164, Reward: 1.36, Epsilon: 0.01
 91%|█████████ | 1816/2000 [36:14<04:13,  1.38s/it]
[INFO] Global step: 1816, Cumulative rewards: 25.8864, Runtime (s): 2174.80
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 1817, loss: 336267.6875
[INFO] Global_t: 1817, Episode_t: 1, Action: 1, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1818, loss: 777793.875
[INFO] Global_t: 1818, Episode_t: 2, Action: 6, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1819, loss: 222194.8125
[INFO] Global_t: 1819, Episode_t: 3, Action: 22, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1820, loss: 193067.53125
[INFO] Global_t: 1820, Episode_t: 4, Action: 0, Reward: 4.81, Epsilon: 0.01
[INFO] model update: t: 1821, loss: 517311.0625
[INFO] Global_t: 1821, Episode_t: 5, Action: 104, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1822, loss: 204309.046875
[INFO] Global_t: 1822, Episode_t: 6, Action: 171, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1823, loss: 369823.125
[INFO] Global_t: 1823, Episode_t: 7, Action: 180, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1824, loss: 588747.875
[INFO] Global_t: 1824, Episode_t: 8, Action: 119, Reward: 1.05, Epsilon: 0.01
 91%|█████████ | 1824/2000 [36:17<03:09,  1.08s/it]
[INFO] Global step: 1824, Cumulative rewards: 23.455559999999995, Runtime (s): 2177.82
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.658268690109253
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3061580657958984
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.269270896911621
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3654353618621826
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2994608879089355
average cummulative reward vector is:  [0.09978816 0.06224745 0.08777842 0.07804743 0.08894194]
average cummulative reward is:  0.08336067845788
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 1825, loss: 1132892.75
[INFO] Global_t: 1825, Episode_t: 1, Action: 1, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1826, loss: 463493.03125
[INFO] Global_t: 1826, Episode_t: 2, Action: 167, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1827, loss: 382599.21875
[INFO] Global_t: 1827, Episode_t: 3, Action: 137, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1828, loss: 391783.375
[INFO] Global_t: 1828, Episode_t: 4, Action: 164, Reward: 1.13, Epsilon: 0.01
[INFO] model update: t: 1829, loss: 667861.5625
[INFO] Global_t: 1829, Episode_t: 5, Action: 174, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 1830, loss: 515537.6875
[INFO] Global_t: 1830, Episode_t: 6, Action: 152, Reward: 1.34, Epsilon: 0.01
[INFO] model update: t: 1831, loss: 317223.65625
[INFO] Global_t: 1831, Episode_t: 7, Action: 171, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1832, loss: 264749.875
[INFO] Global_t: 1832, Episode_t: 8, Action: 132, Reward: 1.48, Epsilon: 0.01
 92%|█████████▏| 1832/2000 [36:33<03:48,  1.36s/it]
[INFO] Global step: 1832, Cumulative rewards: 14.22456, Runtime (s): 2193.97
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 1833, loss: 228964.0625
[INFO] Global_t: 1833, Episode_t: 1, Action: 44, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1834, loss: 230711.796875
[INFO] Global_t: 1834, Episode_t: 2, Action: 7, Reward: 4.80, Epsilon: 0.01
[INFO] model update: t: 1835, loss: 337436.875
[INFO] Global_t: 1835, Episode_t: 3, Action: 9, Reward: 4.63, Epsilon: 0.01
[INFO] model update: t: 1836, loss: 330258.875
[INFO] Global_t: 1836, Episode_t: 4, Action: 190, Reward: 1.28, Epsilon: 0.01
[INFO] model update: t: 1837, loss: 260607.75
[INFO] Global_t: 1837, Episode_t: 5, Action: 200, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1838, loss: 294454.46875
[INFO] Global_t: 1838, Episode_t: 6, Action: 145, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 1839, loss: 388361.15625
[INFO] Global_t: 1839, Episode_t: 7, Action: 102, Reward: 1.09, Epsilon: 0.01
[INFO] model update: t: 1840, loss: 454904.34375
[INFO] Global_t: 1840, Episode_t: 8, Action: 134, Reward: 1.24, Epsilon: 0.01
 92%|█████████▏| 1840/2000 [36:37<02:51,  1.07s/it]
[INFO] Global step: 1840, Cumulative rewards: 18.072960000000002, Runtime (s): 2197.18
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.077345371246338
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2189760208129883
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.5447819232940674
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.4542784690856934
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.2004432678222656
average cummulative reward vector is:  [0.07424711 0.07358657 0.08210027 0.08190888 0.08286586]
average cummulative reward is:  0.07894173825620046
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 1841, loss: 469256.59375
[INFO] Global_t: 1841, Episode_t: 1, Action: 11, Reward: 4.72, Epsilon: 0.01
[INFO] model update: t: 1842, loss: 135962.171875
[INFO] Global_t: 1842, Episode_t: 2, Action: 209, Reward: 1.34, Epsilon: 0.01
[INFO] model update: t: 1843, loss: 256050.78125
[INFO] Global_t: 1843, Episode_t: 3, Action: 166, Reward: 1.11, Epsilon: 0.01
[INFO] model update: t: 1844, loss: 170235.4375
[INFO] Global_t: 1844, Episode_t: 4, Action: 210, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1845, loss: 352402.5
[INFO] Global_t: 1845, Episode_t: 5, Action: 121, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1846, loss: 638941.5
[INFO] Global_t: 1846, Episode_t: 6, Action: 212, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1847, loss: 932691.375
[INFO] Global_t: 1847, Episode_t: 7, Action: 176, Reward: 1.36, Epsilon: 0.01
[INFO] model update: t: 1848, loss: 285733.1875
[INFO] Global_t: 1848, Episode_t: 8, Action: 174, Reward: 1.15, Epsilon: 0.01
 92%|█████████▏| 1848/2000 [36:52<03:18,  1.31s/it]
[INFO] Global step: 1848, Cumulative rewards: 13.980120000000001, Runtime (s): 2212.00
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 1849, loss: 641019.125
[INFO] Global_t: 1849, Episode_t: 1, Action: 8, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1850, loss: 276579.21875
[INFO] Global_t: 1850, Episode_t: 2, Action: 92, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 1851, loss: 644465.125
[INFO] Global_t: 1851, Episode_t: 3, Action: 165, Reward: 1.10, Epsilon: 0.01
[INFO] model update: t: 1852, loss: 395846.6875
[INFO] Global_t: 1852, Episode_t: 4, Action: 193, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1853, loss: 396879.25
[INFO] Global_t: 1853, Episode_t: 5, Action: 102, Reward: 0.95, Epsilon: 0.01
[INFO] model update: t: 1854, loss: 186179.390625
[INFO] Global_t: 1854, Episode_t: 6, Action: 182, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1855, loss: 58266.5546875
[INFO] Global_t: 1855, Episode_t: 7, Action: 180, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1856, loss: 280997.21875
[INFO] Global_t: 1856, Episode_t: 8, Action: 156, Reward: 1.28, Epsilon: 0.01
 93%|█████████▎| 1856/2000 [36:55<02:33,  1.06s/it]
[INFO] Global step: 1856, Cumulative rewards: 12.776759999999998, Runtime (s): 2215.96
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.136363983154297
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9684815406799316
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.053818941116333
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.6223275661468506
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.3499982357025146
average cummulative reward vector is:  [0.07978974 0.0649875  0.07887377 0.07663411 0.08887124]
average cummulative reward is:  0.07783127120851621
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 1857, loss: 422584.0625
[INFO] Global_t: 1857, Episode_t: 1, Action: 9, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1858, loss: 303020.375
[INFO] Global_t: 1858, Episode_t: 2, Action: 122, Reward: 1.28, Epsilon: 0.01
[INFO] model update: t: 1859, loss: 816072.0
[INFO] Global_t: 1859, Episode_t: 3, Action: 1, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1860, loss: 350637.53125
[INFO] Global_t: 1860, Episode_t: 4, Action: 176, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1861, loss: 835879.5
[INFO] Global_t: 1861, Episode_t: 5, Action: 182, Reward: 0.74, Epsilon: 0.01
[INFO] model update: t: 1862, loss: 464622.125
[INFO] Global_t: 1862, Episode_t: 6, Action: 135, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1863, loss: 525852.0625
[INFO] Global_t: 1863, Episode_t: 7, Action: 144, Reward: 0.83, Epsilon: 0.01
[INFO] model update: t: 1864, loss: 377740.9375
[INFO] Global_t: 1864, Episode_t: 8, Action: 159, Reward: 1.05, Epsilon: 0.01
 93%|█████████▎| 1864/2000 [37:12<03:06,  1.37s/it]
[INFO] Global step: 1864, Cumulative rewards: 15.870959999999997, Runtime (s): 2232.64
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 1865, loss: 392649.59375
[INFO] Global_t: 1865, Episode_t: 1, Action: 14, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1866, loss: 262566.28125
[INFO] Global_t: 1866, Episode_t: 2, Action: 76, Reward: 1.60, Epsilon: 0.01
[INFO] model update: t: 1867, loss: 284984.9375
[INFO] Global_t: 1867, Episode_t: 3, Action: 107, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 1868, loss: 171368.390625
[INFO] Global_t: 1868, Episode_t: 4, Action: 45, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1869, loss: 394435.4375
[INFO] Global_t: 1869, Episode_t: 5, Action: 60, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1870, loss: 895764.0
[INFO] Global_t: 1870, Episode_t: 6, Action: 154, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1871, loss: 172127.875
[INFO] Global_t: 1871, Episode_t: 7, Action: 168, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 1872, loss: 294263.1875
[INFO] Global_t: 1872, Episode_t: 8, Action: 147, Reward: 1.09, Epsilon: 0.01
 94%|█████████▎| 1872/2000 [37:16<02:23,  1.12s/it]
[INFO] Global step: 1872, Cumulative rewards: 14.832839999999997, Runtime (s): 2236.94
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1458330154418945
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1617298126220703
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.365811824798584
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.650003433227539
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.445255756378174
average cummulative reward vector is:  [0.08097737 0.07024306 0.09255519 0.07372009 0.09156371]
average cummulative reward is:  0.0818118836737604
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 1873, loss: 325006.6875
[INFO] Global_t: 1873, Episode_t: 1, Action: 8, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1874, loss: 427102.8125
[INFO] Global_t: 1874, Episode_t: 2, Action: 76, Reward: 1.31, Epsilon: 0.01
[INFO] model update: t: 1875, loss: 433435.875
[INFO] Global_t: 1875, Episode_t: 3, Action: 62, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 1876, loss: 347868.125
[INFO] Global_t: 1876, Episode_t: 4, Action: 139, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1877, loss: 466197.40625
[INFO] Global_t: 1877, Episode_t: 5, Action: 165, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1878, loss: 620028.875
[INFO] Global_t: 1878, Episode_t: 6, Action: 143, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1879, loss: 191728.578125
[INFO] Global_t: 1879, Episode_t: 7, Action: 186, Reward: 1.43, Epsilon: 0.01
[INFO] model update: t: 1880, loss: 369747.5
[INFO] Global_t: 1880, Episode_t: 8, Action: 44, Reward: 1.27, Epsilon: 0.01
 94%|█████████▍| 1880/2000 [37:32<02:44,  1.37s/it]
[INFO] Global step: 1880, Cumulative rewards: 14.564399999999996, Runtime (s): 2252.59
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 1881, loss: 68530.421875
[INFO] Global_t: 1881, Episode_t: 1, Action: 8, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1882, loss: 238923.21875
[INFO] Global_t: 1882, Episode_t: 2, Action: 145, Reward: 0.89, Epsilon: 0.01
[INFO] model update: t: 1883, loss: 614851.25
[INFO] Global_t: 1883, Episode_t: 3, Action: 181, Reward: 1.17, Epsilon: 0.01
[INFO] model update: t: 1884, loss: 458252.625
[INFO] Global_t: 1884, Episode_t: 4, Action: 137, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1885, loss: 605769.4375
[INFO] Global_t: 1885, Episode_t: 5, Action: 101, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1886, loss: 313245.1875
[INFO] Global_t: 1886, Episode_t: 6, Action: 78, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1887, loss: 545423.8125
[INFO] Global_t: 1887, Episode_t: 7, Action: 113, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1888, loss: 433422.03125
[INFO] Global_t: 1888, Episode_t: 8, Action: 128, Reward: 1.15, Epsilon: 0.01
 94%|█████████▍| 1888/2000 [37:36<02:02,  1.09s/it]
[INFO] Global step: 1888, Cumulative rewards: 12.60648, Runtime (s): 2256.13
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.297755002975464
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.5722968578338623
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.0707547664642334
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.733530282974243
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.9911141395568848
average cummulative reward vector is:  [0.08656237 0.08437037 0.08234781 0.07721028 0.07533226]
average cummulative reward is:  0.08116461828748422
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 1889, loss: 582534.625
[INFO] Global_t: 1889, Episode_t: 1, Action: 1, Reward: 4.43, Epsilon: 0.01
[INFO] model update: t: 1890, loss: 319569.25
[INFO] Global_t: 1890, Episode_t: 2, Action: 9, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1891, loss: 635001.75
[INFO] Global_t: 1891, Episode_t: 3, Action: 179, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1892, loss: 516135.25
[INFO] Global_t: 1892, Episode_t: 4, Action: 92, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1893, loss: 304811.90625
[INFO] Global_t: 1893, Episode_t: 5, Action: 91, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1894, loss: 167250.515625
[INFO] Global_t: 1894, Episode_t: 6, Action: 63, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1895, loss: 199989.921875
[INFO] Global_t: 1895, Episode_t: 7, Action: 39, Reward: 1.32, Epsilon: 0.01
[INFO] model update: t: 1896, loss: 176158.921875
[INFO] Global_t: 1896, Episode_t: 8, Action: 47, Reward: 1.16, Epsilon: 0.01
 95%|█████████▍| 1896/2000 [37:51<02:18,  1.33s/it]
[INFO] Global step: 1896, Cumulative rewards: 16.2426, Runtime (s): 2271.23
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 1897, loss: 788403.0
[INFO] Global_t: 1897, Episode_t: 1, Action: 12, Reward: 4.77, Epsilon: 0.01
[INFO] model update: t: 1898, loss: 407199.5625
[INFO] Global_t: 1898, Episode_t: 2, Action: 15, Reward: 4.54, Epsilon: 0.01
[INFO] model update: t: 1899, loss: 306518.28125
[INFO] Global_t: 1899, Episode_t: 3, Action: 39, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 1900, loss: 141234.84375
[INFO] Global_t: 1900, Episode_t: 4, Action: 10, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1901, loss: 366590.75
[INFO] Global_t: 1901, Episode_t: 5, Action: 81, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1902, loss: 665730.1875
[INFO] Global_t: 1902, Episode_t: 6, Action: 186, Reward: 1.07, Epsilon: 0.01
[INFO] model update: t: 1903, loss: 143957.0
[INFO] Global_t: 1903, Episode_t: 7, Action: 169, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1904, loss: 272528.25
[INFO] Global_t: 1904, Episode_t: 8, Action: 161, Reward: 1.08, Epsilon: 0.01
 95%|█████████▌| 1904/2000 [37:54<01:40,  1.05s/it]
[INFO] Global step: 1904, Cumulative rewards: 22.20432, Runtime (s): 2274.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.7784087657928467
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.718989133834839
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.296290397644043
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.3185384273529053
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0496973991394043
average cummulative reward vector is:  [0.09030526 0.08420417 0.08718033 0.07630631 0.06614866]
average cummulative reward is:  0.08082894440372146
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 1905, loss: 249206.25
[INFO] Global_t: 1905, Episode_t: 1, Action: 15, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1906, loss: 122314.0859375
[INFO] Global_t: 1906, Episode_t: 2, Action: 19, Reward: 4.32, Epsilon: 0.01
[INFO] model update: t: 1907, loss: 250999.109375
[INFO] Global_t: 1907, Episode_t: 3, Action: 16, Reward: 4.60, Epsilon: 0.01
[INFO] model update: t: 1908, loss: 689166.625
[INFO] Global_t: 1908, Episode_t: 4, Action: 13, Reward: 5.05, Epsilon: 0.01
[INFO] model update: t: 1909, loss: 480877.28125
[INFO] Global_t: 1909, Episode_t: 5, Action: 109, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1910, loss: 94571.8984375
[INFO] Global_t: 1910, Episode_t: 6, Action: 196, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1911, loss: 328561.0
[INFO] Global_t: 1911, Episode_t: 7, Action: 192, Reward: 1.10, Epsilon: 0.01
[INFO] model update: t: 1912, loss: 203479.1875
[INFO] Global_t: 1912, Episode_t: 8, Action: 48, Reward: 1.06, Epsilon: 0.01
 96%|█████████▌| 1912/2000 [38:09<01:55,  1.31s/it]
[INFO] Global step: 1912, Cumulative rewards: 23.387760000000004, Runtime (s): 2289.72
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 1913, loss: 596865.5
[INFO] Global_t: 1913, Episode_t: 1, Action: 6, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 1914, loss: 207181.625
[INFO] Global_t: 1914, Episode_t: 2, Action: 163, Reward: 1.03, Epsilon: 0.01
[INFO] model update: t: 1915, loss: 162571.15625
[INFO] Global_t: 1915, Episode_t: 3, Action: 148, Reward: 1.68, Epsilon: 0.01
[INFO] model update: t: 1916, loss: 161570.96875
[INFO] Global_t: 1916, Episode_t: 4, Action: 179, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1917, loss: 252277.09375
[INFO] Global_t: 1917, Episode_t: 5, Action: 113, Reward: 0.96, Epsilon: 0.01
[INFO] model update: t: 1918, loss: 291231.375
[INFO] Global_t: 1918, Episode_t: 6, Action: 165, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1919, loss: 146655.375
[INFO] Global_t: 1919, Episode_t: 7, Action: 67, Reward: 1.19, Epsilon: 0.01
[INFO] model update: t: 1920, loss: 380056.8125
[INFO] Global_t: 1920, Episode_t: 8, Action: 90, Reward: 1.20, Epsilon: 0.01

[INFO] Global step: 1920, Cumulative rewards: 13.459799999999998, Runtime (s): 2292.97
------------------------------------------------------------
 
 96%|█████████▌| 1920/2000 [38:12<01:23,  1.04s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.175429105758667
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.685380220413208
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.15124249458313
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.315474510192871
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.199035882949829
average cummulative reward vector is:  [0.08067605 0.07123704 0.08538907 0.07615584 0.08286774]
average cummulative reward is:  0.07926514875276931
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 1921, loss: 449676.625
[INFO] Global_t: 1921, Episode_t: 1, Action: 4, Reward: 4.07, Epsilon: 0.01
[INFO] model update: t: 1922, loss: 418592.75
[INFO] Global_t: 1922, Episode_t: 2, Action: 161, Reward: 1.31, Epsilon: 0.01
[INFO] model update: t: 1923, loss: 176980.609375
[INFO] Global_t: 1923, Episode_t: 3, Action: 148, Reward: 1.03, Epsilon: 0.01
[INFO] model update: t: 1924, loss: 260405.34375
[INFO] Global_t: 1924, Episode_t: 4, Action: 168, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 1925, loss: 428927.6875
[INFO] Global_t: 1925, Episode_t: 5, Action: 167, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1926, loss: 255331.625
[INFO] Global_t: 1926, Episode_t: 6, Action: 121, Reward: 1.17, Epsilon: 0.01
[INFO] model update: t: 1927, loss: 493015.03125
[INFO] Global_t: 1927, Episode_t: 7, Action: 149, Reward: 1.15, Epsilon: 0.01
[INFO] model update: t: 1928, loss: 596615.875
[INFO] Global_t: 1928, Episode_t: 8, Action: 143, Reward: 1.13, Epsilon: 0.01
 96%|█████████▋| 1928/2000 [38:29<01:37,  1.36s/it]
[INFO] Global step: 1928, Cumulative rewards: 12.61608, Runtime (s): 2309.71
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 1929, loss: 365220.96875
[INFO] Global_t: 1929, Episode_t: 1, Action: 8, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 1930, loss: 93290.3125
[INFO] Global_t: 1930, Episode_t: 2, Action: 4, Reward: 4.63, Epsilon: 0.01
[INFO] model update: t: 1931, loss: 221002.90625
[INFO] Global_t: 1931, Episode_t: 3, Action: 7, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 1932, loss: 61156.9921875
[INFO] Global_t: 1932, Episode_t: 4, Action: 16, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1933, loss: 100118.640625
[INFO] Global_t: 1933, Episode_t: 5, Action: 87, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1934, loss: 85076.125
[INFO] Global_t: 1934, Episode_t: 6, Action: 86, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1935, loss: 620523.3125
[INFO] Global_t: 1935, Episode_t: 7, Action: 125, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1936, loss: 271392.375
[INFO] Global_t: 1936, Episode_t: 8, Action: 55, Reward: 0.88, Epsilon: 0.01
 97%|█████████▋| 1936/2000 [38:32<01:07,  1.05s/it]
[INFO] Global step: 1936, Cumulative rewards: 20.85324, Runtime (s): 2312.52
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1051928997039795
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.160951614379883
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.5820369720458984
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.061021089553833
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0969626903533936
average cummulative reward vector is:  [0.07807684 0.0696544  0.08667432 0.06759766 0.08030108]
average cummulative reward is:  0.0764608592027042
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 1937, loss: 553137.3125
[INFO] Global_t: 1937, Episode_t: 1, Action: 10, Reward: 4.34, Epsilon: 0.01
[INFO] model update: t: 1938, loss: 259528.484375
[INFO] Global_t: 1938, Episode_t: 2, Action: 148, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1939, loss: 211200.421875
[INFO] Global_t: 1939, Episode_t: 3, Action: 123, Reward: 1.67, Epsilon: 0.01
[INFO] model update: t: 1940, loss: 185688.3125
[INFO] Global_t: 1940, Episode_t: 4, Action: 78, Reward: 1.43, Epsilon: 0.01
[INFO] model update: t: 1941, loss: 370636.84375
[INFO] Global_t: 1941, Episode_t: 5, Action: 213, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1942, loss: 302937.34375
[INFO] Global_t: 1942, Episode_t: 6, Action: 120, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1943, loss: 119480.1953125
[INFO] Global_t: 1943, Episode_t: 7, Action: 216, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1944, loss: 338499.21875
[INFO] Global_t: 1944, Episode_t: 8, Action: 211, Reward: 1.51, Epsilon: 0.01
 97%|█████████▋| 1944/2000 [38:47<01:11,  1.29s/it]
[INFO] Global step: 1944, Cumulative rewards: 13.917240000000001, Runtime (s): 2327.13
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 1945, loss: 141582.4375
[INFO] Global_t: 1945, Episode_t: 1, Action: 0, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1946, loss: 455636.3125
[INFO] Global_t: 1946, Episode_t: 2, Action: 125, Reward: 1.28, Epsilon: 0.01
[INFO] model update: t: 1947, loss: 273866.875
[INFO] Global_t: 1947, Episode_t: 3, Action: 132, Reward: 1.10, Epsilon: 0.01
[INFO] model update: t: 1948, loss: 507293.4375
[INFO] Global_t: 1948, Episode_t: 4, Action: 129, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1949, loss: 339299.59375
[INFO] Global_t: 1949, Episode_t: 5, Action: 113, Reward: 1.07, Epsilon: 0.01
[INFO] model update: t: 1950, loss: 266810.125
[INFO] Global_t: 1950, Episode_t: 6, Action: 60, Reward: 0.64, Epsilon: 0.01
[INFO] model update: t: 1951, loss: 264782.5
[INFO] Global_t: 1951, Episode_t: 7, Action: 90, Reward: 0.94, Epsilon: 0.01
[INFO] model update: t: 1952, loss: 288519.4375
[INFO] Global_t: 1952, Episode_t: 8, Action: 158, Reward: 0.92, Epsilon: 0.01
 98%|█████████▊| 1952/2000 [38:51<00:50,  1.05s/it]
[INFO] Global step: 1952, Cumulative rewards: 11.79048, Runtime (s): 2331.17
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.1745262145996094
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.151061534881592
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.1335978507995605
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.6808152198791504
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.4343204498291016
average cummulative reward vector is:  [0.07993053 0.06989653 0.08258224 0.07086098 0.09234462]
average cummulative reward is:  0.07912297989901018
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 1953, loss: 317487.375
[INFO] Global_t: 1953, Episode_t: 1, Action: 21, Reward: 4.07, Epsilon: 0.01
[INFO] model update: t: 1954, loss: 185914.21875
[INFO] Global_t: 1954, Episode_t: 2, Action: 71, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1955, loss: 182152.96875
[INFO] Global_t: 1955, Episode_t: 3, Action: 192, Reward: 1.32, Epsilon: 0.01
[INFO] model update: t: 1956, loss: 145814.09375
[INFO] Global_t: 1956, Episode_t: 4, Action: 137, Reward: 0.98, Epsilon: 0.01
[INFO] model update: t: 1957, loss: 123700.0
[INFO] Global_t: 1957, Episode_t: 5, Action: 77, Reward: 1.43, Epsilon: 0.01
[INFO] model update: t: 1958, loss: 131239.5625
[INFO] Global_t: 1958, Episode_t: 6, Action: 106, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 1959, loss: 229177.03125
[INFO] Global_t: 1959, Episode_t: 7, Action: 97, Reward: 1.10, Epsilon: 0.01
[INFO] model update: t: 1960, loss: 118594.40625
[INFO] Global_t: 1960, Episode_t: 8, Action: 121, Reward: 1.23, Epsilon: 0.01
 98%|█████████▊| 1960/2000 [39:06<00:52,  1.31s/it]
[INFO] Global step: 1960, Cumulative rewards: 12.922560000000002, Runtime (s): 2346.46
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 1961, loss: 130440.578125
[INFO] Global_t: 1961, Episode_t: 1, Action: 24, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1962, loss: 317508.625
[INFO] Global_t: 1962, Episode_t: 2, Action: 11, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1963, loss: 164411.109375
[INFO] Global_t: 1963, Episode_t: 3, Action: 35, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1964, loss: 219391.0
[INFO] Global_t: 1964, Episode_t: 4, Action: 8, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1965, loss: 483896.75
[INFO] Global_t: 1965, Episode_t: 5, Action: 134, Reward: 1.23, Epsilon: 0.01
[INFO] model update: t: 1966, loss: 342632.03125
[INFO] Global_t: 1966, Episode_t: 6, Action: 185, Reward: 1.36, Epsilon: 0.01
[INFO] model update: t: 1967, loss: 251543.078125
[INFO] Global_t: 1967, Episode_t: 7, Action: 109, Reward: 0.96, Epsilon: 0.01
[INFO] model update: t: 1968, loss: 137127.46875
[INFO] Global_t: 1968, Episode_t: 8, Action: 186, Reward: 1.38, Epsilon: 0.01
 98%|█████████▊| 1968/2000 [39:09<00:32,  1.03s/it]
[INFO] Global step: 1968, Cumulative rewards: 19.742880000000003, Runtime (s): 2349.50
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.085475444793701
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.152510643005371
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.043915271759033
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.2055442333221436
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.5537712574005127
average cummulative reward vector is:  [0.08000947 0.07136481 0.0801571  0.07377407 0.0886328 ]
average cummulative reward is:  0.07878765068872948
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 1969, loss: 288728.4375
[INFO] Global_t: 1969, Episode_t: 1, Action: 5, Reward: 4.39, Epsilon: 0.01
[INFO] model update: t: 1970, loss: 139890.671875
[INFO] Global_t: 1970, Episode_t: 2, Action: 91, Reward: 1.07, Epsilon: 0.01
[INFO] model update: t: 1971, loss: 223238.9375
[INFO] Global_t: 1971, Episode_t: 3, Action: 57, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1972, loss: 186993.46875
[INFO] Global_t: 1972, Episode_t: 4, Action: 183, Reward: 1.31, Epsilon: 0.01
[INFO] model update: t: 1973, loss: 196952.9375
[INFO] Global_t: 1973, Episode_t: 5, Action: 172, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1974, loss: 165029.5625
[INFO] Global_t: 1974, Episode_t: 6, Action: 140, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1975, loss: 181382.734375
[INFO] Global_t: 1975, Episode_t: 7, Action: 50, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1976, loss: 316519.75
[INFO] Global_t: 1976, Episode_t: 8, Action: 100, Reward: 1.48, Epsilon: 0.01

 99%|█████████▉| 1976/2000 [39:23<00:30,  1.26s/it]1, Runtime (s): 2363.75
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 1977, loss: 312629.75
[INFO] Global_t: 1977, Episode_t: 1, Action: 17, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 1978, loss: 183623.6875
[INFO] Global_t: 1978, Episode_t: 2, Action: 40, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1979, loss: 293745.8125
[INFO] Global_t: 1979, Episode_t: 3, Action: 79, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1980, loss: 150021.859375
[INFO] Global_t: 1980, Episode_t: 4, Action: 178, Reward: 1.01, Epsilon: 0.01
[INFO] model update: t: 1981, loss: 190373.625
[INFO] Global_t: 1981, Episode_t: 5, Action: 72, Reward: 1.29, Epsilon: 0.01
[INFO] model update: t: 1982, loss: 238302.828125
[INFO] Global_t: 1982, Episode_t: 6, Action: 122, Reward: 1.43, Epsilon: 0.01
[INFO] model update: t: 1983, loss: 100277.8046875
[INFO] Global_t: 1983, Episode_t: 7, Action: 144, Reward: 0.98, Epsilon: 0.01
[INFO] model update: t: 1984, loss: 269297.875
[INFO] Global_t: 1984, Episode_t: 8, Action: 78, Reward: 1.18, Epsilon: 0.01
 99%|█████████▉| 1984/2000 [39:27<00:16,  1.00s/it]
[INFO] Global step: 1984, Cumulative rewards: 12.663240000000002, Runtime (s): 2367.06
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.538180112838745
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1763885021209717
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.228351593017578
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.473818302154541
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.374344825744629
average cummulative reward vector is:  [0.08468684 0.07072708 0.08449754 0.07978879 0.09050887]
average cummulative reward is:  0.0820418244873348
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 1985, loss: 242381.15625
[INFO] Global_t: 1985, Episode_t: 1, Action: 11, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1986, loss: 472718.5
[INFO] Global_t: 1986, Episode_t: 2, Action: 10, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1987, loss: 177938.234375
[INFO] Global_t: 1987, Episode_t: 3, Action: 5, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 1988, loss: 363998.875
[INFO] Global_t: 1988, Episode_t: 4, Action: 169, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1989, loss: 146462.5
[INFO] Global_t: 1989, Episode_t: 5, Action: 141, Reward: 1.03, Epsilon: 0.01
[INFO] model update: t: 1990, loss: 199401.90625
[INFO] Global_t: 1990, Episode_t: 6, Action: 140, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1991, loss: 227765.109375
[INFO] Global_t: 1991, Episode_t: 7, Action: 92, Reward: 1.26, Epsilon: 0.01
[INFO] model update: t: 1992, loss: 221230.90625
[INFO] Global_t: 1992, Episode_t: 8, Action: 84, Reward: 1.28, Epsilon: 0.01
100%|█████████▉| 1992/2000 [39:42<00:10,  1.26s/it]
[INFO] Global step: 1992, Cumulative rewards: 17.99844, Runtime (s): 2382.05
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 1993, loss: 132701.421875
[INFO] Global_t: 1993, Episode_t: 1, Action: 18, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1994, loss: 244675.5625
[INFO] Global_t: 1994, Episode_t: 2, Action: 130, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 1995, loss: 232111.75
[INFO] Global_t: 1995, Episode_t: 3, Action: 143, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 1996, loss: 207298.84375
[INFO] Global_t: 1996, Episode_t: 4, Action: 2, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1997, loss: 368988.75
[INFO] Global_t: 1997, Episode_t: 5, Action: 134, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1998, loss: 148213.328125
[INFO] Global_t: 1998, Episode_t: 6, Action: 65, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1999, loss: 103762.90625
[INFO] Global_t: 1999, Episode_t: 7, Action: 110, Reward: 0.97, Epsilon: 0.01

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.166987419128418
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.2313075065612793
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.496450424194336
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.99534273147583
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.199725866317749
average cummulative reward vector is:  [0.08091184 0.07232014 0.08501612 0.06496192 0.08655215]
average cummulative reward is:  0.07795243352764322
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  2
[DEBUG 16:43:41] my_main Finished after 0:40:18.
[INFO 16:43:41] Experiments Completed after 0:40:18
