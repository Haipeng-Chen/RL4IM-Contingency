[INFO 02:15:53] Experiments Running command 'my_main'
[INFO 02:15:53] Experiments Started run with ID "5"
[DEBUG 02:15:53] Experiments Starting Heartbeat
Loading train graph:  powerlaw
[DEBUG 02:15:53] my_main Started
train graphs in total:  200
Loading test graph:  powerlaw
merged graphs length:  205
/home/docker/app/src/agent/colge/utils/config.py:10: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  model_config = yaml.load(config_file)
  0%|          | 0/2000 [00:00<?, ?it/s]epoch:  0
graph: 0, nodes: 180, edges: 531
[INFO] Global_t: 1, Episode_t: 1, Action: 155, Reward: 2.04, Epsilon: 0.99
[INFO] Global_t: 2, Episode_t: 2, Action: 116, Reward: 1.69, Epsilon: 0.99
[INFO] Global_t: 3, Episode_t: 3, Action: 23, Reward: 2.36, Epsilon: 0.99
[INFO] Global_t: 4, Episode_t: 4, Action: 62, Reward: 1.93, Epsilon: 0.99
[INFO] Global_t: 5, Episode_t: 5, Action: 41, Reward: 2.01, Epsilon: 0.99
[INFO] Global_t: 6, Episode_t: 6, Action: 30, Reward: 2.51, Epsilon: 0.98
[INFO] Global_t: 7, Episode_t: 7, Action: 11, Reward: 2.97, Epsilon: 0.98
[INFO] Global_t: 8, Episode_t: 8, Action: 90, Reward: 1.71, Epsilon: 0.98
  0%|          | 8/2000 [00:03<14:54,  2.23it/s]
[INFO] Global step: 8, Cumulative rewards: 17.218560000000004, Runtime (s): 3.59
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] Global_t: 9, Episode_t: 1, Action: 54, Reward: 2.15, Epsilon: 0.98
[INFO] Global_t: 10, Episode_t: 2, Action: 70, Reward: 2.58, Epsilon: 0.98
[INFO] Global_t: 11, Episode_t: 3, Action: 209, Reward: 1.49, Epsilon: 0.98
[INFO] Global_t: 12, Episode_t: 4, Action: 93, Reward: 1.20, Epsilon: 0.98
[INFO] Global_t: 13, Episode_t: 5, Action: 139, Reward: 1.65, Epsilon: 0.98
[INFO] Global_t: 14, Episode_t: 6, Action: 153, Reward: 1.61, Epsilon: 0.98
[INFO] Global_t: 15, Episode_t: 7, Action: 98, Reward: 1.75, Epsilon: 0.97
  1%|          | 16/2000 [00:06<14:19,  2.31it/s][INFO] Global_t: 16, Episode_t: 8, Action: 104, Reward: 1.31, Epsilon: 0.97

[INFO] Global step: 16, Cumulative rewards: 13.736279999999999, Runtime (s): 6.76
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.159209966659546
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.865687847137451
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.826387882232666
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  5.987860441207886
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.4505455493927
average cummulative reward vector is:  [0.14677684 0.13664051 0.13781803 0.12217523 0.1482629 ]
average cummulative reward is:  0.1383347042044148
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] Global_t: 17, Episode_t: 1, Action: 217, Reward: 2.04, Epsilon: 0.97
[INFO] Global_t: 18, Episode_t: 2, Action: 190, Reward: 1.01, Epsilon: 0.97
[INFO] Global_t: 19, Episode_t: 3, Action: 154, Reward: 1.87, Epsilon: 0.97
[INFO] Global_t: 20, Episode_t: 4, Action: 145, Reward: 1.66, Epsilon: 0.97
[INFO] Global_t: 21, Episode_t: 5, Action: 137, Reward: 2.25, Epsilon: 0.97
[INFO] Global_t: 22, Episode_t: 6, Action: 4, Reward: 6.68, Epsilon: 0.97
[INFO] Global_t: 23, Episode_t: 7, Action: 169, Reward: 1.21, Epsilon: 0.97
[INFO] Global_t: 24, Episode_t: 8, Action: 12, Reward: 4.17, Epsilon: 0.96
  1%|          | 24/2000 [00:42<53:41,  1.63s/it]
[INFO] Global step: 24, Cumulative rewards: 20.89452, Runtime (s): 42.15
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] Global_t: 25, Episode_t: 1, Action: 8, Reward: 7.75, Epsilon: 0.96
[INFO] Global_t: 26, Episode_t: 2, Action: 146, Reward: 1.50, Epsilon: 0.96
[INFO] Global_t: 27, Episode_t: 3, Action: 111, Reward: 1.81, Epsilon: 0.96
[INFO] Global_t: 28, Episode_t: 4, Action: 91, Reward: 1.90, Epsilon: 0.96
[INFO] Global_t: 29, Episode_t: 5, Action: 173, Reward: 1.05, Epsilon: 0.96
[INFO] Global_t: 30, Episode_t: 6, Action: 183, Reward: 1.31, Epsilon: 0.96
[INFO] Global_t: 31, Episode_t: 7, Action: 136, Reward: 1.47, Epsilon: 0.96
[INFO] Global_t: 32, Episode_t: 8, Action: 7, Reward: 3.90, Epsilon: 0.96
  2%|▏         | 32/2000 [00:47<44:03,  1.34s/it]
[INFO] Global step: 32, Cumulative rewards: 20.6856, Runtime (s): 47.53
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  7.166836977005005
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.015521287918091
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.899223327636719
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.664471626281738
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.150690793991089
average cummulative reward vector is:  [0.15830605 0.1273081  0.14316093 0.12870117 0.13912312]
average cummulative reward is:  0.13931987398980966
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] Global_t: 33, Episode_t: 1, Action: 129, Reward: 2.01, Epsilon: 0.96
[INFO] Global_t: 34, Episode_t: 2, Action: 175, Reward: 1.17, Epsilon: 0.95
[INFO] Global_t: 35, Episode_t: 3, Action: 77, Reward: 2.04, Epsilon: 0.95
[INFO] Global_t: 36, Episode_t: 4, Action: 112, Reward: 1.89, Epsilon: 0.95
[INFO] Global_t: 37, Episode_t: 5, Action: 57, Reward: 1.76, Epsilon: 0.95
[INFO] Global_t: 38, Episode_t: 6, Action: 12, Reward: 2.95, Epsilon: 0.95
[INFO] Global_t: 39, Episode_t: 7, Action: 32, Reward: 2.19, Epsilon: 0.95
[INFO] Global_t: 40, Episode_t: 8, Action: 105, Reward: 1.46, Epsilon: 0.95
  2%|▏         | 40/2000 [01:24<1:15:24,  2.31s/it]
[INFO] Global step: 40, Cumulative rewards: 15.47268, Runtime (s): 84.02
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] Global_t: 41, Episode_t: 1, Action: 192, Reward: 1.53, Epsilon: 0.95
[INFO] Global_t: 42, Episode_t: 2, Action: 58, Reward: 2.16, Epsilon: 0.95
[INFO] Global_t: 43, Episode_t: 3, Action: 148, Reward: 1.52, Epsilon: 0.94
[INFO] Global_t: 44, Episode_t: 4, Action: 99, Reward: 1.97, Epsilon: 0.94
[INFO] Global_t: 45, Episode_t: 5, Action: 163, Reward: 1.28, Epsilon: 0.94
[INFO] Global_t: 46, Episode_t: 6, Action: 92, Reward: 1.72, Epsilon: 0.94
[INFO] Global_t: 47, Episode_t: 7, Action: 29, Reward: 3.09, Epsilon: 0.94
[INFO] Global_t: 48, Episode_t: 8, Action: 40, Reward: 1.75, Epsilon: 0.94
  2%|▏         | 48/2000 [01:27<56:22,  1.73s/it]  
[INFO] Global step: 48, Cumulative rewards: 15.034439999999996, Runtime (s): 87.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.189509630203247
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.604907989501953
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.1557629108428955
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.697229862213135
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  7.260623455047607
average cummulative reward vector is:  [0.14672658 0.12889236 0.13707213 0.14022243 0.15094946]
average cummulative reward is:  0.14077259269563078
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 49, loss: 22959630336.0
[INFO] Global_t: 49, Episode_t: 1, Action: 53, Reward: 2.28, Epsilon: 0.94
[INFO] model update: t: 50, loss: 529810325504.0
[INFO] Global_t: 50, Episode_t: 2, Action: 3, Reward: 8.01, Epsilon: 0.94
[INFO] model update: t: 51, loss: 117761277952.0
[INFO] Global_t: 51, Episode_t: 3, Action: 4, Reward: 6.29, Epsilon: 0.94
[INFO] model update: t: 52, loss: 390262587392.0
[INFO] Global_t: 52, Episode_t: 4, Action: 2, Reward: 4.37, Epsilon: 0.93
[INFO] model update: t: 53, loss: 91812282368.0
[INFO] Global_t: 53, Episode_t: 5, Action: 126, Reward: 1.25, Epsilon: 0.93
[INFO] model update: t: 54, loss: 187551680.0
[INFO] Global_t: 54, Episode_t: 6, Action: 71, Reward: 2.34, Epsilon: 0.93
[INFO] model update: t: 55, loss: 39927283712.0
[INFO] Global_t: 55, Episode_t: 7, Action: 103, Reward: 1.51, Epsilon: 0.93
  3%|▎         | 56/2000 [03:15<2:51:16,  5.29s/it][INFO] model update: t: 56, loss: 71248003072.0
[INFO] Global_t: 56, Episode_t: 8, Action: 74, Reward: 1.65, Epsilon: 0.93

[INFO] Global step: 56, Cumulative rewards: 27.70092, Runtime (s): 195.76
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 57, loss: 60935815168.0
[INFO] Global_t: 57, Episode_t: 1, Action: 76, Reward: 1.96, Epsilon: 0.93
[INFO] model update: t: 58, loss: 23636195328.0
[INFO] Global_t: 58, Episode_t: 2, Action: 4, Reward: 4.31, Epsilon: 0.93
[INFO] model update: t: 59, loss: 2476537344.0
[INFO] Global_t: 59, Episode_t: 3, Action: 47, Reward: 1.58, Epsilon: 0.93
[INFO] model update: t: 60, loss: 2476446720.0
[INFO] Global_t: 60, Episode_t: 4, Action: 0, Reward: 6.35, Epsilon: 0.93
[INFO] model update: t: 61, loss: 12841958400.0
[INFO] Global_t: 61, Episode_t: 5, Action: 43, Reward: 1.33, Epsilon: 0.92
[INFO] model update: t: 62, loss: 20969439232.0
[INFO] Global_t: 62, Episode_t: 6, Action: 24, Reward: 2.97, Epsilon: 0.92
[INFO] model update: t: 63, loss: 22361122816.0
[INFO] Global_t: 63, Episode_t: 7, Action: 130, Reward: 1.57, Epsilon: 0.92
[INFO] model update: t: 64, loss: 17069441024.0
[INFO] Global_t: 64, Episode_t: 8, Action: 117, Reward: 1.18, Epsilon: 0.92
  3%|▎         | 64/2000 [04:29<3:28:54,  6.47s/it]
[INFO] Global step: 64, Cumulative rewards: 21.250079999999997, Runtime (s): 269.73
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.5870537757873535
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.7710418701171875
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.849302053451538
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.227814435958862
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  5.864886283874512
average cummulative reward vector is:  [0.13730316 0.13578333 0.14960738 0.13624229 0.13552231]
average cummulative reward is:  0.13889169396496676
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 65, loss: 7712872448.0
[INFO] Global_t: 65, Episode_t: 1, Action: 97, Reward: 1.62, Epsilon: 0.92
[INFO] model update: t: 66, loss: 2049013888.0
[INFO] Global_t: 66, Episode_t: 2, Action: 117, Reward: 1.72, Epsilon: 0.92
[INFO] model update: t: 67, loss: 1653146.875
[INFO] Global_t: 67, Episode_t: 3, Action: 17, Reward: 3.20, Epsilon: 0.92
[INFO] model update: t: 68, loss: 1524291584.0
[INFO] Global_t: 68, Episode_t: 4, Action: 58, Reward: 1.78, Epsilon: 0.92
[INFO] model update: t: 69, loss: 3670534656.0
[INFO] Global_t: 69, Episode_t: 5, Action: 112, Reward: 1.58, Epsilon: 0.92
[INFO] model update: t: 70, loss: 4551731200.0
[INFO] Global_t: 70, Episode_t: 6, Action: 34, Reward: 2.57, Epsilon: 0.91
[INFO] model update: t: 71, loss: 4000517120.0
[INFO] Global_t: 71, Episode_t: 7, Action: 0, Reward: 5.66, Epsilon: 0.91
[INFO] model update: t: 72, loss: 2769679616.0
[INFO] Global_t: 72, Episode_t: 8, Action: 1, Reward: 5.78, Epsilon: 0.91
  4%|▎         | 72/2000 [06:10<4:27:10,  8.31s/it]
[INFO] Global step: 72, Cumulative rewards: 23.9214, Runtime (s): 370.59
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 73, loss: 951583168.0
[INFO] Global_t: 73, Episode_t: 1, Action: 145, Reward: 1.59, Epsilon: 0.91
[INFO] model update: t: 74, loss: 33867440.0
[INFO] Global_t: 74, Episode_t: 2, Action: 5, Reward: 5.13, Epsilon: 0.91
[INFO] model update: t: 75, loss: 268346128.0
[INFO] Global_t: 75, Episode_t: 3, Action: 73, Reward: 1.80, Epsilon: 0.91
[INFO] model update: t: 76, loss: 874384640.0
[INFO] Global_t: 76, Episode_t: 4, Action: 155, Reward: 1.68, Epsilon: 0.91
[INFO] model update: t: 77, loss: 1195271424.0
[INFO] Global_t: 77, Episode_t: 5, Action: 89, Reward: 2.01, Epsilon: 0.91
[INFO] model update: t: 78, loss: 1142395264.0
[INFO] Global_t: 78, Episode_t: 6, Action: 44, Reward: 1.96, Epsilon: 0.91
[INFO] model update: t: 79, loss: 895275904.0
[INFO] Global_t: 79, Episode_t: 7, Action: 103, Reward: 1.69, Epsilon: 0.91
[INFO] model update: t: 80, loss: 469995296.0
[INFO] Global_t: 80, Episode_t: 8, Action: 148, Reward: 1.31, Epsilon: 0.90
  4%|▍         | 80/2000 [07:28<4:39:17,  8.73s/it]
[INFO] Global step: 80, Cumulative rewards: 17.17776, Runtime (s): 448.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.746229410171509
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.857913494110107
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.216697931289673
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.659460544586182
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  7.217689037322998
average cummulative reward vector is:  [0.14569289 0.12392083 0.14900492 0.13348458 0.1498914 ]
average cummulative reward is:  0.14039892467833542
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 81, loss: 197025456.0
[INFO] Global_t: 81, Episode_t: 1, Action: 17, Reward: 2.81, Epsilon: 0.90
[INFO] model update: t: 82, loss: 28393088.0
[INFO] Global_t: 82, Episode_t: 2, Action: 172, Reward: 1.37, Epsilon: 0.90
[INFO] model update: t: 83, loss: 7456321.0
[INFO] Global_t: 83, Episode_t: 3, Action: 67, Reward: 1.75, Epsilon: 0.90
[INFO] model update: t: 84, loss: 54758960.0
[INFO] Global_t: 84, Episode_t: 4, Action: 42, Reward: 1.62, Epsilon: 0.90
[INFO] model update: t: 85, loss: 96538600.0
[INFO] Global_t: 85, Episode_t: 5, Action: 121, Reward: 1.70, Epsilon: 0.90
[INFO] model update: t: 86, loss: 151928960.0
[INFO] Global_t: 86, Episode_t: 6, Action: 123, Reward: 2.03, Epsilon: 0.90
[INFO] model update: t: 87, loss: 186444416.0
[INFO] Global_t: 87, Episode_t: 7, Action: 106, Reward: 1.42, Epsilon: 0.90
[INFO] model update: t: 88, loss: 168352544.0
[INFO] Global_t: 88, Episode_t: 8, Action: 2, Reward: 4.83, Epsilon: 0.90
  4%|▍         | 88/2000 [09:18<5:26:22, 10.24s/it]
[INFO] Global step: 88, Cumulative rewards: 17.5218, Runtime (s): 558.33
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 89, loss: 123864256.0
[INFO] Global_t: 89, Episode_t: 1, Action: 164, Reward: 1.26, Epsilon: 0.89
[INFO] model update: t: 90, loss: 84190960.0
[INFO] Global_t: 90, Episode_t: 2, Action: 181, Reward: 1.57, Epsilon: 0.89
[INFO] model update: t: 91, loss: 43971260.0
[INFO] Global_t: 91, Episode_t: 3, Action: 179, Reward: 1.53, Epsilon: 0.89
[INFO] model update: t: 92, loss: 20702170.0
[INFO] Global_t: 92, Episode_t: 4, Action: 4, Reward: 6.27, Epsilon: 0.89
[INFO] model update: t: 93, loss: 4653356.0
[INFO] Global_t: 93, Episode_t: 5, Action: 48, Reward: 2.07, Epsilon: 0.89
[INFO] model update: t: 94, loss: 436131.375
[INFO] Global_t: 94, Episode_t: 6, Action: 119, Reward: 1.75, Epsilon: 0.89
[INFO] model update: t: 95, loss: 5388284.5
[INFO] Global_t: 95, Episode_t: 7, Action: 158, Reward: 1.07, Epsilon: 0.89
[INFO] model update: t: 96, loss: 15805224.0
[INFO] Global_t: 96, Episode_t: 8, Action: 35, Reward: 2.49, Epsilon: 0.89
  5%|▍         | 96/2000 [10:33<5:16:52,  9.99s/it]
[INFO] Global step: 96, Cumulative rewards: 18.016560000000002, Runtime (s): 633.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.465365886688232
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.926466703414917
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.205916166305542
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.037320613861084
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.61939001083374
average cummulative reward vector is:  [0.14071342 0.1322169  0.13863825 0.12807266 0.14748333]
average cummulative reward is:  0.137424913490327
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 97, loss: 29567494.0
[INFO] Global_t: 97, Episode_t: 1, Action: 48, Reward: 1.64, Epsilon: 0.89
[INFO] model update: t: 98, loss: 47241404.0
[INFO] Global_t: 98, Episode_t: 2, Action: 83, Reward: 1.45, Epsilon: 0.88
[INFO] model update: t: 99, loss: 45888492.0
[INFO] Global_t: 99, Episode_t: 3, Action: 157, Reward: 1.62, Epsilon: 0.88
[INFO] model update: t: 100, loss: 49013124.0
[INFO] Global_t: 100, Episode_t: 4, Action: 57, Reward: 1.77, Epsilon: 0.88
[INFO] model update: t: 101, loss: 40703700.0
[INFO] Global_t: 101, Episode_t: 5, Action: 160, Reward: 1.82, Epsilon: 0.88
[INFO] model update: t: 102, loss: 34401080.0
[INFO] Global_t: 102, Episode_t: 6, Action: 132, Reward: 1.51, Epsilon: 0.88
[INFO] model update: t: 103, loss: 20282438.0
[INFO] Global_t: 103, Episode_t: 7, Action: 1, Reward: 5.29, Epsilon: 0.88
[INFO] model update: t: 104, loss: 9551506.0
[INFO] Global_t: 104, Episode_t: 8, Action: 162, Reward: 1.47, Epsilon: 0.88
  5%|▌         | 104/2000 [12:22<5:49:57, 11.07s/it]
[INFO] Global step: 104, Cumulative rewards: 16.56036, Runtime (s): 742.35
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 105, loss: 3416138.0
[INFO] Global_t: 105, Episode_t: 1, Action: 17, Reward: 2.92, Epsilon: 0.88
[INFO] model update: t: 106, loss: 571536.8125
[INFO] Global_t: 106, Episode_t: 2, Action: 59, Reward: 1.98, Epsilon: 0.88
[INFO] model update: t: 107, loss: 520280.90625
[INFO] Global_t: 107, Episode_t: 3, Action: 96, Reward: 2.13, Epsilon: 0.87
[INFO] model update: t: 108, loss: 2521121.0
[INFO] Global_t: 108, Episode_t: 4, Action: 49, Reward: 2.11, Epsilon: 0.87
[INFO] model update: t: 109, loss: 5032654.0
[INFO] Global_t: 109, Episode_t: 5, Action: 151, Reward: 1.43, Epsilon: 0.87
[INFO] model update: t: 110, loss: 9352834.0
[INFO] Global_t: 110, Episode_t: 6, Action: 183, Reward: 1.55, Epsilon: 0.87
[INFO] model update: t: 111, loss: 10622926.0
[INFO] Global_t: 111, Episode_t: 7, Action: 94, Reward: 1.52, Epsilon: 0.87
[INFO] model update: t: 112, loss: 12029973.0
[INFO] Global_t: 112, Episode_t: 8, Action: 21, Reward: 2.96, Epsilon: 0.87
  6%|▌         | 112/2000 [13:39<5:34:38, 10.63s/it]
[INFO] Global step: 112, Cumulative rewards: 16.59708, Runtime (s): 819.22
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.135728359222412
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.9612650871276855
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.680812358856201
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.3882012367248535
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  5.767349481582642
average cummulative reward vector is:  [0.14466474 0.12594537 0.14098634 0.11815818 0.14138495]
average cummulative reward is:  0.1342279139633885
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 113, loss: 14667170.0
[INFO] Global_t: 113, Episode_t: 1, Action: 199, Reward: 2.01, Epsilon: 0.87
[INFO] model update: t: 114, loss: 12146434.0
[INFO] Global_t: 114, Episode_t: 2, Action: 8, Reward: 5.30, Epsilon: 0.87
[INFO] model update: t: 115, loss: 9384833.0
[INFO] Global_t: 115, Episode_t: 3, Action: 172, Reward: 1.43, Epsilon: 0.87
[INFO] model update: t: 116, loss: 6126384.0
[INFO] Global_t: 116, Episode_t: 4, Action: 15, Reward: 1.86, Epsilon: 0.86
[INFO] model update: t: 117, loss: 2893925.5
[INFO] Global_t: 117, Episode_t: 5, Action: 93, Reward: 2.23, Epsilon: 0.86
[INFO] model update: t: 118, loss: 1315886.25
[INFO] Global_t: 118, Episode_t: 6, Action: 113, Reward: 1.47, Epsilon: 0.86
[INFO] model update: t: 119, loss: 372126.4375
[INFO] Global_t: 119, Episode_t: 7, Action: 200, Reward: 1.79, Epsilon: 0.86
[INFO] model update: t: 120, loss: 152277.375
[INFO] Global_t: 120, Episode_t: 8, Action: 5, Reward: 3.83, Epsilon: 0.86
  6%|▌         | 120/2000 [15:16<5:47:48, 11.10s/it]
[INFO] Global step: 120, Cumulative rewards: 19.91988, Runtime (s): 916.71
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 121, loss: 770686.4375
[INFO] Global_t: 121, Episode_t: 1, Action: 7, Reward: 4.58, Epsilon: 0.86
[INFO] model update: t: 122, loss: 1255243.5
[INFO] Global_t: 122, Episode_t: 2, Action: 176, Reward: 1.47, Epsilon: 0.86
[INFO] model update: t: 123, loss: 2335154.75
[INFO] Global_t: 123, Episode_t: 3, Action: 4, Reward: 5.18, Epsilon: 0.86
[INFO] model update: t: 124, loss: 3423066.0
[INFO] Global_t: 124, Episode_t: 4, Action: 3, Reward: 4.73, Epsilon: 0.86
[INFO] model update: t: 125, loss: 3639579.25
[INFO] Global_t: 125, Episode_t: 5, Action: 182, Reward: 0.99, Epsilon: 0.85
[INFO] model update: t: 126, loss: 2953394.0
[INFO] Global_t: 126, Episode_t: 6, Action: 165, Reward: 1.06, Epsilon: 0.85
[INFO] model update: t: 127, loss: 3119012.0
[INFO] Global_t: 127, Episode_t: 7, Action: 167, Reward: 1.10, Epsilon: 0.85
[INFO] model update: t: 128, loss: 2496650.5
  6%|▋         | 128/2000 [16:16<5:12:24, 10.01s/it][INFO] Global_t: 128, Episode_t: 8, Action: 36, Reward: 1.71, Epsilon: 0.85

[INFO] Global step: 128, Cumulative rewards: 20.829359999999998, Runtime (s): 976.52
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.249655246734619
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.017075300216675
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.847621202468872
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.1954121589660645
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.428742170333862
average cummulative reward vector is:  [0.13887921 0.13732407 0.15381831 0.13713435 0.14737876]
average cummulative reward is:  0.14290693996931433
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 129, loss: 1728258.25
[INFO] Global_t: 129, Episode_t: 1, Action: 117, Reward: 1.52, Epsilon: 0.85
[INFO] model update: t: 130, loss: 1120693.75
[INFO] Global_t: 130, Episode_t: 2, Action: 65, Reward: 1.62, Epsilon: 0.85
[INFO] model update: t: 131, loss: 555719.625
[INFO] Global_t: 131, Episode_t: 3, Action: 28, Reward: 2.17, Epsilon: 0.85
[INFO] model update: t: 132, loss: 242044.078125
[INFO] Global_t: 132, Episode_t: 4, Action: 4, Reward: 5.67, Epsilon: 0.85
[INFO] model update: t: 133, loss: 106374.40625
[INFO] Global_t: 133, Episode_t: 5, Action: 70, Reward: 1.45, Epsilon: 0.85
[INFO] model update: t: 134, loss: 407257.09375
[INFO] Global_t: 134, Episode_t: 6, Action: 56, Reward: 1.74, Epsilon: 0.85
[INFO] model update: t: 135, loss: 822676.5
[INFO] Global_t: 135, Episode_t: 7, Action: 175, Reward: 1.16, Epsilon: 0.84
  7%|▋         | 136/2000 [17:57<5:34:59, 10.78s/it][INFO] model update: t: 136, loss: 855302.4375
[INFO] Global_t: 136, Episode_t: 8, Action: 116, Reward: 1.49, Epsilon: 0.84

[INFO] Global step: 136, Cumulative rewards: 16.827119999999997, Runtime (s): 1077.16
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 137, loss: 1019633.375
[INFO] Global_t: 137, Episode_t: 1, Action: 127, Reward: 1.40, Epsilon: 0.84
[INFO] model update: t: 138, loss: 1143058.0
[INFO] Global_t: 138, Episode_t: 2, Action: 32, Reward: 2.31, Epsilon: 0.84
[INFO] model update: t: 139, loss: 824443.5
[INFO] Global_t: 139, Episode_t: 3, Action: 124, Reward: 1.14, Epsilon: 0.84
[INFO] model update: t: 140, loss: 863251.0625
[INFO] Global_t: 140, Episode_t: 4, Action: 159, Reward: 0.94, Epsilon: 0.84
[INFO] model update: t: 141, loss: 811255.375
[INFO] Global_t: 141, Episode_t: 5, Action: 101, Reward: 1.37, Epsilon: 0.84
[INFO] model update: t: 142, loss: 444623.84375
[INFO] Global_t: 142, Episode_t: 6, Action: 77, Reward: 1.55, Epsilon: 0.84
[INFO] model update: t: 143, loss: 275466.125
[INFO] Global_t: 143, Episode_t: 7, Action: 7, Reward: 5.01, Epsilon: 0.84
[INFO] model update: t: 144, loss: 313545.3125
[INFO] Global_t: 144, Episode_t: 8, Action: 56, Reward: 1.54, Epsilon: 0.83

[INFO] Global step: 144, Cumulative rewards: 15.254879999999998, Runtime (s): 1131.83
------------------------------------------------------------
 
  7%|▋         | 144/2000 [18:51<4:56:54,  9.60s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  5.442362546920776
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.273437023162842
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.1145594120025635
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.383883476257324
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  5.0266571044921875
average cummulative reward vector is:  [0.13014789 0.12700949 0.14715383 0.13501565 0.12925054]
average cummulative reward is:  0.1337154804908422
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 145, loss: 220382.015625
[INFO] Global_t: 145, Episode_t: 1, Action: 14, Reward: 3.09, Epsilon: 0.83
[INFO] model update: t: 146, loss: 181897.9375
[INFO] Global_t: 146, Episode_t: 2, Action: 15, Reward: 3.25, Epsilon: 0.83
[INFO] model update: t: 147, loss: 357559.34375
[INFO] Global_t: 147, Episode_t: 3, Action: 84, Reward: 1.35, Epsilon: 0.83
[INFO] model update: t: 148, loss: 306186.875
[INFO] Global_t: 148, Episode_t: 4, Action: 9, Reward: 5.36, Epsilon: 0.83
[INFO] model update: t: 149, loss: 487969.90625
[INFO] Global_t: 149, Episode_t: 5, Action: 123, Reward: 1.35, Epsilon: 0.83
[INFO] model update: t: 150, loss: 499942.03125
[INFO] Global_t: 150, Episode_t: 6, Action: 112, Reward: 1.49, Epsilon: 0.83
[INFO] model update: t: 151, loss: 371016.9375
[INFO] Global_t: 151, Episode_t: 7, Action: 20, Reward: 4.03, Epsilon: 0.83
[INFO] model update: t: 152, loss: 473809.125
[INFO] Global_t: 152, Episode_t: 8, Action: 156, Reward: 1.17, Epsilon: 0.83
  8%|▊         | 152/2000 [20:30<5:21:26, 10.44s/it]
[INFO] Global step: 152, Cumulative rewards: 21.09864, Runtime (s): 1230.97
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 153, loss: 363374.3125
[INFO] Global_t: 153, Episode_t: 1, Action: 76, Reward: 2.45, Epsilon: 0.82
[INFO] model update: t: 154, loss: 327319.625
[INFO] Global_t: 154, Episode_t: 2, Action: 7, Reward: 5.89, Epsilon: 0.82
[INFO] model update: t: 155, loss: 272447.5625
[INFO] Global_t: 155, Episode_t: 3, Action: 103, Reward: 1.44, Epsilon: 0.82
[INFO] model update: t: 156, loss: 309283.65625
[INFO] Global_t: 156, Episode_t: 4, Action: 195, Reward: 1.54, Epsilon: 0.82
[INFO] model update: t: 157, loss: 150188.46875
[INFO] Global_t: 157, Episode_t: 5, Action: 10, Reward: 4.38, Epsilon: 0.82
[INFO] model update: t: 158, loss: 297874.78125
[INFO] Global_t: 158, Episode_t: 6, Action: 6, Reward: 7.14, Epsilon: 0.82
[INFO] model update: t: 159, loss: 223835.875
[INFO] Global_t: 159, Episode_t: 7, Action: 122, Reward: 1.66, Epsilon: 0.82
[INFO] model update: t: 160, loss: 341692.3125
[INFO] Global_t: 160, Episode_t: 8, Action: 179, Reward: 1.65, Epsilon: 0.82
  8%|▊         | 160/2000 [21:33<4:56:27,  9.67s/it]
[INFO] Global step: 160, Cumulative rewards: 26.154480000000003, Runtime (s): 1293.95
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.623415231704712
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.51751446723938
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.648987293243408
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.6753623485565186
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.243091583251953
average cummulative reward vector is:  [0.14494289 0.1348875  0.1344847  0.13684603 0.14160995]
average cummulative reward is:  0.1385542136928673
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 161, loss: 165315.53125
[INFO] Global_t: 161, Episode_t: 1, Action: 72, Reward: 1.79, Epsilon: 0.82
[INFO] model update: t: 162, loss: 214001.296875
[INFO] Global_t: 162, Episode_t: 2, Action: 53, Reward: 2.60, Epsilon: 0.81
[INFO] model update: t: 163, loss: 220904.84375
[INFO] Global_t: 163, Episode_t: 3, Action: 18, Reward: 4.22, Epsilon: 0.81
[INFO] model update: t: 164, loss: 208423.328125
[INFO] Global_t: 164, Episode_t: 4, Action: 119, Reward: 1.77, Epsilon: 0.81
[INFO] model update: t: 165, loss: 165239.59375
[INFO] Global_t: 165, Episode_t: 5, Action: 15, Reward: 2.91, Epsilon: 0.81
[INFO] model update: t: 166, loss: 273239.875
[INFO] Global_t: 166, Episode_t: 6, Action: 85, Reward: 2.04, Epsilon: 0.81
[INFO] model update: t: 167, loss: 205746.578125
[INFO] Global_t: 167, Episode_t: 7, Action: 76, Reward: 1.37, Epsilon: 0.81
[INFO] model update: t: 168, loss: 131414.75
[INFO] Global_t: 168, Episode_t: 8, Action: 172, Reward: 2.02, Epsilon: 0.81
  8%|▊         | 168/2000 [23:17<5:25:32, 10.66s/it]
[INFO] Global step: 168, Cumulative rewards: 18.716639999999998, Runtime (s): 1397.80
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 169, loss: 273174.6875
[INFO] Global_t: 169, Episode_t: 1, Action: 56, Reward: 2.16, Epsilon: 0.81
[INFO] model update: t: 170, loss: 153417.0
[INFO] Global_t: 170, Episode_t: 2, Action: 159, Reward: 1.44, Epsilon: 0.81
[INFO] model update: t: 171, loss: 156526.296875
[INFO] Global_t: 171, Episode_t: 3, Action: 109, Reward: 1.69, Epsilon: 0.80
[INFO] model update: t: 172, loss: 209414.546875
[INFO] Global_t: 172, Episode_t: 4, Action: 185, Reward: 1.24, Epsilon: 0.80
[INFO] model update: t: 173, loss: 203682.96875
[INFO] Global_t: 173, Episode_t: 5, Action: 33, Reward: 1.93, Epsilon: 0.80
[INFO] model update: t: 174, loss: 155859.3125
[INFO] Global_t: 174, Episode_t: 6, Action: 84, Reward: 1.91, Epsilon: 0.80
[INFO] model update: t: 175, loss: 188353.8125
[INFO] Global_t: 175, Episode_t: 7, Action: 1, Reward: 5.09, Epsilon: 0.80
[INFO] model update: t: 176, loss: 188670.03125
[INFO] Global_t: 176, Episode_t: 8, Action: 177, Reward: 1.34, Epsilon: 0.80
  9%|▉         | 176/2000 [24:08<4:44:48,  9.37s/it]
[INFO] Global step: 176, Cumulative rewards: 16.813679999999998, Runtime (s): 1448.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.6392340660095215
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  5.901007175445557
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.222795724868774
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.8327789306640625
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.850972652435303
average cummulative reward vector is:  [0.13974079 0.12491042 0.14857623 0.12985631 0.14652715]
average cummulative reward is:  0.1379221789194794
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 177, loss: 123502.609375
[INFO] Global_t: 177, Episode_t: 1, Action: 110, Reward: 1.98, Epsilon: 0.80
[INFO] model update: t: 178, loss: 210734.40625
[INFO] Global_t: 178, Episode_t: 2, Action: 10, Reward: 2.81, Epsilon: 0.80
[INFO] model update: t: 179, loss: 87928.6875
[INFO] Global_t: 179, Episode_t: 3, Action: 146, Reward: 1.48, Epsilon: 0.80
[INFO] model update: t: 180, loss: 255040.71875
[INFO] Global_t: 180, Episode_t: 4, Action: 79, Reward: 2.71, Epsilon: 0.80
[INFO] model update: t: 181, loss: 135964.75
[INFO] Global_t: 181, Episode_t: 5, Action: 44, Reward: 1.44, Epsilon: 0.79
[INFO] model update: t: 182, loss: 289069.65625
[INFO] Global_t: 182, Episode_t: 6, Action: 182, Reward: 2.29, Epsilon: 0.79
[INFO] model update: t: 183, loss: 174820.984375
[INFO] Global_t: 183, Episode_t: 7, Action: 0, Reward: 6.90, Epsilon: 0.79
[INFO] model update: t: 184, loss: 318235.71875
[INFO] Global_t: 184, Episode_t: 8, Action: 7, Reward: 3.91, Epsilon: 0.79

[INFO] Global step: 184, Cumulative rewards: 23.51544, Runtime (s): 1553.84
------------------------------------------------------------
 
  9%|▉         | 184/2000 [25:53<5:17:55, 10.50s/it]graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 185, loss: 270483.625
[INFO] Global_t: 185, Episode_t: 1, Action: 66, Reward: 2.66, Epsilon: 0.79
[INFO] model update: t: 186, loss: 187166.78125
[INFO] Global_t: 186, Episode_t: 2, Action: 157, Reward: 1.33, Epsilon: 0.79
[INFO] model update: t: 187, loss: 286312.9375
[INFO] Global_t: 187, Episode_t: 3, Action: 145, Reward: 1.26, Epsilon: 0.79
[INFO] model update: t: 188, loss: 164481.34375
[INFO] Global_t: 188, Episode_t: 4, Action: 55, Reward: 2.32, Epsilon: 0.79
[INFO] model update: t: 189, loss: 219991.59375
[INFO] Global_t: 189, Episode_t: 5, Action: 12, Reward: 3.43, Epsilon: 0.79
[INFO] model update: t: 190, loss: 221284.84375
[INFO] Global_t: 190, Episode_t: 6, Action: 1, Reward: 5.48, Epsilon: 0.78
[INFO] model update: t: 191, loss: 232633.734375
[INFO] Global_t: 191, Episode_t: 7, Action: 164, Reward: 1.58, Epsilon: 0.78
[INFO] model update: t: 192, loss: 136889.15625
[INFO] Global_t: 192, Episode_t: 8, Action: 63, Reward: 0.99, Epsilon: 0.78
 10%|▉         | 192/2000 [26:20<4:11:19,  8.34s/it]
[INFO] Global step: 192, Cumulative rewards: 19.06596, Runtime (s): 1580.18
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.035584449768066
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  5.336803913116455
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.720992803573608
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.320667743682861
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.325422286987305
average cummulative reward vector is:  [0.14601947 0.12706736 0.14254126 0.13191425 0.1535664 ]
average cummulative reward is:  0.14022174836236673
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 193, loss: 209342.609375
[INFO] Global_t: 193, Episode_t: 1, Action: 2, Reward: 6.28, Epsilon: 0.78
[INFO] model update: t: 194, loss: 127752.5625
[INFO] Global_t: 194, Episode_t: 2, Action: 4, Reward: 5.42, Epsilon: 0.78
[INFO] model update: t: 195, loss: 246410.46875
[INFO] Global_t: 195, Episode_t: 3, Action: 192, Reward: 1.53, Epsilon: 0.78
[INFO] model update: t: 196, loss: 264937.53125
[INFO] Global_t: 196, Episode_t: 4, Action: 10, Reward: 4.64, Epsilon: 0.78
[INFO] model update: t: 197, loss: 164238.3125
[INFO] Global_t: 197, Episode_t: 5, Action: 7, Reward: 4.59, Epsilon: 0.78
[INFO] model update: t: 198, loss: 272124.3125
[INFO] Global_t: 198, Episode_t: 6, Action: 3, Reward: 4.42, Epsilon: 0.78
[INFO] model update: t: 199, loss: 195196.25
[INFO] Global_t: 199, Episode_t: 7, Action: 11, Reward: 3.53, Epsilon: 0.77
[INFO] model update: t: 200, loss: 373314.4375
[INFO] Global_t: 200, Episode_t: 8, Action: 5, Reward: 6.05, Epsilon: 0.77
 10%|█         | 200/2000 [28:02<4:50:25,  9.68s/it]
[INFO] Global step: 200, Cumulative rewards: 36.45252, Runtime (s): 1682.65
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 201, loss: 213672.78125
[INFO] Global_t: 201, Episode_t: 1, Action: 4, Reward: 5.57, Epsilon: 0.77
[INFO] model update: t: 202, loss: 230223.59375
[INFO] Global_t: 202, Episode_t: 2, Action: 147, Reward: 1.26, Epsilon: 0.77
[INFO] model update: t: 203, loss: 168187.609375
[INFO] Global_t: 203, Episode_t: 3, Action: 1, Reward: 6.09, Epsilon: 0.77
[INFO] model update: t: 204, loss: 145229.40625
[INFO] Global_t: 204, Episode_t: 4, Action: 39, Reward: 1.66, Epsilon: 0.77
[INFO] model update: t: 205, loss: 250464.1875
[INFO] Global_t: 205, Episode_t: 5, Action: 157, Reward: 1.60, Epsilon: 0.77
[INFO] model update: t: 206, loss: 211292.515625
[INFO] Global_t: 206, Episode_t: 6, Action: 169, Reward: 1.54, Epsilon: 0.77
[INFO] model update: t: 207, loss: 235641.625
[INFO] Global_t: 207, Episode_t: 7, Action: 8, Reward: 4.41, Epsilon: 0.77
[INFO] model update: t: 208, loss: 162530.53125
[INFO] Global_t: 208, Episode_t: 8, Action: 166, Reward: 1.08, Epsilon: 0.76
 10%|█         | 208/2000 [29:05<4:33:05,  9.14s/it]
[INFO] Global step: 208, Cumulative rewards: 23.22012, Runtime (s): 1745.77
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.783190011978149
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.387506723403931
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.534067869186401
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.617684602737427
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.556135177612305
average cummulative reward vector is:  [0.14518974 0.12501875 0.14884563 0.12883318 0.14517339]
average cummulative reward is:  0.13861213598485472
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 209, loss: 138772.3125
[INFO] Global_t: 209, Episode_t: 1, Action: 137, Reward: 1.38, Epsilon: 0.76
[INFO] model update: t: 210, loss: 165706.28125
[INFO] Global_t: 210, Episode_t: 2, Action: 138, Reward: 1.55, Epsilon: 0.76
[INFO] model update: t: 211, loss: 363242.34375
[INFO] Global_t: 211, Episode_t: 3, Action: 59, Reward: 2.26, Epsilon: 0.76
[INFO] model update: t: 212, loss: 167558.09375
[INFO] Global_t: 212, Episode_t: 4, Action: 88, Reward: 1.74, Epsilon: 0.76
[INFO] model update: t: 213, loss: 225490.5
[INFO] Global_t: 213, Episode_t: 5, Action: 4, Reward: 5.87, Epsilon: 0.76
[INFO] model update: t: 214, loss: 145645.421875
[INFO] Global_t: 214, Episode_t: 6, Action: 12, Reward: 5.37, Epsilon: 0.76
[INFO] model update: t: 215, loss: 125267.109375
[INFO] Global_t: 215, Episode_t: 7, Action: 123, Reward: 1.59, Epsilon: 0.76
[INFO] model update: t: 216, loss: 195387.90625
[INFO] Global_t: 216, Episode_t: 8, Action: 18, Reward: 2.74, Epsilon: 0.76
 11%|█         | 216/2000 [30:50<5:07:29, 10.34s/it]
[INFO] Global step: 216, Cumulative rewards: 22.5048, Runtime (s): 1850.87
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 217, loss: 136104.71875
[INFO] Global_t: 217, Episode_t: 1, Action: 174, Reward: 2.02, Epsilon: 0.75
[INFO] model update: t: 218, loss: 165286.28125
[INFO] Global_t: 218, Episode_t: 2, Action: 9, Reward: 3.49, Epsilon: 0.75
[INFO] model update: t: 219, loss: 247136.828125
[INFO] Global_t: 219, Episode_t: 3, Action: 131, Reward: 1.90, Epsilon: 0.75
[INFO] model update: t: 220, loss: 235733.75
[INFO] Global_t: 220, Episode_t: 4, Action: 2, Reward: 5.45, Epsilon: 0.75
[INFO] model update: t: 221, loss: 131080.3125
[INFO] Global_t: 221, Episode_t: 5, Action: 93, Reward: 1.50, Epsilon: 0.75
[INFO] model update: t: 222, loss: 306822.09375
[INFO] Global_t: 222, Episode_t: 6, Action: 0, Reward: 4.06, Epsilon: 0.75
[INFO] model update: t: 223, loss: 183998.8125
[INFO] Global_t: 223, Episode_t: 7, Action: 10, Reward: 4.71, Epsilon: 0.75
[INFO] model update: t: 224, loss: 258987.40625
[INFO] Global_t: 224, Episode_t: 8, Action: 55, Reward: 1.77, Epsilon: 0.75
 11%|█         | 224/2000 [31:44<4:34:16,  9.27s/it]
[INFO] Global step: 224, Cumulative rewards: 24.89184, Runtime (s): 1904.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.1612467765808105
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.673857688903809
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.032532691955566
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.92386531829834
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  5.848084926605225
average cummulative reward vector is:  [0.14108553 0.13929282 0.13388634 0.12843598 0.14596694]
average cummulative reward is:  0.137733521195992
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 225, loss: 308152.75
[INFO] Global_t: 225, Episode_t: 1, Action: 38, Reward: 2.63, Epsilon: 0.75
[INFO] model update: t: 226, loss: 198877.625
[INFO] Global_t: 226, Episode_t: 2, Action: 152, Reward: 1.51, Epsilon: 0.74
[INFO] model update: t: 227, loss: 193790.046875
[INFO] Global_t: 227, Episode_t: 3, Action: 21, Reward: 3.65, Epsilon: 0.74
[INFO] model update: t: 228, loss: 226383.265625
[INFO] Global_t: 228, Episode_t: 4, Action: 99, Reward: 1.64, Epsilon: 0.74
[INFO] model update: t: 229, loss: 89080.8671875
[INFO] Global_t: 229, Episode_t: 5, Action: 164, Reward: 1.41, Epsilon: 0.74
[INFO] model update: t: 230, loss: 196669.625
[INFO] Global_t: 230, Episode_t: 6, Action: 4, Reward: 5.45, Epsilon: 0.74
[INFO] model update: t: 231, loss: 281763.59375
[INFO] Global_t: 231, Episode_t: 7, Action: 120, Reward: 1.21, Epsilon: 0.74
[INFO] model update: t: 232, loss: 356862.375
[INFO] Global_t: 232, Episode_t: 8, Action: 127, Reward: 1.35, Epsilon: 0.74
 12%|█▏        | 232/2000 [33:23<4:59:43, 10.17s/it]
[INFO] Global step: 232, Cumulative rewards: 18.84612, Runtime (s): 2003.19
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 233, loss: 272141.75
[INFO] Global_t: 233, Episode_t: 1, Action: 49, Reward: 1.89, Epsilon: 0.74
[INFO] model update: t: 234, loss: 236006.96875
[INFO] Global_t: 234, Episode_t: 2, Action: 5, Reward: 6.11, Epsilon: 0.74
[INFO] model update: t: 235, loss: 318713.5625
[INFO] Global_t: 235, Episode_t: 3, Action: 199, Reward: 1.23, Epsilon: 0.74
[INFO] model update: t: 236, loss: 194697.46875
[INFO] Global_t: 236, Episode_t: 4, Action: 182, Reward: 1.90, Epsilon: 0.73
[INFO] model update: t: 237, loss: 260471.375
[INFO] Global_t: 237, Episode_t: 5, Action: 107, Reward: 1.17, Epsilon: 0.73
[INFO] model update: t: 238, loss: 192587.59375
[INFO] Global_t: 238, Episode_t: 6, Action: 7, Reward: 3.82, Epsilon: 0.73
[INFO] model update: t: 239, loss: 207852.6875
[INFO] Global_t: 239, Episode_t: 7, Action: 6, Reward: 5.11, Epsilon: 0.73
[INFO] model update: t: 240, loss: 174893.75
[INFO] Global_t: 240, Episode_t: 8, Action: 4, Reward: 6.16, Epsilon: 0.73
 12%|█▏        | 240/2000 [34:30<4:43:05,  9.65s/it]
[INFO] Global step: 240, Cumulative rewards: 27.392039999999994, Runtime (s): 2070.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.268082857131958
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.569977283477783
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.740231990814209
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.075610876083374
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.216783761978149
average cummulative reward vector is:  [0.13937289 0.1298713  0.14512377 0.13866425 0.14096344]
average cummulative reward is:  0.1387991309443211
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 241, loss: 234952.453125
[INFO] Global_t: 241, Episode_t: 1, Action: 128, Reward: 1.65, Epsilon: 0.73
[INFO] model update: t: 242, loss: 205992.78125
[INFO] Global_t: 242, Episode_t: 2, Action: 18, Reward: 2.88, Epsilon: 0.73
[INFO] model update: t: 243, loss: 120520.921875
[INFO] Global_t: 243, Episode_t: 3, Action: 106, Reward: 1.75, Epsilon: 0.73
[INFO] model update: t: 244, loss: 232788.046875
[INFO] Global_t: 244, Episode_t: 4, Action: 151, Reward: 1.29, Epsilon: 0.73
[INFO] model update: t: 245, loss: 131322.53125
[INFO] Global_t: 245, Episode_t: 5, Action: 16, Reward: 5.21, Epsilon: 0.72
[INFO] model update: t: 246, loss: 235135.890625
[INFO] Global_t: 246, Episode_t: 6, Action: 61, Reward: 1.99, Epsilon: 0.72
[INFO] model update: t: 247, loss: 220671.96875
[INFO] Global_t: 247, Episode_t: 7, Action: 0, Reward: 5.32, Epsilon: 0.72
[INFO] model update: t: 248, loss: 187447.515625
 12%|█▏        | 248/2000 [36:15<5:11:41, 10.67s/it][INFO] Global_t: 248, Episode_t: 8, Action: 1, Reward: 6.25, Epsilon: 0.72

[INFO] Global step: 248, Cumulative rewards: 26.341559999999998, Runtime (s): 2175.17
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 249, loss: 195154.515625
[INFO] Global_t: 249, Episode_t: 1, Action: 20, Reward: 5.13, Epsilon: 0.72
[INFO] model update: t: 250, loss: 160629.46875
[INFO] Global_t: 250, Episode_t: 2, Action: 68, Reward: 2.04, Epsilon: 0.72
[INFO] model update: t: 251, loss: 217442.96875
[INFO] Global_t: 251, Episode_t: 3, Action: 171, Reward: 1.55, Epsilon: 0.72
[INFO] model update: t: 252, loss: 181202.78125
[INFO] Global_t: 252, Episode_t: 4, Action: 163, Reward: 1.34, Epsilon: 0.72
[INFO] model update: t: 253, loss: 194426.4375
[INFO] Global_t: 253, Episode_t: 5, Action: 61, Reward: 1.84, Epsilon: 0.72
[INFO] model update: t: 254, loss: 197386.6875
[INFO] Global_t: 254, Episode_t: 6, Action: 5, Reward: 5.42, Epsilon: 0.71
[INFO] model update: t: 255, loss: 204562.0
[INFO] Global_t: 255, Episode_t: 7, Action: 122, Reward: 2.18, Epsilon: 0.71
[INFO] model update: t: 256, loss: 138369.96875
[INFO] Global_t: 256, Episode_t: 8, Action: 44, Reward: 1.62, Epsilon: 0.71
 13%|█▎        | 256/2000 [36:49<4:14:24,  8.75s/it]
[INFO] Global step: 256, Cumulative rewards: 21.12408, Runtime (s): 2209.33
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.013880014419556
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.442056179046631
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.477476119995117
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  5.660777568817139
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.738258361816406
average cummulative reward vector is:  [0.13945053 0.13226481 0.13440546 0.1351785  0.15184086]
average cummulative reward is:  0.13862803409988592
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 257, loss: 169895.984375
[INFO] Global_t: 257, Episode_t: 1, Action: 10, Reward: 5.18, Epsilon: 0.71
[INFO] model update: t: 258, loss: 231687.046875
[INFO] Global_t: 258, Episode_t: 2, Action: 93, Reward: 1.76, Epsilon: 0.71
[INFO] model update: t: 259, loss: 272642.625
[INFO] Global_t: 259, Episode_t: 3, Action: 162, Reward: 1.25, Epsilon: 0.71
[INFO] model update: t: 260, loss: 212716.15625
[INFO] Global_t: 260, Episode_t: 4, Action: 3, Reward: 7.19, Epsilon: 0.71
[INFO] model update: t: 261, loss: 197314.75
[INFO] Global_t: 261, Episode_t: 5, Action: 194, Reward: 0.93, Epsilon: 0.71
[INFO] model update: t: 262, loss: 355106.125
[INFO] Global_t: 262, Episode_t: 6, Action: 137, Reward: 1.30, Epsilon: 0.71
[INFO] model update: t: 263, loss: 154074.015625
[INFO] Global_t: 263, Episode_t: 7, Action: 0, Reward: 5.07, Epsilon: 0.70
 13%|█▎        | 264/2000 [38:26<4:42:21,  9.76s/it][INFO] model update: t: 264, loss: 166567.078125
[INFO] Global_t: 264, Episode_t: 8, Action: 39, Reward: 1.85, Epsilon: 0.70

[INFO] Global step: 264, Cumulative rewards: 24.54048, Runtime (s): 2306.18
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 265, loss: 221261.25
[INFO] Global_t: 265, Episode_t: 1, Action: 93, Reward: 1.70, Epsilon: 0.70
[INFO] model update: t: 266, loss: 281644.125
[INFO] Global_t: 266, Episode_t: 2, Action: 1, Reward: 5.68, Epsilon: 0.70
[INFO] model update: t: 267, loss: 284209.375
[INFO] Global_t: 267, Episode_t: 3, Action: 154, Reward: 1.42, Epsilon: 0.70
[INFO] model update: t: 268, loss: 317777.1875
[INFO] Global_t: 268, Episode_t: 4, Action: 54, Reward: 2.43, Epsilon: 0.70
[INFO] model update: t: 269, loss: 308701.25
[INFO] Global_t: 269, Episode_t: 5, Action: 192, Reward: 1.20, Epsilon: 0.70
[INFO] model update: t: 270, loss: 146832.65625
[INFO] Global_t: 270, Episode_t: 6, Action: 27, Reward: 2.10, Epsilon: 0.70
[INFO] model update: t: 271, loss: 220976.34375
[INFO] Global_t: 271, Episode_t: 7, Action: 5, Reward: 5.08, Epsilon: 0.70
[INFO] model update: t: 272, loss: 204047.8125
[INFO] Global_t: 272, Episode_t: 8, Action: 70, Reward: 2.23, Epsilon: 0.69
 14%|█▎        | 272/2000 [38:49<3:42:10,  7.71s/it]
[INFO] Global step: 272, Cumulative rewards: 21.83304, Runtime (s): 2329.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.252561807632446
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.905879259109497
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.346645832061768
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.522418975830078
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  7.107500076293945
average cummulative reward vector is:  [0.14214132 0.12858542 0.13551311 0.12979369 0.15739973]
average cummulative reward is:  0.13868665399636387
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 273, loss: 188076.5
[INFO] Global_t: 273, Episode_t: 1, Action: 36, Reward: 2.25, Epsilon: 0.69
[INFO] model update: t: 274, loss: 280553.4375
[INFO] Global_t: 274, Episode_t: 2, Action: 35, Reward: 2.81, Epsilon: 0.69
[INFO] model update: t: 275, loss: 284624.625
[INFO] Global_t: 275, Episode_t: 3, Action: 61, Reward: 2.05, Epsilon: 0.69
[INFO] model update: t: 276, loss: 170551.46875
[INFO] Global_t: 276, Episode_t: 4, Action: 198, Reward: 1.27, Epsilon: 0.69
[INFO] model update: t: 277, loss: 162614.046875
[INFO] Global_t: 277, Episode_t: 5, Action: 6, Reward: 5.31, Epsilon: 0.69
[INFO] model update: t: 278, loss: 109973.4921875
[INFO] Global_t: 278, Episode_t: 6, Action: 8, Reward: 4.37, Epsilon: 0.69
[INFO] model update: t: 279, loss: 268393.59375
[INFO] Global_t: 279, Episode_t: 7, Action: 139, Reward: 1.39, Epsilon: 0.69
 14%|█▍        | 280/2000 [40:24<4:16:59,  8.96s/it][INFO] model update: t: 280, loss: 236885.6875
[INFO] Global_t: 280, Episode_t: 8, Action: 24, Reward: 4.63, Epsilon: 0.69

[INFO] Global step: 280, Cumulative rewards: 24.097559999999998, Runtime (s): 2424.80
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 281, loss: 181680.21875
[INFO] Global_t: 281, Episode_t: 1, Action: 53, Reward: 2.86, Epsilon: 0.69
[INFO] model update: t: 282, loss: 275759.125
[INFO] Global_t: 282, Episode_t: 2, Action: 2, Reward: 4.59, Epsilon: 0.68
[INFO] model update: t: 283, loss: 167733.109375
[INFO] Global_t: 283, Episode_t: 3, Action: 64, Reward: 2.01, Epsilon: 0.68
[INFO] model update: t: 284, loss: 211720.578125
[INFO] Global_t: 284, Episode_t: 4, Action: 180, Reward: 1.15, Epsilon: 0.68
[INFO] model update: t: 285, loss: 241312.828125
[INFO] Global_t: 285, Episode_t: 5, Action: 126, Reward: 1.68, Epsilon: 0.68
[INFO] model update: t: 286, loss: 120585.203125
[INFO] Global_t: 286, Episode_t: 6, Action: 1, Reward: 4.93, Epsilon: 0.68
[INFO] model update: t: 287, loss: 171371.9375
[INFO] Global_t: 287, Episode_t: 7, Action: 150, Reward: 1.31, Epsilon: 0.68
[INFO] model update: t: 288, loss: 177152.6875
[INFO] Global_t: 288, Episode_t: 8, Action: 103, Reward: 1.20, Epsilon: 0.68
 14%|█▍        | 288/2000 [41:26<4:05:35,  8.61s/it]
[INFO] Global step: 288, Cumulative rewards: 19.74756, Runtime (s): 2486.98
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  5.746081352233887
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.446980953216553
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.035236835479736
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.164518594741821
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  5.988986492156982
average cummulative reward vector is:  [0.14188    0.13022523 0.14188306 0.13378061 0.14038683]
average cummulative reward is:  0.13763114540487917
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 289, loss: 214082.484375
[INFO] Global_t: 289, Episode_t: 1, Action: 6, Reward: 5.34, Epsilon: 0.68
[INFO] model update: t: 290, loss: 179333.421875
[INFO] Global_t: 290, Episode_t: 2, Action: 119, Reward: 1.52, Epsilon: 0.68
[INFO] model update: t: 291, loss: 223538.765625
[INFO] Global_t: 291, Episode_t: 3, Action: 8, Reward: 4.69, Epsilon: 0.67
[INFO] model update: t: 292, loss: 122386.8984375
[INFO] Global_t: 292, Episode_t: 4, Action: 183, Reward: 1.47, Epsilon: 0.67
[INFO] model update: t: 293, loss: 206529.390625
[INFO] Global_t: 293, Episode_t: 5, Action: 80, Reward: 1.63, Epsilon: 0.67
[INFO] model update: t: 294, loss: 280100.8125
[INFO] Global_t: 294, Episode_t: 6, Action: 112, Reward: 1.86, Epsilon: 0.67
[INFO] model update: t: 295, loss: 121943.0
[INFO] Global_t: 295, Episode_t: 7, Action: 18, Reward: 4.20, Epsilon: 0.67
 15%|█▍        | 296/2000 [43:03<4:33:48,  9.64s/it][INFO] model update: t: 296, loss: 124535.7734375
[INFO] Global_t: 296, Episode_t: 8, Action: 132, Reward: 1.67, Epsilon: 0.67

[INFO] Global step: 296, Cumulative rewards: 22.3818, Runtime (s): 2583.40
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 297, loss: 181283.15625
[INFO] Global_t: 297, Episode_t: 1, Action: 27, Reward: 3.80, Epsilon: 0.67
[INFO] model update: t: 298, loss: 126165.4375
[INFO] Global_t: 298, Episode_t: 2, Action: 165, Reward: 1.91, Epsilon: 0.67
[INFO] model update: t: 299, loss: 149444.109375
[INFO] Global_t: 299, Episode_t: 3, Action: 84, Reward: 2.44, Epsilon: 0.67
[INFO] model update: t: 300, loss: 184321.765625
[INFO] Global_t: 300, Episode_t: 4, Action: 48, Reward: 2.48, Epsilon: 0.66
[INFO] model update: t: 301, loss: 130866.6640625
[INFO] Global_t: 301, Episode_t: 5, Action: 53, Reward: 2.81, Epsilon: 0.66
[INFO] model update: t: 302, loss: 117406.296875
[INFO] Global_t: 302, Episode_t: 6, Action: 0, Reward: 4.76, Epsilon: 0.66
[INFO] model update: t: 303, loss: 310943.53125
[INFO] Global_t: 303, Episode_t: 7, Action: 87, Reward: 2.58, Epsilon: 0.66
[INFO] model update: t: 304, loss: 216207.21875
[INFO] Global_t: 304, Episode_t: 8, Action: 51, Reward: 1.51, Epsilon: 0.66
 15%|█▌        | 304/2000 [44:14<4:26:26,  9.43s/it]
[INFO] Global step: 304, Cumulative rewards: 22.287119999999998, Runtime (s): 2654.79
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.629102945327759
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.15554666519165
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.198742866516113
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.94275426864624
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.37499213218689
average cummulative reward vector is:  [0.14035895 0.12455995 0.13003798 0.1335521  0.14785269]
average cummulative reward is:  0.13527233403799652
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 305, loss: 147631.6875
[INFO] Global_t: 305, Episode_t: 1, Action: 1, Reward: 5.77, Epsilon: 0.66
[INFO] model update: t: 306, loss: 176770.484375
[INFO] Global_t: 306, Episode_t: 2, Action: 154, Reward: 1.50, Epsilon: 0.66
[INFO] model update: t: 307, loss: 164186.1875
[INFO] Global_t: 307, Episode_t: 3, Action: 12, Reward: 5.30, Epsilon: 0.66
[INFO] model update: t: 308, loss: 138733.734375
[INFO] Global_t: 308, Episode_t: 4, Action: 0, Reward: 4.81, Epsilon: 0.66
[INFO] model update: t: 309, loss: 144206.5
[INFO] Global_t: 309, Episode_t: 5, Action: 177, Reward: 1.32, Epsilon: 0.65
[INFO] model update: t: 310, loss: 264034.21875
[INFO] Global_t: 310, Episode_t: 6, Action: 40, Reward: 2.04, Epsilon: 0.65
[INFO] model update: t: 311, loss: 123383.3203125
[INFO] Global_t: 311, Episode_t: 7, Action: 5, Reward: 5.48, Epsilon: 0.65
[INFO] model update: t: 312, loss: 180278.28125
[INFO] Global_t: 312, Episode_t: 8, Action: 211, Reward: 1.19, Epsilon: 0.65
 16%|█▌        | 312/2000 [45:55<4:52:09, 10.38s/it]
[INFO] Global step: 312, Cumulative rewards: 27.41556, Runtime (s): 2755.77
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 313, loss: 222342.40625
[INFO] Global_t: 313, Episode_t: 1, Action: 19, Reward: 2.43, Epsilon: 0.65
[INFO] model update: t: 314, loss: 130393.875
[INFO] Global_t: 314, Episode_t: 2, Action: 4, Reward: 5.45, Epsilon: 0.65
[INFO] model update: t: 315, loss: 217825.78125
[INFO] Global_t: 315, Episode_t: 3, Action: 26, Reward: 4.39, Epsilon: 0.65
[INFO] model update: t: 316, loss: 224486.09375
[INFO] Global_t: 316, Episode_t: 4, Action: 143, Reward: 1.06, Epsilon: 0.65
[INFO] model update: t: 317, loss: 128256.1484375
[INFO] Global_t: 317, Episode_t: 5, Action: 34, Reward: 2.26, Epsilon: 0.65
[INFO] model update: t: 318, loss: 249692.71875
[INFO] Global_t: 318, Episode_t: 6, Action: 84, Reward: 1.77, Epsilon: 0.64
[INFO] model update: t: 319, loss: 362379.5625
[INFO] Global_t: 319, Episode_t: 7, Action: 76, Reward: 1.97, Epsilon: 0.64
[INFO] model update: t: 320, loss: 132776.8125
[INFO] Global_t: 320, Episode_t: 8, Action: 16, Reward: 1.79, Epsilon: 0.64
 16%|█▌        | 320/2000 [47:05<4:36:46,  9.88s/it]
[INFO] Global step: 320, Cumulative rewards: 21.121799999999997, Runtime (s): 2825.52
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.260348796844482
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.54142165184021
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.469080448150635
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.280415058135986
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.940174341201782
average cummulative reward vector is:  [0.14670579 0.12850185 0.14923443 0.13740187 0.14583226]
average cummulative reward is:  0.1415352389556878
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 321, loss: 243418.84375
[INFO] Global_t: 321, Episode_t: 1, Action: 7, Reward: 4.58, Epsilon: 0.64
[INFO] model update: t: 322, loss: 131274.625
[INFO] Global_t: 322, Episode_t: 2, Action: 116, Reward: 1.78, Epsilon: 0.64
[INFO] model update: t: 323, loss: 112427.5078125
[INFO] Global_t: 323, Episode_t: 3, Action: 96, Reward: 1.15, Epsilon: 0.64
[INFO] model update: t: 324, loss: 198724.09375
[INFO] Global_t: 324, Episode_t: 4, Action: 0, Reward: 5.24, Epsilon: 0.64
[INFO] model update: t: 325, loss: 196709.75
[INFO] Global_t: 325, Episode_t: 5, Action: 26, Reward: 1.63, Epsilon: 0.64
[INFO] model update: t: 326, loss: 293612.9375
[INFO] Global_t: 326, Episode_t: 6, Action: 62, Reward: 1.40, Epsilon: 0.64
[INFO] model update: t: 327, loss: 242167.0625
[INFO] Global_t: 327, Episode_t: 7, Action: 152, Reward: 1.40, Epsilon: 0.64
[INFO] model update: t: 328, loss: 234794.28125
[INFO] Global_t: 328, Episode_t: 8, Action: 141, Reward: 1.20, Epsilon: 0.63

[INFO] Global step: 328, Cumulative rewards: 18.40164, Runtime (s): 2924.53
------------------------------------------------------------
 
 16%|█▋        | 328/2000 [48:44<4:56:17, 10.63s/it]graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 329, loss: 176076.96875
[INFO] Global_t: 329, Episode_t: 1, Action: 76, Reward: 1.67, Epsilon: 0.63
[INFO] model update: t: 330, loss: 247433.125
[INFO] Global_t: 330, Episode_t: 2, Action: 173, Reward: 1.14, Epsilon: 0.63
[INFO] model update: t: 331, loss: 183627.1875
[INFO] Global_t: 331, Episode_t: 3, Action: 50, Reward: 1.80, Epsilon: 0.63
[INFO] model update: t: 332, loss: 156225.84375
[INFO] Global_t: 332, Episode_t: 4, Action: 0, Reward: 4.76, Epsilon: 0.63
[INFO] model update: t: 333, loss: 290041.8125
[INFO] Global_t: 333, Episode_t: 5, Action: 6, Reward: 4.23, Epsilon: 0.63
[INFO] model update: t: 334, loss: 238787.109375
[INFO] Global_t: 334, Episode_t: 6, Action: 110, Reward: 1.51, Epsilon: 0.63
[INFO] model update: t: 335, loss: 243066.84375
[INFO] Global_t: 335, Episode_t: 7, Action: 9, Reward: 4.33, Epsilon: 0.63
[INFO] model update: t: 336, loss: 171808.015625
[INFO] Global_t: 336, Episode_t: 8, Action: 5, Reward: 5.25, Epsilon: 0.63
 17%|█▋        | 336/2000 [49:50<4:34:37,  9.90s/it]
[INFO] Global step: 336, Cumulative rewards: 24.703079999999996, Runtime (s): 2990.12
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.373067140579224
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.126687526702881
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.262807130813599
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.874109745025635
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.649720907211304
average cummulative reward vector is:  [0.13066763 0.13494213 0.13716776 0.13772266 0.15058602]
average cummulative reward is:  0.13821724116563935
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 337, loss: 226772.34375
[INFO] Global_t: 337, Episode_t: 1, Action: 24, Reward: 2.20, Epsilon: 0.62
[INFO] model update: t: 338, loss: 92060.203125
[INFO] Global_t: 338, Episode_t: 2, Action: 14, Reward: 6.08, Epsilon: 0.62
[INFO] model update: t: 339, loss: 137185.28125
[INFO] Global_t: 339, Episode_t: 3, Action: 1, Reward: 5.34, Epsilon: 0.62
[INFO] model update: t: 340, loss: 162358.265625
[INFO] Global_t: 340, Episode_t: 4, Action: 6, Reward: 6.42, Epsilon: 0.62
[INFO] model update: t: 341, loss: 214733.625
[INFO] Global_t: 341, Episode_t: 5, Action: 47, Reward: 3.17, Epsilon: 0.62
[INFO] model update: t: 342, loss: 206346.828125
[INFO] Global_t: 342, Episode_t: 6, Action: 13, Reward: 4.28, Epsilon: 0.62
[INFO] model update: t: 343, loss: 235426.765625
[INFO] Global_t: 343, Episode_t: 7, Action: 20, Reward: 4.25, Epsilon: 0.62
[INFO] model update: t: 344, loss: 124292.9375
[INFO] Global_t: 344, Episode_t: 8, Action: 85, Reward: 2.05, Epsilon: 0.62
 17%|█▋        | 344/2000 [51:31<4:56:32, 10.74s/it]
[INFO] Global step: 344, Cumulative rewards: 33.78948, Runtime (s): 3091.80
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 345, loss: 152254.03125
[INFO] Global_t: 345, Episode_t: 1, Action: 10, Reward: 4.81, Epsilon: 0.62
[INFO] model update: t: 346, loss: 191433.1875
[INFO] Global_t: 346, Episode_t: 2, Action: 2, Reward: 5.24, Epsilon: 0.61
[INFO] model update: t: 347, loss: 162179.3125
[INFO] Global_t: 347, Episode_t: 3, Action: 103, Reward: 1.41, Epsilon: 0.61
[INFO] model update: t: 348, loss: 180208.90625
[INFO] Global_t: 348, Episode_t: 4, Action: 104, Reward: 1.35, Epsilon: 0.61
[INFO] model update: t: 349, loss: 171951.84375
[INFO] Global_t: 349, Episode_t: 5, Action: 5, Reward: 4.20, Epsilon: 0.61
[INFO] model update: t: 350, loss: 185355.59375
[INFO] Global_t: 350, Episode_t: 6, Action: 37, Reward: 1.56, Epsilon: 0.61
[INFO] model update: t: 351, loss: 188433.9375
[INFO] Global_t: 351, Episode_t: 7, Action: 179, Reward: 1.32, Epsilon: 0.61
[INFO] model update: t: 352, loss: 193126.046875
[INFO] Global_t: 352, Episode_t: 8, Action: 106, Reward: 1.78, Epsilon: 0.61
 18%|█▊        | 352/2000 [52:35<4:32:16,  9.91s/it]
[INFO] Global step: 352, Cumulative rewards: 21.6768, Runtime (s): 3155.58
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.119425535202026
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.7064714431762695
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.774681329727173
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  5.680859088897705
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.480448246002197
average cummulative reward vector is:  [0.13600079 0.11789977 0.14272432 0.11901939 0.15431586]
average cummulative reward is:  0.13399202553410233
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 353, loss: 268962.71875
[INFO] Global_t: 353, Episode_t: 1, Action: 20, Reward: 2.67, Epsilon: 0.61
[INFO] model update: t: 354, loss: 214104.09375
[INFO] Global_t: 354, Episode_t: 2, Action: 156, Reward: 1.88, Epsilon: 0.61
[INFO] model update: t: 355, loss: 189301.28125
[INFO] Global_t: 355, Episode_t: 3, Action: 0, Reward: 5.07, Epsilon: 0.60
[INFO] model update: t: 356, loss: 162193.53125
[INFO] Global_t: 356, Episode_t: 4, Action: 131, Reward: 1.59, Epsilon: 0.60
[INFO] model update: t: 357, loss: 143008.625
[INFO] Global_t: 357, Episode_t: 5, Action: 1, Reward: 4.89, Epsilon: 0.60
[INFO] model update: t: 358, loss: 171814.484375
[INFO] Global_t: 358, Episode_t: 6, Action: 148, Reward: 1.25, Epsilon: 0.60
[INFO] model update: t: 359, loss: 273470.53125
[INFO] Global_t: 359, Episode_t: 7, Action: 3, Reward: 5.75, Epsilon: 0.60
[INFO] model update: t: 360, loss: 125009.8125
[INFO] Global_t: 360, Episode_t: 8, Action: 29, Reward: 2.74, Epsilon: 0.60

[INFO] Global step: 360, Cumulative rewards: 25.84908, Runtime (s): 3256.20
------------------------------------------------------------
 
 18%|█▊        | 360/2000 [54:16<4:52:47, 10.71s/it]graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 361, loss: 219132.5
[INFO] Global_t: 361, Episode_t: 1, Action: 0, Reward: 5.42, Epsilon: 0.60
[INFO] model update: t: 362, loss: 164556.53125
[INFO] Global_t: 362, Episode_t: 2, Action: 6, Reward: 4.74, Epsilon: 0.60
[INFO] model update: t: 363, loss: 192006.296875
[INFO] Global_t: 363, Episode_t: 3, Action: 149, Reward: 1.30, Epsilon: 0.60
[INFO] model update: t: 364, loss: 94170.125
[INFO] Global_t: 364, Episode_t: 4, Action: 87, Reward: 1.29, Epsilon: 0.59
[INFO] model update: t: 365, loss: 224976.140625
[INFO] Global_t: 365, Episode_t: 5, Action: 67, Reward: 1.61, Epsilon: 0.59
[INFO] model update: t: 366, loss: 178030.09375
[INFO] Global_t: 366, Episode_t: 6, Action: 180, Reward: 1.62, Epsilon: 0.59
[INFO] model update: t: 367, loss: 195356.46875
[INFO] Global_t: 367, Episode_t: 7, Action: 123, Reward: 1.65, Epsilon: 0.59
[INFO] model update: t: 368, loss: 193266.625
[INFO] Global_t: 368, Episode_t: 8, Action: 1, Reward: 4.24, Epsilon: 0.59

[INFO] Global step: 368, Cumulative rewards: 21.87216, Runtime (s): 3316.70
------------------------------------------------------------
 
 18%|█▊        | 368/2000 [55:16<4:25:40,  9.77s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  5.775879144668579
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.264520883560181
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.070769786834717
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.438514947891235
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.571053981781006
average cummulative reward vector is:  [0.13955053 0.12883032 0.13802568 0.1371014  0.14716586]
average cummulative reward is:  0.1381347591068371
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 369, loss: 160924.203125
[INFO] Global_t: 369, Episode_t: 1, Action: 184, Reward: 1.62, Epsilon: 0.59
[INFO] model update: t: 370, loss: 119721.6640625
[INFO] Global_t: 370, Episode_t: 2, Action: 10, Reward: 5.41, Epsilon: 0.59
[INFO] model update: t: 371, loss: 161284.734375
[INFO] Global_t: 371, Episode_t: 3, Action: 156, Reward: 1.77, Epsilon: 0.59
[INFO] model update: t: 372, loss: 167663.5625
[INFO] Global_t: 372, Episode_t: 4, Action: 2, Reward: 5.77, Epsilon: 0.59
[INFO] model update: t: 373, loss: 147713.96875
[INFO] Global_t: 373, Episode_t: 5, Action: 43, Reward: 1.62, Epsilon: 0.58
[INFO] model update: t: 374, loss: 241837.859375
[INFO] Global_t: 374, Episode_t: 6, Action: 0, Reward: 5.31, Epsilon: 0.58
[INFO] model update: t: 375, loss: 92822.5234375
[INFO] Global_t: 375, Episode_t: 7, Action: 48, Reward: 2.16, Epsilon: 0.58
[INFO] model update: t: 376, loss: 245463.34375
[INFO] Global_t: 376, Episode_t: 8, Action: 16, Reward: 3.76, Epsilon: 0.58
 19%|█▉        | 376/2000 [56:59<4:49:49, 10.71s/it]
[INFO] Global step: 376, Cumulative rewards: 27.414359999999995, Runtime (s): 3419.93
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 377, loss: 218391.65625
[INFO] Global_t: 377, Episode_t: 1, Action: 154, Reward: 1.29, Epsilon: 0.58
[INFO] model update: t: 378, loss: 194620.0
[INFO] Global_t: 378, Episode_t: 2, Action: 12, Reward: 4.75, Epsilon: 0.58
[INFO] model update: t: 379, loss: 167842.484375
[INFO] Global_t: 379, Episode_t: 3, Action: 30, Reward: 2.00, Epsilon: 0.58
[INFO] model update: t: 380, loss: 203636.90625
[INFO] Global_t: 380, Episode_t: 4, Action: 140, Reward: 1.57, Epsilon: 0.58
[INFO] model update: t: 381, loss: 160501.75
[INFO] Global_t: 381, Episode_t: 5, Action: 88, Reward: 2.11, Epsilon: 0.58
[INFO] model update: t: 382, loss: 106862.46875
[INFO] Global_t: 382, Episode_t: 6, Action: 13, Reward: 3.79, Epsilon: 0.58
[INFO] model update: t: 383, loss: 152280.578125
[INFO] Global_t: 383, Episode_t: 7, Action: 6, Reward: 4.95, Epsilon: 0.57
[INFO] model update: t: 384, loss: 195885.625
[INFO] Global_t: 384, Episode_t: 8, Action: 7, Reward: 3.87, Epsilon: 0.57
 19%|█▉        | 384/2000 [58:08<4:30:57, 10.06s/it]
[INFO] Global step: 384, Cumulative rewards: 24.329639999999998, Runtime (s): 3488.32
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.252956867218018
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.367224931716919
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.19893479347229
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.683792591094971
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  5.89345121383667
average cummulative reward vector is:  [0.14329474 0.12820741 0.14268279 0.13613224 0.13644355]
average cummulative reward is:  0.13735214450250194
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 385, loss: 298413.4375
[INFO] Global_t: 385, Episode_t: 1, Action: 109, Reward: 1.35, Epsilon: 0.57
[INFO] model update: t: 386, loss: 112416.3046875
[INFO] Global_t: 386, Episode_t: 2, Action: 3, Reward: 5.20, Epsilon: 0.57
[INFO] model update: t: 387, loss: 123091.171875
[INFO] Global_t: 387, Episode_t: 3, Action: 56, Reward: 1.22, Epsilon: 0.57
[INFO] model update: t: 388, loss: 229207.25
[INFO] Global_t: 388, Episode_t: 4, Action: 4, Reward: 4.12, Epsilon: 0.57
[INFO] model update: t: 389, loss: 121644.171875
[INFO] Global_t: 389, Episode_t: 5, Action: 128, Reward: 1.13, Epsilon: 0.57
[INFO] model update: t: 390, loss: 215331.546875
[INFO] Global_t: 390, Episode_t: 6, Action: 88, Reward: 1.58, Epsilon: 0.57
[INFO] model update: t: 391, loss: 198506.6875
[INFO] Global_t: 391, Episode_t: 7, Action: 1, Reward: 4.59, Epsilon: 0.57
 20%|█▉        | 392/2000 [59:49<4:50:41, 10.85s/it][INFO] model update: t: 392, loss: 205957.75
[INFO] Global_t: 392, Episode_t: 8, Action: 122, Reward: 1.24, Epsilon: 0.56

[INFO] Global step: 392, Cumulative rewards: 20.431319999999996, Runtime (s): 3589.77
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 393, loss: 81945.9765625
[INFO] Global_t: 393, Episode_t: 1, Action: 78, Reward: 2.37, Epsilon: 0.56
[INFO] model update: t: 394, loss: 69272.546875
[INFO] Global_t: 394, Episode_t: 2, Action: 170, Reward: 1.79, Epsilon: 0.56
[INFO] model update: t: 395, loss: 202372.046875
[INFO] Global_t: 395, Episode_t: 3, Action: 3, Reward: 5.97, Epsilon: 0.56
[INFO] model update: t: 396, loss: 104993.4453125
[INFO] Global_t: 396, Episode_t: 4, Action: 187, Reward: 1.88, Epsilon: 0.56
[INFO] model update: t: 397, loss: 167150.921875
[INFO] Global_t: 397, Episode_t: 5, Action: 1, Reward: 4.73, Epsilon: 0.56
[INFO] model update: t: 398, loss: 146648.171875
[INFO] Global_t: 398, Episode_t: 6, Action: 12, Reward: 4.74, Epsilon: 0.56
[INFO] model update: t: 399, loss: 115512.953125
[INFO] Global_t: 399, Episode_t: 7, Action: 7, Reward: 4.24, Epsilon: 0.56
[INFO] model update: t: 400, loss: 124463.3046875
[INFO] Global_t: 400, Episode_t: 8, Action: 30, Reward: 3.39, Epsilon: 0.56
 20%|██        | 400/2000 [1:00:53<4:26:19,  9.99s/it]
[INFO] Global step: 400, Cumulative rewards: 29.113199999999996, Runtime (s): 3653.62
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.615544319152832
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.143176078796387
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.598476886749268
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.222985029220581
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.592657804489136
average cummulative reward vector is:  [0.13991368 0.12855694 0.13350628 0.12716636 0.14348091]
average cummulative reward is:  0.13452483638533155
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 401, loss: 311135.65625
[INFO] Global_t: 401, Episode_t: 1, Action: 131, Reward: 1.33, Epsilon: 0.55
[INFO] model update: t: 402, loss: 240499.3125
[INFO] Global_t: 402, Episode_t: 2, Action: 112, Reward: 1.93, Epsilon: 0.55
[INFO] model update: t: 403, loss: 170127.5625
[INFO] Global_t: 403, Episode_t: 3, Action: 63, Reward: 1.39, Epsilon: 0.55
[INFO] model update: t: 404, loss: 199382.328125
[INFO] Global_t: 404, Episode_t: 4, Action: 44, Reward: 2.22, Epsilon: 0.55
[INFO] model update: t: 405, loss: 183578.65625
[INFO] Global_t: 405, Episode_t: 5, Action: 5, Reward: 5.08, Epsilon: 0.55
[INFO] model update: t: 406, loss: 158703.03125
[INFO] Global_t: 406, Episode_t: 6, Action: 4, Reward: 5.22, Epsilon: 0.55
[INFO] model update: t: 407, loss: 143928.578125
[INFO] Global_t: 407, Episode_t: 7, Action: 148, Reward: 1.71, Epsilon: 0.55
[INFO] model update: t: 408, loss: 142389.890625
[INFO] Global_t: 408, Episode_t: 8, Action: 1, Reward: 4.21, Epsilon: 0.55
 20%|██        | 408/2000 [1:02:35<4:46:58, 10.82s/it]
[INFO] Global step: 408, Cumulative rewards: 23.08824, Runtime (s): 3755.61
------------------------------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 409, loss: 163567.9375
[INFO] Global_t: 409, Episode_t: 1, Action: 4, Reward: 5.62, Epsilon: 0.55
[INFO] model update: t: 410, loss: 103395.1796875
[INFO] Global_t: 410, Episode_t: 2, Action: 5, Reward: 6.21, Epsilon: 0.54
[INFO] model update: t: 411, loss: 134558.328125
[INFO] Global_t: 411, Episode_t: 3, Action: 63, Reward: 2.38, Epsilon: 0.54
[INFO] model update: t: 412, loss: 307003.8125
[INFO] Global_t: 412, Episode_t: 4, Action: 9, Reward: 4.55, Epsilon: 0.54
[INFO] model update: t: 413, loss: 203691.6875
[INFO] Global_t: 413, Episode_t: 5, Action: 8, Reward: 5.28, Epsilon: 0.54
[INFO] model update: t: 414, loss: 191713.375
[INFO] Global_t: 414, Episode_t: 6, Action: 16, Reward: 5.22, Epsilon: 0.54
[INFO] model update: t: 415, loss: 242346.9375
[INFO] Global_t: 415, Episode_t: 7, Action: 108, Reward: 1.69, Epsilon: 0.54
[INFO] model update: t: 416, loss: 342596.5625
[INFO] Global_t: 416, Episode_t: 8, Action: 148, Reward: 1.40, Epsilon: 0.54
 21%|██        | 416/2000 [1:03:46<4:30:18, 10.24s/it]
[INFO] Global step: 416, Cumulative rewards: 32.35403999999999, Runtime (s): 3826.76
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.806191682815552
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.600022792816162
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.802732229232788
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.888474225997925
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  5.732280015945435
average cummulative reward vector is:  [0.13839316 0.13573843 0.13152923 0.13564159 0.13440699]
average cummulative reward is:  0.13514187936513977
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 417, loss: 446574.59375
[INFO] Global_t: 417, Episode_t: 1, Action: 34, Reward: 2.69, Epsilon: 0.54
[INFO] model update: t: 418, loss: 314260.65625
[INFO] Global_t: 418, Episode_t: 2, Action: 196, Reward: 1.45, Epsilon: 0.54
[INFO] model update: t: 419, loss: 390336.5
[INFO] Global_t: 419, Episode_t: 3, Action: 9, Reward: 5.72, Epsilon: 0.53
[INFO] model update: t: 420, loss: 250548.5625
[INFO] Global_t: 420, Episode_t: 4, Action: 4, Reward: 5.45, Epsilon: 0.53
[INFO] model update: t: 421, loss: 308129.0625
[INFO] Global_t: 421, Episode_t: 5, Action: 90, Reward: 2.05, Epsilon: 0.53
[INFO] model update: t: 422, loss: 232297.59375
[INFO] Global_t: 422, Episode_t: 6, Action: 0, Reward: 4.88, Epsilon: 0.53
[INFO] model update: t: 423, loss: 202035.96875
[INFO] Global_t: 423, Episode_t: 7, Action: 13, Reward: 4.46, Epsilon: 0.53
[INFO] model update: t: 424, loss: 198233.46875
[INFO] Global_t: 424, Episode_t: 8, Action: 6, Reward: 4.85, Epsilon: 0.53
 21%|██        | 424/2000 [1:05:26<4:46:29, 10.91s/it]
[INFO] Global step: 424, Cumulative rewards: 31.5438, Runtime (s): 3926.49
------------------------------------------------------------
 
graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 425, loss: 138655.046875
[INFO] Global_t: 425, Episode_t: 1, Action: 11, Reward: 5.29, Epsilon: 0.53
[INFO] model update: t: 426, loss: 195373.53125
[INFO] Global_t: 426, Episode_t: 2, Action: 22, Reward: 5.34, Epsilon: 0.53
[INFO] model update: t: 427, loss: 314166.0
[INFO] Global_t: 427, Episode_t: 3, Action: 0, Reward: 4.89, Epsilon: 0.53
[INFO] model update: t: 428, loss: 237398.25
[INFO] Global_t: 428, Episode_t: 4, Action: 24, Reward: 2.96, Epsilon: 0.53
[INFO] model update: t: 429, loss: 282349.125
[INFO] Global_t: 429, Episode_t: 5, Action: 18, Reward: 4.53, Epsilon: 0.52
[INFO] model update: t: 430, loss: 348989.71875
[INFO] Global_t: 430, Episode_t: 6, Action: 198, Reward: 1.54, Epsilon: 0.52
[INFO] model update: t: 431, loss: 217906.265625
[INFO] Global_t: 431, Episode_t: 7, Action: 10, Reward: 5.79, Epsilon: 0.52
[INFO] model update: t: 432, loss: 197723.9375
[INFO] Global_t: 432, Episode_t: 8, Action: 7, Reward: 3.69, Epsilon: 0.52

[INFO] Global step: 432, Cumulative rewards: 34.019639999999995, Runtime (s): 3997.00
------------------------------------------------------------
 
 22%|██▏       | 432/2000 [1:06:36<4:28:37, 10.28s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.6678996086120605
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  8.28103494644165
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.140882253646851
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.782843589782715
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.777981519699097
average cummulative reward vector is:  [0.14466553 0.14079259 0.14193415 0.13594953 0.14912177]
average cummulative reward is:  0.1424927157635351
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 433, loss: 148894.71875
[INFO] Global_t: 433, Episode_t: 1, Action: 92, Reward: 1.42, Epsilon: 0.52
[INFO] model update: t: 434, loss: 164751.578125
[INFO] Global_t: 434, Episode_t: 2, Action: 2, Reward: 5.35, Epsilon: 0.52
[INFO] model update: t: 435, loss: 164193.8125
[INFO] Global_t: 435, Episode_t: 3, Action: 33, Reward: 2.42, Epsilon: 0.52
[INFO] model update: t: 436, loss: 302488.375
[INFO] Global_t: 436, Episode_t: 4, Action: 9, Reward: 4.42, Epsilon: 0.52
[INFO] model update: t: 437, loss: 271241.65625
[INFO] Global_t: 437, Episode_t: 5, Action: 8, Reward: 5.46, Epsilon: 0.52
[INFO] model update: t: 438, loss: 285675.34375
[INFO] Global_t: 438, Episode_t: 6, Action: 4, Reward: 5.54, Epsilon: 0.51
[INFO] model update: t: 439, loss: 347505.71875
[INFO] Global_t: 439, Episode_t: 7, Action: 0, Reward: 5.59, Epsilon: 0.51
 22%|██▏       | 440/2000 [1:08:19<4:47:09, 11.04s/it][INFO] model update: t: 440, loss: 295918.375
[INFO] Global_t: 440, Episode_t: 8, Action: 182, Reward: 1.38, Epsilon: 0.51

[INFO] Global step: 440, Cumulative rewards: 31.59024, Runtime (s): 4099.64
------------------------------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 441, loss: 179221.5625
[INFO] Global_t: 441, Episode_t: 1, Action: 4, Reward: 5.96, Epsilon: 0.51
[INFO] model update: t: 442, loss: 133083.28125
[INFO] Global_t: 442, Episode_t: 2, Action: 1, Reward: 5.52, Epsilon: 0.51
[INFO] model update: t: 443, loss: 94992.9375
[INFO] Global_t: 443, Episode_t: 3, Action: 69, Reward: 1.91, Epsilon: 0.51
[INFO] model update: t: 444, loss: 145484.265625
[INFO] Global_t: 444, Episode_t: 4, Action: 2, Reward: 5.38, Epsilon: 0.51
[INFO] model update: t: 445, loss: 234388.25
[INFO] Global_t: 445, Episode_t: 5, Action: 18, Reward: 1.75, Epsilon: 0.51
[INFO] model update: t: 446, loss: 382837.375
[INFO] Global_t: 446, Episode_t: 6, Action: 8, Reward: 5.40, Epsilon: 0.51
[INFO] model update: t: 447, loss: 253122.140625
[INFO] Global_t: 447, Episode_t: 7, Action: 87, Reward: 2.02, Epsilon: 0.50
[INFO] model update: t: 448, loss: 174206.125
[INFO] Global_t: 448, Episode_t: 8, Action: 9, Reward: 4.01, Epsilon: 0.50
 22%|██▏       | 448/2000 [1:09:27<4:26:07, 10.29s/it]
[INFO] Global step: 448, Cumulative rewards: 31.94784, Runtime (s): 4167.83
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  5.99593186378479
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  5.924969434738159
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.743807077407837
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.219979286193848
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.3935816287994385
average cummulative reward vector is:  [0.13696842 0.12806458 0.13917869 0.12538411 0.14154892]
average cummulative reward is:  0.1342289459582541
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 449, loss: 157405.140625
[INFO] Global_t: 449, Episode_t: 1, Action: 4, Reward: 5.58, Epsilon: 0.50
[INFO] model update: t: 450, loss: 132129.609375
[INFO] Global_t: 450, Episode_t: 2, Action: 110, Reward: 1.40, Epsilon: 0.50
[INFO] model update: t: 451, loss: 87479.96875
[INFO] Global_t: 451, Episode_t: 3, Action: 191, Reward: 1.31, Epsilon: 0.50
[INFO] model update: t: 452, loss: 270480.8125
[INFO] Global_t: 452, Episode_t: 4, Action: 113, Reward: 1.62, Epsilon: 0.50
[INFO] model update: t: 453, loss: 201796.15625
[INFO] Global_t: 453, Episode_t: 5, Action: 2, Reward: 5.07, Epsilon: 0.50
[INFO] model update: t: 454, loss: 85801.6875
[INFO] Global_t: 454, Episode_t: 6, Action: 26, Reward: 2.21, Epsilon: 0.50
[INFO] model update: t: 455, loss: 81754.375
[INFO] Global_t: 455, Episode_t: 7, Action: 77, Reward: 1.71, Epsilon: 0.50
[INFO] model update: t: 456, loss: 311928.875
[INFO] Global_t: 456, Episode_t: 8, Action: 10, Reward: 4.08, Epsilon: 0.49
 23%|██▎       | 456/2000 [1:11:02<4:36:59, 10.76s/it]
[INFO] Global step: 456, Cumulative rewards: 22.98876, Runtime (s): 4262.83
------------------------------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 457, loss: 386661.6875
[INFO] Global_t: 457, Episode_t: 1, Action: 20, Reward: 5.07, Epsilon: 0.49
[INFO] model update: t: 458, loss: 322332.875
[INFO] Global_t: 458, Episode_t: 2, Action: 13, Reward: 3.16, Epsilon: 0.49
[INFO] model update: t: 459, loss: 398607.625
[INFO] Global_t: 459, Episode_t: 3, Action: 124, Reward: 1.95, Epsilon: 0.49
[INFO] model update: t: 460, loss: 319492.3125
[INFO] Global_t: 460, Episode_t: 4, Action: 1, Reward: 4.87, Epsilon: 0.49
[INFO] model update: t: 461, loss: 156474.984375
[INFO] Global_t: 461, Episode_t: 5, Action: 180, Reward: 1.41, Epsilon: 0.49
[INFO] model update: t: 462, loss: 196293.53125
[INFO] Global_t: 462, Episode_t: 6, Action: 92, Reward: 1.44, Epsilon: 0.49
[INFO] model update: t: 463, loss: 150572.078125
[INFO] Global_t: 463, Episode_t: 7, Action: 53, Reward: 1.10, Epsilon: 0.49
[INFO] model update: t: 464, loss: 312474.9375
[INFO] Global_t: 464, Episode_t: 8, Action: 140, Reward: 1.50, Epsilon: 0.49
 23%|██▎       | 464/2000 [1:12:04<4:12:15,  9.85s/it]
[INFO] Global step: 464, Cumulative rewards: 20.49132, Runtime (s): 4324.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.0406410694122314
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.754229784011841
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.550061464309692
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.232673645019531
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.3000547885894775
average cummulative reward vector is:  [0.14119132 0.14529699 0.14982295 0.13221098 0.14001613]
average cummulative reward is:  0.14170767353811117
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 465, loss: 190800.984375
[INFO] Global_t: 465, Episode_t: 1, Action: 70, Reward: 1.70, Epsilon: 0.48
[INFO] model update: t: 466, loss: 164967.34375
[INFO] Global_t: 466, Episode_t: 2, Action: 2, Reward: 5.54, Epsilon: 0.48
[INFO] model update: t: 467, loss: 214633.25
[INFO] Global_t: 467, Episode_t: 3, Action: 5, Reward: 4.88, Epsilon: 0.48
[INFO] model update: t: 468, loss: 130200.5390625
[INFO] Global_t: 468, Episode_t: 4, Action: 49, Reward: 3.66, Epsilon: 0.48
[INFO] model update: t: 469, loss: 189878.4375
[INFO] Global_t: 469, Episode_t: 5, Action: 134, Reward: 1.71, Epsilon: 0.48
[INFO] model update: t: 470, loss: 206239.375
[INFO] Global_t: 470, Episode_t: 6, Action: 0, Reward: 4.19, Epsilon: 0.48
[INFO] model update: t: 471, loss: 166226.0625
[INFO] Global_t: 471, Episode_t: 7, Action: 12, Reward: 4.22, Epsilon: 0.48
[INFO] model update: t: 472, loss: 103895.40625
[INFO] Global_t: 472, Episode_t: 8, Action: 135, Reward: 1.48, Epsilon: 0.48
 24%|██▎       | 472/2000 [1:13:47<4:34:14, 10.77s/it]
[INFO] Global step: 472, Cumulative rewards: 27.37728, Runtime (s): 4427.90
------------------------------------------------------------
 
graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 473, loss: 144283.75
[INFO] Global_t: 473, Episode_t: 1, Action: 1, Reward: 5.36, Epsilon: 0.48
[INFO] model update: t: 474, loss: 238599.28125
[INFO] Global_t: 474, Episode_t: 2, Action: 2, Reward: 5.05, Epsilon: 0.47
[INFO] model update: t: 475, loss: 110901.546875
[INFO] Global_t: 475, Episode_t: 3, Action: 38, Reward: 4.04, Epsilon: 0.47
[INFO] model update: t: 476, loss: 146237.96875
[INFO] Global_t: 476, Episode_t: 4, Action: 8, Reward: 5.86, Epsilon: 0.47
[INFO] model update: t: 477, loss: 229120.25
[INFO] Global_t: 477, Episode_t: 5, Action: 6, Reward: 3.49, Epsilon: 0.47
[INFO] model update: t: 478, loss: 214456.296875
[INFO] Global_t: 478, Episode_t: 6, Action: 45, Reward: 3.20, Epsilon: 0.47
[INFO] model update: t: 479, loss: 173764.875
[INFO] Global_t: 479, Episode_t: 7, Action: 180, Reward: 1.63, Epsilon: 0.47
[INFO] model update: t: 480, loss: 269429.75
[INFO] Global_t: 480, Episode_t: 8, Action: 88, Reward: 1.41, Epsilon: 0.47
 24%|██▍       | 480/2000 [1:14:53<4:13:38, 10.01s/it]
[INFO] Global step: 480, Cumulative rewards: 30.0432, Runtime (s): 4493.87
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.166032552719116
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.0241053104400635
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.813632488250732
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.1753668785095215
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.2447967529296875
average cummulative reward vector is:  [0.13856316 0.13577755 0.14106093 0.13185888 0.15066532]
average cummulative reward is:  0.13958516684761996
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 481, loss: 319084.375
[INFO] Global_t: 481, Episode_t: 1, Action: 9, Reward: 4.95, Epsilon: 0.47
[INFO] model update: t: 482, loss: 333789.1875
[INFO] Global_t: 482, Episode_t: 2, Action: 67, Reward: 1.62, Epsilon: 0.47
[INFO] model update: t: 483, loss: 304274.28125
[INFO] Global_t: 483, Episode_t: 3, Action: 121, Reward: 1.18, Epsilon: 0.47
[INFO] model update: t: 484, loss: 128030.375
[INFO] Global_t: 484, Episode_t: 4, Action: 0, Reward: 4.24, Epsilon: 0.46
[INFO] model update: t: 485, loss: 219154.6875
[INFO] Global_t: 485, Episode_t: 5, Action: 138, Reward: 1.62, Epsilon: 0.46
[INFO] model update: t: 486, loss: 247460.140625
[INFO] Global_t: 486, Episode_t: 6, Action: 1, Reward: 3.73, Epsilon: 0.46
[INFO] model update: t: 487, loss: 200486.53125
[INFO] Global_t: 487, Episode_t: 7, Action: 10, Reward: 3.55, Epsilon: 0.46
[INFO] model update: t: 488, loss: 154702.703125
[INFO] Global_t: 488, Episode_t: 8, Action: 78, Reward: 1.77, Epsilon: 0.46
 24%|██▍       | 488/2000 [1:16:38<4:35:23, 10.93s/it]
[INFO] Global step: 488, Cumulative rewards: 22.65336, Runtime (s): 4598.40
------------------------------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 489, loss: 380933.21875
[INFO] Global_t: 489, Episode_t: 1, Action: 14, Reward: 5.93, Epsilon: 0.46
[INFO] model update: t: 490, loss: 408817.9375
[INFO] Global_t: 490, Episode_t: 2, Action: 5, Reward: 5.86, Epsilon: 0.46
[INFO] model update: t: 491, loss: 168451.6875
[INFO] Global_t: 491, Episode_t: 3, Action: 3, Reward: 5.23, Epsilon: 0.46
[INFO] model update: t: 492, loss: 294122.375
[INFO] Global_t: 492, Episode_t: 4, Action: 6, Reward: 4.70, Epsilon: 0.46
[INFO] model update: t: 493, loss: 160436.84375
[INFO] Global_t: 493, Episode_t: 5, Action: 124, Reward: 1.30, Epsilon: 0.45
[INFO] model update: t: 494, loss: 166806.109375
[INFO] Global_t: 494, Episode_t: 6, Action: 42, Reward: 3.91, Epsilon: 0.45
[INFO] model update: t: 495, loss: 318774.53125
[INFO] Global_t: 495, Episode_t: 7, Action: 15, Reward: 3.92, Epsilon: 0.45
[INFO] model update: t: 496, loss: 324991.375
[INFO] Global_t: 496, Episode_t: 8, Action: 2, Reward: 6.17, Epsilon: 0.45
 25%|██▍       | 496/2000 [1:17:50<4:19:24, 10.35s/it]
[INFO] Global step: 496, Cumulative rewards: 37.034760000000006, Runtime (s): 4670.38
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  7.1411755084991455
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.430605888366699
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.261989593505859
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.153918743133545
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.125103950500488
average cummulative reward vector is:  [0.14342684 0.13261644 0.13774891 0.13030678 0.13731371]
average cummulative reward is:  0.13628253395452544
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 497, loss: 300385.3125
[INFO] Global_t: 497, Episode_t: 1, Action: 4, Reward: 5.63, Epsilon: 0.45
[INFO] model update: t: 498, loss: 453882.875
[INFO] Global_t: 498, Episode_t: 2, Action: 125, Reward: 1.44, Epsilon: 0.45
[INFO] model update: t: 499, loss: 150084.046875
[INFO] Global_t: 499, Episode_t: 3, Action: 5, Reward: 5.18, Epsilon: 0.45
[INFO] model update: t: 500, loss: 129451.78125
[INFO] Global_t: 500, Episode_t: 4, Action: 0, Reward: 4.10, Epsilon: 0.45
[INFO] model update: t: 501, loss: 274277.40625
[INFO] Global_t: 501, Episode_t: 5, Action: 24, Reward: 3.23, Epsilon: 0.45
[INFO] model update: t: 502, loss: 192761.0625
[INFO] Global_t: 502, Episode_t: 6, Action: 2, Reward: 6.14, Epsilon: 0.44
[INFO] model update: t: 503, loss: 130136.546875
[INFO] Global_t: 503, Episode_t: 7, Action: 27, Reward: 2.91, Epsilon: 0.44
[INFO] model update: t: 504, loss: 173532.5625
[INFO] Global_t: 504, Episode_t: 8, Action: 105, Reward: 1.83, Epsilon: 0.44

 25%|██▌       | 504/2000 [1:19:33<4:37:20, 11.12s/it]999999994, Runtime (s): 4773.82
------------------------------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 505, loss: 347372.875
[INFO] Global_t: 505, Episode_t: 1, Action: 11, Reward: 5.52, Epsilon: 0.44
[INFO] model update: t: 506, loss: 292414.59375
[INFO] Global_t: 506, Episode_t: 2, Action: 10, Reward: 2.18, Epsilon: 0.44
[INFO] model update: t: 507, loss: 115858.578125
[INFO] Global_t: 507, Episode_t: 3, Action: 40, Reward: 1.67, Epsilon: 0.44
[INFO] model update: t: 508, loss: 290054.71875
[INFO] Global_t: 508, Episode_t: 4, Action: 3, Reward: 5.30, Epsilon: 0.44
[INFO] model update: t: 509, loss: 210263.625
[INFO] Global_t: 509, Episode_t: 5, Action: 182, Reward: 1.19, Epsilon: 0.44
[INFO] model update: t: 510, loss: 275803.0
[INFO] Global_t: 510, Episode_t: 6, Action: 30, Reward: 1.99, Epsilon: 0.44
[INFO] model update: t: 511, loss: 112170.6328125
[INFO] Global_t: 511, Episode_t: 7, Action: 9, Reward: 4.43, Epsilon: 0.43
[INFO] model update: t: 512, loss: 170638.203125
[INFO] Global_t: 512, Episode_t: 8, Action: 13, Reward: 2.87, Epsilon: 0.43
 26%|██▌       | 512/2000 [1:20:13<3:50:07,  9.28s/it]
[INFO] Global step: 512, Cumulative rewards: 25.140479999999997, Runtime (s): 4813.62
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.187819004058838
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.2721874713897705
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.29033899307251
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.139599561691284
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.723614454269409
average cummulative reward vector is:  [0.13936816 0.12818796 0.14781776 0.1311722  0.14894543]
average cummulative reward is:  0.1390983013579501
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 513, loss: 152549.5625
[INFO] Global_t: 513, Episode_t: 1, Action: 2, Reward: 5.35, Epsilon: 0.43
[INFO] model update: t: 514, loss: 162072.671875
[INFO] Global_t: 514, Episode_t: 2, Action: 5, Reward: 5.58, Epsilon: 0.43
[INFO] model update: t: 515, loss: 253332.359375
[INFO] Global_t: 515, Episode_t: 3, Action: 7, Reward: 4.40, Epsilon: 0.43
[INFO] model update: t: 516, loss: 141223.71875
[INFO] Global_t: 516, Episode_t: 4, Action: 1, Reward: 4.04, Epsilon: 0.43
[INFO] model update: t: 517, loss: 153314.4375
[INFO] Global_t: 517, Episode_t: 5, Action: 0, Reward: 4.02, Epsilon: 0.43
[INFO] model update: t: 518, loss: 110608.71875
[INFO] Global_t: 518, Episode_t: 6, Action: 151, Reward: 1.32, Epsilon: 0.43
[INFO] model update: t: 519, loss: 142272.78125
[INFO] Global_t: 519, Episode_t: 7, Action: 176, Reward: 1.14, Epsilon: 0.43
[INFO] model update: t: 520, loss: 135461.203125
[INFO] Global_t: 520, Episode_t: 8, Action: 3, Reward: 6.12, Epsilon: 0.42
 26%|██▌       | 520/2000 [1:21:57<4:16:06, 10.38s/it]
[INFO] Global step: 520, Cumulative rewards: 31.97184, Runtime (s): 4917.29
------------------------------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 521, loss: 174791.46875
[INFO] Global_t: 521, Episode_t: 1, Action: 11, Reward: 5.38, Epsilon: 0.42
[INFO] model update: t: 522, loss: 117487.09375
[INFO] Global_t: 522, Episode_t: 2, Action: 2, Reward: 5.85, Epsilon: 0.42
[INFO] model update: t: 523, loss: 246437.421875
[INFO] Global_t: 523, Episode_t: 3, Action: 15, Reward: 5.04, Epsilon: 0.42
[INFO] model update: t: 524, loss: 221825.75
[INFO] Global_t: 524, Episode_t: 4, Action: 1, Reward: 5.67, Epsilon: 0.42
[INFO] model update: t: 525, loss: 368104.5
[INFO] Global_t: 525, Episode_t: 5, Action: 4, Reward: 4.83, Epsilon: 0.42
[INFO] model update: t: 526, loss: 211538.46875
[INFO] Global_t: 526, Episode_t: 6, Action: 8, Reward: 4.43, Epsilon: 0.42
[INFO] model update: t: 527, loss: 211042.171875
[INFO] Global_t: 527, Episode_t: 7, Action: 3, Reward: 6.47, Epsilon: 0.42
[INFO] model update: t: 528, loss: 230071.078125
[INFO] Global_t: 528, Episode_t: 8, Action: 13, Reward: 3.79, Epsilon: 0.42

[INFO] Global step: 528, Cumulative rewards: 41.45568, Runtime (s): 4952.41
------------------------------------------------------------
 
 26%|██▋       | 528/2000 [1:22:32<3:30:37,  8.59s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  7.266447067260742
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  5.423552513122559
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  5.700976371765137
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.685467958450317
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.6420369148254395
average cummulative reward vector is:  [0.15492868 0.11337824 0.14547596 0.12861542 0.15336425]
average cummulative reward is:  0.13915250982159916
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 529, loss: 135265.484375
[INFO] Global_t: 529, Episode_t: 1, Action: 10, Reward: 5.62, Epsilon: 0.42
[INFO] model update: t: 530, loss: 161025.34375
[INFO] Global_t: 530, Episode_t: 2, Action: 182, Reward: 1.22, Epsilon: 0.41
[INFO] model update: t: 531, loss: 137521.203125
[INFO] Global_t: 531, Episode_t: 3, Action: 7, Reward: 5.07, Epsilon: 0.41
[INFO] model update: t: 532, loss: 287234.0
[INFO] Global_t: 532, Episode_t: 4, Action: 80, Reward: 1.67, Epsilon: 0.41
[INFO] model update: t: 533, loss: 147042.421875
[INFO] Global_t: 533, Episode_t: 5, Action: 134, Reward: 1.62, Epsilon: 0.41
[INFO] model update: t: 534, loss: 180847.90625
[INFO] Global_t: 534, Episode_t: 6, Action: 175, Reward: 1.76, Epsilon: 0.41
[INFO] model update: t: 535, loss: 160030.59375
[INFO] Global_t: 535, Episode_t: 7, Action: 4, Reward: 5.27, Epsilon: 0.41
 27%|██▋       | 536/2000 [1:24:14<3:59:36,  9.82s/it][INFO] model update: t: 536, loss: 160167.375
[INFO] Global_t: 536, Episode_t: 8, Action: 199, Reward: 1.52, Epsilon: 0.41

[INFO] Global step: 536, Cumulative rewards: 23.7516, Runtime (s): 5054.02
------------------------------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 537, loss: 273709.71875
[INFO] Global_t: 537, Episode_t: 1, Action: 104, Reward: 1.99, Epsilon: 0.41
[INFO] model update: t: 538, loss: 163393.046875
[INFO] Global_t: 538, Episode_t: 2, Action: 1, Reward: 5.37, Epsilon: 0.41
[INFO] model update: t: 539, loss: 144191.46875
[INFO] Global_t: 539, Episode_t: 3, Action: 3, Reward: 5.24, Epsilon: 0.40
[INFO] model update: t: 540, loss: 136583.3125
[INFO] Global_t: 540, Episode_t: 4, Action: 120, Reward: 1.23, Epsilon: 0.40
[INFO] model update: t: 541, loss: 188677.3125
[INFO] Global_t: 541, Episode_t: 5, Action: 11, Reward: 4.20, Epsilon: 0.40
[INFO] model update: t: 542, loss: 265630.8125
[INFO] Global_t: 542, Episode_t: 6, Action: 132, Reward: 1.57, Epsilon: 0.40
[INFO] model update: t: 543, loss: 153469.0625
[INFO] Global_t: 543, Episode_t: 7, Action: 35, Reward: 1.88, Epsilon: 0.40
[INFO] model update: t: 544, loss: 186141.0
[INFO] Global_t: 544, Episode_t: 8, Action: 145, Reward: 1.12, Epsilon: 0.40
 27%|██▋       | 544/2000 [1:25:24<3:50:33,  9.50s/it]
[INFO] Global step: 544, Cumulative rewards: 22.58411999999999, Runtime (s): 5124.08
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.858844757080078
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.856295347213745
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.944308280944824
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.643768072128296
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  7.633544445037842
average cummulative reward vector is:  [0.13412526 0.1317037  0.14716066 0.12988201 0.15168575]
average cummulative reward is:  0.13891147692665395
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 545, loss: 133324.671875
[INFO] Global_t: 545, Episode_t: 1, Action: 14, Reward: 5.24, Epsilon: 0.40
[INFO] model update: t: 546, loss: 251530.4375
[INFO] Global_t: 546, Episode_t: 2, Action: 5, Reward: 6.06, Epsilon: 0.40
[INFO] model update: t: 547, loss: 110967.390625
[INFO] Global_t: 547, Episode_t: 3, Action: 4, Reward: 6.34, Epsilon: 0.40
[INFO] model update: t: 548, loss: 196872.390625
[INFO] Global_t: 548, Episode_t: 4, Action: 6, Reward: 5.47, Epsilon: 0.39
[INFO] model update: t: 549, loss: 137196.46875
[INFO] Global_t: 549, Episode_t: 5, Action: 8, Reward: 5.48, Epsilon: 0.39
[INFO] model update: t: 550, loss: 194979.484375
[INFO] Global_t: 550, Episode_t: 6, Action: 7, Reward: 5.28, Epsilon: 0.39
[INFO] model update: t: 551, loss: 308553.21875
[INFO] Global_t: 551, Episode_t: 7, Action: 189, Reward: 1.35, Epsilon: 0.39
 28%|██▊       | 552/2000 [1:26:59<4:06:59, 10.23s/it][INFO] model update: t: 552, loss: 254817.0625
[INFO] Global_t: 552, Episode_t: 8, Action: 95, Reward: 2.28, Epsilon: 0.39

[INFO] Global step: 552, Cumulative rewards: 37.49616, Runtime (s): 5219.64
------------------------------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 553, loss: 76602.6640625
[INFO] Global_t: 553, Episode_t: 1, Action: 3, Reward: 5.50, Epsilon: 0.39
[INFO] model update: t: 554, loss: 92097.546875
[INFO] Global_t: 554, Episode_t: 2, Action: 2, Reward: 4.69, Epsilon: 0.39
[INFO] model update: t: 555, loss: 214086.125
[INFO] Global_t: 555, Episode_t: 3, Action: 10, Reward: 4.58, Epsilon: 0.39
[INFO] model update: t: 556, loss: 65711.640625
[INFO] Global_t: 556, Episode_t: 4, Action: 0, Reward: 4.66, Epsilon: 0.39
[INFO] model update: t: 557, loss: 190820.546875
[INFO] Global_t: 557, Episode_t: 5, Action: 6, Reward: 5.17, Epsilon: 0.38
[INFO] model update: t: 558, loss: 210738.9375
[INFO] Global_t: 558, Episode_t: 6, Action: 173, Reward: 1.20, Epsilon: 0.38
[INFO] model update: t: 559, loss: 75772.671875
[INFO] Global_t: 559, Episode_t: 7, Action: 188, Reward: 1.50, Epsilon: 0.38
[INFO] model update: t: 560, loss: 156163.578125
[INFO] Global_t: 560, Episode_t: 8, Action: 32, Reward: 3.22, Epsilon: 0.38
 28%|██▊       | 560/2000 [1:28:10<3:55:29,  9.81s/it]
[INFO] Global step: 560, Cumulative rewards: 30.518639999999998, Runtime (s): 5290.25
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.638854742050171
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.029655456542969
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.559404134750366
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.8735575675964355
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.402188062667847
average cummulative reward vector is:  [0.13594632 0.13139792 0.13505956 0.13223037 0.14901801]
average cummulative reward is:  0.13673043597642684
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 561, loss: 104008.1015625
[INFO] Global_t: 561, Episode_t: 1, Action: 174, Reward: 2.06, Epsilon: 0.38
[INFO] model update: t: 562, loss: 218338.453125
[INFO] Global_t: 562, Episode_t: 2, Action: 0, Reward: 5.71, Epsilon: 0.38
[INFO] model update: t: 563, loss: 226910.859375
[INFO] Global_t: 563, Episode_t: 3, Action: 57, Reward: 2.56, Epsilon: 0.38
[INFO] model update: t: 564, loss: 91963.640625
[INFO] Global_t: 564, Episode_t: 4, Action: 99, Reward: 2.12, Epsilon: 0.38
[INFO] model update: t: 565, loss: 100183.375
[INFO] Global_t: 565, Episode_t: 5, Action: 58, Reward: 1.94, Epsilon: 0.38
[INFO] model update: t: 566, loss: 169258.6875
[INFO] Global_t: 566, Episode_t: 6, Action: 7, Reward: 5.01, Epsilon: 0.37
[INFO] model update: t: 567, loss: 218646.59375
[INFO] Global_t: 567, Episode_t: 7, Action: 30, Reward: 3.16, Epsilon: 0.37
[INFO] model update: t: 568, loss: 99059.6640625
[INFO] Global_t: 568, Episode_t: 8, Action: 4, Reward: 5.15, Epsilon: 0.37
 28%|██▊       | 568/2000 [1:29:53<4:16:05, 10.73s/it]
[INFO] Global step: 568, Cumulative rewards: 27.71352, Runtime (s): 5393.24
------------------------------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 569, loss: 48474.25
[INFO] Global_t: 569, Episode_t: 1, Action: 0, Reward: 5.98, Epsilon: 0.37
[INFO] model update: t: 570, loss: 256322.15625
[INFO] Global_t: 570, Episode_t: 2, Action: 1, Reward: 4.90, Epsilon: 0.37
[INFO] model update: t: 571, loss: 166760.0625
[INFO] Global_t: 571, Episode_t: 3, Action: 21, Reward: 5.56, Epsilon: 0.37
[INFO] model update: t: 572, loss: 122472.8125
[INFO] Global_t: 572, Episode_t: 4, Action: 124, Reward: 1.34, Epsilon: 0.37
[INFO] model update: t: 573, loss: 174377.65625
[INFO] Global_t: 573, Episode_t: 5, Action: 168, Reward: 1.27, Epsilon: 0.37
[INFO] model update: t: 574, loss: 296972.90625
[INFO] Global_t: 574, Episode_t: 6, Action: 81, Reward: 1.29, Epsilon: 0.37
[INFO] model update: t: 575, loss: 165479.59375
[INFO] Global_t: 575, Episode_t: 7, Action: 5, Reward: 4.43, Epsilon: 0.36
 29%|██▉       | 576/2000 [1:31:01<3:59:12, 10.08s/it][INFO] model update: t: 576, loss: 107960.796875
[INFO] Global_t: 576, Episode_t: 8, Action: 112, Reward: 1.65, Epsilon: 0.36

[INFO] Global step: 576, Cumulative rewards: 26.41608, Runtime (s): 5461.73
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.194674968719482
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  8.14486026763916
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.543039083480835
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.012688159942627
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.61412787437439
average cummulative reward vector is:  [0.13581421 0.14408819 0.13817322 0.13786589 0.15547043]
average cummulative reward is:  0.14228238939449406
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 577, loss: 300506.71875
[INFO] Global_t: 577, Episode_t: 1, Action: 8, Reward: 4.52, Epsilon: 0.36
[INFO] model update: t: 578, loss: 265589.375
[INFO] Global_t: 578, Episode_t: 2, Action: 1, Reward: 4.64, Epsilon: 0.36
[INFO] model update: t: 579, loss: 156313.8125
[INFO] Global_t: 579, Episode_t: 3, Action: 7, Reward: 4.64, Epsilon: 0.36
[INFO] model update: t: 580, loss: 78091.59375
[INFO] Global_t: 580, Episode_t: 4, Action: 3, Reward: 5.93, Epsilon: 0.36
[INFO] model update: t: 581, loss: 183332.828125
[INFO] Global_t: 581, Episode_t: 5, Action: 24, Reward: 3.79, Epsilon: 0.36
[INFO] model update: t: 582, loss: 129206.0234375
[INFO] Global_t: 582, Episode_t: 6, Action: 2, Reward: 5.76, Epsilon: 0.36
[INFO] model update: t: 583, loss: 126173.109375
[INFO] Global_t: 583, Episode_t: 7, Action: 14, Reward: 3.38, Epsilon: 0.36
[INFO] model update: t: 584, loss: 144012.625
[INFO] Global_t: 584, Episode_t: 8, Action: 4, Reward: 3.76, Epsilon: 0.36
 29%|██▉       | 584/2000 [1:32:45<4:17:59, 10.93s/it]
[INFO] Global step: 584, Cumulative rewards: 36.417959999999994, Runtime (s): 5565.10
------------------------------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 585, loss: 180039.515625
[INFO] Global_t: 585, Episode_t: 1, Action: 177, Reward: 1.47, Epsilon: 0.35
[INFO] model update: t: 586, loss: 97289.1015625
[INFO] Global_t: 586, Episode_t: 2, Action: 0, Reward: 5.37, Epsilon: 0.35
[INFO] model update: t: 587, loss: 137606.4375
[INFO] Global_t: 587, Episode_t: 3, Action: 7, Reward: 4.84, Epsilon: 0.35
[INFO] model update: t: 588, loss: 124128.1875
[INFO] Global_t: 588, Episode_t: 4, Action: 6, Reward: 5.17, Epsilon: 0.35
[INFO] model update: t: 589, loss: 124778.484375
[INFO] Global_t: 589, Episode_t: 5, Action: 24, Reward: 4.11, Epsilon: 0.35
[INFO] model update: t: 590, loss: 103952.3671875
[INFO] Global_t: 590, Episode_t: 6, Action: 4, Reward: 5.76, Epsilon: 0.35
[INFO] model update: t: 591, loss: 98143.421875
[INFO] Global_t: 591, Episode_t: 7, Action: 3, Reward: 5.69, Epsilon: 0.35
[INFO] model update: t: 592, loss: 102311.4609375
[INFO] Global_t: 592, Episode_t: 8, Action: 2, Reward: 4.18, Epsilon: 0.35
 30%|██▉       | 592/2000 [1:33:48<3:55:42, 10.04s/it]
[INFO] Global step: 592, Cumulative rewards: 36.58812, Runtime (s): 5628.87
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  5.219652414321899
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.806799650192261
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.527741193771362
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.194161891937256
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.453869342803955
average cummulative reward vector is:  [0.13509921 0.13972917 0.14291667 0.12958131 0.15710296]
average cummulative reward is:  0.1408858618520223
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 593, loss: 90946.046875
[INFO] Global_t: 593, Episode_t: 1, Action: 4, Reward: 6.27, Epsilon: 0.35
[INFO] model update: t: 594, loss: 124048.359375
[INFO] Global_t: 594, Episode_t: 2, Action: 2, Reward: 5.31, Epsilon: 0.34
[INFO] model update: t: 595, loss: 152793.953125
[INFO] Global_t: 595, Episode_t: 3, Action: 59, Reward: 2.37, Epsilon: 0.34
[INFO] model update: t: 596, loss: 153148.65625
[INFO] Global_t: 596, Episode_t: 4, Action: 0, Reward: 4.76, Epsilon: 0.34
[INFO] model update: t: 597, loss: 56334.4921875
[INFO] Global_t: 597, Episode_t: 5, Action: 18, Reward: 3.68, Epsilon: 0.34
[INFO] model update: t: 598, loss: 118462.8828125
[INFO] Global_t: 598, Episode_t: 6, Action: 8, Reward: 5.76, Epsilon: 0.34
[INFO] model update: t: 599, loss: 107760.875
[INFO] Global_t: 599, Episode_t: 7, Action: 13, Reward: 4.45, Epsilon: 0.34
 30%|███       | 600/2000 [1:35:33<4:15:15, 10.94s/it][INFO] model update: t: 600, loss: 125949.609375
[INFO] Global_t: 600, Episode_t: 8, Action: 139, Reward: 1.44, Epsilon: 0.34

[INFO] Global step: 600, Cumulative rewards: 34.04556, Runtime (s): 5733.11
------------------------------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 601, loss: 143094.515625
[INFO] Global_t: 601, Episode_t: 1, Action: 0, Reward: 5.08, Epsilon: 0.34
[INFO] model update: t: 602, loss: 184451.296875
[INFO] Global_t: 602, Episode_t: 2, Action: 11, Reward: 4.86, Epsilon: 0.34
[INFO] model update: t: 603, loss: 78699.328125
[INFO] Global_t: 603, Episode_t: 3, Action: 4, Reward: 5.77, Epsilon: 0.33
[INFO] model update: t: 604, loss: 127829.96875
[INFO] Global_t: 604, Episode_t: 4, Action: 5, Reward: 6.19, Epsilon: 0.33
[INFO] model update: t: 605, loss: 123725.6484375
[INFO] Global_t: 605, Episode_t: 5, Action: 1, Reward: 6.42, Epsilon: 0.33
[INFO] model update: t: 606, loss: 116123.0078125
[INFO] Global_t: 606, Episode_t: 6, Action: 22, Reward: 3.08, Epsilon: 0.33
[INFO] model update: t: 607, loss: 122305.046875
[INFO] Global_t: 607, Episode_t: 7, Action: 8, Reward: 3.84, Epsilon: 0.33
 30%|███       | 608/2000 [1:36:39<3:55:28, 10.15s/it][INFO] model update: t: 608, loss: 253882.375
[INFO] Global_t: 608, Episode_t: 8, Action: 2, Reward: 3.81, Epsilon: 0.33

[INFO] Global step: 608, Cumulative rewards: 39.04727999999999, Runtime (s): 5799.56
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.430260181427002
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.656336307525635
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.70212197303772
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.285017728805542
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.273406028747559
average cummulative reward vector is:  [0.13980711 0.13138148 0.14438634 0.14090607 0.1452828 ]
average cummulative reward is:  0.1403527592015467
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 609, loss: 154900.140625
[INFO] Global_t: 609, Episode_t: 1, Action: 210, Reward: 1.89, Epsilon: 0.33
[INFO] model update: t: 610, loss: 123194.15625
[INFO] Global_t: 610, Episode_t: 2, Action: 2, Reward: 6.21, Epsilon: 0.33
[INFO] model update: t: 611, loss: 199949.453125
[INFO] Global_t: 611, Episode_t: 3, Action: 8, Reward: 5.68, Epsilon: 0.33
[INFO] model update: t: 612, loss: 218158.0
[INFO] Global_t: 612, Episode_t: 4, Action: 101, Reward: 2.08, Epsilon: 0.32
[INFO] model update: t: 613, loss: 84941.0703125
[INFO] Global_t: 613, Episode_t: 5, Action: 178, Reward: 1.65, Epsilon: 0.32
[INFO] model update: t: 614, loss: 231075.953125
[INFO] Global_t: 614, Episode_t: 6, Action: 14, Reward: 4.07, Epsilon: 0.32
[INFO] model update: t: 615, loss: 161655.328125
[INFO] Global_t: 615, Episode_t: 7, Action: 115, Reward: 1.47, Epsilon: 0.32
[INFO] model update: t: 616, loss: 188613.78125
[INFO] Global_t: 616, Episode_t: 8, Action: 10, Reward: 3.61, Epsilon: 0.32
 31%|███       | 616/2000 [1:38:22<4:13:10, 10.98s/it]
[INFO] Global step: 616, Cumulative rewards: 26.642159999999997, Runtime (s): 5902.78
------------------------------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 617, loss: 108282.140625
[INFO] Global_t: 617, Episode_t: 1, Action: 1, Reward: 5.40, Epsilon: 0.32
[INFO] model update: t: 618, loss: 149209.375
[INFO] Global_t: 618, Episode_t: 2, Action: 169, Reward: 1.41, Epsilon: 0.32
[INFO] model update: t: 619, loss: 133120.71875
[INFO] Global_t: 619, Episode_t: 3, Action: 161, Reward: 1.24, Epsilon: 0.32
[INFO] model update: t: 620, loss: 78836.453125
[INFO] Global_t: 620, Episode_t: 4, Action: 2, Reward: 5.53, Epsilon: 0.32
[INFO] model update: t: 621, loss: 85309.125
[INFO] Global_t: 621, Episode_t: 5, Action: 12, Reward: 4.58, Epsilon: 0.31
[INFO] model update: t: 622, loss: 210384.109375
[INFO] Global_t: 622, Episode_t: 6, Action: 11, Reward: 3.91, Epsilon: 0.31
[INFO] model update: t: 623, loss: 95394.265625
[INFO] Global_t: 623, Episode_t: 7, Action: 3, Reward: 5.93, Epsilon: 0.31
[INFO] model update: t: 624, loss: 87269.2734375
[INFO] Global_t: 624, Episode_t: 8, Action: 0, Reward: 5.78, Epsilon: 0.31
 31%|███       | 624/2000 [1:39:25<3:50:09, 10.04s/it]
[INFO] Global step: 624, Cumulative rewards: 33.770399999999995, Runtime (s): 5965.52
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.553605079650879
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  7.554203033447266
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.486577749252319
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.49140739440918
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  7.475091218948364
average cummulative reward vector is:  [0.15141895 0.13922616 0.13315109 0.12561121 0.14382366]
average cummulative reward is:  0.13864621370785057
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 625, loss: 113500.609375
[INFO] Global_t: 625, Episode_t: 1, Action: 10, Reward: 5.06, Epsilon: 0.31
[INFO] model update: t: 626, loss: 190858.4375
[INFO] Global_t: 626, Episode_t: 2, Action: 0, Reward: 4.99, Epsilon: 0.31
[INFO] model update: t: 627, loss: 171579.875
[INFO] Global_t: 627, Episode_t: 3, Action: 16, Reward: 3.59, Epsilon: 0.31
[INFO] model update: t: 628, loss: 106994.0625
[INFO] Global_t: 628, Episode_t: 4, Action: 2, Reward: 4.39, Epsilon: 0.31
[INFO] model update: t: 629, loss: 89924.1796875
[INFO] Global_t: 629, Episode_t: 5, Action: 77, Reward: 1.51, Epsilon: 0.31
[INFO] model update: t: 630, loss: 170502.53125
[INFO] Global_t: 630, Episode_t: 6, Action: 4, Reward: 5.00, Epsilon: 0.31
[INFO] model update: t: 631, loss: 133928.625
[INFO] Global_t: 631, Episode_t: 7, Action: 8, Reward: 5.26, Epsilon: 0.30
[INFO] model update: t: 632, loss: 140142.75
[INFO] Global_t: 632, Episode_t: 8, Action: 9, Reward: 4.02, Epsilon: 0.30
 32%|███▏      | 632/2000 [1:41:11<4:10:59, 11.01s/it]
[INFO] Global step: 632, Cumulative rewards: 33.82416, Runtime (s): 6071.74
------------------------------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 633, loss: 158711.90625
[INFO] Global_t: 633, Episode_t: 1, Action: 2, Reward: 5.82, Epsilon: 0.30
[INFO] model update: t: 634, loss: 94600.9140625
[INFO] Global_t: 634, Episode_t: 2, Action: 15, Reward: 4.59, Epsilon: 0.30
[INFO] model update: t: 635, loss: 130634.265625
[INFO] Global_t: 635, Episode_t: 3, Action: 115, Reward: 1.51, Epsilon: 0.30
[INFO] model update: t: 636, loss: 68222.109375
[INFO] Global_t: 636, Episode_t: 4, Action: 99, Reward: 1.15, Epsilon: 0.30
[INFO] model update: t: 637, loss: 139222.8125
[INFO] Global_t: 637, Episode_t: 5, Action: 16, Reward: 5.28, Epsilon: 0.30
[INFO] model update: t: 638, loss: 179231.15625
[INFO] Global_t: 638, Episode_t: 6, Action: 6, Reward: 5.19, Epsilon: 0.30
[INFO] model update: t: 639, loss: 110525.1875
[INFO] Global_t: 639, Episode_t: 7, Action: 1, Reward: 4.06, Epsilon: 0.30
[INFO] model update: t: 640, loss: 150625.765625
[INFO] Global_t: 640, Episode_t: 8, Action: 181, Reward: 1.56, Epsilon: 0.29

[INFO] Global step: 640, Cumulative rewards: 29.161920000000002, Runtime (s): 6130.27
------------------------------------------------------------
 
 32%|███▏      | 640/2000 [1:42:10<3:44:24,  9.90s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.4476165771484375
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.171373128890991
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  7.345245838165283
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  7.012582778930664
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.244102239608765
average cummulative reward vector is:  [0.14299395 0.13047222 0.14594645 0.13222313 0.14629812]
average cummulative reward is:  0.13958677335975328
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 641, loss: 70103.390625
[INFO] Global_t: 641, Episode_t: 1, Action: 8, Reward: 5.80, Epsilon: 0.29
[INFO] model update: t: 642, loss: 118598.6328125
[INFO] Global_t: 642, Episode_t: 2, Action: 34, Reward: 4.51, Epsilon: 0.29
[INFO] model update: t: 643, loss: 114077.5703125
[INFO] Global_t: 643, Episode_t: 3, Action: 9, Reward: 5.53, Epsilon: 0.29
[INFO] model update: t: 644, loss: 148846.8125
[INFO] Global_t: 644, Episode_t: 4, Action: 19, Reward: 3.61, Epsilon: 0.29
[INFO] model update: t: 645, loss: 151542.09375
[INFO] Global_t: 645, Episode_t: 5, Action: 10, Reward: 6.00, Epsilon: 0.29
[INFO] model update: t: 646, loss: 101899.234375
[INFO] Global_t: 646, Episode_t: 6, Action: 2, Reward: 5.76, Epsilon: 0.29
[INFO] model update: t: 647, loss: 277328.3125
[INFO] Global_t: 647, Episode_t: 7, Action: 7, Reward: 4.44, Epsilon: 0.29
[INFO] model update: t: 648, loss: 201558.75
[INFO] Global_t: 648, Episode_t: 8, Action: 59, Reward: 1.90, Epsilon: 0.29
 32%|███▏      | 648/2000 [1:43:52<4:02:56, 10.78s/it]
[INFO] Global step: 648, Cumulative rewards: 37.5246, Runtime (s): 6232.97
------------------------------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 649, loss: 185760.015625
[INFO] Global_t: 649, Episode_t: 1, Action: 1, Reward: 5.17, Epsilon: 0.28
[INFO] model update: t: 650, loss: 132392.8125
[INFO] Global_t: 650, Episode_t: 2, Action: 11, Reward: 2.96, Epsilon: 0.28
[INFO] model update: t: 651, loss: 103228.484375
[INFO] Global_t: 651, Episode_t: 3, Action: 15, Reward: 4.61, Epsilon: 0.28
[INFO] model update: t: 652, loss: 203949.171875
[INFO] Global_t: 652, Episode_t: 4, Action: 139, Reward: 1.35, Epsilon: 0.28
[INFO] model update: t: 653, loss: 69094.0703125
[INFO] Global_t: 653, Episode_t: 5, Action: 9, Reward: 4.62, Epsilon: 0.28
[INFO] model update: t: 654, loss: 110252.8203125
[INFO] Global_t: 654, Episode_t: 6, Action: 17, Reward: 3.19, Epsilon: 0.28
[INFO] model update: t: 655, loss: 91925.9453125
[INFO] Global_t: 655, Episode_t: 7, Action: 18, Reward: 3.40, Epsilon: 0.28
 33%|███▎      | 656/2000 [1:45:00<3:45:48, 10.08s/it][INFO] model update: t: 656, loss: 106724.3046875
[INFO] Global_t: 656, Episode_t: 8, Action: 6, Reward: 6.20, Epsilon: 0.28

[INFO] Global step: 656, Cumulative rewards: 31.503479999999996, Runtime (s): 6300.53
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  6.4307146072387695
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  6.614611864089966
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  6.505887031555176
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  6.31040096282959
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  6.28286600112915
average cummulative reward vector is:  [0.14455579 0.12885718 0.13025383 0.13126075 0.13919946]
average cummulative reward is:  0.134825400113073
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
