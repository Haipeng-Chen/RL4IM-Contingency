[INFO 16:03:37] Experiments Running command 'my_main'
[INFO 16:03:37] Experiments Started run with ID "4"
[DEBUG 16:03:37] Experiments Starting Heartbeat
[DEBUG 16:03:37] my_main Started
Loading train graph:  powerlaw
train graphs in total:  200
Loading test graph:  powerlaw
merged graphs length:  205
/home/docker/app/src/agent/colge/utils/config.py:10: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  model_config = yaml.load(config_file)
  0%|          | 0/2000 [00:00<?, ?it/s]epoch:  0
graph: 0, nodes: 180, edges: 531
[INFO] Global_t: 1, Episode_t: 1, Action: 173, Reward: 1.27, Epsilon: 0.99
[INFO] Global_t: 2, Episode_t: 2, Action: 137, Reward: 1.52, Epsilon: 0.99
[INFO] Global_t: 3, Episode_t: 3, Action: 172, Reward: 1.17, Epsilon: 0.99
[INFO] Global_t: 4, Episode_t: 4, Action: 67, Reward: 1.48, Epsilon: 0.99
[INFO] Global_t: 5, Episode_t: 5, Action: 83, Reward: 1.61, Epsilon: 0.99
[INFO] Global_t: 6, Episode_t: 6, Action: 91, Reward: 2.07, Epsilon: 0.99
[INFO] Global_t: 7, Episode_t: 7, Action: 92, Reward: 1.44, Epsilon: 0.98
[INFO] Global_t: 8, Episode_t: 8, Action: 47, Reward: 1.39, Epsilon: 0.98
  0%|          | 8/2000 [00:01<08:16,  4.01it/s]
[INFO] Global step: 8, Cumulative rewards: 11.95236, Runtime (s): 2.00
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] Global_t: 9, Episode_t: 1, Action: 192, Reward: 1.16, Epsilon: 0.98
[INFO] Global_t: 10, Episode_t: 2, Action: 5, Reward: 5.39, Epsilon: 0.98
[INFO] Global_t: 11, Episode_t: 3, Action: 104, Reward: 1.33, Epsilon: 0.98
[INFO] Global_t: 12, Episode_t: 4, Action: 144, Reward: 1.71, Epsilon: 0.98
[INFO] Global_t: 13, Episode_t: 5, Action: 42, Reward: 2.60, Epsilon: 0.98
[INFO] Global_t: 14, Episode_t: 6, Action: 37, Reward: 2.10, Epsilon: 0.98
[INFO] Global_t: 15, Episode_t: 7, Action: 47, Reward: 1.34, Epsilon: 0.98
[INFO] Global_t: 16, Episode_t: 8, Action: 89, Reward: 1.87, Epsilon: 0.98

[INFO] Global step: 16, Cumulative rewards: 17.502119999999998, Runtime (s): 5.52
------------------------------------------------------------
 
  1%|          | 16/2000 [00:05<10:08,  3.26it/s]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.1236958503723145
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.039958238601685
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.920410394668579
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9731266498565674
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.110682725906372
average cummulative reward vector is:  [0.14903895 0.12621458 0.1496194  0.12607617 0.15084005]
average cummulative reward is:  0.14035783031931964
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] Global_t: 17, Episode_t: 1, Action: 131, Reward: 1.42, Epsilon: 0.97
[INFO] Global_t: 18, Episode_t: 2, Action: 15, Reward: 5.85, Epsilon: 0.97
[INFO] Global_t: 19, Episode_t: 3, Action: 21, Reward: 2.59, Epsilon: 0.97
[INFO] Global_t: 20, Episode_t: 4, Action: 147, Reward: 1.27, Epsilon: 0.97
[INFO] Global_t: 21, Episode_t: 5, Action: 127, Reward: 1.49, Epsilon: 0.97
[INFO] Global_t: 22, Episode_t: 6, Action: 192, Reward: 1.74, Epsilon: 0.97
[INFO] Global_t: 23, Episode_t: 7, Action: 201, Reward: 1.66, Epsilon: 0.97
[INFO] Global_t: 24, Episode_t: 8, Action: 94, Reward: 1.33, Epsilon: 0.97
  1%|          | 24/2000 [00:29<36:45,  1.12s/it]
[INFO] Global step: 24, Cumulative rewards: 17.358719999999998, Runtime (s): 29.56
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] Global_t: 25, Episode_t: 1, Action: 175, Reward: 1.24, Epsilon: 0.97
[INFO] Global_t: 26, Episode_t: 2, Action: 27, Reward: 2.20, Epsilon: 0.97
[INFO] Global_t: 27, Episode_t: 3, Action: 171, Reward: 1.30, Epsilon: 0.96
[INFO] Global_t: 28, Episode_t: 4, Action: 111, Reward: 1.91, Epsilon: 0.96
[INFO] Global_t: 29, Episode_t: 5, Action: 5, Reward: 4.28, Epsilon: 0.96
[INFO] Global_t: 30, Episode_t: 6, Action: 115, Reward: 1.40, Epsilon: 0.96
[INFO] Global_t: 31, Episode_t: 7, Action: 113, Reward: 1.59, Epsilon: 0.96
[INFO] Global_t: 32, Episode_t: 8, Action: 183, Reward: 1.27, Epsilon: 0.96
  2%|▏         | 32/2000 [00:32<28:55,  1.13it/s]
[INFO] Global step: 32, Cumulative rewards: 15.179759999999998, Runtime (s): 32.24
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.932206153869629
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.4441022872924805
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8562521934509277
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.461711883544922
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.0098795890808105
average cummulative reward vector is:  [0.14077184 0.13792755 0.14578497 0.13967477 0.14704355]
average cummulative reward is:  0.14224053516427843
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] Global_t: 33, Episode_t: 1, Action: 115, Reward: 1.45, Epsilon: 0.96
[INFO] Global_t: 34, Episode_t: 2, Action: 3, Reward: 6.92, Epsilon: 0.96
[INFO] Global_t: 35, Episode_t: 3, Action: 79, Reward: 1.42, Epsilon: 0.96
[INFO] Global_t: 36, Episode_t: 4, Action: 173, Reward: 1.45, Epsilon: 0.96
[INFO] Global_t: 37, Episode_t: 5, Action: 113, Reward: 1.59, Epsilon: 0.95
[INFO] Global_t: 38, Episode_t: 6, Action: 145, Reward: 1.28, Epsilon: 0.95
[INFO] Global_t: 39, Episode_t: 7, Action: 86, Reward: 2.06, Epsilon: 0.95
[INFO] Global_t: 40, Episode_t: 8, Action: 139, Reward: 1.44, Epsilon: 0.95
  2%|▏         | 40/2000 [00:56<49:35,  1.52s/it]
[INFO] Global step: 40, Cumulative rewards: 17.590440000000005, Runtime (s): 56.27
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] Global_t: 41, Episode_t: 1, Action: 9, Reward: 7.09, Epsilon: 0.95
[INFO] Global_t: 42, Episode_t: 2, Action: 4, Reward: 7.11, Epsilon: 0.95
[INFO] Global_t: 43, Episode_t: 3, Action: 150, Reward: 1.50, Epsilon: 0.95
[INFO] Global_t: 44, Episode_t: 4, Action: 130, Reward: 2.00, Epsilon: 0.95
[INFO] Global_t: 45, Episode_t: 5, Action: 174, Reward: 1.37, Epsilon: 0.95
[INFO] Global_t: 46, Episode_t: 6, Action: 135, Reward: 1.15, Epsilon: 0.95
[INFO] Global_t: 47, Episode_t: 7, Action: 63, Reward: 1.68, Epsilon: 0.94
[INFO] Global_t: 48, Episode_t: 8, Action: 200, Reward: 1.07, Epsilon: 0.94
  2%|▏         | 48/2000 [01:01<40:24,  1.24s/it]
[INFO] Global step: 48, Cumulative rewards: 22.966920000000002, Runtime (s): 61.05
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.254452466964722
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9673757553100586
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9575412273406982
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.263222932815552
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.174038648605347
average cummulative reward vector is:  [0.15386211 0.12434907 0.14714645 0.13016916 0.15089328]
average cummulative reward is:  0.14128401317461217
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 49, loss: 9160005632.0
[INFO] Global_t: 49, Episode_t: 1, Action: 19, Reward: 3.28, Epsilon: 0.94
[INFO] model update: t: 50, loss: 540805595136.0
[INFO] Global_t: 50, Episode_t: 2, Action: 0, Reward: 3.96, Epsilon: 0.94
[INFO] model update: t: 51, loss: 183381131264.0
[INFO] Global_t: 51, Episode_t: 3, Action: 109, Reward: 1.40, Epsilon: 0.94
[INFO] model update: t: 52, loss: 136162148352.0
[INFO] Global_t: 52, Episode_t: 4, Action: 7, Reward: 3.79, Epsilon: 0.94
[INFO] model update: t: 53, loss: 97514618880.0
[INFO] Global_t: 53, Episode_t: 5, Action: 181, Reward: 1.34, Epsilon: 0.94
[INFO] model update: t: 54, loss: 11752947712.0
[INFO] Global_t: 54, Episode_t: 6, Action: 127, Reward: 1.48, Epsilon: 0.94
[INFO] model update: t: 55, loss: 8476336128.0
[INFO] Global_t: 55, Episode_t: 7, Action: 70, Reward: 1.80, Epsilon: 0.94
[INFO] model update: t: 56, loss: 14555053056.0
[INFO] Global_t: 56, Episode_t: 8, Action: 105, Reward: 1.96, Epsilon: 0.94
  3%|▎         | 56/2000 [01:26<58:54,  1.82s/it]
[INFO] Global step: 56, Cumulative rewards: 19.003680000000003, Runtime (s): 86.35
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 57, loss: 2630945792.0
[INFO] Global_t: 57, Episode_t: 1, Action: 0, Reward: 6.64, Epsilon: 0.94
[INFO] model update: t: 58, loss: 3586908672.0
[INFO] Global_t: 58, Episode_t: 2, Action: 151, Reward: 1.69, Epsilon: 0.93
[INFO] model update: t: 59, loss: 9611784192.0
[INFO] Global_t: 59, Episode_t: 3, Action: 161, Reward: 1.26, Epsilon: 0.93
[INFO] model update: t: 60, loss: 4211012608.0
[INFO] Global_t: 60, Episode_t: 4, Action: 17, Reward: 2.27, Epsilon: 0.93
[INFO] model update: t: 61, loss: 103184800.0
[INFO] Global_t: 61, Episode_t: 5, Action: 150, Reward: 1.14, Epsilon: 0.93
[INFO] model update: t: 62, loss: 4184505088.0
[INFO] Global_t: 62, Episode_t: 6, Action: 172, Reward: 1.27, Epsilon: 0.93
[INFO] model update: t: 63, loss: 1677312640.0
[INFO] Global_t: 63, Episode_t: 7, Action: 25, Reward: 1.47, Epsilon: 0.93
[INFO] model update: t: 64, loss: 476933600.0
[INFO] Global_t: 64, Episode_t: 8, Action: 141, Reward: 1.14, Epsilon: 0.93
  3%|▎         | 64/2000 [01:30<46:37,  1.44s/it]
[INFO] Global step: 64, Cumulative rewards: 16.88076, Runtime (s): 90.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.009623050689697
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9057576656341553
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.644440174102783
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.782249927520752
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.962085485458374
average cummulative reward vector is:  [0.14458342 0.12248333 0.13589973 0.14783481 0.14315565]
average cummulative reward is:  0.13879138788146475
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 65, loss: 2783354880.0
[INFO] Global_t: 65, Episode_t: 1, Action: 140, Reward: 1.94, Epsilon: 0.93
[INFO] model update: t: 66, loss: 111296592.0
[INFO] Global_t: 66, Episode_t: 2, Action: 78, Reward: 1.66, Epsilon: 0.93
[INFO] model update: t: 67, loss: 1336710656.0
[INFO] Global_t: 67, Episode_t: 3, Action: 1, Reward: 5.87, Epsilon: 0.93
[INFO] model update: t: 68, loss: 934973248.0
[INFO] Global_t: 68, Episode_t: 4, Action: 83, Reward: 1.46, Epsilon: 0.92
[INFO] model update: t: 69, loss: 45017168.0
[INFO] Global_t: 69, Episode_t: 5, Action: 63, Reward: 1.65, Epsilon: 0.92
[INFO] model update: t: 70, loss: 1057246656.0
[INFO] Global_t: 70, Episode_t: 6, Action: 97, Reward: 1.23, Epsilon: 0.92
[INFO] model update: t: 71, loss: 458714112.0
[INFO] Global_t: 71, Episode_t: 7, Action: 0, Reward: 5.50, Epsilon: 0.92
[INFO] model update: t: 72, loss: 33348204.0
[INFO] Global_t: 72, Episode_t: 8, Action: 177, Reward: 0.96, Epsilon: 0.92
  4%|▎         | 72/2000 [01:55<1:01:51,  1.92s/it]
[INFO] Global step: 72, Cumulative rewards: 20.26296, Runtime (s): 115.30
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 73, loss: 679995648.0
[INFO] Global_t: 73, Episode_t: 1, Action: 32, Reward: 3.84, Epsilon: 0.92
[INFO] model update: t: 74, loss: 402812224.0
[INFO] Global_t: 74, Episode_t: 2, Action: 89, Reward: 1.99, Epsilon: 0.92
[INFO] model update: t: 75, loss: 28525016.0
[INFO] Global_t: 75, Episode_t: 3, Action: 123, Reward: 1.29, Epsilon: 0.92
[INFO] model update: t: 76, loss: 446346336.0
[INFO] Global_t: 76, Episode_t: 4, Action: 115, Reward: 1.74, Epsilon: 0.92
[INFO] model update: t: 77, loss: 349566656.0
[INFO] Global_t: 77, Episode_t: 5, Action: 184, Reward: 1.35, Epsilon: 0.92
[INFO] model update: t: 78, loss: 1264387.875
[INFO] Global_t: 78, Episode_t: 6, Action: 189, Reward: 1.83, Epsilon: 0.91
[INFO] model update: t: 79, loss: 223298432.0
[INFO] Global_t: 79, Episode_t: 7, Action: 60, Reward: 1.87, Epsilon: 0.91
[INFO] model update: t: 80, loss: 198961696.0
[INFO] Global_t: 80, Episode_t: 8, Action: 104, Reward: 1.33, Epsilon: 0.91
  4%|▍         | 80/2000 [01:59<47:39,  1.49s/it]  
[INFO] Global step: 80, Cumulative rewards: 15.253319999999999, Runtime (s): 119.07
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.079235076904297
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.361206531524658
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.150838851928711
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.3895423412323
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.300849914550781
average cummulative reward vector is:  [0.14791368 0.13436551 0.14993388 0.13570607 0.15709032]
average cummulative reward is:  0.14500189411964132
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 81, loss: 2505683.0
[INFO] Global_t: 81, Episode_t: 1, Action: 167, Reward: 1.36, Epsilon: 0.91
[INFO] model update: t: 82, loss: 154199168.0
[INFO] Global_t: 82, Episode_t: 2, Action: 52, Reward: 2.22, Epsilon: 0.91
[INFO] model update: t: 83, loss: 142240528.0
[INFO] Global_t: 83, Episode_t: 3, Action: 95, Reward: 1.56, Epsilon: 0.91
[INFO] model update: t: 84, loss: 6300594.0
[INFO] Global_t: 84, Episode_t: 4, Action: 96, Reward: 1.71, Epsilon: 0.91
[INFO] model update: t: 85, loss: 148041344.0
[INFO] Global_t: 85, Episode_t: 5, Action: 2, Reward: 4.92, Epsilon: 0.91
[INFO] model update: t: 86, loss: 81416416.0
[INFO] Global_t: 86, Episode_t: 6, Action: 188, Reward: 1.14, Epsilon: 0.91
[INFO] model update: t: 87, loss: 20893954.0
[INFO] Global_t: 87, Episode_t: 7, Action: 57, Reward: 1.77, Epsilon: 0.91
[INFO] model update: t: 88, loss: 60953524.0
[INFO] Global_t: 88, Episode_t: 8, Action: 73, Reward: 1.79, Epsilon: 0.90
  4%|▍         | 88/2000 [02:23<1:02:52,  1.97s/it]
[INFO] Global step: 88, Cumulative rewards: 16.46808, Runtime (s): 143.89
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 89, loss: 25788266.0
[INFO] Global_t: 89, Episode_t: 1, Action: 84, Reward: 2.33, Epsilon: 0.90
[INFO] model update: t: 90, loss: 1985025.125
[INFO] Global_t: 90, Episode_t: 2, Action: 135, Reward: 2.07, Epsilon: 0.90
[INFO] model update: t: 91, loss: 38158296.0
[INFO] Global_t: 91, Episode_t: 3, Action: 4, Reward: 6.03, Epsilon: 0.90
[INFO] model update: t: 92, loss: 21906092.0
[INFO] Global_t: 92, Episode_t: 4, Action: 186, Reward: 1.51, Epsilon: 0.90
[INFO] model update: t: 93, loss: 1853709.25
[INFO] Global_t: 93, Episode_t: 5, Action: 19, Reward: 3.28, Epsilon: 0.90
[INFO] model update: t: 94, loss: 25373532.0
[INFO] Global_t: 94, Episode_t: 6, Action: 70, Reward: 1.88, Epsilon: 0.90
[INFO] model update: t: 95, loss: 18488758.0
[INFO] Global_t: 95, Episode_t: 7, Action: 3, Reward: 6.02, Epsilon: 0.90
[INFO] model update: t: 96, loss: 867181.25
[INFO] Global_t: 96, Episode_t: 8, Action: 102, Reward: 1.11, Epsilon: 0.90
  5%|▍         | 96/2000 [02:28<49:23,  1.56s/it]  
[INFO] Global step: 96, Cumulative rewards: 24.22704, Runtime (s): 148.56
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.002297401428223
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.364678144454956
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.929584503173828
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.298110485076904
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.314100027084351
average cummulative reward vector is:  [0.14058658 0.13681667 0.14567732 0.13419322 0.15602634]
average cummulative reward is:  0.14266002728069868
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 97, loss: 20458710.0
[INFO] Global_t: 97, Episode_t: 1, Action: 10, Reward: 6.78, Epsilon: 0.90
[INFO] model update: t: 98, loss: 15548735.0
[INFO] Global_t: 98, Episode_t: 2, Action: 2, Reward: 6.01, Epsilon: 0.89
[INFO] model update: t: 99, loss: 1130505.125
[INFO] Global_t: 99, Episode_t: 3, Action: 88, Reward: 1.38, Epsilon: 0.89
[INFO] model update: t: 100, loss: 16822520.0
[INFO] Global_t: 100, Episode_t: 4, Action: 129, Reward: 1.98, Epsilon: 0.89
[INFO] model update: t: 101, loss: 7620706.0
[INFO] Global_t: 101, Episode_t: 5, Action: 17, Reward: 3.41, Epsilon: 0.89
[INFO] model update: t: 102, loss: 509328.75
[INFO] Global_t: 102, Episode_t: 6, Action: 74, Reward: 2.01, Epsilon: 0.89
[INFO] model update: t: 103, loss: 8314965.0
[INFO] Global_t: 103, Episode_t: 7, Action: 0, Reward: 5.30, Epsilon: 0.89
[INFO] model update: t: 104, loss: 8861550.0
[INFO] Global_t: 104, Episode_t: 8, Action: 165, Reward: 1.72, Epsilon: 0.89
  5%|▌         | 104/2000 [02:55<1:06:08,  2.09s/it]
[INFO] Global step: 104, Cumulative rewards: 28.595159999999996, Runtime (s): 175.33
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 105, loss: 424083.9375
[INFO] Global_t: 105, Episode_t: 1, Action: 149, Reward: 1.62, Epsilon: 0.89
[INFO] model update: t: 106, loss: 9187654.0
[INFO] Global_t: 106, Episode_t: 2, Action: 4, Reward: 6.24, Epsilon: 0.89
[INFO] model update: t: 107, loss: 5489491.5
[INFO] Global_t: 107, Episode_t: 3, Action: 103, Reward: 2.36, Epsilon: 0.89
[INFO] model update: t: 108, loss: 554758.125
[INFO] Global_t: 108, Episode_t: 4, Action: 110, Reward: 1.10, Epsilon: 0.89
[INFO] model update: t: 109, loss: 8377013.0
[INFO] Global_t: 109, Episode_t: 5, Action: 162, Reward: 1.35, Epsilon: 0.88
[INFO] model update: t: 110, loss: 3226827.5
[INFO] Global_t: 110, Episode_t: 6, Action: 154, Reward: 1.84, Epsilon: 0.88
[INFO] model update: t: 111, loss: 1712601.75
[INFO] Global_t: 111, Episode_t: 7, Action: 92, Reward: 1.62, Epsilon: 0.88
[INFO] model update: t: 112, loss: 7086776.5
[INFO] Global_t: 112, Episode_t: 8, Action: 2, Reward: 5.61, Epsilon: 0.88
  6%|▌         | 112/2000 [02:59<51:09,  1.63s/it]  
[INFO] Global step: 112, Cumulative rewards: 21.73068, Runtime (s): 179.62
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.975618600845337
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.02848482131958
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.957235336303711
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.355467319488525
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.10608696937561
average cummulative reward vector is:  [0.14337342 0.12558218 0.14386038 0.13768808 0.14935645]
average cummulative reward is:  0.13997210304345428
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 113, loss: 1669055.25
[INFO] Global_t: 113, Episode_t: 1, Action: 0, Reward: 4.02, Epsilon: 0.88
[INFO] model update: t: 114, loss: 2867265.0
[INFO] Global_t: 114, Episode_t: 2, Action: 2, Reward: 6.78, Epsilon: 0.88
[INFO] model update: t: 115, loss: 5105529.0
[INFO] Global_t: 115, Episode_t: 3, Action: 36, Reward: 2.00, Epsilon: 0.88
[INFO] model update: t: 116, loss: 391771.375
[INFO] Global_t: 116, Episode_t: 4, Action: 188, Reward: 1.48, Epsilon: 0.88
[INFO] model update: t: 117, loss: 2648840.0
[INFO] Global_t: 117, Episode_t: 5, Action: 125, Reward: 1.82, Epsilon: 0.88
[INFO] model update: t: 118, loss: 3448706.0
[INFO] Global_t: 118, Episode_t: 6, Action: 143, Reward: 1.37, Epsilon: 0.88
[INFO] model update: t: 119, loss: 169217.09375
[INFO] Global_t: 119, Episode_t: 7, Action: 184, Reward: 1.29, Epsilon: 0.87
[INFO] model update: t: 120, loss: 2085124.375
[INFO] Global_t: 120, Episode_t: 8, Action: 3, Reward: 5.78, Epsilon: 0.87
  6%|▌         | 120/2000 [03:24<1:05:27,  2.09s/it]
[INFO] Global step: 120, Cumulative rewards: 24.55284, Runtime (s): 204.97
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 121, loss: 2401477.25
[INFO] Global_t: 121, Episode_t: 1, Action: 2, Reward: 6.27, Epsilon: 0.87
[INFO] model update: t: 122, loss: 63977.40625
[INFO] Global_t: 122, Episode_t: 2, Action: 95, Reward: 1.43, Epsilon: 0.87
[INFO] model update: t: 123, loss: 1854511.75
[INFO] Global_t: 123, Episode_t: 3, Action: 4, Reward: 5.12, Epsilon: 0.87
[INFO] model update: t: 124, loss: 1649099.875
[INFO] Global_t: 124, Episode_t: 4, Action: 63, Reward: 1.41, Epsilon: 0.87
[INFO] model update: t: 125, loss: 227488.453125
[INFO] Global_t: 125, Episode_t: 5, Action: 3, Reward: 4.74, Epsilon: 0.87
[INFO] model update: t: 126, loss: 1788916.75
[INFO] Global_t: 126, Episode_t: 6, Action: 61, Reward: 1.47, Epsilon: 0.87
[INFO] model update: t: 127, loss: 596047.5
[INFO] Global_t: 127, Episode_t: 7, Action: 128, Reward: 1.09, Epsilon: 0.87
[INFO] model update: t: 128, loss: 392399.875
[INFO] Global_t: 128, Episode_t: 8, Action: 74, Reward: 1.60, Epsilon: 0.87
  6%|▋         | 128/2000 [03:29<51:20,  1.65s/it]  
[INFO] Global step: 128, Cumulative rewards: 23.12844, Runtime (s): 209.85
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.32322359085083
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.440032720565796
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.014463424682617
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.409109354019165
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.075113773345947
average cummulative reward vector is:  [0.14929737 0.13535093 0.14880601 0.13864042 0.14826478]
average cummulative reward is:  0.1440719021565849
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 129, loss: 1312333.25
[INFO] Global_t: 129, Episode_t: 1, Action: 103, Reward: 2.03, Epsilon: 0.86
[INFO] model update: t: 130, loss: 442343.25
[INFO] Global_t: 130, Episode_t: 2, Action: 54, Reward: 3.05, Epsilon: 0.86
[INFO] model update: t: 131, loss: 499324.53125
[INFO] Global_t: 131, Episode_t: 3, Action: 44, Reward: 2.80, Epsilon: 0.86
[INFO] model update: t: 132, loss: 1258323.5
[INFO] Global_t: 132, Episode_t: 4, Action: 162, Reward: 1.08, Epsilon: 0.86
[INFO] model update: t: 133, loss: 82728.09375
[INFO] Global_t: 133, Episode_t: 5, Action: 5, Reward: 6.67, Epsilon: 0.86
[INFO] model update: t: 134, loss: 586767.3125
[INFO] Global_t: 134, Episode_t: 6, Action: 26, Reward: 1.91, Epsilon: 0.86
[INFO] model update: t: 135, loss: 746024.75
[INFO] Global_t: 135, Episode_t: 7, Action: 128, Reward: 1.23, Epsilon: 0.86
[INFO] model update: t: 136, loss: 76282.15625
[INFO] Global_t: 136, Episode_t: 8, Action: 177, Reward: 1.54, Epsilon: 0.86
  7%|▋         | 136/2000 [03:55<1:05:42,  2.12s/it]
[INFO] Global step: 136, Cumulative rewards: 20.28732, Runtime (s): 235.54
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 137, loss: 724748.375
[INFO] Global_t: 137, Episode_t: 1, Action: 107, Reward: 1.87, Epsilon: 0.86
[INFO] model update: t: 138, loss: 479765.5
[INFO] Global_t: 138, Episode_t: 2, Action: 7, Reward: 4.97, Epsilon: 0.86
[INFO] model update: t: 139, loss: 210021.3125
[INFO] Global_t: 139, Episode_t: 3, Action: 184, Reward: 1.60, Epsilon: 0.85
[INFO] model update: t: 140, loss: 671988.9375
[INFO] Global_t: 140, Episode_t: 4, Action: 4, Reward: 4.27, Epsilon: 0.85
[INFO] model update: t: 141, loss: 184319.953125
[INFO] Global_t: 141, Episode_t: 5, Action: 73, Reward: 1.42, Epsilon: 0.85
[INFO] model update: t: 142, loss: 229505.0
[INFO] Global_t: 142, Episode_t: 6, Action: 34, Reward: 4.01, Epsilon: 0.85
[INFO] model update: t: 143, loss: 398636.75
[INFO] Global_t: 143, Episode_t: 7, Action: 79, Reward: 1.57, Epsilon: 0.85
[INFO] model update: t: 144, loss: 83310.0625
[INFO] Global_t: 144, Episode_t: 8, Action: 33, Reward: 1.68, Epsilon: 0.85
  7%|▋         | 144/2000 [04:00<51:36,  1.67s/it]  
[INFO] Global step: 144, Cumulative rewards: 21.39864, Runtime (s): 240.55
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.105579137802124
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.580449342727661
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.236923933029175
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.517850875854492
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.076978921890259
average cummulative reward vector is:  [0.14523737 0.14161181 0.15492049 0.1420979  0.14862796]
average cummulative reward is:  0.14649910399307914
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 145, loss: 330276.125
[INFO] Global_t: 145, Episode_t: 1, Action: 56, Reward: 2.41, Epsilon: 0.85
[INFO] model update: t: 146, loss: 363497.28125
[INFO] Global_t: 146, Episode_t: 2, Action: 169, Reward: 1.45, Epsilon: 0.85
[INFO] model update: t: 147, loss: 101282.328125
[INFO] Global_t: 147, Episode_t: 3, Action: 46, Reward: 2.81, Epsilon: 0.85
[INFO] model update: t: 148, loss: 381573.21875
[INFO] Global_t: 148, Episode_t: 4, Action: 86, Reward: 1.65, Epsilon: 0.85
[INFO] model update: t: 149, loss: 85935.1015625
[INFO] Global_t: 149, Episode_t: 5, Action: 41, Reward: 1.77, Epsilon: 0.84
[INFO] model update: t: 150, loss: 134587.3125
[INFO] Global_t: 150, Episode_t: 6, Action: 166, Reward: 1.32, Epsilon: 0.84
[INFO] model update: t: 151, loss: 174383.546875
[INFO] Global_t: 151, Episode_t: 7, Action: 3, Reward: 8.91, Epsilon: 0.84
[INFO] model update: t: 152, loss: 79322.609375
[INFO] Global_t: 152, Episode_t: 8, Action: 2, Reward: 5.46, Epsilon: 0.84
  8%|▊         | 152/2000 [04:25<1:05:15,  2.12s/it]
[INFO] Global step: 152, Cumulative rewards: 25.777440000000002, Runtime (s): 265.91
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 153, loss: 196063.875
[INFO] Global_t: 153, Episode_t: 1, Action: 44, Reward: 2.78, Epsilon: 0.84
[INFO] model update: t: 154, loss: 192899.25
[INFO] Global_t: 154, Episode_t: 2, Action: 16, Reward: 3.39, Epsilon: 0.84
[INFO] model update: t: 155, loss: 148790.78125
[INFO] Global_t: 155, Episode_t: 3, Action: 22, Reward: 3.00, Epsilon: 0.84
[INFO] model update: t: 156, loss: 182769.4375
[INFO] Global_t: 156, Episode_t: 4, Action: 190, Reward: 1.42, Epsilon: 0.84
[INFO] model update: t: 157, loss: 65941.4609375
[INFO] Global_t: 157, Episode_t: 5, Action: 78, Reward: 2.15, Epsilon: 0.84
[INFO] model update: t: 158, loss: 137746.546875
[INFO] Global_t: 158, Episode_t: 6, Action: 98, Reward: 2.13, Epsilon: 0.84
[INFO] model update: t: 159, loss: 82642.8984375
[INFO] Global_t: 159, Episode_t: 7, Action: 86, Reward: 2.13, Epsilon: 0.84
[INFO] model update: t: 160, loss: 88373.4609375
[INFO] Global_t: 160, Episode_t: 8, Action: 93, Reward: 1.77, Epsilon: 0.83
  8%|▊         | 160/2000 [04:35<56:11,  1.83s/it]  
[INFO] Global step: 160, Cumulative rewards: 18.77376, Runtime (s): 275.22
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.349008560180664
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.517202377319336
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8129539489746094
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.374916076660156
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.046353340148926
average cummulative reward vector is:  [0.15259921 0.13642569 0.14464372 0.13635935 0.14879624]
average cummulative reward is:  0.14376484063425746
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 161, loss: 97915.09375
[INFO] Global_t: 161, Episode_t: 1, Action: 194, Reward: 1.51, Epsilon: 0.83
[INFO] model update: t: 162, loss: 35476.89453125
[INFO] Global_t: 162, Episode_t: 2, Action: 31, Reward: 2.71, Epsilon: 0.83
[INFO] model update: t: 163, loss: 120197.609375
[INFO] Global_t: 163, Episode_t: 3, Action: 19, Reward: 2.83, Epsilon: 0.83
[INFO] model update: t: 164, loss: 60987.83984375
[INFO] Global_t: 164, Episode_t: 4, Action: 61, Reward: 2.24, Epsilon: 0.83
[INFO] model update: t: 165, loss: 60647.35546875
[INFO] Global_t: 165, Episode_t: 5, Action: 69, Reward: 2.02, Epsilon: 0.83
[INFO] model update: t: 166, loss: 64483.0625
[INFO] Global_t: 166, Episode_t: 6, Action: 30, Reward: 1.94, Epsilon: 0.83
[INFO] model update: t: 167, loss: 64516.5625
[INFO] Global_t: 167, Episode_t: 7, Action: 4, Reward: 7.31, Epsilon: 0.83
[INFO] model update: t: 168, loss: 58205.40625
[INFO] Global_t: 168, Episode_t: 8, Action: 2, Reward: 6.02, Epsilon: 0.83
  8%|▊         | 168/2000 [05:01<1:09:10,  2.27s/it]
[INFO] Global step: 168, Cumulative rewards: 26.57568, Runtime (s): 301.43
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 169, loss: 56505.1015625
[INFO] Global_t: 169, Episode_t: 1, Action: 97, Reward: 1.87, Epsilon: 0.83
[INFO] model update: t: 170, loss: 56112.8671875
[INFO] Global_t: 170, Episode_t: 2, Action: 75, Reward: 1.36, Epsilon: 0.82
[INFO] model update: t: 171, loss: 64366.21484375
[INFO] Global_t: 171, Episode_t: 3, Action: 98, Reward: 1.85, Epsilon: 0.82
[INFO] model update: t: 172, loss: 51924.0078125
[INFO] Global_t: 172, Episode_t: 4, Action: 4, Reward: 5.56, Epsilon: 0.82
[INFO] model update: t: 173, loss: 45581.90234375
[INFO] Global_t: 173, Episode_t: 5, Action: 106, Reward: 1.25, Epsilon: 0.82
[INFO] model update: t: 174, loss: 28640.10546875
[INFO] Global_t: 174, Episode_t: 6, Action: 110, Reward: 1.31, Epsilon: 0.82
[INFO] model update: t: 175, loss: 86138.0
[INFO] Global_t: 175, Episode_t: 7, Action: 177, Reward: 1.23, Epsilon: 0.82
[INFO] model update: t: 176, loss: 78438.1484375
[INFO] Global_t: 176, Episode_t: 8, Action: 186, Reward: 1.04, Epsilon: 0.82
  9%|▉         | 176/2000 [05:05<52:46,  1.74s/it]  
[INFO] Global step: 176, Cumulative rewards: 15.480359999999997, Runtime (s): 305.44
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.104160308837891
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.480739116668701
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.003546953201294
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.389045000076294
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.104968309402466
average cummulative reward vector is:  [0.14564605 0.13557431 0.14820656 0.13640864 0.15112796]
average cummulative reward is:  0.1433927034826488
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 177, loss: 64794.37890625
[INFO] Global_t: 177, Episode_t: 1, Action: 3, Reward: 7.61, Epsilon: 0.82
[INFO] model update: t: 178, loss: 37038.83203125
[INFO] Global_t: 178, Episode_t: 2, Action: 55, Reward: 2.14, Epsilon: 0.82
[INFO] model update: t: 179, loss: 66594.453125
[INFO] Global_t: 179, Episode_t: 3, Action: 66, Reward: 1.83, Epsilon: 0.82
[INFO] model update: t: 180, loss: 55919.87890625
[INFO] Global_t: 180, Episode_t: 4, Action: 100, Reward: 1.44, Epsilon: 0.81
[INFO] model update: t: 181, loss: 93552.0
[INFO] Global_t: 181, Episode_t: 5, Action: 4, Reward: 4.72, Epsilon: 0.81
[INFO] model update: t: 182, loss: 43130.9921875
[INFO] Global_t: 182, Episode_t: 6, Action: 1, Reward: 3.39, Epsilon: 0.81
[INFO] model update: t: 183, loss: 73978.9375
[INFO] Global_t: 183, Episode_t: 7, Action: 0, Reward: 6.56, Epsilon: 0.81
[INFO] model update: t: 184, loss: 85586.03125
[INFO] Global_t: 184, Episode_t: 8, Action: 6, Reward: 5.14, Epsilon: 0.81
  9%|▉         | 184/2000 [05:31<1:06:49,  2.21s/it]
[INFO] Global step: 184, Cumulative rewards: 32.824079999999995, Runtime (s): 331.91
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 185, loss: 45297.8984375
[INFO] Global_t: 185, Episode_t: 1, Action: 102, Reward: 1.99, Epsilon: 0.81
[INFO] model update: t: 186, loss: 104159.703125
[INFO] Global_t: 186, Episode_t: 2, Action: 130, Reward: 2.09, Epsilon: 0.81
[INFO] model update: t: 187, loss: 53294.81640625
[INFO] Global_t: 187, Episode_t: 3, Action: 21, Reward: 3.43, Epsilon: 0.81
[INFO] model update: t: 188, loss: 48155.01953125
[INFO] Global_t: 188, Episode_t: 4, Action: 117, Reward: 1.31, Epsilon: 0.81
[INFO] model update: t: 189, loss: 29519.0078125
[INFO] Global_t: 189, Episode_t: 5, Action: 80, Reward: 1.71, Epsilon: 0.81
[INFO] model update: t: 190, loss: 41916.7890625
[INFO] Global_t: 190, Episode_t: 6, Action: 172, Reward: 1.86, Epsilon: 0.80
[INFO] model update: t: 191, loss: 50262.609375
[INFO] Global_t: 191, Episode_t: 7, Action: 6, Reward: 3.74, Epsilon: 0.80
[INFO] model update: t: 192, loss: 50965.0
[INFO] Global_t: 192, Episode_t: 8, Action: 3, Reward: 6.06, Epsilon: 0.80

[INFO] Global step: 192, Cumulative rewards: 22.19292, Runtime (s): 336.16
 10%|▉         | 192/2000 [05:36<51:22,  1.71s/it]  ------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.239277601242065
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.310447454452515
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5372414588928223
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.50797438621521
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.963548183441162
average cummulative reward vector is:  [0.15124395 0.13213958 0.13170082 0.13788364 0.14409328]
average cummulative reward is:  0.13941225496071824
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 193, loss: 65827.109375
[INFO] Global_t: 193, Episode_t: 1, Action: 127, Reward: 1.47, Epsilon: 0.80
[INFO] model update: t: 194, loss: 30449.787109375
[INFO] Global_t: 194, Episode_t: 2, Action: 69, Reward: 1.79, Epsilon: 0.80
[INFO] model update: t: 195, loss: 44488.6796875
[INFO] Global_t: 195, Episode_t: 3, Action: 54, Reward: 2.17, Epsilon: 0.80
[INFO] model update: t: 196, loss: 20144.4609375
[INFO] Global_t: 196, Episode_t: 4, Action: 5, Reward: 6.62, Epsilon: 0.80
[INFO] model update: t: 197, loss: 53731.6640625
[INFO] Global_t: 197, Episode_t: 5, Action: 209, Reward: 1.35, Epsilon: 0.80
[INFO] model update: t: 198, loss: 50394.1953125
[INFO] Global_t: 198, Episode_t: 6, Action: 142, Reward: 1.42, Epsilon: 0.80
[INFO] model update: t: 199, loss: 58192.1015625
[INFO] Global_t: 199, Episode_t: 7, Action: 141, Reward: 1.33, Epsilon: 0.80
[INFO] model update: t: 200, loss: 39861.515625
[INFO] Global_t: 200, Episode_t: 8, Action: 68, Reward: 1.64, Epsilon: 0.79
 10%|█         | 200/2000 [06:01<1:04:32,  2.15s/it]
[INFO] Global step: 200, Cumulative rewards: 17.79312, Runtime (s): 361.71
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 201, loss: 45982.84765625
[INFO] Global_t: 201, Episode_t: 1, Action: 114, Reward: 2.64, Epsilon: 0.79
[INFO] model update: t: 202, loss: 30224.060546875
[INFO] Global_t: 202, Episode_t: 2, Action: 82, Reward: 1.98, Epsilon: 0.79
[INFO] model update: t: 203, loss: 58571.26171875
[INFO] Global_t: 203, Episode_t: 3, Action: 3, Reward: 6.26, Epsilon: 0.79
[INFO] model update: t: 204, loss: 37929.5234375
[INFO] Global_t: 204, Episode_t: 4, Action: 167, Reward: 1.16, Epsilon: 0.79
[INFO] model update: t: 205, loss: 63203.4140625
[INFO] Global_t: 205, Episode_t: 5, Action: 38, Reward: 2.39, Epsilon: 0.79
[INFO] model update: t: 206, loss: 35408.41796875
[INFO] Global_t: 206, Episode_t: 6, Action: 135, Reward: 1.72, Epsilon: 0.79
[INFO] model update: t: 207, loss: 45974.125
[INFO] Global_t: 207, Episode_t: 7, Action: 44, Reward: 2.33, Epsilon: 0.79
[INFO] model update: t: 208, loss: 45528.86328125
[INFO] Global_t: 208, Episode_t: 8, Action: 149, Reward: 1.47, Epsilon: 0.79
 10%|█         | 208/2000 [06:06<50:07,  1.68s/it]  
[INFO] Global step: 208, Cumulative rewards: 19.958039999999997, Runtime (s): 366.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.088972330093384
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.51533317565918
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8183367252349854
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.508565187454224
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.984865665435791
average cummulative reward vector is:  [0.144835   0.13806204 0.14143251 0.13931238 0.14658145]
average cummulative reward is:  0.14204467709774252
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 209, loss: 47785.15625
[INFO] Global_t: 209, Episode_t: 1, Action: 180, Reward: 1.23, Epsilon: 0.79
[INFO] model update: t: 210, loss: 26687.51953125
[INFO] Global_t: 210, Episode_t: 2, Action: 78, Reward: 1.55, Epsilon: 0.79
[INFO] model update: t: 211, loss: 45351.890625
[INFO] Global_t: 211, Episode_t: 3, Action: 21, Reward: 2.44, Epsilon: 0.78
[INFO] model update: t: 212, loss: 40373.265625
[INFO] Global_t: 212, Episode_t: 4, Action: 27, Reward: 2.37, Epsilon: 0.78
[INFO] model update: t: 213, loss: 40303.3515625
[INFO] Global_t: 213, Episode_t: 5, Action: 104, Reward: 1.40, Epsilon: 0.78
[INFO] model update: t: 214, loss: 41266.48046875
[INFO] Global_t: 214, Episode_t: 6, Action: 3, Reward: 7.63, Epsilon: 0.78
[INFO] model update: t: 215, loss: 27736.568359375
[INFO] Global_t: 215, Episode_t: 7, Action: 116, Reward: 1.69, Epsilon: 0.78
[INFO] model update: t: 216, loss: 55127.375
[INFO] Global_t: 216, Episode_t: 8, Action: 14, Reward: 2.96, Epsilon: 0.78
 11%|█         | 216/2000 [06:31<1:02:30,  2.10s/it]
[INFO] Global step: 216, Cumulative rewards: 21.266519999999996, Runtime (s): 391.04
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 217, loss: 48205.296875
[INFO] Global_t: 217, Episode_t: 1, Action: 66, Reward: 1.53, Epsilon: 0.78
[INFO] model update: t: 218, loss: 74839.5703125
[INFO] Global_t: 218, Episode_t: 2, Action: 6, Reward: 4.72, Epsilon: 0.78
[INFO] model update: t: 219, loss: 39527.359375
[INFO] Global_t: 219, Episode_t: 3, Action: 150, Reward: 1.63, Epsilon: 0.78
[INFO] model update: t: 220, loss: 79140.0859375
[INFO] Global_t: 220, Episode_t: 4, Action: 141, Reward: 1.26, Epsilon: 0.78
[INFO] model update: t: 221, loss: 49730.3359375
[INFO] Global_t: 221, Episode_t: 5, Action: 17, Reward: 2.55, Epsilon: 0.77
[INFO] model update: t: 222, loss: 66821.9375
[INFO] Global_t: 222, Episode_t: 6, Action: 1, Reward: 4.07, Epsilon: 0.77
[INFO] model update: t: 223, loss: 36697.5625
[INFO] Global_t: 223, Episode_t: 7, Action: 154, Reward: 1.33, Epsilon: 0.77
[INFO] model update: t: 224, loss: 38035.85546875
[INFO] Global_t: 224, Episode_t: 8, Action: 2, Reward: 5.24, Epsilon: 0.77
 11%|█         | 224/2000 [06:35<48:48,  1.65s/it]  
[INFO] Global step: 224, Cumulative rewards: 22.333559999999995, Runtime (s): 395.77
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.035246849060059
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.520772457122803
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8144426345825195
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.971093416213989
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.018935680389404
average cummulative reward vector is:  [0.14435605 0.1378206  0.14196858 0.14656939 0.14509247]
average cummulative reward is:  0.1431614198720095
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 225, loss: 42245.63671875
[INFO] Global_t: 225, Episode_t: 1, Action: 130, Reward: 1.80, Epsilon: 0.77
[INFO] model update: t: 226, loss: 20474.2109375
[INFO] Global_t: 226, Episode_t: 2, Action: 3, Reward: 6.93, Epsilon: 0.77
[INFO] model update: t: 227, loss: 33276.81640625
[INFO] Global_t: 227, Episode_t: 3, Action: 136, Reward: 1.66, Epsilon: 0.77
[INFO] model update: t: 228, loss: 26668.146484375
[INFO] Global_t: 228, Episode_t: 4, Action: 175, Reward: 1.23, Epsilon: 0.77
[INFO] model update: t: 229, loss: 40456.84765625
[INFO] Global_t: 229, Episode_t: 5, Action: 87, Reward: 1.31, Epsilon: 0.77
[INFO] model update: t: 230, loss: 51099.58203125
[INFO] Global_t: 230, Episode_t: 6, Action: 6, Reward: 5.82, Epsilon: 0.77
[INFO] model update: t: 231, loss: 46654.7734375
[INFO] Global_t: 231, Episode_t: 7, Action: 33, Reward: 1.88, Epsilon: 0.76
[INFO] model update: t: 232, loss: 35898.85546875
[INFO] Global_t: 232, Episode_t: 8, Action: 179, Reward: 1.28, Epsilon: 0.76
 12%|█▏        | 232/2000 [07:02<1:03:13,  2.15s/it]
[INFO] Global step: 232, Cumulative rewards: 21.91152, Runtime (s): 422.21
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 233, loss: 43695.5625
[INFO] Global_t: 233, Episode_t: 1, Action: 1, Reward: 7.34, Epsilon: 0.76
[INFO] model update: t: 234, loss: 38993.453125
[INFO] Global_t: 234, Episode_t: 2, Action: 72, Reward: 2.14, Epsilon: 0.76
[INFO] model update: t: 235, loss: 47982.99609375
[INFO] Global_t: 235, Episode_t: 3, Action: 158, Reward: 2.06, Epsilon: 0.76
[INFO] model update: t: 236, loss: 59515.3984375
[INFO] Global_t: 236, Episode_t: 4, Action: 194, Reward: 2.39, Epsilon: 0.76
[INFO] model update: t: 237, loss: 26275.439453125
[INFO] Global_t: 237, Episode_t: 5, Action: 4, Reward: 6.37, Epsilon: 0.76
[INFO] model update: t: 238, loss: 30395.12890625
[INFO] Global_t: 238, Episode_t: 6, Action: 63, Reward: 2.02, Epsilon: 0.76
[INFO] model update: t: 239, loss: 47047.5
[INFO] Global_t: 239, Episode_t: 7, Action: 32, Reward: 1.83, Epsilon: 0.76
[INFO] model update: t: 240, loss: 20496.263671875
[INFO] Global_t: 240, Episode_t: 8, Action: 3, Reward: 6.21, Epsilon: 0.76
 12%|█▏        | 240/2000 [07:07<50:03,  1.71s/it]  
[INFO] Global step: 240, Cumulative rewards: 30.363239999999998, Runtime (s): 427.66
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.166654825210571
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.619752883911133
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.06251335144043
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.329060316085815
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.863708257675171
average cummulative reward vector is:  [0.14773158 0.14087986 0.15254016 0.13268715 0.13982742]
average cummulative reward is:  0.14273323457609094
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 241, loss: 19347.33203125
[INFO] Global_t: 241, Episode_t: 1, Action: 73, Reward: 2.02, Epsilon: 0.75
[INFO] model update: t: 242, loss: 54247.3203125
[INFO] Global_t: 242, Episode_t: 2, Action: 120, Reward: 1.89, Epsilon: 0.75
[INFO] model update: t: 243, loss: 48422.828125
[INFO] Global_t: 243, Episode_t: 3, Action: 132, Reward: 1.53, Epsilon: 0.75
[INFO] model update: t: 244, loss: 44586.0703125
[INFO] Global_t: 244, Episode_t: 4, Action: 67, Reward: 2.31, Epsilon: 0.75
[INFO] model update: t: 245, loss: 47640.51171875
[INFO] Global_t: 245, Episode_t: 5, Action: 142, Reward: 1.41, Epsilon: 0.75
[INFO] model update: t: 246, loss: 42664.796875
[INFO] Global_t: 246, Episode_t: 6, Action: 197, Reward: 1.78, Epsilon: 0.75
[INFO] model update: t: 247, loss: 48803.8203125
[INFO] Global_t: 247, Episode_t: 7, Action: 178, Reward: 1.78, Epsilon: 0.75
[INFO] model update: t: 248, loss: 38978.79296875
[INFO] Global_t: 248, Episode_t: 8, Action: 47, Reward: 2.37, Epsilon: 0.75
 12%|█▏        | 248/2000 [07:35<1:05:49,  2.25s/it]
[INFO] Global step: 248, Cumulative rewards: 15.098639999999996, Runtime (s): 455.92
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 249, loss: 34301.828125
[INFO] Global_t: 249, Episode_t: 1, Action: 86, Reward: 1.91, Epsilon: 0.75
[INFO] model update: t: 250, loss: 27674.66015625
[INFO] Global_t: 250, Episode_t: 2, Action: 107, Reward: 1.26, Epsilon: 0.75
[INFO] model update: t: 251, loss: 27097.84765625
[INFO] Global_t: 251, Episode_t: 3, Action: 155, Reward: 1.68, Epsilon: 0.74
[INFO] model update: t: 252, loss: 44231.5078125
[INFO] Global_t: 252, Episode_t: 4, Action: 122, Reward: 2.33, Epsilon: 0.74
[INFO] model update: t: 253, loss: 15917.818359375
[INFO] Global_t: 253, Episode_t: 5, Action: 89, Reward: 1.51, Epsilon: 0.74
[INFO] model update: t: 254, loss: 46181.3359375
[INFO] Global_t: 254, Episode_t: 6, Action: 41, Reward: 2.31, Epsilon: 0.74
[INFO] model update: t: 255, loss: 26259.44140625
[INFO] Global_t: 255, Episode_t: 7, Action: 158, Reward: 1.11, Epsilon: 0.74
[INFO] model update: t: 256, loss: 16703.076171875
[INFO] Global_t: 256, Episode_t: 8, Action: 97, Reward: 2.03, Epsilon: 0.74

[INFO] Global step: 256, Cumulative rewards: 14.147040000000004, Runtime (s): 461.17
------------------------------------------------------------
 
 13%|█▎        | 256/2000 [07:41<51:35,  1.77s/it]  
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.00602912902832
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.327916145324707
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.696079730987549
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.432949542999268
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.029613256454468
average cummulative reward vector is:  [0.14132368 0.13336273 0.14006202 0.13695935 0.14660349]
average cummulative reward is:  0.13966225559359594
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 257, loss: 33516.5859375
[INFO] Global_t: 257, Episode_t: 1, Action: 3, Reward: 7.78, Epsilon: 0.74
[INFO] model update: t: 258, loss: 11062.234375
[INFO] Global_t: 258, Episode_t: 2, Action: 1, Reward: 6.37, Epsilon: 0.74
[INFO] model update: t: 259, loss: 25995.55078125
[INFO] Global_t: 259, Episode_t: 3, Action: 125, Reward: 2.12, Epsilon: 0.74
[INFO] model update: t: 260, loss: 37439.1875
[INFO] Global_t: 260, Episode_t: 4, Action: 0, Reward: 5.36, Epsilon: 0.74
[INFO] model update: t: 261, loss: 18967.453125
[INFO] Global_t: 261, Episode_t: 5, Action: 4, Reward: 6.01, Epsilon: 0.74
[INFO] model update: t: 262, loss: 53906.578125
[INFO] Global_t: 262, Episode_t: 6, Action: 164, Reward: 0.96, Epsilon: 0.73
[INFO] model update: t: 263, loss: 51783.375
[INFO] Global_t: 263, Episode_t: 7, Action: 2, Reward: 6.29, Epsilon: 0.73
[INFO] model update: t: 264, loss: 27494.41796875
[INFO] Global_t: 264, Episode_t: 8, Action: 10, Reward: 4.37, Epsilon: 0.73
 13%|█▎        | 264/2000 [08:07<1:04:20,  2.22s/it]
[INFO] Global step: 264, Cumulative rewards: 39.269999999999996, Runtime (s): 487.34
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 265, loss: 36490.296875
[INFO] Global_t: 265, Episode_t: 1, Action: 193, Reward: 1.29, Epsilon: 0.73
[INFO] model update: t: 266, loss: 64495.4765625
[INFO] Global_t: 266, Episode_t: 2, Action: 87, Reward: 1.94, Epsilon: 0.73
[INFO] model update: t: 267, loss: 32864.359375
[INFO] Global_t: 267, Episode_t: 3, Action: 12, Reward: 3.55, Epsilon: 0.73
[INFO] model update: t: 268, loss: 46925.6640625
[INFO] Global_t: 268, Episode_t: 4, Action: 97, Reward: 1.76, Epsilon: 0.73
[INFO] model update: t: 269, loss: 13619.916015625
[INFO] Global_t: 269, Episode_t: 5, Action: 142, Reward: 2.67, Epsilon: 0.73
[INFO] model update: t: 270, loss: 49877.1640625
[INFO] Global_t: 270, Episode_t: 6, Action: 182, Reward: 1.82, Epsilon: 0.73
[INFO] model update: t: 271, loss: 31659.634765625
[INFO] Global_t: 271, Episode_t: 7, Action: 71, Reward: 1.90, Epsilon: 0.73
[INFO] model update: t: 272, loss: 21796.19921875
[INFO] Global_t: 272, Episode_t: 8, Action: 38, Reward: 2.42, Epsilon: 0.72
 14%|█▎        | 272/2000 [08:11<48:53,  1.70s/it]  
[INFO] Global step: 272, Cumulative rewards: 17.350440000000003, Runtime (s): 491.09
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.120558500289917
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.910565137863159
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.239050388336182
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.629503488540649
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.008760213851929
average cummulative reward vector is:  [0.14421895 0.12208495 0.15842623 0.14239696 0.14448253]
average cummulative reward is:  0.14232192401577287
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 273, loss: 29766.08203125
[INFO] Global_t: 273, Episode_t: 1, Action: 5, Reward: 7.33, Epsilon: 0.72
[INFO] model update: t: 274, loss: 25099.40625
[INFO] Global_t: 274, Episode_t: 2, Action: 3, Reward: 8.36, Epsilon: 0.72
[INFO] model update: t: 275, loss: 36827.109375
[INFO] Global_t: 275, Episode_t: 3, Action: 13, Reward: 4.94, Epsilon: 0.72
[INFO] model update: t: 276, loss: 14111.2509765625
[INFO] Global_t: 276, Episode_t: 4, Action: 113, Reward: 1.62, Epsilon: 0.72
[INFO] model update: t: 277, loss: 20248.1015625
[INFO] Global_t: 277, Episode_t: 5, Action: 1, Reward: 4.43, Epsilon: 0.72
[INFO] model update: t: 278, loss: 16866.751953125
[INFO] Global_t: 278, Episode_t: 6, Action: 103, Reward: 1.42, Epsilon: 0.72
[INFO] model update: t: 279, loss: 27054.625
[INFO] Global_t: 279, Episode_t: 7, Action: 112, Reward: 1.59, Epsilon: 0.72
[INFO] model update: t: 280, loss: 17734.001953125
[INFO] Global_t: 280, Episode_t: 8, Action: 0, Reward: 2.95, Epsilon: 0.72
 14%|█▍        | 280/2000 [08:38<1:03:25,  2.21s/it]
[INFO] Global step: 280, Cumulative rewards: 32.64684, Runtime (s): 518.41
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 281, loss: 34752.51171875
[INFO] Global_t: 281, Episode_t: 1, Action: 0, Reward: 6.70, Epsilon: 0.72
[INFO] model update: t: 282, loss: 29426.08984375
[INFO] Global_t: 282, Episode_t: 2, Action: 185, Reward: 1.63, Epsilon: 0.71
[INFO] model update: t: 283, loss: 22619.84765625
[INFO] Global_t: 283, Episode_t: 3, Action: 158, Reward: 1.40, Epsilon: 0.71
[INFO] model update: t: 284, loss: 23206.466796875
[INFO] Global_t: 284, Episode_t: 4, Action: 7, Reward: 5.22, Epsilon: 0.71
[INFO] model update: t: 285, loss: 35583.80859375
[INFO] Global_t: 285, Episode_t: 5, Action: 86, Reward: 1.11, Epsilon: 0.71
[INFO] model update: t: 286, loss: 32211.41796875
[INFO] Global_t: 286, Episode_t: 6, Action: 37, Reward: 2.68, Epsilon: 0.71
[INFO] model update: t: 287, loss: 29433.861328125
[INFO] Global_t: 287, Episode_t: 7, Action: 3, Reward: 4.77, Epsilon: 0.71
[INFO] model update: t: 288, loss: 23463.00390625
[INFO] Global_t: 288, Episode_t: 8, Action: 161, Reward: 1.01, Epsilon: 0.71
 14%|█▍        | 288/2000 [08:43<49:13,  1.73s/it]  
[INFO] Global step: 288, Cumulative rewards: 24.517199999999995, Runtime (s): 523.11
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.497003793716431
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.360561847686768
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.362392902374268
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.156417608261108
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.945427894592285
average cummulative reward vector is:  [0.15598763 0.13235023 0.15469426 0.13063715 0.14757043]
average cummulative reward is:  0.1442479409991496
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 289, loss: 39275.6015625
[INFO] Global_t: 289, Episode_t: 1, Action: 2, Reward: 6.09, Epsilon: 0.71
[INFO] model update: t: 290, loss: 29598.140625
[INFO] Global_t: 290, Episode_t: 2, Action: 180, Reward: 1.25, Epsilon: 0.71
[INFO] model update: t: 291, loss: 23943.943359375
[INFO] Global_t: 291, Episode_t: 3, Action: 162, Reward: 1.15, Epsilon: 0.71
[INFO] model update: t: 292, loss: 19234.7578125
[INFO] Global_t: 292, Episode_t: 4, Action: 123, Reward: 1.66, Epsilon: 0.70
[INFO] model update: t: 293, loss: 29264.9375
[INFO] Global_t: 293, Episode_t: 5, Action: 85, Reward: 1.18, Epsilon: 0.70
[INFO] model update: t: 294, loss: 18164.66796875
[INFO] Global_t: 294, Episode_t: 6, Action: 49, Reward: 1.83, Epsilon: 0.70
[INFO] model update: t: 295, loss: 35048.0078125
[INFO] Global_t: 295, Episode_t: 7, Action: 136, Reward: 1.11, Epsilon: 0.70
[INFO] model update: t: 296, loss: 33544.515625
[INFO] Global_t: 296, Episode_t: 8, Action: 56, Reward: 1.79, Epsilon: 0.70
 15%|█▍        | 296/2000 [09:09<1:01:53,  2.18s/it]
[INFO] Global step: 296, Cumulative rewards: 16.053959999999996, Runtime (s): 549.02
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 297, loss: 77441.4375
[INFO] Global_t: 297, Episode_t: 1, Action: 34, Reward: 3.47, Epsilon: 0.70
[INFO] model update: t: 298, loss: 21264.89453125
[INFO] Global_t: 298, Episode_t: 2, Action: 95, Reward: 1.50, Epsilon: 0.70
[INFO] model update: t: 299, loss: 21057.5625
[INFO] Global_t: 299, Episode_t: 3, Action: 148, Reward: 1.77, Epsilon: 0.70
[INFO] model update: t: 300, loss: 16826.296875
[INFO] Global_t: 300, Episode_t: 4, Action: 1, Reward: 8.23, Epsilon: 0.70
[INFO] model update: t: 301, loss: 18045.470703125
[INFO] Global_t: 301, Episode_t: 5, Action: 52, Reward: 1.57, Epsilon: 0.70
[INFO] model update: t: 302, loss: 30697.46484375
[INFO] Global_t: 302, Episode_t: 6, Action: 4, Reward: 7.45, Epsilon: 0.70
[INFO] model update: t: 303, loss: 25198.185546875
[INFO] Global_t: 303, Episode_t: 7, Action: 166, Reward: 1.68, Epsilon: 0.69
[INFO] model update: t: 304, loss: 22974.591796875
[INFO] Global_t: 304, Episode_t: 8, Action: 9, Reward: 6.79, Epsilon: 0.69
 15%|█▌        | 304/2000 [09:13<48:08,  1.70s/it]  
[INFO] Global step: 304, Cumulative rewards: 32.4552, Runtime (s): 553.76
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.127133846282959
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.429498672485352
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9454262256622314
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.344703435897827
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.156425476074219
average cummulative reward vector is:  [0.14324947 0.13406065 0.14237432 0.13555023 0.15249758]
average cummulative reward is:  0.1415464506124541
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 305, loss: 38436.5078125
[INFO] Global_t: 305, Episode_t: 1, Action: 3, Reward: 7.52, Epsilon: 0.69
[INFO] model update: t: 306, loss: 38339.79296875
[INFO] Global_t: 306, Episode_t: 2, Action: 83, Reward: 1.57, Epsilon: 0.69
[INFO] model update: t: 307, loss: 39240.734375
[INFO] Global_t: 307, Episode_t: 3, Action: 199, Reward: 1.50, Epsilon: 0.69
[INFO] model update: t: 308, loss: 78937.4375
[INFO] Global_t: 308, Episode_t: 4, Action: 31, Reward: 2.56, Epsilon: 0.69
[INFO] model update: t: 309, loss: 24831.109375
[INFO] Global_t: 309, Episode_t: 5, Action: 67, Reward: 1.76, Epsilon: 0.69
[INFO] model update: t: 310, loss: 41384.28515625
[INFO] Global_t: 310, Episode_t: 6, Action: 168, Reward: 1.58, Epsilon: 0.69
[INFO] model update: t: 311, loss: 45670.34765625
[INFO] Global_t: 311, Episode_t: 7, Action: 210, Reward: 0.92, Epsilon: 0.69
[INFO] model update: t: 312, loss: 16907.955078125
[INFO] Global_t: 312, Episode_t: 8, Action: 108, Reward: 1.75, Epsilon: 0.69
 16%|█▌        | 312/2000 [09:39<1:01:12,  2.18s/it]
[INFO] Global step: 312, Cumulative rewards: 19.16628, Runtime (s): 579.98
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 313, loss: 29386.72265625
[INFO] Global_t: 313, Episode_t: 1, Action: 2, Reward: 6.09, Epsilon: 0.68
[INFO] model update: t: 314, loss: 18774.974609375
[INFO] Global_t: 314, Episode_t: 2, Action: 27, Reward: 1.77, Epsilon: 0.68
[INFO] model update: t: 315, loss: 19338.12109375
[INFO] Global_t: 315, Episode_t: 3, Action: 4, Reward: 5.18, Epsilon: 0.68
[INFO] model update: t: 316, loss: 36685.4609375
[INFO] Global_t: 316, Episode_t: 4, Action: 1, Reward: 5.52, Epsilon: 0.68
[INFO] model update: t: 317, loss: 34347.96875
[INFO] Global_t: 317, Episode_t: 5, Action: 35, Reward: 2.31, Epsilon: 0.68
[INFO] model update: t: 318, loss: 30192.62890625
[INFO] Global_t: 318, Episode_t: 6, Action: 105, Reward: 1.44, Epsilon: 0.68
[INFO] model update: t: 319, loss: 38652.3046875
[INFO] Global_t: 319, Episode_t: 7, Action: 143, Reward: 1.26, Epsilon: 0.68
[INFO] model update: t: 320, loss: 13486.2265625
[INFO] Global_t: 320, Episode_t: 8, Action: 0, Reward: 5.45, Epsilon: 0.68
 16%|█▌        | 320/2000 [09:48<51:18,  1.83s/it]  
[INFO] Global step: 320, Cumulative rewards: 29.023919999999997, Runtime (s): 588.23
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.424740552902222
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.329785108566284
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.18528938293457
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.797689437866211
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.174985408782959
average cummulative reward vector is:  [0.15681789 0.13302685 0.15792923 0.14658785 0.15325968]
average cummulative reward is:  0.14952430188960325
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 321, loss: 25498.060546875
[INFO] Global_t: 321, Episode_t: 1, Action: 164, Reward: 1.46, Epsilon: 0.68
[INFO] model update: t: 322, loss: 18781.546875
[INFO] Global_t: 322, Episode_t: 2, Action: 3, Reward: 5.93, Epsilon: 0.68
[INFO] model update: t: 323, loss: 11530.47265625
[INFO] Global_t: 323, Episode_t: 3, Action: 167, Reward: 1.56, Epsilon: 0.67
[INFO] model update: t: 324, loss: 24846.509765625
[INFO] Global_t: 324, Episode_t: 4, Action: 62, Reward: 1.76, Epsilon: 0.67
[INFO] model update: t: 325, loss: 22371.59765625
[INFO] Global_t: 325, Episode_t: 5, Action: 8, Reward: 5.95, Epsilon: 0.67
[INFO] model update: t: 326, loss: 11984.2822265625
[INFO] Global_t: 326, Episode_t: 6, Action: 57, Reward: 1.62, Epsilon: 0.67
[INFO] model update: t: 327, loss: 17403.89453125
[INFO] Global_t: 327, Episode_t: 7, Action: 5, Reward: 4.25, Epsilon: 0.67
[INFO] model update: t: 328, loss: 14565.5244140625
[INFO] Global_t: 328, Episode_t: 8, Action: 44, Reward: 2.43, Epsilon: 0.67

[INFO] Global step: 328, Cumulative rewards: 24.96732, Runtime (s): 614.49
------------------------------------------------------------
 
 16%|█▋        | 328/2000 [10:14<1:03:10,  2.27s/it]graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 329, loss: 25175.78515625
[INFO] Global_t: 329, Episode_t: 1, Action: 42, Reward: 2.30, Epsilon: 0.67
[INFO] model update: t: 330, loss: 26902.294921875
[INFO] Global_t: 330, Episode_t: 2, Action: 93, Reward: 1.40, Epsilon: 0.67
[INFO] model update: t: 331, loss: 17727.626953125
[INFO] Global_t: 331, Episode_t: 3, Action: 108, Reward: 1.38, Epsilon: 0.67
[INFO] model update: t: 332, loss: 17412.798828125
[INFO] Global_t: 332, Episode_t: 4, Action: 1, Reward: 5.75, Epsilon: 0.67
[INFO] model update: t: 333, loss: 24069.2109375
[INFO] Global_t: 333, Episode_t: 5, Action: 72, Reward: 1.24, Epsilon: 0.66
[INFO] model update: t: 334, loss: 26506.34375
[INFO] Global_t: 334, Episode_t: 6, Action: 98, Reward: 1.55, Epsilon: 0.66
[INFO] model update: t: 335, loss: 61028.953125
[INFO] Global_t: 335, Episode_t: 7, Action: 15, Reward: 1.69, Epsilon: 0.66
[INFO] model update: t: 336, loss: 8617.423828125
[INFO] Global_t: 336, Episode_t: 8, Action: 84, Reward: 1.35, Epsilon: 0.66
 17%|█▋        | 336/2000 [10:19<48:44,  1.76s/it]  
[INFO] Global step: 336, Cumulative rewards: 16.66716, Runtime (s): 619.03
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.976173162460327
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.83393120765686
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.139618873596191
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.475967168807983
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.092193603515625
average cummulative reward vector is:  [0.14190947 0.14560301 0.15586503 0.13713364 0.15126425]
average cummulative reward is:  0.14635508048750306
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 337, loss: 85430.75
[INFO] Global_t: 337, Episode_t: 1, Action: 3, Reward: 8.86, Epsilon: 0.66
[INFO] model update: t: 338, loss: 94504.625
[INFO] Global_t: 338, Episode_t: 2, Action: 123, Reward: 1.23, Epsilon: 0.66
[INFO] model update: t: 339, loss: 28338.51171875
[INFO] Global_t: 339, Episode_t: 3, Action: 141, Reward: 1.90, Epsilon: 0.66
[INFO] model update: t: 340, loss: 86007.328125
[INFO] Global_t: 340, Episode_t: 4, Action: 82, Reward: 1.48, Epsilon: 0.66
[INFO] model update: t: 341, loss: 20425.4921875
[INFO] Global_t: 341, Episode_t: 5, Action: 54, Reward: 2.18, Epsilon: 0.66
[INFO] model update: t: 342, loss: 91791.078125
[INFO] Global_t: 342, Episode_t: 6, Action: 133, Reward: 1.81, Epsilon: 0.66
[INFO] model update: t: 343, loss: 23191.33984375
[INFO] Global_t: 343, Episode_t: 7, Action: 6, Reward: 5.78, Epsilon: 0.65
[INFO] model update: t: 344, loss: 68983.4765625
[INFO] Global_t: 344, Episode_t: 8, Action: 113, Reward: 1.99, Epsilon: 0.65
 17%|█▋        | 344/2000 [10:54<1:10:42,  2.56s/it]
[INFO] Global step: 344, Cumulative rewards: 25.22784, Runtime (s): 654.55
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 345, loss: 39131.2890625
[INFO] Global_t: 345, Episode_t: 1, Action: 100, Reward: 1.93, Epsilon: 0.65
[INFO] model update: t: 346, loss: 81965.78125
[INFO] Global_t: 346, Episode_t: 2, Action: 19, Reward: 3.08, Epsilon: 0.65
[INFO] model update: t: 347, loss: 24725.1875
[INFO] Global_t: 347, Episode_t: 3, Action: 97, Reward: 1.59, Epsilon: 0.65
[INFO] model update: t: 348, loss: 62811.25390625
[INFO] Global_t: 348, Episode_t: 4, Action: 145, Reward: 1.53, Epsilon: 0.65
[INFO] model update: t: 349, loss: 14767.0654296875
[INFO] Global_t: 349, Episode_t: 5, Action: 63, Reward: 2.49, Epsilon: 0.65
[INFO] model update: t: 350, loss: 23055.076171875
[INFO] Global_t: 350, Episode_t: 6, Action: 18, Reward: 3.11, Epsilon: 0.65
[INFO] model update: t: 351, loss: 40148.84765625
[INFO] Global_t: 351, Episode_t: 7, Action: 91, Reward: 1.07, Epsilon: 0.65
[INFO] model update: t: 352, loss: 10996.6103515625
[INFO] Global_t: 352, Episode_t: 8, Action: 76, Reward: 1.92, Epsilon: 0.65
 18%|█▊        | 352/2000 [11:00<55:30,  2.02s/it]  
[INFO] Global step: 352, Cumulative rewards: 16.71456, Runtime (s): 660.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.210010051727295
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9569170475006104
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.885380744934082
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.423672676086426
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8788540363311768
average cummulative reward vector is:  [0.15119237 0.12073495 0.14552158 0.13610911 0.13922823]
average cummulative reward is:  0.13855724895603883
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 353, loss: 34743.578125
[INFO] Global_t: 353, Episode_t: 1, Action: 146, Reward: 1.30, Epsilon: 0.65
[INFO] model update: t: 354, loss: 30782.404296875
[INFO] Global_t: 354, Episode_t: 2, Action: 182, Reward: 1.71, Epsilon: 0.64
[INFO] model update: t: 355, loss: 19372.08203125
[INFO] Global_t: 355, Episode_t: 3, Action: 128, Reward: 1.22, Epsilon: 0.64
[INFO] model update: t: 356, loss: 22420.76953125
[INFO] Global_t: 356, Episode_t: 4, Action: 99, Reward: 1.59, Epsilon: 0.64
[INFO] model update: t: 357, loss: 26264.806640625
[INFO] Global_t: 357, Episode_t: 5, Action: 3, Reward: 6.15, Epsilon: 0.64
[INFO] model update: t: 358, loss: 11983.15625
[INFO] Global_t: 358, Episode_t: 6, Action: 20, Reward: 2.21, Epsilon: 0.64
[INFO] model update: t: 359, loss: 37554.828125
[INFO] Global_t: 359, Episode_t: 7, Action: 71, Reward: 1.42, Epsilon: 0.64
[INFO] model update: t: 360, loss: 23253.390625
[INFO] Global_t: 360, Episode_t: 8, Action: 104, Reward: 1.66, Epsilon: 0.64
 18%|█▊        | 360/2000 [11:26<1:05:06,  2.38s/it]
[INFO] Global step: 360, Cumulative rewards: 17.239559999999997, Runtime (s): 686.40
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 361, loss: 19592.458984375
[INFO] Global_t: 361, Episode_t: 1, Action: 174, Reward: 1.86, Epsilon: 0.64
[INFO] model update: t: 362, loss: 19184.53125
[INFO] Global_t: 362, Episode_t: 2, Action: 5, Reward: 5.08, Epsilon: 0.64
[INFO] model update: t: 363, loss: 29987.296875
[INFO] Global_t: 363, Episode_t: 3, Action: 3, Reward: 6.42, Epsilon: 0.64
[INFO] model update: t: 364, loss: 23337.8125
[INFO] Global_t: 364, Episode_t: 4, Action: 0, Reward: 4.80, Epsilon: 0.63
[INFO] model update: t: 365, loss: 27487.560546875
[INFO] Global_t: 365, Episode_t: 5, Action: 6, Reward: 4.28, Epsilon: 0.63
[INFO] model update: t: 366, loss: 29292.90625
[INFO] Global_t: 366, Episode_t: 6, Action: 82, Reward: 1.68, Epsilon: 0.63
[INFO] model update: t: 367, loss: 19616.623046875
[INFO] Global_t: 367, Episode_t: 7, Action: 64, Reward: 1.15, Epsilon: 0.63
[INFO] model update: t: 368, loss: 19768.44921875
[INFO] Global_t: 368, Episode_t: 8, Action: 170, Reward: 1.37, Epsilon: 0.63
 18%|█▊        | 368/2000 [11:31<50:18,  1.85s/it]  
[INFO] Global step: 368, Cumulative rewards: 26.66064, Runtime (s): 691.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.058205842971802
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.494815826416016
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7933382987976074
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.27280330657959
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.07469916343689
average cummulative reward vector is:  [0.14024395 0.13959329 0.14386885 0.13230234 0.14498065]
average cummulative reward is:  0.14019781369487258
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 369, loss: 25700.466796875
[INFO] Global_t: 369, Episode_t: 1, Action: 4, Reward: 7.39, Epsilon: 0.63
[INFO] model update: t: 370, loss: 41213.46875
[INFO] Global_t: 370, Episode_t: 2, Action: 86, Reward: 1.57, Epsilon: 0.63
[INFO] model update: t: 371, loss: 18703.38671875
[INFO] Global_t: 371, Episode_t: 3, Action: 164, Reward: 1.50, Epsilon: 0.63
[INFO] model update: t: 372, loss: 16938.705078125
[INFO] Global_t: 372, Episode_t: 4, Action: 3, Reward: 7.39, Epsilon: 0.63
[INFO] model update: t: 373, loss: 20497.7265625
[INFO] Global_t: 373, Episode_t: 5, Action: 83, Reward: 1.69, Epsilon: 0.63
[INFO] model update: t: 374, loss: 18294.607421875
[INFO] Global_t: 374, Episode_t: 6, Action: 2, Reward: 5.49, Epsilon: 0.62
[INFO] model update: t: 375, loss: 41664.08203125
[INFO] Global_t: 375, Episode_t: 7, Action: 0, Reward: 4.92, Epsilon: 0.62
[INFO] model update: t: 376, loss: 65055.93359375
[INFO] Global_t: 376, Episode_t: 8, Action: 10, Reward: 4.96, Epsilon: 0.62
 19%|█▉        | 376/2000 [11:56<1:01:09,  2.26s/it]
[INFO] Global step: 376, Cumulative rewards: 34.92576, Runtime (s): 717.00
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 377, loss: 29539.25
[INFO] Global_t: 377, Episode_t: 1, Action: 2, Reward: 5.91, Epsilon: 0.62
[INFO] model update: t: 378, loss: 28587.251953125
[INFO] Global_t: 378, Episode_t: 2, Action: 117, Reward: 1.52, Epsilon: 0.62
[INFO] model update: t: 379, loss: 60180.71484375
[INFO] Global_t: 379, Episode_t: 3, Action: 4, Reward: 3.75, Epsilon: 0.62
[INFO] model update: t: 380, loss: 26621.85546875
[INFO] Global_t: 380, Episode_t: 4, Action: 89, Reward: 1.86, Epsilon: 0.62
[INFO] model update: t: 381, loss: 58723.8984375
[INFO] Global_t: 381, Episode_t: 5, Action: 6, Reward: 4.71, Epsilon: 0.62
[INFO] model update: t: 382, loss: 39450.171875
[INFO] Global_t: 382, Episode_t: 6, Action: 8, Reward: 2.62, Epsilon: 0.62
[INFO] model update: t: 383, loss: 19932.474609375
[INFO] Global_t: 383, Episode_t: 7, Action: 5, Reward: 3.94, Epsilon: 0.62
[INFO] model update: t: 384, loss: 35385.34375
[INFO] Global_t: 384, Episode_t: 8, Action: 122, Reward: 1.26, Epsilon: 0.61
 19%|█▉        | 384/2000 [12:02<48:05,  1.79s/it]  
[INFO] Global step: 384, Cumulative rewards: 25.5594, Runtime (s): 722.44
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.192535638809204
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.437620639801025
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0482659339904785
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.468525171279907
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9527781009674072
average cummulative reward vector is:  [0.15039605 0.1356875  0.15358579 0.13755023 0.13876156]
average cummulative reward is:  0.14319622755319011
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 385, loss: 74788.375
[INFO] Global_t: 385, Episode_t: 1, Action: 2, Reward: 6.10, Epsilon: 0.61
[INFO] model update: t: 386, loss: 59577.828125
[INFO] Global_t: 386, Episode_t: 2, Action: 11, Reward: 3.88, Epsilon: 0.61
[INFO] model update: t: 387, loss: 17489.193359375
[INFO] Global_t: 387, Episode_t: 3, Action: 20, Reward: 1.69, Epsilon: 0.61
[INFO] model update: t: 388, loss: 39741.7734375
[INFO] Global_t: 388, Episode_t: 4, Action: 3, Reward: 4.74, Epsilon: 0.61
[INFO] model update: t: 389, loss: 18655.720703125
[INFO] Global_t: 389, Episode_t: 5, Action: 8, Reward: 4.32, Epsilon: 0.61
[INFO] model update: t: 390, loss: 95173.71875
[INFO] Global_t: 390, Episode_t: 6, Action: 149, Reward: 1.27, Epsilon: 0.61
[INFO] model update: t: 391, loss: 63313.65625
[INFO] Global_t: 391, Episode_t: 7, Action: 136, Reward: 1.16, Epsilon: 0.61
[INFO] model update: t: 392, loss: 25165.75
[INFO] Global_t: 392, Episode_t: 8, Action: 1, Reward: 4.16, Epsilon: 0.61
 20%|█▉        | 392/2000 [12:28<59:33,  2.22s/it]
[INFO] Global step: 392, Cumulative rewards: 27.318239999999996, Runtime (s): 748.36
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 393, loss: 83637.46875
[INFO] Global_t: 393, Episode_t: 1, Action: 0, Reward: 7.72, Epsilon: 0.61
[INFO] model update: t: 394, loss: 16905.0546875
[INFO] Global_t: 394, Episode_t: 2, Action: 4, Reward: 6.46, Epsilon: 0.60
[INFO] model update: t: 395, loss: 62064.171875
[INFO] Global_t: 395, Episode_t: 3, Action: 168, Reward: 1.29, Epsilon: 0.60
[INFO] model update: t: 396, loss: 56393.8515625
[INFO] Global_t: 396, Episode_t: 4, Action: 3, Reward: 5.28, Epsilon: 0.60
[INFO] model update: t: 397, loss: 10903.3125
[INFO] Global_t: 397, Episode_t: 5, Action: 170, Reward: 1.75, Epsilon: 0.60
[INFO] model update: t: 398, loss: 61705.515625
[INFO] Global_t: 398, Episode_t: 6, Action: 1, Reward: 4.69, Epsilon: 0.60
[INFO] model update: t: 399, loss: 25655.236328125
[INFO] Global_t: 399, Episode_t: 7, Action: 216, Reward: 1.37, Epsilon: 0.60
[INFO] model update: t: 400, loss: 85502.890625
[INFO] Global_t: 400, Episode_t: 8, Action: 7, Reward: 4.43, Epsilon: 0.60
 20%|██        | 400/2000 [12:34<47:24,  1.78s/it]
[INFO] Global step: 400, Cumulative rewards: 32.98644, Runtime (s): 754.28
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.522934436798096
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.323684215545654
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.167038440704346
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.386521339416504
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9850916862487793
average cummulative reward vector is:  [0.15378421 0.1342169  0.15504699 0.13368131 0.14472097]
average cummulative reward is:  0.1442900758726267
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 401, loss: 103911.703125
[INFO] Global_t: 401, Episode_t: 1, Action: 3, Reward: 7.35, Epsilon: 0.60
[INFO] model update: t: 402, loss: 21101.251953125
[INFO] Global_t: 402, Episode_t: 2, Action: 40, Reward: 2.12, Epsilon: 0.60
[INFO] model update: t: 403, loss: 112405.9296875
[INFO] Global_t: 403, Episode_t: 3, Action: 2, Reward: 7.36, Epsilon: 0.60
[INFO] model update: t: 404, loss: 50611.52734375
[INFO] Global_t: 404, Episode_t: 4, Action: 4, Reward: 4.77, Epsilon: 0.60
[INFO] model update: t: 405, loss: 34170.296875
[INFO] Global_t: 405, Episode_t: 5, Action: 159, Reward: 1.56, Epsilon: 0.59
[INFO] model update: t: 406, loss: 49145.40625
[INFO] Global_t: 406, Episode_t: 6, Action: 121, Reward: 1.55, Epsilon: 0.59
[INFO] model update: t: 407, loss: 27441.640625
[INFO] Global_t: 407, Episode_t: 7, Action: 95, Reward: 1.83, Epsilon: 0.59
[INFO] model update: t: 408, loss: 37797.16015625
[INFO] Global_t: 408, Episode_t: 8, Action: 54, Reward: 1.30, Epsilon: 0.59
 20%|██        | 408/2000 [13:01<1:00:19,  2.27s/it]
[INFO] Global step: 408, Cumulative rewards: 27.840959999999995, Runtime (s): 781.73
------------------------------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 409, loss: 15758.478515625
[INFO] Global_t: 409, Episode_t: 1, Action: 3, Reward: 8.05, Epsilon: 0.59
[INFO] model update: t: 410, loss: 21315.76171875
[INFO] Global_t: 410, Episode_t: 2, Action: 41, Reward: 2.76, Epsilon: 0.59
[INFO] model update: t: 411, loss: 24355.8828125
[INFO] Global_t: 411, Episode_t: 3, Action: 102, Reward: 1.71, Epsilon: 0.59
[INFO] model update: t: 412, loss: 18993.8671875
[INFO] Global_t: 412, Episode_t: 4, Action: 140, Reward: 1.66, Epsilon: 0.59
[INFO] model update: t: 413, loss: 27067.0390625
[INFO] Global_t: 413, Episode_t: 5, Action: 42, Reward: 3.37, Epsilon: 0.59
[INFO] model update: t: 414, loss: 32171.03125
[INFO] Global_t: 414, Episode_t: 6, Action: 7, Reward: 5.95, Epsilon: 0.59
[INFO] model update: t: 415, loss: 12070.8408203125
[INFO] Global_t: 415, Episode_t: 7, Action: 60, Reward: 2.08, Epsilon: 0.58
[INFO] model update: t: 416, loss: 79087.078125
[INFO] Global_t: 416, Episode_t: 8, Action: 5, Reward: 5.60, Epsilon: 0.58
 21%|██        | 416/2000 [13:07<47:32,  1.80s/it]  
[INFO] Global step: 416, Cumulative rewards: 31.184639999999998, Runtime (s): 787.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.225796461105347
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.317960262298584
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.162682771682739
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.434855699539185
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.212594985961914
average cummulative reward vector is:  [0.14712684 0.13446273 0.14757322 0.13580771 0.1557129 ]
average cummulative reward is:  0.14413668222732814
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 417, loss: 80725.59375
[INFO] Global_t: 417, Episode_t: 1, Action: 2, Reward: 7.75, Epsilon: 0.58
[INFO] model update: t: 418, loss: 50127.5390625
[INFO] Global_t: 418, Episode_t: 2, Action: 3, Reward: 6.19, Epsilon: 0.58
[INFO] model update: t: 419, loss: 191765.71875
[INFO] Global_t: 419, Episode_t: 3, Action: 8, Reward: 6.49, Epsilon: 0.58
[INFO] model update: t: 420, loss: 33189.13671875
[INFO] Global_t: 420, Episode_t: 4, Action: 114, Reward: 1.50, Epsilon: 0.58
[INFO] model update: t: 421, loss: 94375.953125
[INFO] Global_t: 421, Episode_t: 5, Action: 4, Reward: 5.01, Epsilon: 0.58
[INFO] model update: t: 422, loss: 55210.0625
[INFO] Global_t: 422, Episode_t: 6, Action: 6, Reward: 4.78, Epsilon: 0.58
[INFO] model update: t: 423, loss: 34250.609375
[INFO] Global_t: 423, Episode_t: 7, Action: 23, Reward: 1.72, Epsilon: 0.58
[INFO] model update: t: 424, loss: 73713.8203125
[INFO] Global_t: 424, Episode_t: 8, Action: 187, Reward: 1.79, Epsilon: 0.58
 21%|██        | 424/2000 [13:34<59:49,  2.28s/it]
[INFO] Global step: 424, Cumulative rewards: 35.226839999999996, Runtime (s): 814.44
------------------------------------------------------------
 
graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 425, loss: 24482.56640625
[INFO] Global_t: 425, Episode_t: 1, Action: 3, Reward: 8.52, Epsilon: 0.57
[INFO] model update: t: 426, loss: 92363.53125
[INFO] Global_t: 426, Episode_t: 2, Action: 195, Reward: 1.55, Epsilon: 0.57
[INFO] model update: t: 427, loss: 70430.140625
[INFO] Global_t: 427, Episode_t: 3, Action: 6, Reward: 6.76, Epsilon: 0.57
[INFO] model update: t: 428, loss: 84453.6328125
[INFO] Global_t: 428, Episode_t: 4, Action: 10, Reward: 5.48, Epsilon: 0.57
[INFO] model update: t: 429, loss: 156973.734375
[INFO] Global_t: 429, Episode_t: 5, Action: 0, Reward: 4.65, Epsilon: 0.57
[INFO] model update: t: 430, loss: 28120.837890625
[INFO] Global_t: 430, Episode_t: 6, Action: 100, Reward: 1.74, Epsilon: 0.57
[INFO] model update: t: 431, loss: 157450.5625
[INFO] Global_t: 431, Episode_t: 7, Action: 15, Reward: 2.03, Epsilon: 0.57
[INFO] model update: t: 432, loss: 123519.25
[INFO] Global_t: 432, Episode_t: 8, Action: 11, Reward: 4.76, Epsilon: 0.57
 22%|██▏       | 432/2000 [13:40<47:21,  1.81s/it]
[INFO] Global step: 432, Cumulative rewards: 35.47991999999999, Runtime (s): 820.24
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.036280393600464
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.301059722900391
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8532073497772217
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.167546272277832
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.302544593811035
average cummulative reward vector is:  [0.14152132 0.13103056 0.14091831 0.13106285 0.1501914 ]
average cummulative reward is:  0.13894488513454203
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 433, loss: 53783.14453125
[INFO] Global_t: 433, Episode_t: 1, Action: 24, Reward: 2.93, Epsilon: 0.57
[INFO] model update: t: 434, loss: 227115.46875
[INFO] Global_t: 434, Episode_t: 2, Action: 4, Reward: 6.25, Epsilon: 0.57
[INFO] model update: t: 435, loss: 78614.2734375
[INFO] Global_t: 435, Episode_t: 3, Action: 3, Reward: 6.43, Epsilon: 0.56
[INFO] model update: t: 436, loss: 48421.5859375
[INFO] Global_t: 436, Episode_t: 4, Action: 0, Reward: 5.58, Epsilon: 0.56
[INFO] model update: t: 437, loss: 52381.26953125
[INFO] Global_t: 437, Episode_t: 5, Action: 154, Reward: 1.64, Epsilon: 0.56
[INFO] model update: t: 438, loss: 19809.34765625
[INFO] Global_t: 438, Episode_t: 6, Action: 8, Reward: 4.73, Epsilon: 0.56
[INFO] model update: t: 439, loss: 62537.765625
[INFO] Global_t: 439, Episode_t: 7, Action: 55, Reward: 1.77, Epsilon: 0.56
[INFO] model update: t: 440, loss: 32866.8359375
[INFO] Global_t: 440, Episode_t: 8, Action: 123, Reward: 1.56, Epsilon: 0.56
 22%|██▏       | 440/2000 [14:06<58:05,  2.23s/it]
[INFO] Global step: 440, Cumulative rewards: 30.89508, Runtime (s): 846.00
------------------------------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 441, loss: 17627.0703125
[INFO] Global_t: 441, Episode_t: 1, Action: 3, Reward: 8.53, Epsilon: 0.56
[INFO] model update: t: 442, loss: 27038.166015625
[INFO] Global_t: 442, Episode_t: 2, Action: 4, Reward: 5.33, Epsilon: 0.56
[INFO] model update: t: 443, loss: 24155.28515625
[INFO] Global_t: 443, Episode_t: 3, Action: 97, Reward: 1.74, Epsilon: 0.56
[INFO] model update: t: 444, loss: 52337.49609375
[INFO] Global_t: 444, Episode_t: 4, Action: 2, Reward: 5.16, Epsilon: 0.56
[INFO] model update: t: 445, loss: 23585.791015625
[INFO] Global_t: 445, Episode_t: 5, Action: 1, Reward: 4.80, Epsilon: 0.55
[INFO] model update: t: 446, loss: 32195.765625
[INFO] Global_t: 446, Episode_t: 6, Action: 31, Reward: 3.17, Epsilon: 0.55
[INFO] model update: t: 447, loss: 30327.623046875
[INFO] Global_t: 447, Episode_t: 7, Action: 150, Reward: 1.23, Epsilon: 0.55
[INFO] model update: t: 448, loss: 21742.49609375
[INFO] Global_t: 448, Episode_t: 8, Action: 8, Reward: 4.69, Epsilon: 0.55
 22%|██▏       | 448/2000 [14:11<45:45,  1.77s/it]
[INFO] Global step: 448, Cumulative rewards: 34.62504, Runtime (s): 851.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.137984991073608
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.178487539291382
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.927643060684204
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.434048414230347
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.188846588134766
average cummulative reward vector is:  [0.14404737 0.1304831  0.14544617 0.13949907 0.15078468]
average cummulative reward is:  0.14205207759524163
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 449, loss: 30922.171875
[INFO] Global_t: 449, Episode_t: 1, Action: 123, Reward: 1.57, Epsilon: 0.55
[INFO] model update: t: 450, loss: 41413.6484375
[INFO] Global_t: 450, Episode_t: 2, Action: 3, Reward: 6.66, Epsilon: 0.55
[INFO] model update: t: 451, loss: 16369.302734375
[INFO] Global_t: 451, Episode_t: 3, Action: 200, Reward: 1.32, Epsilon: 0.55
[INFO] model update: t: 452, loss: 54914.4375
[INFO] Global_t: 452, Episode_t: 4, Action: 4, Reward: 5.01, Epsilon: 0.55
[INFO] model update: t: 453, loss: 24012.36328125
[INFO] Global_t: 453, Episode_t: 5, Action: 176, Reward: 1.37, Epsilon: 0.55
[INFO] model update: t: 454, loss: 45890.8046875
[INFO] Global_t: 454, Episode_t: 6, Action: 0, Reward: 4.43, Epsilon: 0.55
[INFO] model update: t: 455, loss: 130008.9375
[INFO] Global_t: 455, Episode_t: 7, Action: 1, Reward: 3.99, Epsilon: 0.55
[INFO] model update: t: 456, loss: 39184.70703125
[INFO] Global_t: 456, Episode_t: 8, Action: 2, Reward: 4.73, Epsilon: 0.54
 23%|██▎       | 456/2000 [14:36<56:24,  2.19s/it]
[INFO] Global step: 456, Cumulative rewards: 29.089199999999998, Runtime (s): 876.89
------------------------------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 457, loss: 66580.9921875
[INFO] Global_t: 457, Episode_t: 1, Action: 21, Reward: 2.27, Epsilon: 0.54
[INFO] model update: t: 458, loss: 129207.484375
[INFO] Global_t: 458, Episode_t: 2, Action: 80, Reward: 1.64, Epsilon: 0.54
[INFO] model update: t: 459, loss: 22463.5078125
[INFO] Global_t: 459, Episode_t: 3, Action: 108, Reward: 1.76, Epsilon: 0.54
[INFO] model update: t: 460, loss: 134092.109375
[INFO] Global_t: 460, Episode_t: 4, Action: 3, Reward: 6.83, Epsilon: 0.54
[INFO] model update: t: 461, loss: 133171.78125
[INFO] Global_t: 461, Episode_t: 5, Action: 12, Reward: 2.37, Epsilon: 0.54
[INFO] model update: t: 462, loss: 29023.71875
[INFO] Global_t: 462, Episode_t: 6, Action: 46, Reward: 2.07, Epsilon: 0.54
[INFO] model update: t: 463, loss: 43027.0078125
[INFO] Global_t: 463, Episode_t: 7, Action: 0, Reward: 5.15, Epsilon: 0.54
[INFO] model update: t: 464, loss: 29967.1796875
[INFO] Global_t: 464, Episode_t: 8, Action: 155, Reward: 1.86, Epsilon: 0.54
 23%|██▎       | 464/2000 [14:41<43:29,  1.70s/it]
[INFO] Global step: 464, Cumulative rewards: 23.937119999999997, Runtime (s): 881.28
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9332525730133057
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.37017822265625
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.048743724822998
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.541740417480469
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.110064506530762
average cummulative reward vector is:  [0.14119211 0.13457014 0.14667705 0.14306472 0.14809946]
average cummulative reward is:  0.14272069506482685
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 465, loss: 34182.12109375
[INFO] Global_t: 465, Episode_t: 1, Action: 1, Reward: 7.31, Epsilon: 0.54
[INFO] model update: t: 466, loss: 37322.328125
[INFO] Global_t: 466, Episode_t: 2, Action: 3, Reward: 5.80, Epsilon: 0.53
[INFO] model update: t: 467, loss: 19815.98828125
[INFO] Global_t: 467, Episode_t: 3, Action: 96, Reward: 1.29, Epsilon: 0.53
[INFO] model update: t: 468, loss: 31766.56640625
[INFO] Global_t: 468, Episode_t: 4, Action: 33, Reward: 2.19, Epsilon: 0.53
[INFO] model update: t: 469, loss: 30447.708984375
[INFO] Global_t: 469, Episode_t: 5, Action: 2, Reward: 5.24, Epsilon: 0.53
[INFO] model update: t: 470, loss: 17161.283203125
[INFO] Global_t: 470, Episode_t: 6, Action: 9, Reward: 5.40, Epsilon: 0.53
[INFO] model update: t: 471, loss: 30140.349609375
[INFO] Global_t: 471, Episode_t: 7, Action: 138, Reward: 1.19, Epsilon: 0.53
[INFO] model update: t: 472, loss: 17200.390625
[INFO] Global_t: 472, Episode_t: 8, Action: 5, Reward: 4.45, Epsilon: 0.53
 24%|██▎       | 472/2000 [15:07<55:18,  2.17s/it]
[INFO] Global step: 472, Cumulative rewards: 32.87496, Runtime (s): 907.49
------------------------------------------------------------
 
graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 473, loss: 17332.21875
[INFO] Global_t: 473, Episode_t: 1, Action: 116, Reward: 1.83, Epsilon: 0.53
[INFO] model update: t: 474, loss: 24851.080078125
[INFO] Global_t: 474, Episode_t: 2, Action: 57, Reward: 2.36, Epsilon: 0.53
[INFO] model update: t: 475, loss: 31205.697265625
[INFO] Global_t: 475, Episode_t: 3, Action: 126, Reward: 1.34, Epsilon: 0.53
[INFO] model update: t: 476, loss: 26385.34375
[INFO] Global_t: 476, Episode_t: 4, Action: 5, Reward: 7.17, Epsilon: 0.52
[INFO] model update: t: 477, loss: 30125.8125
[INFO] Global_t: 477, Episode_t: 5, Action: 8, Reward: 5.96, Epsilon: 0.52
[INFO] model update: t: 478, loss: 23664.421875
[INFO] Global_t: 478, Episode_t: 6, Action: 2, Reward: 4.55, Epsilon: 0.52
[INFO] model update: t: 479, loss: 36436.703125
[INFO] Global_t: 479, Episode_t: 7, Action: 165, Reward: 1.12, Epsilon: 0.52
[INFO] model update: t: 480, loss: 64332.3359375
[INFO] Global_t: 480, Episode_t: 8, Action: 1, Reward: 4.57, Epsilon: 0.52
 24%|██▍       | 480/2000 [15:11<42:34,  1.68s/it]
[INFO] Global step: 480, Cumulative rewards: 28.90284, Runtime (s): 911.75
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.196361303329468
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.261893033981323
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.063180208206177
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.319653749465942
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.105039358139038
average cummulative reward vector is:  [0.15121342 0.13211898 0.14618552 0.13420654 0.14302849]
average cummulative reward is:  0.14135059166790537
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 481, loss: 30151.04296875
[INFO] Global_t: 481, Episode_t: 1, Action: 54, Reward: 2.14, Epsilon: 0.52
[INFO] model update: t: 482, loss: 40785.21875
[INFO] Global_t: 482, Episode_t: 2, Action: 112, Reward: 1.84, Epsilon: 0.52
[INFO] model update: t: 483, loss: 33182.76171875
[INFO] Global_t: 483, Episode_t: 3, Action: 3, Reward: 6.83, Epsilon: 0.52
[INFO] model update: t: 484, loss: 32256.013671875
[INFO] Global_t: 484, Episode_t: 4, Action: 21, Reward: 2.13, Epsilon: 0.52
[INFO] model update: t: 485, loss: 11597.55859375
[INFO] Global_t: 485, Episode_t: 5, Action: 9, Reward: 4.50, Epsilon: 0.52
[INFO] model update: t: 486, loss: 14848.60546875
[INFO] Global_t: 486, Episode_t: 6, Action: 122, Reward: 1.19, Epsilon: 0.51
[INFO] model update: t: 487, loss: 19483.70703125
[INFO] Global_t: 487, Episode_t: 7, Action: 25, Reward: 2.49, Epsilon: 0.51
[INFO] model update: t: 488, loss: 17513.330078125
[INFO] Global_t: 488, Episode_t: 8, Action: 59, Reward: 1.99, Epsilon: 0.51
 24%|██▍       | 488/2000 [15:36<53:27,  2.12s/it]
[INFO] Global step: 488, Cumulative rewards: 23.099879999999995, Runtime (s): 936.96
------------------------------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 489, loss: 22099.2890625
[INFO] Global_t: 489, Episode_t: 1, Action: 2, Reward: 7.40, Epsilon: 0.51
[INFO] model update: t: 490, loss: 80565.8984375
[INFO] Global_t: 490, Episode_t: 2, Action: 0, Reward: 7.62, Epsilon: 0.51
[INFO] model update: t: 491, loss: 65556.4453125
[INFO] Global_t: 491, Episode_t: 3, Action: 4, Reward: 8.61, Epsilon: 0.51
[INFO] model update: t: 492, loss: 21770.35546875
[INFO] Global_t: 492, Episode_t: 4, Action: 36, Reward: 1.86, Epsilon: 0.51
[INFO] model update: t: 493, loss: 140771.15625
[INFO] Global_t: 493, Episode_t: 5, Action: 198, Reward: 1.43, Epsilon: 0.51
[INFO] model update: t: 494, loss: 95828.0078125
[INFO] Global_t: 494, Episode_t: 6, Action: 159, Reward: 1.74, Epsilon: 0.51
[INFO] model update: t: 495, loss: 14415.9951171875
[INFO] Global_t: 495, Episode_t: 7, Action: 105, Reward: 1.71, Epsilon: 0.51
[INFO] model update: t: 496, loss: 81643.65625
[INFO] Global_t: 496, Episode_t: 8, Action: 177, Reward: 1.13, Epsilon: 0.50
 25%|██▍       | 496/2000 [15:43<43:29,  1.73s/it]
[INFO] Global step: 496, Cumulative rewards: 31.49928, Runtime (s): 943.62
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.128545522689819
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.789479970932007
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.822298288345337
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.4011266231536865
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.276295185089111
average cummulative reward vector is:  [0.14769605 0.14274213 0.14241366 0.13719533 0.15378495]
average cummulative reward is:  0.14476642336055143
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 497, loss: 52083.34375
[INFO] Global_t: 497, Episode_t: 1, Action: 2, Reward: 6.87, Epsilon: 0.50
[INFO] model update: t: 498, loss: 17936.462890625
[INFO] Global_t: 498, Episode_t: 2, Action: 5, Reward: 5.22, Epsilon: 0.50
[INFO] model update: t: 499, loss: 21365.92578125
[INFO] Global_t: 499, Episode_t: 3, Action: 4, Reward: 4.91, Epsilon: 0.50
[INFO] model update: t: 500, loss: 28771.982421875
[INFO] Global_t: 500, Episode_t: 4, Action: 28, Reward: 1.69, Epsilon: 0.50
[INFO] model update: t: 501, loss: 16371.1123046875
[INFO] Global_t: 501, Episode_t: 5, Action: 52, Reward: 1.78, Epsilon: 0.50
[INFO] model update: t: 502, loss: 19540.89453125
[INFO] Global_t: 502, Episode_t: 6, Action: 0, Reward: 4.12, Epsilon: 0.50
[INFO] model update: t: 503, loss: 24699.564453125
[INFO] Global_t: 503, Episode_t: 7, Action: 127, Reward: 1.24, Epsilon: 0.50
[INFO] model update: t: 504, loss: 16846.61328125
[INFO] Global_t: 504, Episode_t: 8, Action: 3, Reward: 3.60, Epsilon: 0.50
 25%|██▌       | 504/2000 [16:10<55:11,  2.21s/it]
[INFO] Global step: 504, Cumulative rewards: 29.446199999999994, Runtime (s): 970.26
------------------------------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 505, loss: 32854.89453125
[INFO] Global_t: 505, Episode_t: 1, Action: 59, Reward: 2.32, Epsilon: 0.50
[INFO] model update: t: 506, loss: 15842.83203125
[INFO] Global_t: 506, Episode_t: 2, Action: 2, Reward: 6.05, Epsilon: 0.50
[INFO] model update: t: 507, loss: 24667.0
[INFO] Global_t: 507, Episode_t: 3, Action: 174, Reward: 1.04, Epsilon: 0.49
[INFO] model update: t: 508, loss: 43270.5859375
[INFO] Global_t: 508, Episode_t: 4, Action: 13, Reward: 2.67, Epsilon: 0.49
[INFO] model update: t: 509, loss: 30791.578125
[INFO] Global_t: 509, Episode_t: 5, Action: 42, Reward: 1.78, Epsilon: 0.49
[INFO] model update: t: 510, loss: 23403.673828125
[INFO] Global_t: 510, Episode_t: 6, Action: 27, Reward: 2.25, Epsilon: 0.49
[INFO] model update: t: 511, loss: 26856.03125
[INFO] Global_t: 511, Episode_t: 7, Action: 117, Reward: 1.89, Epsilon: 0.49
[INFO] model update: t: 512, loss: 11437.0224609375
[INFO] Global_t: 512, Episode_t: 8, Action: 3, Reward: 5.29, Epsilon: 0.49
 26%|██▌       | 512/2000 [16:14<42:40,  1.72s/it]
[INFO] Global step: 512, Cumulative rewards: 23.305079999999997, Runtime (s): 974.84
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8492391109466553
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.752882957458496
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.125288486480713
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.361446857452393
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.153320550918579
average cummulative reward vector is:  [0.137115   0.14218843 0.15457268 0.13750584 0.14728091]
average cummulative reward is:  0.14373257172430887
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 513, loss: 17460.69140625
[INFO] Global_t: 513, Episode_t: 1, Action: 170, Reward: 1.43, Epsilon: 0.49
[INFO] model update: t: 514, loss: 13232.1953125
[INFO] Global_t: 514, Episode_t: 2, Action: 5, Reward: 5.87, Epsilon: 0.49
[INFO] model update: t: 515, loss: 30564.546875
[INFO] Global_t: 515, Episode_t: 3, Action: 102, Reward: 1.50, Epsilon: 0.49
[INFO] model update: t: 516, loss: 22905.73828125
[INFO] Global_t: 516, Episode_t: 4, Action: 23, Reward: 2.19, Epsilon: 0.49
[INFO] model update: t: 517, loss: 24792.79296875
[INFO] Global_t: 517, Episode_t: 5, Action: 153, Reward: 1.23, Epsilon: 0.48
[INFO] model update: t: 518, loss: 58401.94921875
[INFO] Global_t: 518, Episode_t: 6, Action: 2, Reward: 4.65, Epsilon: 0.48
[INFO] model update: t: 519, loss: 16278.068359375
[INFO] Global_t: 519, Episode_t: 7, Action: 65, Reward: 2.00, Epsilon: 0.48
[INFO] model update: t: 520, loss: 73501.28125
[INFO] Global_t: 520, Episode_t: 8, Action: 4, Reward: 6.34, Epsilon: 0.48
 26%|██▌       | 520/2000 [16:41<54:20,  2.20s/it]
[INFO] Global step: 520, Cumulative rewards: 25.2108, Runtime (s): 1001.47
------------------------------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 521, loss: 130692.265625
[INFO] Global_t: 521, Episode_t: 1, Action: 67, Reward: 2.43, Epsilon: 0.48
[INFO] model update: t: 522, loss: 98848.640625
[INFO] Global_t: 522, Episode_t: 2, Action: 0, Reward: 8.34, Epsilon: 0.48
[INFO] model update: t: 523, loss: 23482.50390625
[INFO] Global_t: 523, Episode_t: 3, Action: 3, Reward: 7.01, Epsilon: 0.48
[INFO] model update: t: 524, loss: 113490.359375
[INFO] Global_t: 524, Episode_t: 4, Action: 193, Reward: 1.55, Epsilon: 0.48
[INFO] model update: t: 525, loss: 42621.33203125
[INFO] Global_t: 525, Episode_t: 5, Action: 93, Reward: 2.30, Epsilon: 0.48
[INFO] model update: t: 526, loss: 27315.31640625
[INFO] Global_t: 526, Episode_t: 6, Action: 89, Reward: 1.40, Epsilon: 0.48
[INFO] model update: t: 527, loss: 65111.69921875
[INFO] Global_t: 527, Episode_t: 7, Action: 12, Reward: 2.18, Epsilon: 0.47
[INFO] model update: t: 528, loss: 57081.2890625
[INFO] Global_t: 528, Episode_t: 8, Action: 101, Reward: 2.71, Epsilon: 0.47
 26%|██▋       | 528/2000 [16:47<43:21,  1.77s/it]
[INFO] Global step: 528, Cumulative rewards: 27.933, Runtime (s): 1007.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.048808813095093
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.293847322463989
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9314000606536865
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.440528869628906
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.161543607711792
average cummulative reward vector is:  [0.14399921 0.12996412 0.1460235  0.13335327 0.15144973]
average cummulative reward is:  0.14095796607505579
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 529, loss: 32639.62109375
[INFO] Global_t: 529, Episode_t: 1, Action: 10, Reward: 5.33, Epsilon: 0.47
[INFO] model update: t: 530, loss: 27375.41796875
[INFO] Global_t: 530, Episode_t: 2, Action: 4, Reward: 5.52, Epsilon: 0.47
[INFO] model update: t: 531, loss: 55862.5625
[INFO] Global_t: 531, Episode_t: 3, Action: 146, Reward: 1.76, Epsilon: 0.47
[INFO] model update: t: 532, loss: 45130.6640625
[INFO] Global_t: 532, Episode_t: 4, Action: 115, Reward: 1.61, Epsilon: 0.47
[INFO] model update: t: 533, loss: 18884.916015625
[INFO] Global_t: 533, Episode_t: 5, Action: 5, Reward: 6.08, Epsilon: 0.47
[INFO] model update: t: 534, loss: 34132.2890625
[INFO] Global_t: 534, Episode_t: 6, Action: 100, Reward: 1.80, Epsilon: 0.47
[INFO] model update: t: 535, loss: 25903.37109375
[INFO] Global_t: 535, Episode_t: 7, Action: 3, Reward: 4.55, Epsilon: 0.47
[INFO] model update: t: 536, loss: 11424.548828125
[INFO] Global_t: 536, Episode_t: 8, Action: 143, Reward: 1.16, Epsilon: 0.47
 27%|██▋       | 536/2000 [17:13<54:23,  2.23s/it]
[INFO] Global step: 536, Cumulative rewards: 27.80424, Runtime (s): 1033.92
------------------------------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 537, loss: 29957.33203125
[INFO] Global_t: 537, Episode_t: 1, Action: 4, Reward: 6.47, Epsilon: 0.46
[INFO] model update: t: 538, loss: 22677.22265625
[INFO] Global_t: 538, Episode_t: 2, Action: 8, Reward: 5.04, Epsilon: 0.46
[INFO] model update: t: 539, loss: 21327.03515625
[INFO] Global_t: 539, Episode_t: 3, Action: 30, Reward: 2.33, Epsilon: 0.46
[INFO] model update: t: 540, loss: 29400.921875
[INFO] Global_t: 540, Episode_t: 4, Action: 3, Reward: 4.73, Epsilon: 0.46
[INFO] model update: t: 541, loss: 6262.61279296875
[INFO] Global_t: 541, Episode_t: 5, Action: 1, Reward: 4.34, Epsilon: 0.46
[INFO] model update: t: 542, loss: 19115.16015625
[INFO] Global_t: 542, Episode_t: 6, Action: 53, Reward: 1.53, Epsilon: 0.46
[INFO] model update: t: 543, loss: 14299.99609375
[INFO] Global_t: 543, Episode_t: 7, Action: 11, Reward: 4.38, Epsilon: 0.46
[INFO] model update: t: 544, loss: 27790.5
[INFO] Global_t: 544, Episode_t: 8, Action: 0, Reward: 4.98, Epsilon: 0.46
 27%|██▋       | 544/2000 [17:18<42:21,  1.75s/it]
[INFO] Global step: 544, Cumulative rewards: 33.797039999999996, Runtime (s): 1038.86
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7991538047790527
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.440634727478027
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.039666175842285
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.5645751953125
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.115224123001099
average cummulative reward vector is:  [0.13669211 0.13396088 0.14939918 0.13768995 0.14967661]
average cummulative reward is:  0.14148374627898205
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 545, loss: 14354.9599609375
[INFO] Global_t: 545, Episode_t: 1, Action: 2, Reward: 8.23, Epsilon: 0.46
[INFO] model update: t: 546, loss: 19573.001953125
[INFO] Global_t: 546, Episode_t: 2, Action: 91, Reward: 1.92, Epsilon: 0.46
[INFO] model update: t: 547, loss: 23661.693359375
[INFO] Global_t: 547, Episode_t: 3, Action: 4, Reward: 6.14, Epsilon: 0.45
[INFO] model update: t: 548, loss: 40572.39453125
[INFO] Global_t: 548, Episode_t: 4, Action: 6, Reward: 5.75, Epsilon: 0.45
[INFO] model update: t: 549, loss: 13846.41796875
[INFO] Global_t: 549, Episode_t: 5, Action: 159, Reward: 1.42, Epsilon: 0.45
[INFO] model update: t: 550, loss: 20820.943359375
[INFO] Global_t: 550, Episode_t: 6, Action: 5, Reward: 5.41, Epsilon: 0.45
[INFO] model update: t: 551, loss: 48026.06640625
[INFO] Global_t: 551, Episode_t: 7, Action: 7, Reward: 5.41, Epsilon: 0.45
[INFO] model update: t: 552, loss: 34043.09375
[INFO] Global_t: 552, Episode_t: 8, Action: 164, Reward: 1.26, Epsilon: 0.45
 28%|██▊       | 552/2000 [17:45<53:44,  2.23s/it]
[INFO] Global step: 552, Cumulative rewards: 35.55648000000001, Runtime (s): 1065.65
------------------------------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 553, loss: 23577.6484375
[INFO] Global_t: 553, Episode_t: 1, Action: 169, Reward: 1.79, Epsilon: 0.45
[INFO] model update: t: 554, loss: 34863.98046875
[INFO] Global_t: 554, Episode_t: 2, Action: 1, Reward: 7.20, Epsilon: 0.45
[INFO] model update: t: 555, loss: 19408.044921875
[INFO] Global_t: 555, Episode_t: 3, Action: 6, Reward: 5.53, Epsilon: 0.45
[INFO] model update: t: 556, loss: 27756.32421875
[INFO] Global_t: 556, Episode_t: 4, Action: 150, Reward: 1.09, Epsilon: 0.45
[INFO] model update: t: 557, loss: 31219.06640625
[INFO] Global_t: 557, Episode_t: 5, Action: 30, Reward: 2.31, Epsilon: 0.45
[INFO] model update: t: 558, loss: 17108.630859375
[INFO] Global_t: 558, Episode_t: 6, Action: 3, Reward: 4.89, Epsilon: 0.44
[INFO] model update: t: 559, loss: 36893.453125
[INFO] Global_t: 559, Episode_t: 7, Action: 137, Reward: 1.10, Epsilon: 0.44
[INFO] model update: t: 560, loss: 39550.90234375
[INFO] Global_t: 560, Episode_t: 8, Action: 0, Reward: 4.24, Epsilon: 0.44
 28%|██▊       | 560/2000 [17:50<41:38,  1.74s/it]
[INFO] Global step: 560, Cumulative rewards: 28.156800000000004, Runtime (s): 1070.36
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.576894044876099
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.086655378341675
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.02580714225769
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.390768766403198
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.079139232635498
average cummulative reward vector is:  [0.15558789 0.12763704 0.15022596 0.13400864 0.14696774]
average cummulative reward is:  0.14288545497066582
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 561, loss: 12190.3203125
[INFO] Global_t: 561, Episode_t: 1, Action: 27, Reward: 2.07, Epsilon: 0.44
[INFO] model update: t: 562, loss: 100628.34375
[INFO] Global_t: 562, Episode_t: 2, Action: 1, Reward: 6.34, Epsilon: 0.44
[INFO] model update: t: 563, loss: 201612.875
[INFO] Global_t: 563, Episode_t: 3, Action: 53, Reward: 1.97, Epsilon: 0.44
[INFO] model update: t: 564, loss: 99153.5390625
[INFO] Global_t: 564, Episode_t: 4, Action: 68, Reward: 1.57, Epsilon: 0.44
[INFO] model update: t: 565, loss: 19271.30859375
[INFO] Global_t: 565, Episode_t: 5, Action: 16, Reward: 5.78, Epsilon: 0.44
[INFO] model update: t: 566, loss: 28541.908203125
[INFO] Global_t: 566, Episode_t: 6, Action: 3, Reward: 7.37, Epsilon: 0.44
[INFO] model update: t: 567, loss: 55391.39453125
[INFO] Global_t: 567, Episode_t: 7, Action: 5, Reward: 2.68, Epsilon: 0.44
[INFO] model update: t: 568, loss: 25783.603515625
[INFO] Global_t: 568, Episode_t: 8, Action: 0, Reward: 5.02, Epsilon: 0.43

 28%|██▊       | 568/2000 [18:16<52:25,  2.20s/it]536, Runtime (s): 1096.54
------------------------------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 569, loss: 22553.89453125
[INFO] Global_t: 569, Episode_t: 1, Action: 4, Reward: 7.91, Epsilon: 0.43
[INFO] model update: t: 570, loss: 52808.640625
[INFO] Global_t: 570, Episode_t: 2, Action: 3, Reward: 6.55, Epsilon: 0.43
[INFO] model update: t: 571, loss: 26059.9140625
[INFO] Global_t: 571, Episode_t: 3, Action: 18, Reward: 2.54, Epsilon: 0.43
[INFO] model update: t: 572, loss: 55488.44921875
[INFO] Global_t: 572, Episode_t: 4, Action: 170, Reward: 0.89, Epsilon: 0.43
[INFO] model update: t: 573, loss: 168421.25
[INFO] Global_t: 573, Episode_t: 5, Action: 128, Reward: 1.76, Epsilon: 0.43
[INFO] model update: t: 574, loss: 154830.296875
[INFO] Global_t: 574, Episode_t: 6, Action: 0, Reward: 5.17, Epsilon: 0.43
[INFO] model update: t: 575, loss: 18970.830078125
[INFO] Global_t: 575, Episode_t: 7, Action: 59, Reward: 2.18, Epsilon: 0.43
[INFO] model update: t: 576, loss: 194137.78125
[INFO] Global_t: 576, Episode_t: 8, Action: 21, Reward: 4.82, Epsilon: 0.43
 29%|██▉       | 576/2000 [18:21<41:17,  1.74s/it]
[INFO] Global step: 576, Cumulative rewards: 31.828799999999998, Runtime (s): 1101.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.228155612945557
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.409085512161255
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0682220458984375
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.55205512046814
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8436596393585205
average cummulative reward vector is:  [0.14810026 0.13386435 0.15097732 0.13875607 0.14000108]
average cummulative reward is:  0.1423398174898581
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 577, loss: 369783.09375
[INFO] Global_t: 577, Episode_t: 1, Action: 134, Reward: 1.76, Epsilon: 0.43
[INFO] model update: t: 578, loss: 150038.78125
[INFO] Global_t: 578, Episode_t: 2, Action: 109, Reward: 1.45, Epsilon: 0.42
[INFO] model update: t: 579, loss: 54346.328125
[INFO] Global_t: 579, Episode_t: 3, Action: 2, Reward: 6.71, Epsilon: 0.42
[INFO] model update: t: 580, loss: 425297.4375
[INFO] Global_t: 580, Episode_t: 4, Action: 3, Reward: 6.04, Epsilon: 0.42
[INFO] model update: t: 581, loss: 418172.34375
[INFO] Global_t: 581, Episode_t: 5, Action: 172, Reward: 1.58, Epsilon: 0.42
[INFO] model update: t: 582, loss: 75685.3828125
[INFO] Global_t: 582, Episode_t: 6, Action: 0, Reward: 7.23, Epsilon: 0.42
[INFO] model update: t: 583, loss: 131371.640625
[INFO] Global_t: 583, Episode_t: 7, Action: 7, Reward: 3.94, Epsilon: 0.42
[INFO] model update: t: 584, loss: 446856.40625
[INFO] Global_t: 584, Episode_t: 8, Action: 124, Reward: 1.64, Epsilon: 0.42
 29%|██▉       | 584/2000 [18:47<51:38,  2.19s/it]
[INFO] Global step: 584, Cumulative rewards: 30.35472, Runtime (s): 1127.81
------------------------------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 585, loss: 331861.375
[INFO] Global_t: 585, Episode_t: 1, Action: 99, Reward: 1.56, Epsilon: 0.42
[INFO] model update: t: 586, loss: 15195.7978515625
[INFO] Global_t: 586, Episode_t: 2, Action: 10, Reward: 4.17, Epsilon: 0.42
[INFO] model update: t: 587, loss: 201215.34375
[INFO] Global_t: 587, Episode_t: 3, Action: 4, Reward: 6.37, Epsilon: 0.42
[INFO] model update: t: 588, loss: 285259.125
[INFO] Global_t: 588, Episode_t: 4, Action: 108, Reward: 1.44, Epsilon: 0.41
[INFO] model update: t: 589, loss: 188547.46875
[INFO] Global_t: 589, Episode_t: 5, Action: 3, Reward: 6.04, Epsilon: 0.41
[INFO] model update: t: 590, loss: 53509.296875
[INFO] Global_t: 590, Episode_t: 6, Action: 56, Reward: 2.13, Epsilon: 0.41
[INFO] model update: t: 591, loss: 15695.369140625
[INFO] Global_t: 591, Episode_t: 7, Action: 115, Reward: 1.63, Epsilon: 0.41
[INFO] model update: t: 592, loss: 115076.0
[INFO] Global_t: 592, Episode_t: 8, Action: 2, Reward: 4.45, Epsilon: 0.41
 30%|██▉       | 592/2000 [18:52<40:19,  1.72s/it]
[INFO] Global step: 592, Cumulative rewards: 27.782159999999998, Runtime (s): 1132.79
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.131550073623657
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.624598264694214
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.037610769271851
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.546185493469238
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.046759128570557
average cummulative reward vector is:  [0.14460395 0.14221597 0.14703825 0.1374493  0.15041075]
average cummulative reward is:  0.14434364454207121
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 593, loss: 183831.078125
[INFO] Global_t: 593, Episode_t: 1, Action: 17, Reward: 2.77, Epsilon: 0.41
[INFO] model update: t: 594, loss: 115055.140625
[INFO] Global_t: 594, Episode_t: 2, Action: 3, Reward: 7.98, Epsilon: 0.41
[INFO] model update: t: 595, loss: 15165.220703125
[INFO] Global_t: 595, Episode_t: 3, Action: 4, Reward: 5.63, Epsilon: 0.41
[INFO] model update: t: 596, loss: 102067.5703125
[INFO] Global_t: 596, Episode_t: 4, Action: 1, Reward: 6.18, Epsilon: 0.41
[INFO] model update: t: 597, loss: 133134.6875
[INFO] Global_t: 597, Episode_t: 5, Action: 119, Reward: 1.10, Epsilon: 0.41
[INFO] model update: t: 598, loss: 22841.958984375
[INFO] Global_t: 598, Episode_t: 6, Action: 8, Reward: 5.65, Epsilon: 0.40
[INFO] model update: t: 599, loss: 52489.1953125
[INFO] Global_t: 599, Episode_t: 7, Action: 122, Reward: 1.81, Epsilon: 0.40
[INFO] model update: t: 600, loss: 81199.6328125
[INFO] Global_t: 600, Episode_t: 8, Action: 0, Reward: 4.53, Epsilon: 0.40
 30%|███       | 600/2000 [19:19<51:42,  2.22s/it]
[INFO] Global step: 600, Cumulative rewards: 35.64204, Runtime (s): 1159.80
------------------------------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 601, loss: 31700.1328125
[INFO] Global_t: 601, Episode_t: 1, Action: 60, Reward: 2.08, Epsilon: 0.40
[INFO] model update: t: 602, loss: 34421.25
[INFO] Global_t: 602, Episode_t: 2, Action: 5, Reward: 6.87, Epsilon: 0.40
[INFO] model update: t: 603, loss: 42151.7421875
[INFO] Global_t: 603, Episode_t: 3, Action: 184, Reward: 0.97, Epsilon: 0.40
[INFO] model update: t: 604, loss: 22065.31640625
[INFO] Global_t: 604, Episode_t: 4, Action: 9, Reward: 3.28, Epsilon: 0.40
[INFO] model update: t: 605, loss: 50616.59375
[INFO] Global_t: 605, Episode_t: 5, Action: 1, Reward: 6.46, Epsilon: 0.40
[INFO] model update: t: 606, loss: 175271.03125
[INFO] Global_t: 606, Episode_t: 6, Action: 3, Reward: 7.28, Epsilon: 0.40
[INFO] model update: t: 607, loss: 205239.140625
[INFO] Global_t: 607, Episode_t: 7, Action: 4, Reward: 4.84, Epsilon: 0.40
[INFO] model update: t: 608, loss: 116570.296875
[INFO] Global_t: 608, Episode_t: 8, Action: 11, Reward: 4.42, Epsilon: 0.40
 30%|███       | 608/2000 [19:24<40:09,  1.73s/it]
[INFO] Global step: 608, Cumulative rewards: 36.19884, Runtime (s): 1164.59
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.237124681472778
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9958531856536865
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.226613283157349
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.7132086753845215
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.840611219406128
average cummulative reward vector is:  [0.14601316 0.12303472 0.15131831 0.1407778  0.13775484]
average cummulative reward is:  0.13977976571517664
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 609, loss: 25455.912109375
[INFO] Global_t: 609, Episode_t: 1, Action: 3, Reward: 7.32, Epsilon: 0.39
[INFO] model update: t: 610, loss: 54140.00390625
[INFO] Global_t: 610, Episode_t: 2, Action: 106, Reward: 1.72, Epsilon: 0.39
[INFO] model update: t: 611, loss: 142664.0
[INFO] Global_t: 611, Episode_t: 3, Action: 2, Reward: 5.62, Epsilon: 0.39
[INFO] model update: t: 612, loss: 237382.75
[INFO] Global_t: 612, Episode_t: 4, Action: 183, Reward: 1.05, Epsilon: 0.39
[INFO] model update: t: 613, loss: 348503.125
[INFO] Global_t: 613, Episode_t: 5, Action: 8, Reward: 5.36, Epsilon: 0.39
[INFO] model update: t: 614, loss: 205263.53125
[INFO] Global_t: 614, Episode_t: 6, Action: 0, Reward: 6.15, Epsilon: 0.39
[INFO] model update: t: 615, loss: 30544.46875
[INFO] Global_t: 615, Episode_t: 7, Action: 6, Reward: 4.07, Epsilon: 0.39
[INFO] model update: t: 616, loss: 369551.40625
[INFO] Global_t: 616, Episode_t: 8, Action: 14, Reward: 3.72, Epsilon: 0.39
 31%|███       | 616/2000 [19:50<50:37,  2.20s/it]
[INFO] Global step: 616, Cumulative rewards: 35.010479999999994, Runtime (s): 1190.82
------------------------------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 617, loss: 451085.0625
[INFO] Global_t: 617, Episode_t: 1, Action: 150, Reward: 1.88, Epsilon: 0.39
[INFO] model update: t: 618, loss: 27833.4375
[INFO] Global_t: 618, Episode_t: 2, Action: 148, Reward: 2.07, Epsilon: 0.39
[INFO] model update: t: 619, loss: 821813.75
[INFO] Global_t: 619, Episode_t: 3, Action: 3, Reward: 6.92, Epsilon: 0.38
[INFO] model update: t: 620, loss: 1661426.5
[INFO] Global_t: 620, Episode_t: 4, Action: 143, Reward: 1.00, Epsilon: 0.38
[INFO] model update: t: 621, loss: 307584.15625
[INFO] Global_t: 621, Episode_t: 5, Action: 4, Reward: 6.81, Epsilon: 0.38
[INFO] model update: t: 622, loss: 255826.3125
[INFO] Global_t: 622, Episode_t: 6, Action: 2, Reward: 5.17, Epsilon: 0.38
[INFO] model update: t: 623, loss: 902700.0
[INFO] Global_t: 623, Episode_t: 7, Action: 0, Reward: 5.77, Epsilon: 0.38
[INFO] model update: t: 624, loss: 542117.9375
[INFO] Global_t: 624, Episode_t: 8, Action: 139, Reward: 1.19, Epsilon: 0.38
 31%|███       | 624/2000 [19:55<39:03,  1.70s/it]
[INFO] Global step: 624, Cumulative rewards: 30.8112, Runtime (s): 1195.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.103431940078735
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.929525852203369
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.850708484649658
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.524700880050659
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.0925116539001465
average cummulative reward vector is:  [0.13758184 0.12152708 0.1433929  0.13522103 0.14991962]
average cummulative reward is:  0.1375284946613514
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 625, loss: 28781.533203125
[INFO] Global_t: 625, Episode_t: 1, Action: 4, Reward: 5.86, Epsilon: 0.38
[INFO] model update: t: 626, loss: 533579.375
[INFO] Global_t: 626, Episode_t: 2, Action: 141, Reward: 1.37, Epsilon: 0.38
[INFO] model update: t: 627, loss: 348944.875
[INFO] Global_t: 627, Episode_t: 3, Action: 8, Reward: 5.86, Epsilon: 0.38
[INFO] model update: t: 628, loss: 20445.3828125
[INFO] Global_t: 628, Episode_t: 4, Action: 56, Reward: 1.87, Epsilon: 0.38
[INFO] model update: t: 629, loss: 311972.125
[INFO] Global_t: 629, Episode_t: 5, Action: 10, Reward: 4.82, Epsilon: 0.37
[INFO] model update: t: 630, loss: 300338.71875
[INFO] Global_t: 630, Episode_t: 6, Action: 0, Reward: 4.24, Epsilon: 0.37
[INFO] model update: t: 631, loss: 15034.8505859375
[INFO] Global_t: 631, Episode_t: 7, Action: 9, Reward: 3.95, Epsilon: 0.37
[INFO] model update: t: 632, loss: 291487.625
[INFO] Global_t: 632, Episode_t: 8, Action: 2, Reward: 3.81, Epsilon: 0.37
 32%|███▏      | 632/2000 [20:20<48:46,  2.14s/it]
[INFO] Global step: 632, Cumulative rewards: 31.775519999999997, Runtime (s): 1220.52
------------------------------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 633, loss: 417467.0
[INFO] Global_t: 633, Episode_t: 1, Action: 3, Reward: 7.25, Epsilon: 0.37
[INFO] model update: t: 634, loss: 373382.25
[INFO] Global_t: 634, Episode_t: 2, Action: 6, Reward: 5.75, Epsilon: 0.37
[INFO] model update: t: 635, loss: 118011.84375
[INFO] Global_t: 635, Episode_t: 3, Action: 2, Reward: 5.12, Epsilon: 0.37
[INFO] model update: t: 636, loss: 61400.796875
[INFO] Global_t: 636, Episode_t: 4, Action: 15, Reward: 4.41, Epsilon: 0.37
[INFO] model update: t: 637, loss: 296983.5625
[INFO] Global_t: 637, Episode_t: 5, Action: 16, Reward: 4.89, Epsilon: 0.37
[INFO] model update: t: 638, loss: 132540.375
[INFO] Global_t: 638, Episode_t: 6, Action: 59, Reward: 1.58, Epsilon: 0.37
[INFO] model update: t: 639, loss: 14753.533203125
[INFO] Global_t: 639, Episode_t: 7, Action: 5, Reward: 3.78, Epsilon: 0.36
[INFO] model update: t: 640, loss: 155487.9375
[INFO] Global_t: 640, Episode_t: 8, Action: 26, Reward: 1.61, Epsilon: 0.36
 32%|███▏      | 640/2000 [20:25<38:28,  1.70s/it]
[INFO] Global step: 640, Cumulative rewards: 34.41636, Runtime (s): 1225.84
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.140394449234009
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.061412334442139
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.850472927093506
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.563943862915039
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.017022371292114
average cummulative reward vector is:  [0.14400237 0.12202176 0.14381721 0.13976659 0.1471664 ]
average cummulative reward is:  0.139354865485915
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 641, loss: 217049.421875
[INFO] Global_t: 641, Episode_t: 1, Action: 3, Reward: 7.85, Epsilon: 0.36
[INFO] model update: t: 642, loss: 76502.7265625
[INFO] Global_t: 642, Episode_t: 2, Action: 2, Reward: 5.73, Epsilon: 0.36
[INFO] model update: t: 643, loss: 22123.62890625
[INFO] Global_t: 643, Episode_t: 3, Action: 10, Reward: 5.85, Epsilon: 0.36
[INFO] model update: t: 644, loss: 57237.9140625
[INFO] Global_t: 644, Episode_t: 4, Action: 0, Reward: 6.71, Epsilon: 0.36
[INFO] model update: t: 645, loss: 84981.375
[INFO] Global_t: 645, Episode_t: 5, Action: 8, Reward: 4.92, Epsilon: 0.36
[INFO] model update: t: 646, loss: 31322.630859375
[INFO] Global_t: 646, Episode_t: 6, Action: 5, Reward: 4.69, Epsilon: 0.36
[INFO] model update: t: 647, loss: 10205.203125
[INFO] Global_t: 647, Episode_t: 7, Action: 9, Reward: 5.08, Epsilon: 0.36
[INFO] model update: t: 648, loss: 52764.9609375
[INFO] Global_t: 648, Episode_t: 8, Action: 7, Reward: 4.21, Epsilon: 0.36
 32%|███▏      | 648/2000 [20:52<48:57,  2.17s/it]
[INFO] Global step: 648, Cumulative rewards: 45.04739999999999, Runtime (s): 1252.10
------------------------------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 649, loss: 109707.921875
[INFO] Global_t: 649, Episode_t: 1, Action: 6, Reward: 6.99, Epsilon: 0.35
[INFO] model update: t: 650, loss: 106835.1875
[INFO] Global_t: 650, Episode_t: 2, Action: 9, Reward: 4.63, Epsilon: 0.35
[INFO] model update: t: 651, loss: 21043.16015625
[INFO] Global_t: 651, Episode_t: 3, Action: 1, Reward: 4.75, Epsilon: 0.35
[INFO] model update: t: 652, loss: 75360.3515625
[INFO] Global_t: 652, Episode_t: 4, Action: 156, Reward: 0.86, Epsilon: 0.35
[INFO] model update: t: 653, loss: 157349.46875
[INFO] Global_t: 653, Episode_t: 5, Action: 44, Reward: 1.91, Epsilon: 0.35
[INFO] model update: t: 654, loss: 129554.546875
[INFO] Global_t: 654, Episode_t: 6, Action: 15, Reward: 3.98, Epsilon: 0.35
[INFO] model update: t: 655, loss: 67003.359375
[INFO] Global_t: 655, Episode_t: 7, Action: 2, Reward: 6.03, Epsilon: 0.35
[INFO] model update: t: 656, loss: 13989.15234375
[INFO] Global_t: 656, Episode_t: 8, Action: 8, Reward: 3.37, Epsilon: 0.35

[INFO] Global step: 656, Cumulative rewards: 32.52648, Runtime (s): 1257.18
------------------------------------------------------------
 
 33%|███▎      | 656/2000 [20:57<38:20,  1.71s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.267361402511597
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.616352319717407
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.304682016372681
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.310661792755127
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.936067819595337
average cummulative reward vector is:  [0.14432816 0.1394412  0.14813224 0.13630794 0.14512769]
average cummulative reward is:  0.14266744682657512
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
[INFO] model update: t: 657, loss: 61182.875
[INFO] Global_t: 657, Episode_t: 1, Action: 0, Reward: 5.61, Epsilon: 0.35
[INFO] model update: t: 658, loss: 110134.6171875
[INFO] Global_t: 658, Episode_t: 2, Action: 1, Reward: 5.12, Epsilon: 0.35
[INFO] model update: t: 659, loss: 42158.3671875
[INFO] Global_t: 659, Episode_t: 3, Action: 31, Reward: 2.02, Epsilon: 0.35
[INFO] model update: t: 660, loss: 7447.951171875
[INFO] Global_t: 660, Episode_t: 4, Action: 2, Reward: 4.50, Epsilon: 0.34
[INFO] model update: t: 661, loss: 29250.99609375
[INFO] Global_t: 661, Episode_t: 5, Action: 180, Reward: 1.08, Epsilon: 0.34
[INFO] model update: t: 662, loss: 36059.7109375
[INFO] Global_t: 662, Episode_t: 6, Action: 9, Reward: 4.31, Epsilon: 0.34
[INFO] model update: t: 663, loss: 23677.052734375
[INFO] Global_t: 663, Episode_t: 7, Action: 6, Reward: 3.27, Epsilon: 0.34
[INFO] model update: t: 664, loss: 12987.880859375
[INFO] Global_t: 664, Episode_t: 8, Action: 5, Reward: 3.54, Epsilon: 0.34
 33%|███▎      | 664/2000 [21:24<49:39,  2.23s/it]
[INFO] Global step: 664, Cumulative rewards: 29.444039999999994, Runtime (s): 1284.71
------------------------------------------------------------
 
graph: 83, nodes: 198, edges: 584
[INFO] model update: t: 665, loss: 15181.9296875
[INFO] Global_t: 665, Episode_t: 1, Action: 3, Reward: 8.00, Epsilon: 0.34
[INFO] model update: t: 666, loss: 20376.56640625
[INFO] Global_t: 666, Episode_t: 2, Action: 175, Reward: 1.02, Epsilon: 0.34
[INFO] model update: t: 667, loss: 16104.0185546875
[INFO] Global_t: 667, Episode_t: 3, Action: 4, Reward: 5.07, Epsilon: 0.34
[INFO] model update: t: 668, loss: 21518.05078125
[INFO] Global_t: 668, Episode_t: 4, Action: 7, Reward: 4.53, Epsilon: 0.34
[INFO] model update: t: 669, loss: 27674.3671875
[INFO] Global_t: 669, Episode_t: 5, Action: 152, Reward: 1.66, Epsilon: 0.34
[INFO] model update: t: 670, loss: 75004.015625
[INFO] Global_t: 670, Episode_t: 6, Action: 8, Reward: 3.94, Epsilon: 0.33
[INFO] model update: t: 671, loss: 73924.8984375
[INFO] Global_t: 671, Episode_t: 7, Action: 45, Reward: 2.67, Epsilon: 0.33
[INFO] model update: t: 672, loss: 22366.03125
[INFO] Global_t: 672, Episode_t: 8, Action: 5, Reward: 5.76, Epsilon: 0.33
 34%|███▎      | 672/2000 [21:37<44:54,  2.03s/it]
[INFO] Global step: 672, Cumulative rewards: 32.65008, Runtime (s): 1297.17
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.941426992416382
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.546581983566284
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0345458984375
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.30859112739563
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.871082067489624
average cummulative reward vector is:  [0.13626316 0.14157269 0.14915546 0.12793949 0.13988952]
average cummulative reward is:  0.1389640619342274
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 84, nodes: 205, edges: 606
[INFO] model update: t: 673, loss: 13367.474609375
[INFO] Global_t: 673, Episode_t: 1, Action: 3, Reward: 6.56, Epsilon: 0.33
[INFO] model update: t: 674, loss: 43164.9921875
[INFO] Global_t: 674, Episode_t: 2, Action: 2, Reward: 5.71, Epsilon: 0.33
[INFO] model update: t: 675, loss: 45129.6484375
[INFO] Global_t: 675, Episode_t: 3, Action: 84, Reward: 1.85, Epsilon: 0.33
[INFO] model update: t: 676, loss: 38013.04296875
[INFO] Global_t: 676, Episode_t: 4, Action: 5, Reward: 5.81, Epsilon: 0.33
[INFO] model update: t: 677, loss: 30158.587890625
[INFO] Global_t: 677, Episode_t: 5, Action: 141, Reward: 1.36, Epsilon: 0.33
[INFO] model update: t: 678, loss: 17248.921875
[INFO] Global_t: 678, Episode_t: 6, Action: 10, Reward: 5.08, Epsilon: 0.33
[INFO] model update: t: 679, loss: 30162.7265625
[INFO] Global_t: 679, Episode_t: 7, Action: 0, Reward: 4.29, Epsilon: 0.33
[INFO] model update: t: 680, loss: 75340.03125
[INFO] Global_t: 680, Episode_t: 8, Action: 7, Reward: 4.09, Epsilon: 0.32
 34%|███▍      | 680/2000 [22:03<52:36,  2.39s/it]
[INFO] Global step: 680, Cumulative rewards: 34.746599999999994, Runtime (s): 1323.08
------------------------------------------------------------
 
graph: 85, nodes: 212, edges: 627
[INFO] model update: t: 681, loss: 116189.453125
[INFO] Global_t: 681, Episode_t: 1, Action: 80, Reward: 1.40, Epsilon: 0.32
[INFO] model update: t: 682, loss: 98007.4296875
[INFO] Global_t: 682, Episode_t: 2, Action: 17, Reward: 4.41, Epsilon: 0.32
[INFO] model update: t: 683, loss: 55888.0546875
[INFO] Global_t: 683, Episode_t: 3, Action: 53, Reward: 1.92, Epsilon: 0.32
[INFO] model update: t: 684, loss: 33637.62109375
[INFO] Global_t: 684, Episode_t: 4, Action: 4, Reward: 6.63, Epsilon: 0.32
[INFO] model update: t: 685, loss: 211402.125
[INFO] Global_t: 685, Episode_t: 5, Action: 5, Reward: 5.27, Epsilon: 0.32
[INFO] model update: t: 686, loss: 161330.53125
[INFO] Global_t: 686, Episode_t: 6, Action: 0, Reward: 4.70, Epsilon: 0.32
[INFO] model update: t: 687, loss: 17997.439453125
[INFO] Global_t: 687, Episode_t: 7, Action: 3, Reward: 5.64, Epsilon: 0.32
[INFO] model update: t: 688, loss: 157715.375
[INFO] Global_t: 688, Episode_t: 8, Action: 156, Reward: 1.19, Epsilon: 0.32
 34%|███▍      | 688/2000 [22:09<42:00,  1.92s/it]
[INFO] Global step: 688, Cumulative rewards: 31.158720000000002, Runtime (s): 1329.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.825951099395752
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.284164667129517
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.440141201019287
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.412335395812988
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.072181701660156
average cummulative reward vector is:  [0.13305316 0.13210324 0.1581765  0.13617453 0.14696828]
average cummulative reward is:  0.1412951427295782
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 86, nodes: 200, edges: 591
[INFO] model update: t: 689, loss: 349718.9375
[INFO] Global_t: 689, Episode_t: 1, Action: 4, Reward: 6.86, Epsilon: 0.32
[INFO] model update: t: 690, loss: 414993.9375
[INFO] Global_t: 690, Episode_t: 2, Action: 6, Reward: 5.70, Epsilon: 0.31
[INFO] model update: t: 691, loss: 356746.09375
[INFO] Global_t: 691, Episode_t: 3, Action: 8, Reward: 4.95, Epsilon: 0.31
[INFO] model update: t: 692, loss: 287723.78125
[INFO] Global_t: 692, Episode_t: 4, Action: 2, Reward: 6.30, Epsilon: 0.31
[INFO] model update: t: 693, loss: 206636.9375
[INFO] Global_t: 693, Episode_t: 5, Action: 1, Reward: 3.18, Epsilon: 0.31
[INFO] model update: t: 694, loss: 27405.013671875
[INFO] Global_t: 694, Episode_t: 6, Action: 24, Reward: 3.58, Epsilon: 0.31
[INFO] model update: t: 695, loss: 183508.5
[INFO] Global_t: 695, Episode_t: 7, Action: 9, Reward: 5.33, Epsilon: 0.31
[INFO] model update: t: 696, loss: 388229.375
[INFO] Global_t: 696, Episode_t: 8, Action: 3, Reward: 3.97, Epsilon: 0.31
 35%|███▍      | 696/2000 [22:36<51:08,  2.35s/it]
[INFO] Global step: 696, Cumulative rewards: 39.865199999999994, Runtime (s): 1356.55
------------------------------------------------------------
 
graph: 87, nodes: 218, edges: 645
[INFO] model update: t: 697, loss: 237692.59375
[INFO] Global_t: 697, Episode_t: 1, Action: 5, Reward: 6.85, Epsilon: 0.31
[INFO] model update: t: 698, loss: 29681.65234375
[INFO] Global_t: 698, Episode_t: 2, Action: 61, Reward: 1.37, Epsilon: 0.31
[INFO] model update: t: 699, loss: 69673.109375
[INFO] Global_t: 699, Episode_t: 3, Action: 3, Reward: 6.73, Epsilon: 0.31
[INFO] model update: t: 700, loss: 161034.796875
[INFO] Global_t: 700, Episode_t: 4, Action: 4, Reward: 6.81, Epsilon: 0.30
[INFO] model update: t: 701, loss: 110761.359375
[INFO] Global_t: 701, Episode_t: 5, Action: 2, Reward: 4.24, Epsilon: 0.30
[INFO] model update: t: 702, loss: 35726.84765625
[INFO] Global_t: 702, Episode_t: 6, Action: 7, Reward: 4.35, Epsilon: 0.30
[INFO] model update: t: 703, loss: 90903.0234375
[INFO] Global_t: 703, Episode_t: 7, Action: 12, Reward: 4.33, Epsilon: 0.30
[INFO] model update: t: 704, loss: 336758.53125
[INFO] Global_t: 704, Episode_t: 8, Action: 8, Reward: 3.97, Epsilon: 0.30
 35%|███▌      | 704/2000 [22:41<39:33,  1.83s/it]
[INFO] Global step: 704, Cumulative rewards: 38.65716, Runtime (s): 1361.47
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.349168062210083
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.267276048660278
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.317230224609375
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.297938346862793
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.489156723022461
average cummulative reward vector is:  [0.14367132 0.13248264 0.15436585 0.13364766 0.15488199]
average cummulative reward is:  0.14380989089432236
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 88, nodes: 204, edges: 603
[INFO] model update: t: 705, loss: 705167.625
[INFO] Global_t: 705, Episode_t: 1, Action: 6, Reward: 5.74, Epsilon: 0.30
[INFO] model update: t: 706, loss: 738967.9375
[INFO] Global_t: 706, Episode_t: 2, Action: 1, Reward: 5.38, Epsilon: 0.30
[INFO] model update: t: 707, loss: 237104.5625
[INFO] Global_t: 707, Episode_t: 3, Action: 203, Reward: 0.96, Epsilon: 0.30
[INFO] model update: t: 708, loss: 17031.65625
[INFO] Global_t: 708, Episode_t: 4, Action: 185, Reward: 1.47, Epsilon: 0.30
[INFO] model update: t: 709, loss: 111759.4765625
[INFO] Global_t: 709, Episode_t: 5, Action: 3, Reward: 4.69, Epsilon: 0.30
[INFO] model update: t: 710, loss: 124969.890625
[INFO] Global_t: 710, Episode_t: 6, Action: 109, Reward: 1.27, Epsilon: 0.30
[INFO] model update: t: 711, loss: 21594.427734375
[INFO] Global_t: 711, Episode_t: 7, Action: 63, Reward: 1.49, Epsilon: 0.29
[INFO] model update: t: 712, loss: 45764.984375
[INFO] Global_t: 712, Episode_t: 8, Action: 4, Reward: 4.39, Epsilon: 0.29
 36%|███▌      | 712/2000 [23:08<48:52,  2.28s/it]
[INFO] Global step: 712, Cumulative rewards: 25.3872, Runtime (s): 1388.00
------------------------------------------------------------
 
graph: 89, nodes: 199, edges: 588
[INFO] model update: t: 713, loss: 137505.640625
[INFO] Global_t: 713, Episode_t: 1, Action: 128, Reward: 1.24, Epsilon: 0.29
[INFO] model update: t: 714, loss: 239768.75
[INFO] Global_t: 714, Episode_t: 2, Action: 6, Reward: 5.33, Epsilon: 0.29
[INFO] model update: t: 715, loss: 183840.5625
[INFO] Global_t: 715, Episode_t: 3, Action: 5, Reward: 4.87, Epsilon: 0.29
[INFO] model update: t: 716, loss: 84480.0625
[INFO] Global_t: 716, Episode_t: 4, Action: 195, Reward: 1.62, Epsilon: 0.29
[INFO] model update: t: 717, loss: 26887.51171875
[INFO] Global_t: 717, Episode_t: 5, Action: 4, Reward: 4.65, Epsilon: 0.29
[INFO] model update: t: 718, loss: 12728.376953125
[INFO] Global_t: 718, Episode_t: 6, Action: 164, Reward: 1.15, Epsilon: 0.29
[INFO] model update: t: 719, loss: 77247.75
[INFO] Global_t: 719, Episode_t: 7, Action: 96, Reward: 1.15, Epsilon: 0.29
[INFO] model update: t: 720, loss: 165530.828125
[INFO] Global_t: 720, Episode_t: 8, Action: 89, Reward: 1.63, Epsilon: 0.29
 36%|███▌      | 720/2000 [23:12<37:40,  1.77s/it]
[INFO] Global step: 720, Cumulative rewards: 21.639239999999997, Runtime (s): 1392.59
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.471625328063965
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.605170011520386
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0746495723724365
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.417446851730347
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.320001602172852
average cummulative reward vector is:  [0.15431368 0.13851852 0.14263115 0.1397528  0.14677742]
average cummulative reward is:  0.14439871467263699
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 90, nodes: 207, edges: 612
[INFO] model update: t: 721, loss: 241941.75
[INFO] Global_t: 721, Episode_t: 1, Action: 4, Reward: 6.03, Epsilon: 0.28
[INFO] model update: t: 722, loss: 124699.578125
[INFO] Global_t: 722, Episode_t: 2, Action: 2, Reward: 6.35, Epsilon: 0.28
[INFO] model update: t: 723, loss: 10961.93359375
[INFO] Global_t: 723, Episode_t: 3, Action: 5, Reward: 5.16, Epsilon: 0.28
[INFO] model update: t: 724, loss: 191929.15625
[INFO] Global_t: 724, Episode_t: 4, Action: 1, Reward: 4.95, Epsilon: 0.28
[INFO] model update: t: 725, loss: 476056.875
[INFO] Global_t: 725, Episode_t: 5, Action: 3, Reward: 4.38, Epsilon: 0.28
[INFO] model update: t: 726, loss: 550420.3125
[INFO] Global_t: 726, Episode_t: 6, Action: 7, Reward: 4.22, Epsilon: 0.28
[INFO] model update: t: 727, loss: 268088.9375
[INFO] Global_t: 727, Episode_t: 7, Action: 12, Reward: 3.79, Epsilon: 0.28
[INFO] model update: t: 728, loss: 29283.501953125
[INFO] Global_t: 728, Episode_t: 8, Action: 15, Reward: 3.85, Epsilon: 0.28
 36%|███▋      | 728/2000 [23:41<48:49,  2.30s/it]
[INFO] Global step: 728, Cumulative rewards: 38.72436, Runtime (s): 1421.05
------------------------------------------------------------
 
graph: 91, nodes: 198, edges: 585
[INFO] model update: t: 729, loss: 114317.5
[INFO] Global_t: 729, Episode_t: 1, Action: 26, Reward: 3.20, Epsilon: 0.28
[INFO] model update: t: 730, loss: 292839.0
[INFO] Global_t: 730, Episode_t: 2, Action: 4, Reward: 7.62, Epsilon: 0.28
[INFO] model update: t: 731, loss: 117171.546875
[INFO] Global_t: 731, Episode_t: 3, Action: 6, Reward: 6.32, Epsilon: 0.27
[INFO] model update: t: 732, loss: 24071.90234375
[INFO] Global_t: 732, Episode_t: 4, Action: 144, Reward: 1.31, Epsilon: 0.27
[INFO] model update: t: 733, loss: 57842.36328125
[INFO] Global_t: 733, Episode_t: 5, Action: 3, Reward: 5.02, Epsilon: 0.27
[INFO] model update: t: 734, loss: 33146.71875
[INFO] Global_t: 734, Episode_t: 6, Action: 5, Reward: 4.42, Epsilon: 0.27
[INFO] model update: t: 735, loss: 23730.248046875
[INFO] Global_t: 735, Episode_t: 7, Action: 11, Reward: 5.65, Epsilon: 0.27
[INFO] model update: t: 736, loss: 177511.59375
[INFO] Global_t: 736, Episode_t: 8, Action: 9, Reward: 3.84, Epsilon: 0.27
 37%|███▋      | 736/2000 [23:46<38:02,  1.81s/it]
[INFO] Global step: 736, Cumulative rewards: 37.3764, Runtime (s): 1426.22
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.2082579135894775
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.232638120651245
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.204253911972046
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.63781476020813
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.013054132461548
average cummulative reward vector is:  [0.14848132 0.12639861 0.15588716 0.14473341 0.13940484]
average cummulative reward is:  0.14298106705903213
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 92, nodes: 183, edges: 539
[INFO] model update: t: 737, loss: 514776.0
[INFO] Global_t: 737, Episode_t: 1, Action: 8, Reward: 7.07, Epsilon: 0.27
[INFO] model update: t: 738, loss: 882853.5
[INFO] Global_t: 738, Episode_t: 2, Action: 1, Reward: 6.19, Epsilon: 0.27
[INFO] model update: t: 739, loss: 1479124.0
[INFO] Global_t: 739, Episode_t: 3, Action: 4, Reward: 5.94, Epsilon: 0.27
[INFO] model update: t: 740, loss: 2036089.0
[INFO] Global_t: 740, Episode_t: 4, Action: 0, Reward: 4.69, Epsilon: 0.27
[INFO] model update: t: 741, loss: 2292829.5
[INFO] Global_t: 741, Episode_t: 5, Action: 9, Reward: 4.20, Epsilon: 0.26
[INFO] model update: t: 742, loss: 1799875.25
[INFO] Global_t: 742, Episode_t: 6, Action: 135, Reward: 0.96, Epsilon: 0.26
[INFO] model update: t: 743, loss: 579700.25
[INFO] Global_t: 743, Episode_t: 7, Action: 3, Reward: 3.71, Epsilon: 0.26
[INFO] model update: t: 744, loss: 12866.1953125
[INFO] Global_t: 744, Episode_t: 8, Action: 5, Reward: 4.22, Epsilon: 0.26
 37%|███▋      | 744/2000 [24:15<49:06,  2.35s/it]
[INFO] Global step: 744, Cumulative rewards: 36.9828, Runtime (s): 1455.06
------------------------------------------------------------
 
graph: 93, nodes: 217, edges: 642
[INFO] model update: t: 745, loss: 448570.875
[INFO] Global_t: 745, Episode_t: 1, Action: 5, Reward: 7.52, Epsilon: 0.26
[INFO] model update: t: 746, loss: 1171229.5
[INFO] Global_t: 746, Episode_t: 2, Action: 2, Reward: 5.95, Epsilon: 0.26
[INFO] model update: t: 747, loss: 611014.0
[INFO] Global_t: 747, Episode_t: 3, Action: 18, Reward: 2.20, Epsilon: 0.26
[INFO] model update: t: 748, loss: 193833.125
[INFO] Global_t: 748, Episode_t: 4, Action: 0, Reward: 5.01, Epsilon: 0.26
[INFO] model update: t: 749, loss: 48912.078125
[INFO] Global_t: 749, Episode_t: 5, Action: 1, Reward: 4.84, Epsilon: 0.26
[INFO] model update: t: 750, loss: 13776.4404296875
[INFO] Global_t: 750, Episode_t: 6, Action: 189, Reward: 1.38, Epsilon: 0.26
[INFO] model update: t: 751, loss: 83647.78125
[INFO] Global_t: 751, Episode_t: 7, Action: 4, Reward: 4.19, Epsilon: 0.26
[INFO] model update: t: 752, loss: 154001.5
[INFO] Global_t: 752, Episode_t: 8, Action: 8, Reward: 4.56, Epsilon: 0.25
 38%|███▊      | 752/2000 [24:21<39:02,  1.88s/it]
[INFO] Global step: 752, Cumulative rewards: 35.65104, Runtime (s): 1461.33
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.22548770904541
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.017758846282959
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9137845039367676
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.745053291320801
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.183469295501709
average cummulative reward vector is:  [0.14810763 0.1252037  0.14588798 0.14111402 0.1466164 ]
average cummulative reward is:  0.14138594599315574
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 94, nodes: 198, edges: 585
[INFO] model update: t: 753, loss: 136967.546875
[INFO] Global_t: 753, Episode_t: 1, Action: 3, Reward: 7.78, Epsilon: 0.25
[INFO] model update: t: 754, loss: 47865.82421875
[INFO] Global_t: 754, Episode_t: 2, Action: 2, Reward: 5.51, Epsilon: 0.25
[INFO] model update: t: 755, loss: 36361.25
[INFO] Global_t: 755, Episode_t: 3, Action: 1, Reward: 5.58, Epsilon: 0.25
[INFO] model update: t: 756, loss: 227766.953125
[INFO] Global_t: 756, Episode_t: 4, Action: 9, Reward: 4.82, Epsilon: 0.25
[INFO] model update: t: 757, loss: 370571.90625
[INFO] Global_t: 757, Episode_t: 5, Action: 6, Reward: 4.41, Epsilon: 0.25
[INFO] model update: t: 758, loss: 240436.9375
[INFO] Global_t: 758, Episode_t: 6, Action: 4, Reward: 3.79, Epsilon: 0.25
[INFO] model update: t: 759, loss: 39880.6015625
[INFO] Global_t: 759, Episode_t: 7, Action: 158, Reward: 1.25, Epsilon: 0.25
[INFO] model update: t: 760, loss: 120537.109375
[INFO] Global_t: 760, Episode_t: 8, Action: 132, Reward: 1.53, Epsilon: 0.25
 38%|███▊      | 760/2000 [24:47<47:41,  2.31s/it]
[INFO] Global step: 760, Cumulative rewards: 34.69344, Runtime (s): 1487.83
------------------------------------------------------------
 
graph: 95, nodes: 202, edges: 597
[INFO] model update: t: 761, loss: 682033.875
[INFO] Global_t: 761, Episode_t: 1, Action: 6, Reward: 6.76, Epsilon: 0.25
[INFO] model update: t: 762, loss: 1762681.0
[INFO] Global_t: 762, Episode_t: 2, Action: 107, Reward: 2.15, Epsilon: 0.24
[INFO] model update: t: 763, loss: 3821295.75
[INFO] Global_t: 763, Episode_t: 3, Action: 3, Reward: 7.29, Epsilon: 0.24
[INFO] model update: t: 764, loss: 3753755.5
[INFO] Global_t: 764, Episode_t: 4, Action: 2, Reward: 6.51, Epsilon: 0.24
[INFO] model update: t: 765, loss: 7181796.0
[INFO] Global_t: 765, Episode_t: 5, Action: 5, Reward: 4.93, Epsilon: 0.24
[INFO] model update: t: 766, loss: 15688406.0
[INFO] Global_t: 766, Episode_t: 6, Action: 30, Reward: 1.77, Epsilon: 0.24
[INFO] model update: t: 767, loss: 16025724.0
[INFO] Global_t: 767, Episode_t: 7, Action: 4, Reward: 5.37, Epsilon: 0.24
[INFO] model update: t: 768, loss: 3929379.5
[INFO] Global_t: 768, Episode_t: 8, Action: 8, Reward: 5.05, Epsilon: 0.24
 38%|███▊      | 768/2000 [24:53<37:15,  1.81s/it]
[INFO] Global step: 768, Cumulative rewards: 39.82283999999999, Runtime (s): 1493.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.3286521434783936
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.301878929138184
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.044310092926025
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.137256622314453
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7082319259643555
average cummulative reward vector is:  [0.14723289 0.13334259 0.15090027 0.1228715  0.13027151]
average cummulative reward is:  0.1369237522513851
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 96, nodes: 200, edges: 591
[INFO] model update: t: 769, loss: 307828.9375
[INFO] Global_t: 769, Episode_t: 1, Action: 7, Reward: 4.47, Epsilon: 0.24
[INFO] model update: t: 770, loss: 6062604.0
[INFO] Global_t: 770, Episode_t: 2, Action: 159, Reward: 1.57, Epsilon: 0.24
[INFO] model update: t: 771, loss: 13975862.0
[INFO] Global_t: 771, Episode_t: 3, Action: 3, Reward: 6.51, Epsilon: 0.24
[INFO] model update: t: 772, loss: 10424587.0
[INFO] Global_t: 772, Episode_t: 4, Action: 2, Reward: 5.43, Epsilon: 0.23
[INFO] model update: t: 773, loss: 3386672.5
[INFO] Global_t: 773, Episode_t: 5, Action: 5, Reward: 4.08, Epsilon: 0.23
[INFO] model update: t: 774, loss: 54023.5703125
[INFO] Global_t: 774, Episode_t: 6, Action: 1, Reward: 4.27, Epsilon: 0.23
[INFO] model update: t: 775, loss: 2303087.75
[INFO] Global_t: 775, Episode_t: 7, Action: 12, Reward: 4.12, Epsilon: 0.23
[INFO] model update: t: 776, loss: 5472326.5
[INFO] Global_t: 776, Episode_t: 8, Action: 6, Reward: 3.74, Epsilon: 0.23
 39%|███▉      | 776/2000 [25:18<45:27,  2.23s/it]
[INFO] Global step: 776, Cumulative rewards: 34.2018, Runtime (s): 1518.70
------------------------------------------------------------
 
graph: 97, nodes: 206, edges: 609
[INFO] model update: t: 777, loss: 5975475.0
[INFO] Global_t: 777, Episode_t: 1, Action: 193, Reward: 1.40, Epsilon: 0.23
[INFO] model update: t: 778, loss: 4030799.5
[INFO] Global_t: 778, Episode_t: 2, Action: 1, Reward: 7.32, Epsilon: 0.23
[INFO] model update: t: 779, loss: 1970913.625
[INFO] Global_t: 779, Episode_t: 3, Action: 4, Reward: 5.34, Epsilon: 0.23
[INFO] model update: t: 780, loss: 54827.6484375
[INFO] Global_t: 780, Episode_t: 4, Action: 8, Reward: 4.47, Epsilon: 0.23
[INFO] model update: t: 781, loss: 1044804.625
[INFO] Global_t: 781, Episode_t: 5, Action: 3, Reward: 4.66, Epsilon: 0.23
[INFO] model update: t: 782, loss: 2776907.5
[INFO] Global_t: 782, Episode_t: 6, Action: 0, Reward: 4.53, Epsilon: 0.22
[INFO] model update: t: 783, loss: 3327544.5
[INFO] Global_t: 783, Episode_t: 7, Action: 7, Reward: 3.74, Epsilon: 0.22
[INFO] model update: t: 784, loss: 247659.359375
[INFO] Global_t: 784, Episode_t: 8, Action: 158, Reward: 1.27, Epsilon: 0.22
 39%|███▉      | 784/2000 [25:23<35:03,  1.73s/it]
[INFO] Global step: 784, Cumulative rewards: 32.72028, Runtime (s): 1523.23
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.5111589431762695
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.057345151901245
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.12633752822876
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.471965551376343
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.022449970245361
average cummulative reward vector is:  [0.15259105 0.12671644 0.15416366 0.13706145 0.14726989]
average cummulative reward is:  0.1435604980180398
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 98, nodes: 206, edges: 607
[INFO] model update: t: 785, loss: 1346226.625
[INFO] Global_t: 785, Episode_t: 1, Action: 3, Reward: 6.22, Epsilon: 0.22
[INFO] model update: t: 786, loss: 3185884.0
[INFO] Global_t: 786, Episode_t: 2, Action: 6, Reward: 5.29, Epsilon: 0.22
[INFO] model update: t: 787, loss: 925795.0
[INFO] Global_t: 787, Episode_t: 3, Action: 4, Reward: 5.32, Epsilon: 0.22
[INFO] model update: t: 788, loss: 100867.453125
[INFO] Global_t: 788, Episode_t: 4, Action: 7, Reward: 4.86, Epsilon: 0.22
[INFO] model update: t: 789, loss: 908423.625
[INFO] Global_t: 789, Episode_t: 5, Action: 16, Reward: 3.74, Epsilon: 0.22
[INFO] model update: t: 790, loss: 1189895.75
[INFO] Global_t: 790, Episode_t: 6, Action: 12, Reward: 3.74, Epsilon: 0.22
[INFO] model update: t: 791, loss: 355348.9375
[INFO] Global_t: 791, Episode_t: 7, Action: 2, Reward: 3.67, Epsilon: 0.22
[INFO] model update: t: 792, loss: 192421.3125
[INFO] Global_t: 792, Episode_t: 8, Action: 1, Reward: 3.24, Epsilon: 0.21
 40%|███▉      | 792/2000 [25:49<44:08,  2.19s/it]
[INFO] Global step: 792, Cumulative rewards: 36.07152, Runtime (s): 1549.40
------------------------------------------------------------
 
graph: 99, nodes: 181, edges: 533
[INFO] model update: t: 793, loss: 771616.75
[INFO] Global_t: 793, Episode_t: 1, Action: 3, Reward: 6.97, Epsilon: 0.21
[INFO] model update: t: 794, loss: 511372.40625
[INFO] Global_t: 794, Episode_t: 2, Action: 4, Reward: 6.69, Epsilon: 0.21
[INFO] model update: t: 795, loss: 119358.34375
[INFO] Global_t: 795, Episode_t: 3, Action: 93, Reward: 1.19, Epsilon: 0.21
[INFO] model update: t: 796, loss: 127187.7890625
[INFO] Global_t: 796, Episode_t: 4, Action: 2, Reward: 6.38, Epsilon: 0.21
[INFO] model update: t: 797, loss: 707570.25
[INFO] Global_t: 797, Episode_t: 5, Action: 120, Reward: 0.97, Epsilon: 0.21
[INFO] model update: t: 798, loss: 972406.625
[INFO] Global_t: 798, Episode_t: 6, Action: 5, Reward: 4.76, Epsilon: 0.21
[INFO] model update: t: 799, loss: 785221.0625
[INFO] Global_t: 799, Episode_t: 7, Action: 10, Reward: 4.38, Epsilon: 0.21
[INFO] model update: t: 800, loss: 209512.125
[INFO] Global_t: 800, Episode_t: 8, Action: 0, Reward: 4.28, Epsilon: 0.21
 40%|████      | 800/2000 [25:54<34:28,  1.72s/it]
[INFO] Global step: 800, Cumulative rewards: 35.61972, Runtime (s): 1554.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.319935083389282
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.352267026901245
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.094602346420288
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.363478183746338
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6898341178894043
average cummulative reward vector is:  [0.14444053 0.12986273 0.1468     0.13377804 0.13689543]
average cummulative reward is:  0.13835534505759509
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 100, nodes: 188, edges: 555
[INFO] model update: t: 801, loss: 56262.671875
[INFO] Global_t: 801, Episode_t: 1, Action: 1, Reward: 6.25, Epsilon: 0.21
[INFO] model update: t: 802, loss: 660949.25
[INFO] Global_t: 802, Episode_t: 2, Action: 3, Reward: 5.00, Epsilon: 0.21
[INFO] model update: t: 803, loss: 788283.375
[INFO] Global_t: 803, Episode_t: 3, Action: 8, Reward: 6.84, Epsilon: 0.20
[INFO] model update: t: 804, loss: 243887.65625
[INFO] Global_t: 804, Episode_t: 4, Action: 0, Reward: 5.11, Epsilon: 0.20
[INFO] model update: t: 805, loss: 49237.74609375
[INFO] Global_t: 805, Episode_t: 5, Action: 10, Reward: 4.25, Epsilon: 0.20
[INFO] model update: t: 806, loss: 458255.6875
[INFO] Global_t: 806, Episode_t: 6, Action: 4, Reward: 4.32, Epsilon: 0.20
[INFO] model update: t: 807, loss: 571969.125
[INFO] Global_t: 807, Episode_t: 7, Action: 6, Reward: 3.58, Epsilon: 0.20
[INFO] model update: t: 808, loss: 412173.0625
[INFO] Global_t: 808, Episode_t: 8, Action: 13, Reward: 2.30, Epsilon: 0.20
 40%|████      | 808/2000 [26:20<43:28,  2.19s/it]
[INFO] Global step: 808, Cumulative rewards: 37.66224, Runtime (s): 1580.62
------------------------------------------------------------
 
graph: 101, nodes: 211, edges: 624
[INFO] model update: t: 809, loss: 241682.625
[INFO] Global_t: 809, Episode_t: 1, Action: 1, Reward: 7.44, Epsilon: 0.20
[INFO] model update: t: 810, loss: 227883.5
[INFO] Global_t: 810, Episode_t: 2, Action: 10, Reward: 3.94, Epsilon: 0.20
[INFO] model update: t: 811, loss: 88443.8203125
[INFO] Global_t: 811, Episode_t: 3, Action: 3, Reward: 8.40, Epsilon: 0.20
[INFO] model update: t: 812, loss: 14949.4375
[INFO] Global_t: 812, Episode_t: 4, Action: 0, Reward: 6.22, Epsilon: 0.20
[INFO] model update: t: 813, loss: 109566.8671875
[INFO] Global_t: 813, Episode_t: 5, Action: 4, Reward: 4.34, Epsilon: 0.19
[INFO] model update: t: 814, loss: 277889.53125
[INFO] Global_t: 814, Episode_t: 6, Action: 6, Reward: 4.08, Epsilon: 0.19
[INFO] model update: t: 815, loss: 242223.46875
[INFO] Global_t: 815, Episode_t: 7, Action: 123, Reward: 1.64, Epsilon: 0.19
[INFO] model update: t: 816, loss: 47906.16796875
[INFO] Global_t: 816, Episode_t: 8, Action: 25, Reward: 4.31, Epsilon: 0.19
 41%|████      | 816/2000 [26:26<34:25,  1.74s/it]
[INFO] Global step: 816, Cumulative rewards: 40.38419999999999, Runtime (s): 1586.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.950011968612671
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.5483362674713135
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.288423538208008
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.093477249145508
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.822469711303711
average cummulative reward vector is:  [0.13438553 0.13767014 0.15115383 0.12711682 0.14149113]
average cummulative reward is:  0.13836348836069096
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 102, nodes: 180, edges: 531
[INFO] model update: t: 817, loss: 84930.71875
[INFO] Global_t: 817, Episode_t: 1, Action: 178, Reward: 1.12, Epsilon: 0.19
[INFO] model update: t: 818, loss: 382905.5625
[INFO] Global_t: 818, Episode_t: 2, Action: 3, Reward: 7.07, Epsilon: 0.19
[INFO] model update: t: 819, loss: 636996.3125
[INFO] Global_t: 819, Episode_t: 3, Action: 1, Reward: 6.39, Epsilon: 0.19
[INFO] model update: t: 820, loss: 297689.46875
[INFO] Global_t: 820, Episode_t: 4, Action: 4, Reward: 4.89, Epsilon: 0.19
[INFO] model update: t: 821, loss: 55380.5703125
[INFO] Global_t: 821, Episode_t: 5, Action: 6, Reward: 5.06, Epsilon: 0.19
[INFO] model update: t: 822, loss: 390887.9375
[INFO] Global_t: 822, Episode_t: 6, Action: 7, Reward: 4.23, Epsilon: 0.19
[INFO] model update: t: 823, loss: 568441.3125
[INFO] Global_t: 823, Episode_t: 7, Action: 0, Reward: 4.17, Epsilon: 0.18
[INFO] model update: t: 824, loss: 228694.0625
[INFO] Global_t: 824, Episode_t: 8, Action: 13, Reward: 3.59, Epsilon: 0.18
 41%|████      | 824/2000 [26:51<42:27,  2.17s/it]
[INFO] Global step: 824, Cumulative rewards: 36.5322, Runtime (s): 1611.49
------------------------------------------------------------
 
graph: 103, nodes: 187, edges: 551
[INFO] model update: t: 825, loss: 33099.9765625
[INFO] Global_t: 825, Episode_t: 1, Action: 3, Reward: 7.11, Epsilon: 0.18
[INFO] model update: t: 826, loss: 387151.96875
[INFO] Global_t: 826, Episode_t: 2, Action: 4, Reward: 5.47, Epsilon: 0.18
[INFO] model update: t: 827, loss: 793528.875
[INFO] Global_t: 827, Episode_t: 3, Action: 7, Reward: 4.84, Epsilon: 0.18
[INFO] model update: t: 828, loss: 1208749.375
[INFO] Global_t: 828, Episode_t: 4, Action: 0, Reward: 3.91, Epsilon: 0.18
[INFO] model update: t: 829, loss: 833049.25
[INFO] Global_t: 829, Episode_t: 5, Action: 2, Reward: 3.92, Epsilon: 0.18
[INFO] model update: t: 830, loss: 32889.73828125
[INFO] Global_t: 830, Episode_t: 6, Action: 10, Reward: 5.76, Epsilon: 0.18
[INFO] model update: t: 831, loss: 304363.875
[INFO] Global_t: 831, Episode_t: 7, Action: 1, Reward: 3.50, Epsilon: 0.18
[INFO] model update: t: 832, loss: 566953.375
[INFO] Global_t: 832, Episode_t: 8, Action: 147, Reward: 1.53, Epsilon: 0.18
 42%|████▏     | 832/2000 [26:56<33:10,  1.70s/it]
[INFO] Global step: 832, Cumulative rewards: 36.053639999999994, Runtime (s): 1616.51
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.698129653930664
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.43470025062561
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9359116554260254
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.182703495025635
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9940333366394043
average cummulative reward vector is:  [0.15268658 0.13682361 0.13748716 0.13211449 0.1480086 ]
average cummulative reward is:  0.1414240873320542
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 104, nodes: 185, edges: 546
[INFO] model update: t: 833, loss: 804942.75
[INFO] Global_t: 833, Episode_t: 1, Action: 2, Reward: 7.50, Epsilon: 0.17
[INFO] model update: t: 834, loss: 945510.375
[INFO] Global_t: 834, Episode_t: 2, Action: 5, Reward: 5.26, Epsilon: 0.17
[INFO] model update: t: 835, loss: 599015.6875
[INFO] Global_t: 835, Episode_t: 3, Action: 0, Reward: 4.79, Epsilon: 0.17
[INFO] model update: t: 836, loss: 150252.9375
[INFO] Global_t: 836, Episode_t: 4, Action: 178, Reward: 1.04, Epsilon: 0.17
[INFO] model update: t: 837, loss: 17834.328125
[INFO] Global_t: 837, Episode_t: 5, Action: 70, Reward: 1.25, Epsilon: 0.17
[INFO] model update: t: 838, loss: 110161.15625
[INFO] Global_t: 838, Episode_t: 6, Action: 3, Reward: 5.58, Epsilon: 0.17
[INFO] model update: t: 839, loss: 153668.21875
[INFO] Global_t: 839, Episode_t: 7, Action: 129, Reward: 1.37, Epsilon: 0.17
[INFO] model update: t: 840, loss: 20095.078125
[INFO] Global_t: 840, Episode_t: 8, Action: 4, Reward: 3.91, Epsilon: 0.17
 42%|████▏     | 840/2000 [27:23<42:34,  2.20s/it]
[INFO] Global step: 840, Cumulative rewards: 30.70416, Runtime (s): 1643.42
------------------------------------------------------------
 
graph: 105, nodes: 180, edges: 531
[INFO] model update: t: 841, loss: 97224.1796875
[INFO] Global_t: 841, Episode_t: 1, Action: 3, Reward: 6.26, Epsilon: 0.17
[INFO] model update: t: 842, loss: 222124.015625
[INFO] Global_t: 842, Episode_t: 2, Action: 8, Reward: 4.39, Epsilon: 0.17
[INFO] model update: t: 843, loss: 181276.953125
[INFO] Global_t: 843, Episode_t: 3, Action: 2, Reward: 4.11, Epsilon: 0.16
[INFO] model update: t: 844, loss: 39353.75
[INFO] Global_t: 844, Episode_t: 4, Action: 119, Reward: 1.06, Epsilon: 0.16
[INFO] model update: t: 845, loss: 41076.4140625
[INFO] Global_t: 845, Episode_t: 5, Action: 127, Reward: 1.50, Epsilon: 0.16
[INFO] model update: t: 846, loss: 130548.8828125
[INFO] Global_t: 846, Episode_t: 6, Action: 4, Reward: 3.83, Epsilon: 0.16
[INFO] model update: t: 847, loss: 173810.125
[INFO] Global_t: 847, Episode_t: 7, Action: 1, Reward: 3.92, Epsilon: 0.16
[INFO] model update: t: 848, loss: 165252.5
[INFO] Global_t: 848, Episode_t: 8, Action: 18, Reward: 3.61, Epsilon: 0.16
 42%|████▏     | 848/2000 [27:28<33:28,  1.74s/it]
[INFO] Global step: 848, Cumulative rewards: 28.675079999999994, Runtime (s): 1648.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.264348983764648
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.114450454711914
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.088958501815796
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.151093006134033
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9779858589172363
average cummulative reward vector is:  [0.14659684 0.12418819 0.14892213 0.13105561 0.14621398]
average cummulative reward is:  0.13939535073370157
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 106, nodes: 206, edges: 608
[INFO] model update: t: 849, loss: 107781.328125
[INFO] Global_t: 849, Episode_t: 1, Action: 137, Reward: 1.44, Epsilon: 0.16
[INFO] model update: t: 850, loss: 37166.1484375
[INFO] Global_t: 850, Episode_t: 2, Action: 3, Reward: 6.47, Epsilon: 0.16
[INFO] model update: t: 851, loss: 42499.49609375
[INFO] Global_t: 851, Episode_t: 3, Action: 4, Reward: 6.19, Epsilon: 0.16
[INFO] model update: t: 852, loss: 286253.5625
[INFO] Global_t: 852, Episode_t: 4, Action: 13, Reward: 5.98, Epsilon: 0.16
[INFO] model update: t: 853, loss: 363330.09375
[INFO] Global_t: 853, Episode_t: 5, Action: 1, Reward: 5.15, Epsilon: 0.16
[INFO] model update: t: 854, loss: 222078.65625
[INFO] Global_t: 854, Episode_t: 6, Action: 7, Reward: 5.94, Epsilon: 0.15
[INFO] model update: t: 855, loss: 34647.015625
[INFO] Global_t: 855, Episode_t: 7, Action: 2, Reward: 5.41, Epsilon: 0.15
 43%|████▎     | 856/2000 [27:55<42:04,  2.21s/it][INFO] model update: t: 856, loss: 60131.68359375
[INFO] Global_t: 856, Episode_t: 8, Action: 11, Reward: 4.36, Epsilon: 0.15

[INFO] Global step: 856, Cumulative rewards: 40.94135999999999, Runtime (s): 1675.11
------------------------------------------------------------
 
graph: 107, nodes: 205, edges: 606
[INFO] model update: t: 857, loss: 212071.21875
[INFO] Global_t: 857, Episode_t: 1, Action: 2, Reward: 6.72, Epsilon: 0.15
[INFO] model update: t: 858, loss: 163400.03125
[INFO] Global_t: 858, Episode_t: 2, Action: 10, Reward: 5.03, Epsilon: 0.15
[INFO] model update: t: 859, loss: 40333.609375
[INFO] Global_t: 859, Episode_t: 3, Action: 61, Reward: 1.78, Epsilon: 0.15
[INFO] model update: t: 860, loss: 24020.416015625
[INFO] Global_t: 860, Episode_t: 4, Action: 0, Reward: 2.69, Epsilon: 0.15
[INFO] model update: t: 861, loss: 90036.7890625
[INFO] Global_t: 861, Episode_t: 5, Action: 15, Reward: 5.32, Epsilon: 0.15
[INFO] model update: t: 862, loss: 216300.15625
[INFO] Global_t: 862, Episode_t: 6, Action: 3, Reward: 5.72, Epsilon: 0.15
[INFO] model update: t: 863, loss: 116798.7578125
[INFO] Global_t: 863, Episode_t: 7, Action: 5, Reward: 4.22, Epsilon: 0.15
[INFO] model update: t: 864, loss: 21623.77734375
[INFO] Global_t: 864, Episode_t: 8, Action: 27, Reward: 1.74, Epsilon: 0.14
 43%|████▎     | 864/2000 [28:00<33:20,  1.76s/it]
[INFO] Global step: 864, Cumulative rewards: 33.2202, Runtime (s): 1680.87
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.155699968338013
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.408718585968018
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.174190998077393
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.489211320877075
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.461665630340576
average cummulative reward vector is:  [0.14755474 0.13703935 0.1467377  0.13906542 0.15453038]
average cummulative reward is:  0.1449855181033647
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 108, nodes: 215, edges: 636
[INFO] model update: t: 865, loss: 94754.65625
[INFO] Global_t: 865, Episode_t: 1, Action: 4, Reward: 8.95, Epsilon: 0.14
[INFO] model update: t: 866, loss: 133698.9375
[INFO] Global_t: 866, Episode_t: 2, Action: 0, Reward: 5.66, Epsilon: 0.14
[INFO] model update: t: 867, loss: 105508.078125
[INFO] Global_t: 867, Episode_t: 3, Action: 1, Reward: 5.22, Epsilon: 0.14
[INFO] model update: t: 868, loss: 80697.0234375
[INFO] Global_t: 868, Episode_t: 4, Action: 31, Reward: 1.88, Epsilon: 0.14
[INFO] model update: t: 869, loss: 36072.15234375
[INFO] Global_t: 869, Episode_t: 5, Action: 2, Reward: 4.62, Epsilon: 0.14
[INFO] model update: t: 870, loss: 13526.8828125
[INFO] Global_t: 870, Episode_t: 6, Action: 5, Reward: 4.30, Epsilon: 0.14
[INFO] model update: t: 871, loss: 14462.3779296875
[INFO] Global_t: 871, Episode_t: 7, Action: 9, Reward: 4.15, Epsilon: 0.14
[INFO] model update: t: 872, loss: 28448.05078125
[INFO] Global_t: 872, Episode_t: 8, Action: 14, Reward: 3.68, Epsilon: 0.14
 44%|████▎     | 872/2000 [28:31<45:03,  2.40s/it]
[INFO] Global step: 872, Cumulative rewards: 38.44836, Runtime (s): 1711.90
------------------------------------------------------------
 
graph: 109, nodes: 186, edges: 549
[INFO] model update: t: 873, loss: 19597.70703125
[INFO] Global_t: 873, Episode_t: 1, Action: 3, Reward: 5.98, Epsilon: 0.14
[INFO] model update: t: 874, loss: 10865.6279296875
[INFO] Global_t: 874, Episode_t: 2, Action: 4, Reward: 7.67, Epsilon: 0.13
[INFO] model update: t: 875, loss: 7761.4091796875
[INFO] Global_t: 875, Episode_t: 3, Action: 1, Reward: 6.74, Epsilon: 0.13
[INFO] model update: t: 876, loss: 16538.4140625
[INFO] Global_t: 876, Episode_t: 4, Action: 6, Reward: 6.17, Epsilon: 0.13
[INFO] model update: t: 877, loss: 23206.73046875
[INFO] Global_t: 877, Episode_t: 5, Action: 2, Reward: 5.14, Epsilon: 0.13
[INFO] model update: t: 878, loss: 21522.75390625
[INFO] Global_t: 878, Episode_t: 6, Action: 7, Reward: 4.01, Epsilon: 0.13
[INFO] model update: t: 879, loss: 7314.11962890625
[INFO] Global_t: 879, Episode_t: 7, Action: 16, Reward: 3.65, Epsilon: 0.13
[INFO] model update: t: 880, loss: 19504.3203125
[INFO] Global_t: 880, Episode_t: 8, Action: 17, Reward: 3.40, Epsilon: 0.13

[INFO] Global step: 880, Cumulative rewards: 42.76764, Runtime (s): 1717.34
------------------------------------------------------------
 
 44%|████▍     | 880/2000 [28:37<35:07,  1.88s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.129414081573486
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.6829164028167725
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.01134181022644
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.646866321563721
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.178758144378662
average cummulative reward vector is:  [0.14635895 0.13659444 0.14799836 0.1340507  0.15172419]
average cummulative reward is:  0.1433453293903139
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 110, nodes: 180, edges: 531
[INFO] model update: t: 881, loss: 31295.60546875
[INFO] Global_t: 881, Episode_t: 1, Action: 4, Reward: 8.01, Epsilon: 0.13
[INFO] model update: t: 882, loss: 34725.15234375
[INFO] Global_t: 882, Episode_t: 2, Action: 3, Reward: 5.45, Epsilon: 0.13
[INFO] model update: t: 883, loss: 40407.765625
[INFO] Global_t: 883, Episode_t: 3, Action: 0, Reward: 3.85, Epsilon: 0.13
[INFO] model update: t: 884, loss: 67361.8125
[INFO] Global_t: 884, Episode_t: 4, Action: 6, Reward: 3.76, Epsilon: 0.12
[INFO] model update: t: 885, loss: 34651.40234375
[INFO] Global_t: 885, Episode_t: 5, Action: 2, Reward: 3.68, Epsilon: 0.12
[INFO] model update: t: 886, loss: 16543.63671875
[INFO] Global_t: 886, Episode_t: 6, Action: 12, Reward: 3.41, Epsilon: 0.12
[INFO] model update: t: 887, loss: 74778.625
[INFO] Global_t: 887, Episode_t: 7, Action: 14, Reward: 3.66, Epsilon: 0.12
[INFO] model update: t: 888, loss: 102500.484375
[INFO] Global_t: 888, Episode_t: 8, Action: 1, Reward: 3.65, Epsilon: 0.12
 44%|████▍     | 888/2000 [29:04<43:06,  2.33s/it]
[INFO] Global step: 888, Cumulative rewards: 35.4744, Runtime (s): 1744.24
------------------------------------------------------------
 
graph: 111, nodes: 200, edges: 591
[INFO] model update: t: 889, loss: 46480.484375
[INFO] Global_t: 889, Episode_t: 1, Action: 5, Reward: 6.01, Epsilon: 0.12
[INFO] model update: t: 890, loss: 12634.3232421875
[INFO] Global_t: 890, Episode_t: 2, Action: 3, Reward: 5.22, Epsilon: 0.12
[INFO] model update: t: 891, loss: 49730.4140625
[INFO] Global_t: 891, Episode_t: 3, Action: 0, Reward: 5.54, Epsilon: 0.12
[INFO] model update: t: 892, loss: 90423.3828125
[INFO] Global_t: 892, Episode_t: 4, Action: 99, Reward: 1.53, Epsilon: 0.12
[INFO] model update: t: 893, loss: 33869.3359375
[INFO] Global_t: 893, Episode_t: 5, Action: 13, Reward: 4.96, Epsilon: 0.12
[INFO] model update: t: 894, loss: 57095.8984375
[INFO] Global_t: 894, Episode_t: 6, Action: 7, Reward: 4.17, Epsilon: 0.11
[INFO] model update: t: 895, loss: 349099.53125
[INFO] Global_t: 895, Episode_t: 7, Action: 4, Reward: 3.83, Epsilon: 0.11
[INFO] model update: t: 896, loss: 646627.625
[INFO] Global_t: 896, Episode_t: 8, Action: 24, Reward: 3.26, Epsilon: 0.11
 45%|████▍     | 896/2000 [29:08<33:07,  1.80s/it]
[INFO] Global step: 896, Cumulative rewards: 34.5138, Runtime (s): 1748.84
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.482560396194458
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9566943645477295
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.043226003646851
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.390977621078491
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7652580738067627
average cummulative reward vector is:  [0.15360237 0.12298356 0.14803689 0.12791075 0.13789247]
average cummulative reward is:  0.13808520785272
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 112, nodes: 216, edges: 639
[INFO] model update: t: 897, loss: 757787.8125
[INFO] Global_t: 897, Episode_t: 1, Action: 0, Reward: 7.49, Epsilon: 0.11
[INFO] model update: t: 898, loss: 400507.4375
[INFO] Global_t: 898, Episode_t: 2, Action: 3, Reward: 6.31, Epsilon: 0.11
[INFO] model update: t: 899, loss: 20820.203125
[INFO] Global_t: 899, Episode_t: 3, Action: 1, Reward: 6.23, Epsilon: 0.11
[INFO] model update: t: 900, loss: 217255.453125
[INFO] Global_t: 900, Episode_t: 4, Action: 9, Reward: 5.11, Epsilon: 0.11
[INFO] model update: t: 901, loss: 939634.5
[INFO] Global_t: 901, Episode_t: 5, Action: 4, Reward: 4.77, Epsilon: 0.11
[INFO] model update: t: 902, loss: 783320.0
[INFO] Global_t: 902, Episode_t: 6, Action: 5, Reward: 4.32, Epsilon: 0.11
[INFO] model update: t: 903, loss: 97291.34375
[INFO] Global_t: 903, Episode_t: 7, Action: 12, Reward: 3.95, Epsilon: 0.11
[INFO] model update: t: 904, loss: 107101.4609375
[INFO] Global_t: 904, Episode_t: 8, Action: 13, Reward: 3.62, Epsilon: 0.11
 45%|████▌     | 904/2000 [29:35<41:07,  2.25s/it]
[INFO] Global step: 904, Cumulative rewards: 41.78783999999999, Runtime (s): 1775.26
------------------------------------------------------------
 
graph: 113, nodes: 217, edges: 642
[INFO] model update: t: 905, loss: 433958.4375
[INFO] Global_t: 905, Episode_t: 1, Action: 3, Reward: 7.88, Epsilon: 0.10
[INFO] model update: t: 906, loss: 404815.65625
[INFO] Global_t: 906, Episode_t: 2, Action: 1, Reward: 7.72, Epsilon: 0.10
[INFO] model update: t: 907, loss: 49011.9375
[INFO] Global_t: 907, Episode_t: 3, Action: 8, Reward: 5.73, Epsilon: 0.10
[INFO] model update: t: 908, loss: 67098.828125
[INFO] Global_t: 908, Episode_t: 4, Action: 5, Reward: 4.51, Epsilon: 0.10
[INFO] model update: t: 909, loss: 447260.1875
[INFO] Global_t: 909, Episode_t: 5, Action: 86, Reward: 1.97, Epsilon: 0.10
[INFO] model update: t: 910, loss: 944646.625
[INFO] Global_t: 910, Episode_t: 6, Action: 10, Reward: 4.46, Epsilon: 0.10
[INFO] model update: t: 911, loss: 1140133.75
[INFO] Global_t: 911, Episode_t: 7, Action: 6, Reward: 4.70, Epsilon: 0.10
[INFO] model update: t: 912, loss: 918151.0
[INFO] Global_t: 912, Episode_t: 8, Action: 0, Reward: 4.75, Epsilon: 0.10
 46%|████▌     | 912/2000 [29:41<32:34,  1.80s/it]
[INFO] Global step: 912, Cumulative rewards: 41.73084, Runtime (s): 1781.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.23218035697937
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.301021337509155
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.826331615447998
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.5631325244903564
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.103224039077759
average cummulative reward vector is:  [0.14109553 0.1326088  0.14302432 0.13216659 0.14931048]
average cummulative reward is:  0.1396411424415982
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 114, nodes: 190, edges: 561
[INFO] model update: t: 913, loss: 96276.140625
[INFO] Global_t: 913, Episode_t: 1, Action: 3, Reward: 7.01, Epsilon: 0.10
[INFO] model update: t: 914, loss: 201260.140625
[INFO] Global_t: 914, Episode_t: 2, Action: 4, Reward: 5.81, Epsilon: 0.10
[INFO] model update: t: 915, loss: 782650.0
[INFO] Global_t: 915, Episode_t: 3, Action: 0, Reward: 6.98, Epsilon: 0.09
[INFO] model update: t: 916, loss: 455441.5
[INFO] Global_t: 916, Episode_t: 4, Action: 2, Reward: 5.48, Epsilon: 0.09
[INFO] model update: t: 917, loss: 106266.59375
[INFO] Global_t: 917, Episode_t: 5, Action: 5, Reward: 4.48, Epsilon: 0.09
[INFO] model update: t: 918, loss: 40892.046875
[INFO] Global_t: 918, Episode_t: 6, Action: 8, Reward: 3.76, Epsilon: 0.09
[INFO] model update: t: 919, loss: 364527.46875
[INFO] Global_t: 919, Episode_t: 7, Action: 140, Reward: 1.63, Epsilon: 0.09
[INFO] model update: t: 920, loss: 1313147.0
[INFO] Global_t: 920, Episode_t: 8, Action: 18, Reward: 3.94, Epsilon: 0.09
 46%|████▌     | 920/2000 [30:07<40:29,  2.25s/it]
[INFO] Global step: 920, Cumulative rewards: 39.098639999999996, Runtime (s): 1807.61
------------------------------------------------------------
 
graph: 115, nodes: 198, edges: 585
[INFO] model update: t: 921, loss: 1613778.375
[INFO] Global_t: 921, Episode_t: 1, Action: 3, Reward: 6.04, Epsilon: 0.09
[INFO] model update: t: 922, loss: 1150303.75
[INFO] Global_t: 922, Episode_t: 2, Action: 5, Reward: 5.55, Epsilon: 0.09
[INFO] model update: t: 923, loss: 541553.6875
[INFO] Global_t: 923, Episode_t: 3, Action: 4, Reward: 5.16, Epsilon: 0.09
[INFO] model update: t: 924, loss: 84914.1875
[INFO] Global_t: 924, Episode_t: 4, Action: 0, Reward: 4.44, Epsilon: 0.09
[INFO] model update: t: 925, loss: 77982.9921875
[INFO] Global_t: 925, Episode_t: 5, Action: 1, Reward: 4.58, Epsilon: 0.08
[INFO] model update: t: 926, loss: 319473.71875
[INFO] Global_t: 926, Episode_t: 6, Action: 103, Reward: 1.43, Epsilon: 0.08
[INFO] model update: t: 927, loss: 87632.5078125
[INFO] Global_t: 927, Episode_t: 7, Action: 6, Reward: 4.09, Epsilon: 0.08
[INFO] model update: t: 928, loss: 40484.4609375
[INFO] Global_t: 928, Episode_t: 8, Action: 2, Reward: 4.53, Epsilon: 0.08
 46%|████▋     | 928/2000 [30:12<31:30,  1.76s/it]
[INFO] Global step: 928, Cumulative rewards: 35.8326, Runtime (s): 1812.65
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.21361231803894
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.436415433883667
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.044071197509766
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.463010311126709
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9304566383361816
average cummulative reward vector is:  [0.14167974 0.13690833 0.15086995 0.13739743 0.14458656]
average cummulative reward is:  0.14228840091539138
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 116, nodes: 182, edges: 537
[INFO] model update: t: 929, loss: 369626.375
[INFO] Global_t: 929, Episode_t: 1, Action: 3, Reward: 6.80, Epsilon: 0.08
[INFO] model update: t: 930, loss: 876542.875
[INFO] Global_t: 930, Episode_t: 2, Action: 4, Reward: 5.78, Epsilon: 0.08
[INFO] model update: t: 931, loss: 946863.9375
[INFO] Global_t: 931, Episode_t: 3, Action: 2, Reward: 5.46, Epsilon: 0.08
[INFO] model update: t: 932, loss: 1002733.0625
[INFO] Global_t: 932, Episode_t: 4, Action: 6, Reward: 4.34, Epsilon: 0.08
[INFO] model update: t: 933, loss: 617572.6875
[INFO] Global_t: 933, Episode_t: 5, Action: 0, Reward: 3.92, Epsilon: 0.08
[INFO] model update: t: 934, loss: 23400.07421875
[INFO] Global_t: 934, Episode_t: 6, Action: 9, Reward: 3.40, Epsilon: 0.08
[INFO] model update: t: 935, loss: 395733.46875
[INFO] Global_t: 935, Episode_t: 7, Action: 10, Reward: 3.29, Epsilon: 0.07
[INFO] model update: t: 936, loss: 1342956.75
[INFO] Global_t: 936, Episode_t: 8, Action: 5, Reward: 3.14, Epsilon: 0.07
 47%|████▋     | 936/2000 [30:38<39:21,  2.22s/it]
[INFO] Global step: 936, Cumulative rewards: 36.126839999999994, Runtime (s): 1838.91
------------------------------------------------------------
 
graph: 117, nodes: 196, edges: 579
[INFO] model update: t: 937, loss: 1558939.75
[INFO] Global_t: 937, Episode_t: 1, Action: 4, Reward: 6.31, Epsilon: 0.07
[INFO] model update: t: 938, loss: 1437282.5
[INFO] Global_t: 938, Episode_t: 2, Action: 178, Reward: 1.34, Epsilon: 0.07
[INFO] model update: t: 939, loss: 1600348.625
[INFO] Global_t: 939, Episode_t: 3, Action: 2, Reward: 5.75, Epsilon: 0.07
[INFO] model update: t: 940, loss: 1385154.375
[INFO] Global_t: 940, Episode_t: 4, Action: 0, Reward: 4.85, Epsilon: 0.07
[INFO] model update: t: 941, loss: 922271.8125
[INFO] Global_t: 941, Episode_t: 5, Action: 1, Reward: 4.49, Epsilon: 0.07
[INFO] model update: t: 942, loss: 241831.5
[INFO] Global_t: 942, Episode_t: 6, Action: 3, Reward: 5.52, Epsilon: 0.07
[INFO] model update: t: 943, loss: 16787.916015625
[INFO] Global_t: 943, Episode_t: 7, Action: 11, Reward: 4.82, Epsilon: 0.07
[INFO] model update: t: 944, loss: 168240.3125
[INFO] Global_t: 944, Episode_t: 8, Action: 8, Reward: 3.53, Epsilon: 0.07
 47%|████▋     | 944/2000 [30:44<30:52,  1.75s/it]
[INFO] Global step: 944, Cumulative rewards: 36.60611999999999, Runtime (s): 1844.27
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.378432750701904
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.114275693893433
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.080423355102539
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9077789783477783
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.039324045181274
average cummulative reward vector is:  [0.14867316 0.12960949 0.14376257 0.11949836 0.14880645]
average cummulative reward is:  0.1380700066080746
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 118, nodes: 180, edges: 531
[INFO] model update: t: 945, loss: 308641.875
[INFO] Global_t: 945, Episode_t: 1, Action: 6, Reward: 5.49, Epsilon: 0.06
[INFO] model update: t: 946, loss: 126963.203125
[INFO] Global_t: 946, Episode_t: 2, Action: 3, Reward: 4.83, Epsilon: 0.06
[INFO] model update: t: 947, loss: 17707.775390625
[INFO] Global_t: 947, Episode_t: 3, Action: 0, Reward: 5.23, Epsilon: 0.06
[INFO] model update: t: 948, loss: 104690.625
[INFO] Global_t: 948, Episode_t: 4, Action: 2, Reward: 4.49, Epsilon: 0.06
[INFO] model update: t: 949, loss: 438989.625
[INFO] Global_t: 949, Episode_t: 5, Action: 5, Reward: 3.79, Epsilon: 0.06
[INFO] model update: t: 950, loss: 820639.0625
[INFO] Global_t: 950, Episode_t: 6, Action: 20, Reward: 3.43, Epsilon: 0.06
[INFO] model update: t: 951, loss: 409007.90625
[INFO] Global_t: 951, Episode_t: 7, Action: 126, Reward: 1.13, Epsilon: 0.06
[INFO] model update: t: 952, loss: 133797.953125
[INFO] Global_t: 952, Episode_t: 8, Action: 24, Reward: 3.60, Epsilon: 0.06

[INFO] Global step: 952, Cumulative rewards: 31.98756, Runtime (s): 1869.38
------------------------------------------------------------
 
 48%|████▊     | 952/2000 [31:09<37:53,  2.17s/it]graph: 119, nodes: 182, edges: 537
[INFO] model update: t: 953, loss: 25180.296875
[INFO] Global_t: 953, Episode_t: 1, Action: 4, Reward: 7.79, Epsilon: 0.06
[INFO] model update: t: 954, loss: 411148.1875
[INFO] Global_t: 954, Episode_t: 2, Action: 1, Reward: 5.51, Epsilon: 0.06
[INFO] model update: t: 955, loss: 1255547.375
[INFO] Global_t: 955, Episode_t: 3, Action: 0, Reward: 6.56, Epsilon: 0.06
[INFO] model update: t: 956, loss: 3138609.0
[INFO] Global_t: 956, Episode_t: 4, Action: 7, Reward: 3.93, Epsilon: 0.05
[INFO] model update: t: 957, loss: 6146157.0
[INFO] Global_t: 957, Episode_t: 5, Action: 8, Reward: 3.62, Epsilon: 0.05
[INFO] model update: t: 958, loss: 4383486.0
[INFO] Global_t: 958, Episode_t: 6, Action: 20, Reward: 3.85, Epsilon: 0.05
[INFO] model update: t: 959, loss: 1094381.75
[INFO] Global_t: 959, Episode_t: 7, Action: 14, Reward: 3.45, Epsilon: 0.05
[INFO] model update: t: 960, loss: 9395.833984375
[INFO] Global_t: 960, Episode_t: 8, Action: 2, Reward: 3.76, Epsilon: 0.05
 48%|████▊     | 960/2000 [31:15<29:59,  1.73s/it]
[INFO] Global step: 960, Cumulative rewards: 38.463480000000004, Runtime (s): 1875.01
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.38193154335022
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.318400144577026
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8544602394104004
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.612573862075806
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.052683353424072
average cummulative reward vector is:  [0.14650105 0.1351162  0.14390246 0.13116963 0.14597204]
average cummulative reward is:  0.14053227690613063
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 120, nodes: 219, edges: 648
[INFO] model update: t: 961, loss: 773199.8125
[INFO] Global_t: 961, Episode_t: 1, Action: 2, Reward: 6.92, Epsilon: 0.05
[INFO] model update: t: 962, loss: 1528110.125
[INFO] Global_t: 962, Episode_t: 2, Action: 6, Reward: 6.00, Epsilon: 0.05
[INFO] model update: t: 963, loss: 1295750.75
[INFO] Global_t: 963, Episode_t: 3, Action: 8, Reward: 5.23, Epsilon: 0.05
[INFO] model update: t: 964, loss: 455173.5625
[INFO] Global_t: 964, Episode_t: 4, Action: 4, Reward: 4.76, Epsilon: 0.05
[INFO] model update: t: 965, loss: 33304.9140625
[INFO] Global_t: 965, Episode_t: 5, Action: 7, Reward: 5.40, Epsilon: 0.05
[INFO] model update: t: 966, loss: 132161.8125
[INFO] Global_t: 966, Episode_t: 6, Action: 5, Reward: 4.70, Epsilon: 0.04
[INFO] model update: t: 967, loss: 365283.0625
[INFO] Global_t: 967, Episode_t: 7, Action: 9, Reward: 4.73, Epsilon: 0.04
[INFO] model update: t: 968, loss: 748440.625
[INFO] Global_t: 968, Episode_t: 8, Action: 11, Reward: 4.31, Epsilon: 0.04
 48%|████▊     | 968/2000 [31:42<38:17,  2.23s/it]
[INFO] Global step: 968, Cumulative rewards: 42.045, Runtime (s): 1902.09
------------------------------------------------------------
 
graph: 121, nodes: 182, edges: 536
[INFO] model update: t: 969, loss: 1212177.125
[INFO] Global_t: 969, Episode_t: 1, Action: 3, Reward: 6.29, Epsilon: 0.04
[INFO] model update: t: 970, loss: 1958707.375
[INFO] Global_t: 970, Episode_t: 2, Action: 1, Reward: 5.94, Epsilon: 0.04
[INFO] model update: t: 971, loss: 2054877.75
[INFO] Global_t: 971, Episode_t: 3, Action: 4, Reward: 5.76, Epsilon: 0.04
[INFO] model update: t: 972, loss: 1102870.75
[INFO] Global_t: 972, Episode_t: 4, Action: 2, Reward: 5.95, Epsilon: 0.04
[INFO] model update: t: 973, loss: 321363.375
[INFO] Global_t: 973, Episode_t: 5, Action: 10, Reward: 4.04, Epsilon: 0.04
[INFO] model update: t: 974, loss: 18961.94140625
[INFO] Global_t: 974, Episode_t: 6, Action: 9, Reward: 4.28, Epsilon: 0.04
[INFO] model update: t: 975, loss: 184815.90625
[INFO] Global_t: 975, Episode_t: 7, Action: 18, Reward: 3.67, Epsilon: 0.04
[INFO] model update: t: 976, loss: 366265.25
[INFO] Global_t: 976, Episode_t: 8, Action: 8, Reward: 3.46, Epsilon: 0.03
 49%|████▉     | 976/2000 [31:46<29:35,  1.73s/it]
[INFO] Global step: 976, Cumulative rewards: 39.38184, Runtime (s): 1906.78
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.371963024139404
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.425872087478638
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.038615703582764
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.514275074005127
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.196835279464722
average cummulative reward vector is:  [0.14970342 0.13618611 0.13735519 0.138275   0.1550707 ]
average cummulative reward is:  0.14331808446906089
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 122, nodes: 206, edges: 609
[INFO] model update: t: 977, loss: 191754.625
[INFO] Global_t: 977, Episode_t: 1, Action: 3, Reward: 6.55, Epsilon: 0.03
[INFO] model update: t: 978, loss: 56260.40234375
[INFO] Global_t: 978, Episode_t: 2, Action: 2, Reward: 6.37, Epsilon: 0.03
[INFO] model update: t: 979, loss: 26633.41796875
[INFO] Global_t: 979, Episode_t: 3, Action: 6, Reward: 4.63, Epsilon: 0.03
[INFO] model update: t: 980, loss: 96037.015625
[INFO] Global_t: 980, Episode_t: 4, Action: 1, Reward: 4.53, Epsilon: 0.03
[INFO] model update: t: 981, loss: 210544.4375
[INFO] Global_t: 981, Episode_t: 5, Action: 4, Reward: 5.62, Epsilon: 0.03
[INFO] model update: t: 982, loss: 132370.9375
[INFO] Global_t: 982, Episode_t: 6, Action: 8, Reward: 4.43, Epsilon: 0.03
[INFO] model update: t: 983, loss: 26015.306640625
[INFO] Global_t: 983, Episode_t: 7, Action: 7, Reward: 3.46, Epsilon: 0.03
[INFO] model update: t: 984, loss: 46864.8984375
[INFO] Global_t: 984, Episode_t: 8, Action: 10, Reward: 3.30, Epsilon: 0.03
 49%|████▉     | 984/2000 [32:13<37:32,  2.22s/it]
[INFO] Global step: 984, Cumulative rewards: 38.89416, Runtime (s): 1933.51
------------------------------------------------------------
 
graph: 123, nodes: 182, edges: 537
[INFO] model update: t: 985, loss: 143317.625
[INFO] Global_t: 985, Episode_t: 1, Action: 138, Reward: 1.36, Epsilon: 0.03
[INFO] model update: t: 986, loss: 173213.4375
[INFO] Global_t: 986, Episode_t: 2, Action: 0, Reward: 7.54, Epsilon: 0.02
[INFO] model update: t: 987, loss: 53031.28125
[INFO] Global_t: 987, Episode_t: 3, Action: 9, Reward: 5.22, Epsilon: 0.02
[INFO] model update: t: 988, loss: 26532.4921875
[INFO] Global_t: 988, Episode_t: 4, Action: 5, Reward: 4.69, Epsilon: 0.02
[INFO] model update: t: 989, loss: 110904.75
[INFO] Global_t: 989, Episode_t: 5, Action: 10, Reward: 4.81, Epsilon: 0.02
[INFO] model update: t: 990, loss: 126185.359375
[INFO] Global_t: 990, Episode_t: 6, Action: 2, Reward: 4.20, Epsilon: 0.02
[INFO] model update: t: 991, loss: 105966.78125
[INFO] Global_t: 991, Episode_t: 7, Action: 4, Reward: 3.67, Epsilon: 0.02
[INFO] model update: t: 992, loss: 104537.0
[INFO] Global_t: 992, Episode_t: 8, Action: 1, Reward: 3.96, Epsilon: 0.02
 50%|████▉     | 992/2000 [32:18<28:55,  1.72s/it]
[INFO] Global step: 992, Cumulative rewards: 35.456039999999994, Runtime (s): 1938.05
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.064622163772583
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.2370991706848145
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.056116342544556
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.194443464279175
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.083065032958984
average cummulative reward vector is:  [0.13228263 0.13051181 0.15139945 0.12200467 0.1504672 ]
average cummulative reward is:  0.1373331535769374
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 124, nodes: 194, edges: 573
[INFO] model update: t: 993, loss: 178110.296875
[INFO] Global_t: 993, Episode_t: 1, Action: 5, Reward: 6.12, Epsilon: 0.02
[INFO] model update: t: 994, loss: 203041.625
[INFO] Global_t: 994, Episode_t: 2, Action: 4, Reward: 7.16, Epsilon: 0.02
[INFO] model update: t: 995, loss: 225259.234375
[INFO] Global_t: 995, Episode_t: 3, Action: 3, Reward: 7.85, Epsilon: 0.02
[INFO] model update: t: 996, loss: 140224.5625
[INFO] Global_t: 996, Episode_t: 4, Action: 6, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 997, loss: 41953.046875
[INFO] Global_t: 997, Episode_t: 5, Action: 1, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 998, loss: 15821.8359375
[INFO] Global_t: 998, Episode_t: 6, Action: 0, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 999, loss: 32436.9453125
[INFO] Global_t: 999, Episode_t: 7, Action: 8, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 1000, loss: 100224.359375
[INFO] Global_t: 1000, Episode_t: 8, Action: 12, Reward: 3.95, Epsilon: 0.01
 50%|█████     | 1000/2000 [32:43<36:16,  2.18s/it]
[INFO] Global step: 1000, Cumulative rewards: 40.647, Runtime (s): 1963.96
------------------------------------------------------------
 
graph: 125, nodes: 209, edges: 617
[INFO] model update: t: 1001, loss: 170706.703125
[INFO] Global_t: 1001, Episode_t: 1, Action: 1, Reward: 8.89, Epsilon: 0.01
[INFO] model update: t: 1002, loss: 134464.28125
[INFO] Global_t: 1002, Episode_t: 2, Action: 3, Reward: 7.79, Epsilon: 0.01
[INFO] model update: t: 1003, loss: 136886.0625
[INFO] Global_t: 1003, Episode_t: 3, Action: 7, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1004, loss: 151306.3125
[INFO] Global_t: 1004, Episode_t: 4, Action: 0, Reward: 5.82, Epsilon: 0.01
[INFO] model update: t: 1005, loss: 139376.046875
[INFO] Global_t: 1005, Episode_t: 5, Action: 6, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1006, loss: 119131.4140625
[INFO] Global_t: 1006, Episode_t: 6, Action: 9, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1007, loss: 151157.78125
[INFO] Global_t: 1007, Episode_t: 7, Action: 2, Reward: 4.38, Epsilon: 0.01
[INFO] model update: t: 1008, loss: 368019.0625
[INFO] Global_t: 1008, Episode_t: 8, Action: 16, Reward: 4.55, Epsilon: 0.01

[INFO] Global step: 1008, Cumulative rewards: 44.85756, Runtime (s): 1969.49
------------------------------------------------------------
 50%|█████     | 1008/2000 [32:49<28:37,  1.73s/it] 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.5268964767456055
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.463573455810547
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.184814929962158
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.144869804382324
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.0505592823028564
average cummulative reward vector is:  [0.14803921 0.13570556 0.14471311 0.13005631 0.14846559]
average cummulative reward is:  0.14139595612900685
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 126, nodes: 218, edges: 645
[INFO] model update: t: 1009, loss: 599536.0
[INFO] Global_t: 1009, Episode_t: 1, Action: 3, Reward: 6.54, Epsilon: 0.01
[INFO] model update: t: 1010, loss: 261844.296875
[INFO] Global_t: 1010, Episode_t: 2, Action: 0, Reward: 5.56, Epsilon: 0.01
[INFO] model update: t: 1011, loss: 15193.744140625
[INFO] Global_t: 1011, Episode_t: 3, Action: 1, Reward: 7.65, Epsilon: 0.01
[INFO] model update: t: 1012, loss: 189816.9375
[INFO] Global_t: 1012, Episode_t: 4, Action: 4, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1013, loss: 881810.125
[INFO] Global_t: 1013, Episode_t: 5, Action: 13, Reward: 4.63, Epsilon: 0.01
[INFO] model update: t: 1014, loss: 2563236.0
[INFO] Global_t: 1014, Episode_t: 6, Action: 14, Reward: 4.18, Epsilon: 0.01
[INFO] model update: t: 1015, loss: 8202206.0
[INFO] Global_t: 1015, Episode_t: 7, Action: 7, Reward: 3.93, Epsilon: 0.01
[INFO] model update: t: 1016, loss: 11751193.0
[INFO] Global_t: 1016, Episode_t: 8, Action: 6, Reward: 4.07, Epsilon: 0.01
 51%|█████     | 1016/2000 [33:16<36:29,  2.23s/it]
[INFO] Global step: 1016, Cumulative rewards: 41.060759999999995, Runtime (s): 1996.51
------------------------------------------------------------
 
graph: 127, nodes: 189, edges: 558
[INFO] model update: t: 1017, loss: 6849454.0
[INFO] Global_t: 1017, Episode_t: 1, Action: 1, Reward: 6.25, Epsilon: 0.01
[INFO] model update: t: 1018, loss: 370776.9375
[INFO] Global_t: 1018, Episode_t: 2, Action: 5, Reward: 5.31, Epsilon: 0.01
[INFO] model update: t: 1019, loss: 2664579.75
[INFO] Global_t: 1019, Episode_t: 3, Action: 8, Reward: 5.97, Epsilon: 0.01
[INFO] model update: t: 1020, loss: 22612624.0
[INFO] Global_t: 1020, Episode_t: 4, Action: 3, Reward: 5.38, Epsilon: 0.01
[INFO] model update: t: 1021, loss: 79057680.0
[INFO] Global_t: 1021, Episode_t: 5, Action: 11, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1022, loss: 87939408.0
[INFO] Global_t: 1022, Episode_t: 6, Action: 14, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1023, loss: 90185672.0
[INFO] Global_t: 1023, Episode_t: 7, Action: 10, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1024, loss: 54635364.0
[INFO] Global_t: 1024, Episode_t: 8, Action: 6, Reward: 3.50, Epsilon: 0.01
 51%|█████     | 1024/2000 [33:21<28:24,  1.75s/it]
[INFO] Global step: 1024, Cumulative rewards: 39.38819999999999, Runtime (s): 2001.55
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.509265661239624
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.3550732135772705
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.31934118270874
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.260043382644653
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.039017677307129
average cummulative reward vector is:  [0.15240868 0.13303356 0.15471667 0.13298621 0.14904704]
average cummulative reward is:  0.1444384347312063
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 128, nodes: 198, edges: 585
[INFO] model update: t: 1025, loss: 21769102.0
[INFO] Global_t: 1025, Episode_t: 1, Action: 1, Reward: 6.75, Epsilon: 0.01
[INFO] model update: t: 1026, loss: 261097.921875
[INFO] Global_t: 1026, Episode_t: 2, Action: 2, Reward: 6.11, Epsilon: 0.01
[INFO] model update: t: 1027, loss: 15533806.0
[INFO] Global_t: 1027, Episode_t: 3, Action: 10, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1028, loss: 19630774.0
[INFO] Global_t: 1028, Episode_t: 4, Action: 3, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1029, loss: 3477399.5
[INFO] Global_t: 1029, Episode_t: 5, Action: 4, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1030, loss: 2264341.0
[INFO] Global_t: 1030, Episode_t: 6, Action: 8, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1031, loss: 8691862.0
[INFO] Global_t: 1031, Episode_t: 7, Action: 12, Reward: 3.31, Epsilon: 0.01
 52%|█████▏    | 1032/2000 [33:48<35:49,  2.22s/it][INFO] model update: t: 1032, loss: 5213730.5
[INFO] Global_t: 1032, Episode_t: 8, Action: 5, Reward: 3.49, Epsilon: 0.01

[INFO] Global step: 1032, Cumulative rewards: 36.9252, Runtime (s): 2028.15
------------------------------------------------------------
 
graph: 129, nodes: 211, edges: 624
[INFO] model update: t: 1033, loss: 365874.375
[INFO] Global_t: 1033, Episode_t: 1, Action: 2, Reward: 7.07, Epsilon: 0.01
[INFO] model update: t: 1034, loss: 4803188.0
[INFO] Global_t: 1034, Episode_t: 2, Action: 3, Reward: 6.79, Epsilon: 0.01
[INFO] model update: t: 1035, loss: 6047553.0
[INFO] Global_t: 1035, Episode_t: 3, Action: 0, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1036, loss: 3988780.75
[INFO] Global_t: 1036, Episode_t: 4, Action: 8, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1037, loss: 920708.875
[INFO] Global_t: 1037, Episode_t: 5, Action: 10, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1038, loss: 483765.125
[INFO] Global_t: 1038, Episode_t: 6, Action: 5, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1039, loss: 1260204.25
[INFO] Global_t: 1039, Episode_t: 7, Action: 14, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1040, loss: 253349.421875
[INFO] Global_t: 1040, Episode_t: 8, Action: 16, Reward: 3.35, Epsilon: 0.01
 52%|█████▏    | 1040/2000 [33:56<29:41,  1.86s/it]
[INFO] Global step: 1040, Cumulative rewards: 38.75039999999999, Runtime (s): 2036.20
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.480969190597534
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.643117189407349
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7322351932525635
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.173529148101807
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.36814284324646
average cummulative reward vector is:  [0.15211921 0.1315456  0.13866148 0.13183107 0.14970376]
average cummulative reward is:  0.1407722251990438
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 130, nodes: 205, edges: 606
[INFO] model update: t: 1041, loss: 1288201.5
[INFO] Global_t: 1041, Episode_t: 1, Action: 3, Reward: 8.91, Epsilon: 0.01
[INFO] model update: t: 1042, loss: 3068109.0
[INFO] Global_t: 1042, Episode_t: 2, Action: 2, Reward: 7.93, Epsilon: 0.01
[INFO] model update: t: 1043, loss: 1057639.25
[INFO] Global_t: 1043, Episode_t: 3, Action: 6, Reward: 6.19, Epsilon: 0.01
[INFO] model update: t: 1044, loss: 417438.9375
[INFO] Global_t: 1044, Episode_t: 4, Action: 0, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 1045, loss: 1485164.5
[INFO] Global_t: 1045, Episode_t: 5, Action: 8, Reward: 4.31, Epsilon: 0.01
[INFO] model update: t: 1046, loss: 656075.0
[INFO] Global_t: 1046, Episode_t: 6, Action: 5, Reward: 4.32, Epsilon: 0.01
[INFO] model update: t: 1047, loss: 124950.5234375
[INFO] Global_t: 1047, Episode_t: 7, Action: 4, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1048, loss: 694921.25
[INFO] Global_t: 1048, Episode_t: 8, Action: 18, Reward: 3.74, Epsilon: 0.01
 52%|█████▏    | 1048/2000 [34:24<37:13,  2.35s/it]
[INFO] Global step: 1048, Cumulative rewards: 44.22083999999999, Runtime (s): 2064.13
------------------------------------------------------------
 
graph: 131, nodes: 210, edges: 620
[INFO] model update: t: 1049, loss: 258023.921875
[INFO] Global_t: 1049, Episode_t: 1, Action: 4, Reward: 7.71, Epsilon: 0.01
[INFO] model update: t: 1050, loss: 74848.53125
[INFO] Global_t: 1050, Episode_t: 2, Action: 3, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 1051, loss: 535445.0
[INFO] Global_t: 1051, Episode_t: 3, Action: 5, Reward: 5.33, Epsilon: 0.01
[INFO] model update: t: 1052, loss: 268443.28125
[INFO] Global_t: 1052, Episode_t: 4, Action: 6, Reward: 5.98, Epsilon: 0.01
[INFO] model update: t: 1053, loss: 41036.328125
[INFO] Global_t: 1053, Episode_t: 5, Action: 2, Reward: 6.52, Epsilon: 0.01
[INFO] model update: t: 1054, loss: 67154.0
[INFO] Global_t: 1054, Episode_t: 6, Action: 8, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1055, loss: 82619.9375
[INFO] Global_t: 1055, Episode_t: 7, Action: 0, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1056, loss: 23436.05859375
[INFO] Global_t: 1056, Episode_t: 8, Action: 18, Reward: 4.11, Epsilon: 0.01
 53%|█████▎    | 1056/2000 [34:30<29:18,  1.86s/it]
[INFO] Global step: 1056, Cumulative rewards: 43.33104, Runtime (s): 2070.01
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.199034690856934
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.345578908920288
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8598623275756836
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.318333864212036
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.564771413803101
average cummulative reward vector is:  [0.15112947 0.12941921 0.1419541  0.12658762 0.16313065]
average cummulative reward is:  0.14244420939830987
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 132, nodes: 213, edges: 630
[INFO] model update: t: 1057, loss: 27926.4296875
[INFO] Global_t: 1057, Episode_t: 1, Action: 3, Reward: 7.25, Epsilon: 0.01
[INFO] model update: t: 1058, loss: 25484.93359375
[INFO] Global_t: 1058, Episode_t: 2, Action: 4, Reward: 7.35, Epsilon: 0.01
[INFO] model update: t: 1059, loss: 33731.2890625
[INFO] Global_t: 1059, Episode_t: 3, Action: 0, Reward: 5.28, Epsilon: 0.01
[INFO] model update: t: 1060, loss: 38520.21875
[INFO] Global_t: 1060, Episode_t: 4, Action: 5, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1061, loss: 35527.6484375
[INFO] Global_t: 1061, Episode_t: 5, Action: 6, Reward: 4.28, Epsilon: 0.01
[INFO] model update: t: 1062, loss: 23525.810546875
[INFO] Global_t: 1062, Episode_t: 6, Action: 9, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 1063, loss: 30238.498046875
[INFO] Global_t: 1063, Episode_t: 7, Action: 2, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1064, loss: 55733.0546875
[INFO] Global_t: 1064, Episode_t: 8, Action: 1, Reward: 3.66, Epsilon: 0.01
 53%|█████▎    | 1064/2000 [35:01<38:37,  2.48s/it]
[INFO] Global step: 1064, Cumulative rewards: 40.879799999999996, Runtime (s): 2101.25
------------------------------------------------------------
 
graph: 133, nodes: 213, edges: 630
[INFO] model update: t: 1065, loss: 21397.6875
[INFO] Global_t: 1065, Episode_t: 1, Action: 1, Reward: 8.10, Epsilon: 0.01
[INFO] model update: t: 1066, loss: 85812.984375
[INFO] Global_t: 1066, Episode_t: 2, Action: 8, Reward: 5.71, Epsilon: 0.01
[INFO] model update: t: 1067, loss: 176986.4375
[INFO] Global_t: 1067, Episode_t: 3, Action: 5, Reward: 5.71, Epsilon: 0.01
[INFO] model update: t: 1068, loss: 76278.1015625
[INFO] Global_t: 1068, Episode_t: 4, Action: 6, Reward: 5.61, Epsilon: 0.01
[INFO] model update: t: 1069, loss: 13338.79296875
[INFO] Global_t: 1069, Episode_t: 5, Action: 17, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1070, loss: 15693.3583984375
[INFO] Global_t: 1070, Episode_t: 6, Action: 9, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1071, loss: 16400.0078125
[INFO] Global_t: 1071, Episode_t: 7, Action: 3, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1072, loss: 16842.30859375
[INFO] Global_t: 1072, Episode_t: 8, Action: 7, Reward: 3.73, Epsilon: 0.01
 54%|█████▎    | 1072/2000 [35:07<30:24,  1.97s/it]
[INFO] Global step: 1072, Cumulative rewards: 42.20136, Runtime (s): 2107.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.096913576126099
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.5704872608184814
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.176724433898926
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.110245943069458
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.375522136688232
average cummulative reward vector is:  [0.14808711 0.14297176 0.14721913 0.12490701 0.15122876]
average cummulative reward is:  0.14288275259842637
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 134, nodes: 215, edges: 635
[INFO] model update: t: 1073, loss: 58141.90234375
[INFO] Global_t: 1073, Episode_t: 1, Action: 0, Reward: 7.66, Epsilon: 0.01
[INFO] model update: t: 1074, loss: 75404.3671875
[INFO] Global_t: 1074, Episode_t: 2, Action: 8, Reward: 7.88, Epsilon: 0.01
[INFO] model update: t: 1075, loss: 54793.9453125
[INFO] Global_t: 1075, Episode_t: 3, Action: 5, Reward: 5.16, Epsilon: 0.01
[INFO] model update: t: 1076, loss: 14155.2353515625
[INFO] Global_t: 1076, Episode_t: 4, Action: 9, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1077, loss: 45469.2578125
[INFO] Global_t: 1077, Episode_t: 5, Action: 2, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 1078, loss: 204676.8125
[INFO] Global_t: 1078, Episode_t: 6, Action: 6, Reward: 5.61, Epsilon: 0.01
[INFO] model update: t: 1079, loss: 200789.6875
[INFO] Global_t: 1079, Episode_t: 7, Action: 13, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1080, loss: 13755.98046875
[INFO] Global_t: 1080, Episode_t: 8, Action: 1, Reward: 4.27, Epsilon: 0.01
 54%|█████▍    | 1080/2000 [35:34<36:35,  2.39s/it]
[INFO] Global step: 1080, Cumulative rewards: 45.0804, Runtime (s): 2134.40
------------------------------------------------------------
 
graph: 135, nodes: 211, edges: 624
[INFO] model update: t: 1081, loss: 160689.5625
[INFO] Global_t: 1081, Episode_t: 1, Action: 1, Reward: 6.13, Epsilon: 0.01
[INFO] model update: t: 1082, loss: 192443.5
[INFO] Global_t: 1082, Episode_t: 2, Action: 3, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 1083, loss: 21873.33984375
[INFO] Global_t: 1083, Episode_t: 3, Action: 0, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1084, loss: 100011.390625
[INFO] Global_t: 1084, Episode_t: 4, Action: 2, Reward: 4.81, Epsilon: 0.01
[INFO] model update: t: 1085, loss: 196029.984375
[INFO] Global_t: 1085, Episode_t: 5, Action: 9, Reward: 6.49, Epsilon: 0.01
[INFO] model update: t: 1086, loss: 96521.2109375
[INFO] Global_t: 1086, Episode_t: 6, Action: 5, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 1087, loss: 15073.986328125
[INFO] Global_t: 1087, Episode_t: 7, Action: 4, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 1088, loss: 19051.24609375
[INFO] Global_t: 1088, Episode_t: 8, Action: 7, Reward: 3.86, Epsilon: 0.01
 54%|█████▍    | 1088/2000 [35:39<28:32,  1.88s/it]
[INFO] Global step: 1088, Cumulative rewards: 41.67707999999999, Runtime (s): 2139.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.075906276702881
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.483032941818237
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.121901035308838
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.106817722320557
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.768375396728516
average cummulative reward vector is:  [0.14544342 0.13285278 0.14877514 0.12912056 0.15748656]
average cummulative reward is:  0.14273569106597592
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 136, nodes: 211, edges: 624
[INFO] model update: t: 1089, loss: 27719.341796875
[INFO] Global_t: 1089, Episode_t: 1, Action: 5, Reward: 6.79, Epsilon: 0.01
[INFO] model update: t: 1090, loss: 18769.259765625
[INFO] Global_t: 1090, Episode_t: 2, Action: 3, Reward: 5.77, Epsilon: 0.01
[INFO] model update: t: 1091, loss: 15377.3125
[INFO] Global_t: 1091, Episode_t: 3, Action: 0, Reward: 5.42, Epsilon: 0.01
[INFO] model update: t: 1092, loss: 13765.60546875
[INFO] Global_t: 1092, Episode_t: 4, Action: 6, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1093, loss: 29193.447265625
[INFO] Global_t: 1093, Episode_t: 5, Action: 7, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1094, loss: 97198.3046875
[INFO] Global_t: 1094, Episode_t: 6, Action: 1, Reward: 5.24, Epsilon: 0.01
[INFO] model update: t: 1095, loss: 67270.9453125
[INFO] Global_t: 1095, Episode_t: 7, Action: 2, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1096, loss: 56272.1484375
[INFO] Global_t: 1096, Episode_t: 8, Action: 9, Reward: 3.93, Epsilon: 0.01

[INFO] Global step: 1096, Cumulative rewards: 40.24307999999999, Runtime (s): 2166.41
------------------------------------------------------------
 
 55%|█████▍    | 1096/2000 [36:06<34:46,  2.31s/it]graph: 137, nodes: 210, edges: 621
[INFO] model update: t: 1097, loss: 340127.125
[INFO] Global_t: 1097, Episode_t: 1, Action: 3, Reward: 7.98, Epsilon: 0.01
[INFO] model update: t: 1098, loss: 250346.421875
[INFO] Global_t: 1098, Episode_t: 2, Action: 2, Reward: 8.38, Epsilon: 0.01
[INFO] model update: t: 1099, loss: 68004.8203125
[INFO] Global_t: 1099, Episode_t: 3, Action: 4, Reward: 7.30, Epsilon: 0.01
[INFO] model update: t: 1100, loss: 36169.3203125
[INFO] Global_t: 1100, Episode_t: 4, Action: 10, Reward: 4.89, Epsilon: 0.01
[INFO] model update: t: 1101, loss: 177086.9375
[INFO] Global_t: 1101, Episode_t: 5, Action: 8, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1102, loss: 97348.0
[INFO] Global_t: 1102, Episode_t: 6, Action: 12, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 1103, loss: 8918.7783203125
[INFO] Global_t: 1103, Episode_t: 7, Action: 6, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1104, loss: 96757.5078125
[INFO] Global_t: 1104, Episode_t: 8, Action: 15, Reward: 4.28, Epsilon: 0.01
 55%|█████▌    | 1104/2000 [36:12<27:18,  1.83s/it]
[INFO] Global step: 1104, Cumulative rewards: 45.6348, Runtime (s): 2172.10
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.091207265853882
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.6627984046936035
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9447145462036133
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.109099626541138
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.007117986679077
average cummulative reward vector is:  [0.14592842 0.13429236 0.14680847 0.12840724 0.14212581]
average cummulative reward is:  0.139512460310273
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 138, nodes: 185, edges: 545
[INFO] model update: t: 1105, loss: 62003.859375
[INFO] Global_t: 1105, Episode_t: 1, Action: 0, Reward: 6.44, Epsilon: 0.01
[INFO] model update: t: 1106, loss: 26461.37890625
[INFO] Global_t: 1106, Episode_t: 2, Action: 4, Reward: 5.36, Epsilon: 0.01
[INFO] model update: t: 1107, loss: 22668.37890625
[INFO] Global_t: 1107, Episode_t: 3, Action: 6, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1108, loss: 48740.5546875
[INFO] Global_t: 1108, Episode_t: 4, Action: 8, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1109, loss: 34090.5859375
[INFO] Global_t: 1109, Episode_t: 5, Action: 5, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1110, loss: 16671.4453125
[INFO] Global_t: 1110, Episode_t: 6, Action: 10, Reward: 5.84, Epsilon: 0.01
[INFO] model update: t: 1111, loss: 24824.544921875
[INFO] Global_t: 1111, Episode_t: 7, Action: 1, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1112, loss: 28044.48828125
[INFO] Global_t: 1112, Episode_t: 8, Action: 2, Reward: 3.97, Epsilon: 0.01
 56%|█████▌    | 1112/2000 [36:37<33:13,  2.24s/it]
[INFO] Global step: 1112, Cumulative rewards: 40.3422, Runtime (s): 2197.82
------------------------------------------------------------
 
graph: 139, nodes: 184, edges: 543
[INFO] model update: t: 1113, loss: 18861.9140625
[INFO] Global_t: 1113, Episode_t: 1, Action: 2, Reward: 6.58, Epsilon: 0.01
[INFO] model update: t: 1114, loss: 22480.234375
[INFO] Global_t: 1114, Episode_t: 2, Action: 1, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1115, loss: 26699.15625
[INFO] Global_t: 1115, Episode_t: 3, Action: 8, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1116, loss: 21941.310546875
[INFO] Global_t: 1116, Episode_t: 4, Action: 4, Reward: 5.84, Epsilon: 0.01
[INFO] model update: t: 1117, loss: 12842.529296875
[INFO] Global_t: 1117, Episode_t: 5, Action: 6, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 1118, loss: 29361.15625
[INFO] Global_t: 1118, Episode_t: 6, Action: 5, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 1119, loss: 18844.955078125
[INFO] Global_t: 1119, Episode_t: 7, Action: 3, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1120, loss: 23123.005859375
[INFO] Global_t: 1120, Episode_t: 8, Action: 20, Reward: 3.63, Epsilon: 0.01
 56%|█████▌    | 1120/2000 [36:42<25:47,  1.76s/it]
[INFO] Global step: 1120, Cumulative rewards: 37.53156, Runtime (s): 2202.81
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.06991720199585
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.085686445236206
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.03787636756897
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.238105535507202
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.191065788269043
average cummulative reward vector is:  [0.14627789 0.12630509 0.14587404 0.1316278  0.14435296]
average cummulative reward is:  0.13888755835456934
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 140, nodes: 220, edges: 651
[INFO] model update: t: 1121, loss: 54663.98046875
[INFO] Global_t: 1121, Episode_t: 1, Action: 7, Reward: 7.46, Epsilon: 0.01
[INFO] model update: t: 1122, loss: 77872.28125
[INFO] Global_t: 1122, Episode_t: 2, Action: 4, Reward: 6.89, Epsilon: 0.01
[INFO] model update: t: 1123, loss: 40564.58984375
[INFO] Global_t: 1123, Episode_t: 3, Action: 1, Reward: 5.79, Epsilon: 0.01
[INFO] model update: t: 1124, loss: 25105.96875
[INFO] Global_t: 1124, Episode_t: 4, Action: 5, Reward: 5.15, Epsilon: 0.01
[INFO] model update: t: 1125, loss: 62460.3359375
[INFO] Global_t: 1125, Episode_t: 5, Action: 0, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1126, loss: 64302.0
[INFO] Global_t: 1126, Episode_t: 6, Action: 6, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1127, loss: 16479.53125
[INFO] Global_t: 1127, Episode_t: 7, Action: 10, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1128, loss: 37238.0859375
[INFO] Global_t: 1128, Episode_t: 8, Action: 31, Reward: 3.31, Epsilon: 0.01
 56%|█████▋    | 1128/2000 [37:08<31:55,  2.20s/it]
[INFO] Global step: 1128, Cumulative rewards: 42.075480000000006, Runtime (s): 2228.56
------------------------------------------------------------
 
graph: 141, nodes: 205, edges: 606
[INFO] model update: t: 1129, loss: 38262.15625
[INFO] Global_t: 1129, Episode_t: 1, Action: 2, Reward: 7.72, Epsilon: 0.01
[INFO] model update: t: 1130, loss: 16255.369140625
[INFO] Global_t: 1130, Episode_t: 2, Action: 3, Reward: 7.22, Epsilon: 0.01
[INFO] model update: t: 1131, loss: 13512.8046875
[INFO] Global_t: 1131, Episode_t: 3, Action: 1, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1132, loss: 37321.9609375
[INFO] Global_t: 1132, Episode_t: 4, Action: 78, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1133, loss: 8912.064453125
[INFO] Global_t: 1133, Episode_t: 5, Action: 6, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1134, loss: 26694.36328125
[INFO] Global_t: 1134, Episode_t: 6, Action: 7, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1135, loss: 27212.255859375
[INFO] Global_t: 1135, Episode_t: 7, Action: 12, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1136, loss: 9737.6220703125
[INFO] Global_t: 1136, Episode_t: 8, Action: 29, Reward: 3.81, Epsilon: 0.01
 57%|█████▋    | 1136/2000 [37:14<25:11,  1.75s/it]
[INFO] Global step: 1136, Cumulative rewards: 39.06671999999999, Runtime (s): 2234.22
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.128570556640625
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.830257177352905
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.019137859344482
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.654235363006592
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.363306045532227
average cummulative reward vector is:  [0.14596789 0.13748218 0.14778224 0.14517033 0.1494957 ]
average cummulative reward is:  0.1451796674254923
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 142, nodes: 201, edges: 593
[INFO] model update: t: 1137, loss: 21085.53125
[INFO] Global_t: 1137, Episode_t: 1, Action: 1, Reward: 7.33, Epsilon: 0.01
[INFO] model update: t: 1138, loss: 8760.4462890625
[INFO] Global_t: 1138, Episode_t: 2, Action: 3, Reward: 6.33, Epsilon: 0.01
[INFO] model update: t: 1139, loss: 15469.8779296875
[INFO] Global_t: 1139, Episode_t: 3, Action: 2, Reward: 5.46, Epsilon: 0.01
[INFO] model update: t: 1140, loss: 10469.591796875
[INFO] Global_t: 1140, Episode_t: 4, Action: 12, Reward: 4.96, Epsilon: 0.01
[INFO] model update: t: 1141, loss: 14438.67578125
[INFO] Global_t: 1141, Episode_t: 5, Action: 6, Reward: 4.38, Epsilon: 0.01
[INFO] model update: t: 1142, loss: 13152.93359375
[INFO] Global_t: 1142, Episode_t: 6, Action: 5, Reward: 5.43, Epsilon: 0.01
[INFO] model update: t: 1143, loss: 12036.23046875
[INFO] Global_t: 1143, Episode_t: 7, Action: 0, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1144, loss: 20964.30859375
[INFO] Global_t: 1144, Episode_t: 8, Action: 9, Reward: 3.56, Epsilon: 0.01

[INFO] Global step: 1144, Cumulative rewards: 41.20608, Runtime (s): 2261.26
 57%|█████▋    | 1144/2000 [37:41<31:56,  2.24s/it]------------------------------------------------------------
 
graph: 143, nodes: 194, edges: 573
[INFO] model update: t: 1145, loss: 18068.349609375
[INFO] Global_t: 1145, Episode_t: 1, Action: 1, Reward: 6.69, Epsilon: 0.01
[INFO] model update: t: 1146, loss: 45790.09765625
[INFO] Global_t: 1146, Episode_t: 2, Action: 3, Reward: 5.15, Epsilon: 0.01
[INFO] model update: t: 1147, loss: 28521.5234375
[INFO] Global_t: 1147, Episode_t: 3, Action: 2, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1148, loss: 19834.818359375
[INFO] Global_t: 1148, Episode_t: 4, Action: 7, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1149, loss: 29147.51171875
[INFO] Global_t: 1149, Episode_t: 5, Action: 4, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1150, loss: 39581.6171875
[INFO] Global_t: 1150, Episode_t: 6, Action: 5, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1151, loss: 19638.80859375
[INFO] Global_t: 1151, Episode_t: 7, Action: 0, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1152, loss: 16672.7421875
[INFO] Global_t: 1152, Episode_t: 8, Action: 33, Reward: 3.49, Epsilon: 0.01
 58%|█████▊    | 1152/2000 [37:46<24:47,  1.75s/it]
[INFO] Global step: 1152, Cumulative rewards: 36.86832, Runtime (s): 2266.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.770512342453003
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.492321252822876
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.035337924957275
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.1148881912231445
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.433056592941284
average cummulative reward vector is:  [0.13592947 0.1334544  0.15138661 0.13139206 0.14783683]
average cummulative reward is:  0.13999987357719443
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 144, nodes: 219, edges: 648
[INFO] model update: t: 1153, loss: 13367.39453125
[INFO] Global_t: 1153, Episode_t: 1, Action: 4, Reward: 7.92, Epsilon: 0.01
[INFO] model update: t: 1154, loss: 17431.9296875
[INFO] Global_t: 1154, Episode_t: 2, Action: 3, Reward: 6.10, Epsilon: 0.01
[INFO] model update: t: 1155, loss: 12997.0703125
[INFO] Global_t: 1155, Episode_t: 3, Action: 0, Reward: 5.42, Epsilon: 0.01
[INFO] model update: t: 1156, loss: 14647.341796875
[INFO] Global_t: 1156, Episode_t: 4, Action: 6, Reward: 4.81, Epsilon: 0.01
[INFO] model update: t: 1157, loss: 25508.298828125
[INFO] Global_t: 1157, Episode_t: 5, Action: 8, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1158, loss: 17850.236328125
[INFO] Global_t: 1158, Episode_t: 6, Action: 12, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1159, loss: 49076.33203125
[INFO] Global_t: 1159, Episode_t: 7, Action: 7, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 1160, loss: 75384.6875
[INFO] Global_t: 1160, Episode_t: 8, Action: 20, Reward: 3.41, Epsilon: 0.01
 58%|█████▊    | 1160/2000 [38:12<31:04,  2.22s/it]
[INFO] Global step: 1160, Cumulative rewards: 40.4616, Runtime (s): 2292.69
------------------------------------------------------------
 
graph: 145, nodes: 217, edges: 642
[INFO] model update: t: 1161, loss: 22409.66015625
[INFO] Global_t: 1161, Episode_t: 1, Action: 1, Reward: 8.68, Epsilon: 0.01
[INFO] model update: t: 1162, loss: 28665.087890625
[INFO] Global_t: 1162, Episode_t: 2, Action: 2, Reward: 7.72, Epsilon: 0.01
[INFO] model update: t: 1163, loss: 111543.5625
[INFO] Global_t: 1163, Episode_t: 3, Action: 6, Reward: 5.42, Epsilon: 0.01
[INFO] model update: t: 1164, loss: 34805.4375
[INFO] Global_t: 1164, Episode_t: 4, Action: 3, Reward: 5.32, Epsilon: 0.01
[INFO] model update: t: 1165, loss: 59396.4296875
[INFO] Global_t: 1165, Episode_t: 5, Action: 11, Reward: 4.75, Epsilon: 0.01
[INFO] model update: t: 1166, loss: 179130.078125
[INFO] Global_t: 1166, Episode_t: 6, Action: 22, Reward: 4.58, Epsilon: 0.01
[INFO] model update: t: 1167, loss: 96517.890625
[INFO] Global_t: 1167, Episode_t: 7, Action: 8, Reward: 4.29, Epsilon: 0.01
[INFO] model update: t: 1168, loss: 15900.083984375
[INFO] Global_t: 1168, Episode_t: 8, Action: 5, Reward: 4.00, Epsilon: 0.01
 58%|█████▊    | 1168/2000 [38:19<25:09,  1.81s/it]
[INFO] Global step: 1168, Cumulative rewards: 44.75411999999999, Runtime (s): 2299.65
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.2688376903533936
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.4299561977386475
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.725935220718384
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.429579496383667
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.176800012588501
average cummulative reward vector is:  [0.15110105 0.13123935 0.13844699 0.12881192 0.15274086]
average cummulative reward is:  0.14046803502437083
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 146, nodes: 207, edges: 612
[INFO] model update: t: 1169, loss: 13103.5693359375
[INFO] Global_t: 1169, Episode_t: 1, Action: 1, Reward: 7.75, Epsilon: 0.01
[INFO] model update: t: 1170, loss: 37978.6640625
[INFO] Global_t: 1170, Episode_t: 2, Action: 3, Reward: 6.52, Epsilon: 0.01
[INFO] model update: t: 1171, loss: 27275.078125
[INFO] Global_t: 1171, Episode_t: 3, Action: 4, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 1172, loss: 14917.341796875
[INFO] Global_t: 1172, Episode_t: 4, Action: 6, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1173, loss: 43586.90625
[INFO] Global_t: 1173, Episode_t: 5, Action: 8, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1174, loss: 72127.1015625
[INFO] Global_t: 1174, Episode_t: 6, Action: 0, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1175, loss: 53266.015625
[INFO] Global_t: 1175, Episode_t: 7, Action: 2, Reward: 3.69, Epsilon: 0.01
[INFO] model update: t: 1176, loss: 12083.32421875
[INFO] Global_t: 1176, Episode_t: 8, Action: 5, Reward: 3.47, Epsilon: 0.01
 59%|█████▉    | 1176/2000 [38:45<30:54,  2.25s/it]
[INFO] Global step: 1176, Cumulative rewards: 38.7222, Runtime (s): 2325.79
------------------------------------------------------------
 
graph: 147, nodes: 202, edges: 597
[INFO] model update: t: 1177, loss: 35447.46484375
[INFO] Global_t: 1177, Episode_t: 1, Action: 4, Reward: 7.00, Epsilon: 0.01
[INFO] model update: t: 1178, loss: 39998.62890625
[INFO] Global_t: 1178, Episode_t: 2, Action: 6, Reward: 5.71, Epsilon: 0.01
[INFO] model update: t: 1179, loss: 18530.51171875
[INFO] Global_t: 1179, Episode_t: 3, Action: 3, Reward: 5.39, Epsilon: 0.01
[INFO] model update: t: 1180, loss: 11604.05859375
[INFO] Global_t: 1180, Episode_t: 4, Action: 2, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1181, loss: 12285.5712890625
[INFO] Global_t: 1181, Episode_t: 5, Action: 1, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 1182, loss: 22319.068359375
[INFO] Global_t: 1182, Episode_t: 6, Action: 11, Reward: 4.41, Epsilon: 0.01
[INFO] model update: t: 1183, loss: 24231.4453125
[INFO] Global_t: 1183, Episode_t: 7, Action: 8, Reward: 5.73, Epsilon: 0.01
[INFO] model update: t: 1184, loss: 30909.791015625
[INFO] Global_t: 1184, Episode_t: 8, Action: 16, Reward: 3.36, Epsilon: 0.01
 59%|█████▉    | 1184/2000 [38:50<23:52,  1.76s/it]
[INFO] Global step: 1184, Cumulative rewards: 41.795519999999996, Runtime (s): 2330.60
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.082666397094727
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.412917852401733
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.725482940673828
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.619024991989136
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.004514932632446
average cummulative reward vector is:  [0.14357105 0.12523426 0.13958825 0.13494229 0.14484355]
average cummulative reward is:  0.13763588027273627
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 148, nodes: 199, edges: 587
[INFO] model update: t: 1185, loss: 30979.17578125
[INFO] Global_t: 1185, Episode_t: 1, Action: 1, Reward: 6.19, Epsilon: 0.01
[INFO] model update: t: 1186, loss: 27869.66015625
[INFO] Global_t: 1186, Episode_t: 2, Action: 7, Reward: 5.74, Epsilon: 0.01
[INFO] model update: t: 1187, loss: 30164.62890625
[INFO] Global_t: 1187, Episode_t: 3, Action: 3, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 1188, loss: 16872.142578125
[INFO] Global_t: 1188, Episode_t: 4, Action: 6, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1189, loss: 17749.22265625
[INFO] Global_t: 1189, Episode_t: 5, Action: 11, Reward: 4.75, Epsilon: 0.01
[INFO] model update: t: 1190, loss: 15385.98046875
[INFO] Global_t: 1190, Episode_t: 6, Action: 0, Reward: 4.60, Epsilon: 0.01
[INFO] model update: t: 1191, loss: 20220.5390625
[INFO] Global_t: 1191, Episode_t: 7, Action: 18, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 1192, loss: 76553.078125
[INFO] Global_t: 1192, Episode_t: 8, Action: 8, Reward: 3.39, Epsilon: 0.01
 60%|█████▉    | 1192/2000 [39:16<29:28,  2.19s/it]
[INFO] Global step: 1192, Cumulative rewards: 38.0436, Runtime (s): 2356.21
------------------------------------------------------------
 
graph: 149, nodes: 208, edges: 615
[INFO] model update: t: 1193, loss: 69538.015625
[INFO] Global_t: 1193, Episode_t: 1, Action: 3, Reward: 8.41, Epsilon: 0.01
[INFO] model update: t: 1194, loss: 17330.58984375
[INFO] Global_t: 1194, Episode_t: 2, Action: 0, Reward: 7.49, Epsilon: 0.01
[INFO] model update: t: 1195, loss: 143192.59375
[INFO] Global_t: 1195, Episode_t: 3, Action: 1, Reward: 6.05, Epsilon: 0.01
[INFO] model update: t: 1196, loss: 380464.5
[INFO] Global_t: 1196, Episode_t: 4, Action: 5, Reward: 6.06, Epsilon: 0.01
[INFO] model update: t: 1197, loss: 520396.28125
[INFO] Global_t: 1197, Episode_t: 5, Action: 7, Reward: 5.15, Epsilon: 0.01
[INFO] model update: t: 1198, loss: 89876.8203125
[INFO] Global_t: 1198, Episode_t: 6, Action: 8, Reward: 5.04, Epsilon: 0.01
[INFO] model update: t: 1199, loss: 170998.25
[INFO] Global_t: 1199, Episode_t: 7, Action: 4, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1200, loss: 290212.9375
[INFO] Global_t: 1200, Episode_t: 8, Action: 2, Reward: 4.73, Epsilon: 0.01
 60%|██████    | 1200/2000 [39:22<23:31,  1.76s/it]
[INFO] Global step: 1200, Cumulative rewards: 47.15952, Runtime (s): 2362.40
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.376417875289917
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.6200785636901855
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.901118755340576
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.611393213272095
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.190616846084595
average cummulative reward vector is:  [0.15496789 0.13222708 0.14569426 0.1331729  0.15452527]
average cummulative reward is:  0.1441174812757447
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 150, nodes: 216, edges: 639
[INFO] model update: t: 1201, loss: 91503.640625
[INFO] Global_t: 1201, Episode_t: 1, Action: 2, Reward: 6.35, Epsilon: 0.01
[INFO] model update: t: 1202, loss: 24368.265625
[INFO] Global_t: 1202, Episode_t: 2, Action: 3, Reward: 5.80, Epsilon: 0.01
[INFO] model update: t: 1203, loss: 186211.515625
[INFO] Global_t: 1203, Episode_t: 3, Action: 5, Reward: 5.31, Epsilon: 0.01
[INFO] model update: t: 1204, loss: 114176.2265625
[INFO] Global_t: 1204, Episode_t: 4, Action: 10, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1205, loss: 18235.6640625
[INFO] Global_t: 1205, Episode_t: 5, Action: 4, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1206, loss: 47521.35546875
[INFO] Global_t: 1206, Episode_t: 6, Action: 14, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 1207, loss: 90517.6796875
[INFO] Global_t: 1207, Episode_t: 7, Action: 0, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1208, loss: 33927.3125
[INFO] Global_t: 1208, Episode_t: 8, Action: 7, Reward: 3.46, Epsilon: 0.01

[INFO] Global step: 1208, Cumulative rewards: 37.715999999999994, Runtime (s): 2389.39
------------------------------------------------------------
 
 60%|██████    | 1208/2000 [39:49<29:39,  2.25s/it]graph: 151, nodes: 204, edges: 601
[INFO] model update: t: 1209, loss: 18624.310546875
[INFO] Global_t: 1209, Episode_t: 1, Action: 4, Reward: 7.44, Epsilon: 0.01
[INFO] model update: t: 1210, loss: 34715.34375
[INFO] Global_t: 1210, Episode_t: 2, Action: 10, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 1211, loss: 63609.09765625
[INFO] Global_t: 1211, Episode_t: 3, Action: 8, Reward: 5.39, Epsilon: 0.01
[INFO] model update: t: 1212, loss: 39215.65234375
[INFO] Global_t: 1212, Episode_t: 4, Action: 5, Reward: 5.29, Epsilon: 0.01
[INFO] model update: t: 1213, loss: 12838.90625
[INFO] Global_t: 1213, Episode_t: 5, Action: 3, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1214, loss: 13861.9384765625
[INFO] Global_t: 1214, Episode_t: 6, Action: 7, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1215, loss: 25091.205078125
[INFO] Global_t: 1215, Episode_t: 7, Action: 11, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 1216, loss: 43111.1484375
[INFO] Global_t: 1216, Episode_t: 8, Action: 9, Reward: 3.89, Epsilon: 0.01
 61%|██████    | 1216/2000 [39:54<22:50,  1.75s/it]
[INFO] Global step: 1216, Cumulative rewards: 39.36983999999999, Runtime (s): 2394.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9553093910217285
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.643153667449951
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8958911895751953
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.567549228668213
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.985964775085449
average cummulative reward vector is:  [0.14578263 0.13630787 0.14922432 0.13522009 0.14860806]
average cummulative reward is:  0.14302859537265628
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 152, nodes: 208, edges: 615
[INFO] model update: t: 1217, loss: 77531.7265625
[INFO] Global_t: 1217, Episode_t: 1, Action: 3, Reward: 6.62, Epsilon: 0.01
[INFO] model update: t: 1218, loss: 34096.34375
[INFO] Global_t: 1218, Episode_t: 2, Action: 0, Reward: 5.75, Epsilon: 0.01
[INFO] model update: t: 1219, loss: 8204.6259765625
[INFO] Global_t: 1219, Episode_t: 3, Action: 1, Reward: 4.83, Epsilon: 0.01
[INFO] model update: t: 1220, loss: 14431.21484375
[INFO] Global_t: 1220, Episode_t: 4, Action: 10, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1221, loss: 8537.5283203125
[INFO] Global_t: 1221, Episode_t: 5, Action: 6, Reward: 4.41, Epsilon: 0.01
[INFO] model update: t: 1222, loss: 16297.060546875
[INFO] Global_t: 1222, Episode_t: 6, Action: 14, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1223, loss: 18008.515625
[INFO] Global_t: 1223, Episode_t: 7, Action: 8, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1224, loss: 12952.77734375
[INFO] Global_t: 1224, Episode_t: 8, Action: 4, Reward: 3.68, Epsilon: 0.01
 61%|██████    | 1224/2000 [40:20<28:39,  2.22s/it]
[INFO] Global step: 1224, Cumulative rewards: 37.84728, Runtime (s): 2420.52
------------------------------------------------------------
 
graph: 153, nodes: 211, edges: 623
[INFO] model update: t: 1225, loss: 24331.18359375
[INFO] Global_t: 1225, Episode_t: 1, Action: 4, Reward: 8.31, Epsilon: 0.01
[INFO] model update: t: 1226, loss: 11563.970703125
[INFO] Global_t: 1226, Episode_t: 2, Action: 6, Reward: 7.20, Epsilon: 0.01
[INFO] model update: t: 1227, loss: 22627.71875
[INFO] Global_t: 1227, Episode_t: 3, Action: 7, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 1228, loss: 87348.453125
[INFO] Global_t: 1228, Episode_t: 4, Action: 3, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1229, loss: 137305.953125
[INFO] Global_t: 1229, Episode_t: 5, Action: 5, Reward: 4.77, Epsilon: 0.01
[INFO] model update: t: 1230, loss: 54504.6953125
[INFO] Global_t: 1230, Episode_t: 6, Action: 2, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1231, loss: 27521.06640625
[INFO] Global_t: 1231, Episode_t: 7, Action: 0, Reward: 4.40, Epsilon: 0.01
[INFO] model update: t: 1232, loss: 15964.0107421875
[INFO] Global_t: 1232, Episode_t: 8, Action: 12, Reward: 4.28, Epsilon: 0.01
 62%|██████▏   | 1232/2000 [40:25<22:14,  1.74s/it]
[INFO] Global step: 1232, Cumulative rewards: 43.73832, Runtime (s): 2425.48
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.1848835945129395
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.193947076797485
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.038024425506592
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.245807409286499
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9608776569366455
average cummulative reward vector is:  [0.15114079 0.12301458 0.15442049 0.12998388 0.14800161]
average cummulative reward is:  0.14131227120363898
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 154, nodes: 189, edges: 558
[INFO] model update: t: 1233, loss: 6428.6376953125
[INFO] Global_t: 1233, Episode_t: 1, Action: 0, Reward: 7.67, Epsilon: 0.01
[INFO] model update: t: 1234, loss: 13844.0263671875
[INFO] Global_t: 1234, Episode_t: 2, Action: 4, Reward: 7.05, Epsilon: 0.01
[INFO] model update: t: 1235, loss: 30639.2265625
[INFO] Global_t: 1235, Episode_t: 3, Action: 3, Reward: 6.03, Epsilon: 0.01
[INFO] model update: t: 1236, loss: 28932.390625
[INFO] Global_t: 1236, Episode_t: 4, Action: 7, Reward: 5.14, Epsilon: 0.01
[INFO] model update: t: 1237, loss: 18561.310546875
[INFO] Global_t: 1237, Episode_t: 5, Action: 5, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1238, loss: 18286.009765625
[INFO] Global_t: 1238, Episode_t: 6, Action: 2, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1239, loss: 62022.96875
[INFO] Global_t: 1239, Episode_t: 7, Action: 1, Reward: 4.43, Epsilon: 0.01
[INFO] model update: t: 1240, loss: 110688.0
[INFO] Global_t: 1240, Episode_t: 8, Action: 13, Reward: 3.83, Epsilon: 0.01
 62%|██████▏   | 1240/2000 [40:51<27:43,  2.19s/it]
[INFO] Global step: 1240, Cumulative rewards: 43.590959999999995, Runtime (s): 2451.40
------------------------------------------------------------
 
graph: 155, nodes: 203, edges: 599
[INFO] model update: t: 1241, loss: 83880.46875
[INFO] Global_t: 1241, Episode_t: 1, Action: 9, Reward: 6.58, Epsilon: 0.01
[INFO] model update: t: 1242, loss: 16442.9375
[INFO] Global_t: 1242, Episode_t: 2, Action: 3, Reward: 8.57, Epsilon: 0.01
[INFO] model update: t: 1243, loss: 20998.73046875
[INFO] Global_t: 1243, Episode_t: 3, Action: 6, Reward: 5.36, Epsilon: 0.01
[INFO] model update: t: 1244, loss: 44834.2265625
[INFO] Global_t: 1244, Episode_t: 4, Action: 0, Reward: 5.23, Epsilon: 0.01
[INFO] model update: t: 1245, loss: 38490.546875
[INFO] Global_t: 1245, Episode_t: 5, Action: 1, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1246, loss: 15678.04296875
[INFO] Global_t: 1246, Episode_t: 6, Action: 5, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1247, loss: 13763.49609375
[INFO] Global_t: 1247, Episode_t: 7, Action: 2, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 1248, loss: 24680.568359375
[INFO] Global_t: 1248, Episode_t: 8, Action: 8, Reward: 3.77, Epsilon: 0.01
 62%|██████▏   | 1248/2000 [40:56<21:31,  1.72s/it]
[INFO] Global step: 1248, Cumulative rewards: 41.666399999999996, Runtime (s): 2456.36
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8291878700256348
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.51976752281189
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7401962280273438
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.803033113479614
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.959947109222412
average cummulative reward vector is:  [0.14040632 0.13055625 0.14366694 0.14148224 0.14659704]
average cummulative reward is:  0.14054175833631818
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 156, nodes: 192, edges: 567
[INFO] model update: t: 1249, loss: 73616.6640625
[INFO] Global_t: 1249, Episode_t: 1, Action: 3, Reward: 7.20, Epsilon: 0.01
[INFO] model update: t: 1250, loss: 111536.75
[INFO] Global_t: 1250, Episode_t: 2, Action: 1, Reward: 5.66, Epsilon: 0.01
[INFO] model update: t: 1251, loss: 51003.046875
[INFO] Global_t: 1251, Episode_t: 3, Action: 4, Reward: 4.83, Epsilon: 0.01
[INFO] model update: t: 1252, loss: 16804.103515625
[INFO] Global_t: 1252, Episode_t: 4, Action: 2, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1253, loss: 97328.5546875
[INFO] Global_t: 1253, Episode_t: 5, Action: 9, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1254, loss: 75936.53125
[INFO] Global_t: 1254, Episode_t: 6, Action: 31, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1255, loss: 10209.076171875
[INFO] Global_t: 1255, Episode_t: 7, Action: 35, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 1256, loss: 28304.07421875
[INFO] Global_t: 1256, Episode_t: 8, Action: 8, Reward: 3.62, Epsilon: 0.01
 63%|██████▎   | 1256/2000 [41:21<26:44,  2.16s/it]
[INFO] Global step: 1256, Cumulative rewards: 36.4764, Runtime (s): 2481.82
------------------------------------------------------------
 
graph: 157, nodes: 220, edges: 651
[INFO] model update: t: 1257, loss: 107532.453125
[INFO] Global_t: 1257, Episode_t: 1, Action: 4, Reward: 6.73, Epsilon: 0.01
[INFO] model update: t: 1258, loss: 76996.4765625
[INFO] Global_t: 1258, Episode_t: 2, Action: 5, Reward: 6.12, Epsilon: 0.01
[INFO] model update: t: 1259, loss: 11611.578125
[INFO] Global_t: 1259, Episode_t: 3, Action: 3, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 1260, loss: 60990.1796875
[INFO] Global_t: 1260, Episode_t: 4, Action: 1, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1261, loss: 125846.5703125
[INFO] Global_t: 1261, Episode_t: 5, Action: 12, Reward: 5.48, Epsilon: 0.01
[INFO] model update: t: 1262, loss: 133225.6875
[INFO] Global_t: 1262, Episode_t: 6, Action: 6, Reward: 4.39, Epsilon: 0.01
[INFO] model update: t: 1263, loss: 88780.953125
[INFO] Global_t: 1263, Episode_t: 7, Action: 0, Reward: 5.80, Epsilon: 0.01
[INFO] model update: t: 1264, loss: 15128.115234375
[INFO] Global_t: 1264, Episode_t: 8, Action: 2, Reward: 4.31, Epsilon: 0.01
 63%|██████▎   | 1264/2000 [41:27<21:05,  1.72s/it]
[INFO] Global step: 1264, Cumulative rewards: 43.04544, Runtime (s): 2487.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8505823612213135
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  5.066815137863159
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.933258295059204
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.575378894805908
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.960458517074585
average cummulative reward vector is:  [0.14002763 0.14643449 0.15080574 0.13931075 0.14627124]
average cummulative reward is:  0.1445699688494595
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 158, nodes: 209, edges: 618
[INFO] model update: t: 1265, loss: 75388.625
[INFO] Global_t: 1265, Episode_t: 1, Action: 3, Reward: 8.37, Epsilon: 0.01
[INFO] model update: t: 1266, loss: 283011.4375
[INFO] Global_t: 1266, Episode_t: 2, Action: 1, Reward: 7.46, Epsilon: 0.01
[INFO] model update: t: 1267, loss: 533788.375
[INFO] Global_t: 1267, Episode_t: 3, Action: 4, Reward: 6.60, Epsilon: 0.01
[INFO] model update: t: 1268, loss: 647541.0
[INFO] Global_t: 1268, Episode_t: 4, Action: 8, Reward: 4.72, Epsilon: 0.01
[INFO] model update: t: 1269, loss: 225830.546875
[INFO] Global_t: 1269, Episode_t: 5, Action: 9, Reward: 5.14, Epsilon: 0.01
[INFO] model update: t: 1270, loss: 22831.37109375
[INFO] Global_t: 1270, Episode_t: 6, Action: 0, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1271, loss: 238153.34375
[INFO] Global_t: 1271, Episode_t: 7, Action: 12, Reward: 4.72, Epsilon: 0.01
[INFO] model update: t: 1272, loss: 227998.75
[INFO] Global_t: 1272, Episode_t: 8, Action: 18, Reward: 4.25, Epsilon: 0.01
 64%|██████▎   | 1272/2000 [41:54<26:49,  2.21s/it]
[INFO] Global step: 1272, Cumulative rewards: 45.898559999999996, Runtime (s): 2514.27
------------------------------------------------------------
 
graph: 159, nodes: 191, edges: 564
[INFO] model update: t: 1273, loss: 86232.8359375
[INFO] Global_t: 1273, Episode_t: 1, Action: 1, Reward: 7.14, Epsilon: 0.01
[INFO] model update: t: 1274, loss: 23122.91796875
[INFO] Global_t: 1274, Episode_t: 2, Action: 5, Reward: 5.70, Epsilon: 0.01
[INFO] model update: t: 1275, loss: 14776.8828125
[INFO] Global_t: 1275, Episode_t: 3, Action: 3, Reward: 4.89, Epsilon: 0.01
[INFO] model update: t: 1276, loss: 11562.126953125
[INFO] Global_t: 1276, Episode_t: 4, Action: 8, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1277, loss: 24502.66015625
[INFO] Global_t: 1277, Episode_t: 5, Action: 4, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1278, loss: 46144.37109375
[INFO] Global_t: 1278, Episode_t: 6, Action: 144, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1279, loss: 78930.4375
[INFO] Global_t: 1279, Episode_t: 7, Action: 7, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1280, loss: 61402.03125
[INFO] Global_t: 1280, Episode_t: 8, Action: 2, Reward: 4.09, Epsilon: 0.01
 64%|██████▍   | 1280/2000 [41:58<20:40,  1.72s/it]
[INFO] Global step: 1280, Cumulative rewards: 36.162839999999996, Runtime (s): 2518.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.916651725769043
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.944700241088867
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.829237461090088
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.561998128890991
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.187620401382446
average cummulative reward vector is:  [0.14334395 0.13912245 0.1440347  0.13804182 0.15536909]
average cummulative reward is:  0.1439824017954177
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 160, nodes: 220, edges: 650
[INFO] model update: t: 1281, loss: 35556.0859375
[INFO] Global_t: 1281, Episode_t: 1, Action: 3, Reward: 7.49, Epsilon: 0.01
[INFO] model update: t: 1282, loss: 18684.06640625
[INFO] Global_t: 1282, Episode_t: 2, Action: 5, Reward: 5.91, Epsilon: 0.01
[INFO] model update: t: 1283, loss: 122232.7890625
[INFO] Global_t: 1283, Episode_t: 3, Action: 6, Reward: 5.54, Epsilon: 0.01
[INFO] model update: t: 1284, loss: 454030.0625
[INFO] Global_t: 1284, Episode_t: 4, Action: 4, Reward: 5.34, Epsilon: 0.01
[INFO] model update: t: 1285, loss: 601573.375
[INFO] Global_t: 1285, Episode_t: 5, Action: 8, Reward: 6.65, Epsilon: 0.01
[INFO] model update: t: 1286, loss: 671028.75
[INFO] Global_t: 1286, Episode_t: 6, Action: 1, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1287, loss: 604103.5
[INFO] Global_t: 1287, Episode_t: 7, Action: 0, Reward: 4.32, Epsilon: 0.01
[INFO] model update: t: 1288, loss: 249261.046875
[INFO] Global_t: 1288, Episode_t: 8, Action: 12, Reward: 3.71, Epsilon: 0.01
 64%|██████▍   | 1288/2000 [42:26<26:21,  2.22s/it]
[INFO] Global step: 1288, Cumulative rewards: 43.21212, Runtime (s): 2546.01
------------------------------------------------------------
 
graph: 161, nodes: 194, edges: 573
[INFO] model update: t: 1289, loss: 32094.466796875
[INFO] Global_t: 1289, Episode_t: 1, Action: 4, Reward: 7.39, Epsilon: 0.01
[INFO] model update: t: 1290, loss: 56535.4296875
[INFO] Global_t: 1290, Episode_t: 2, Action: 1, Reward: 5.22, Epsilon: 0.01
[INFO] model update: t: 1291, loss: 121774.71875
[INFO] Global_t: 1291, Episode_t: 3, Action: 12, Reward: 4.58, Epsilon: 0.01
[INFO] model update: t: 1292, loss: 37245.8828125
[INFO] Global_t: 1292, Episode_t: 4, Action: 0, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 1293, loss: 23980.70703125
[INFO] Global_t: 1293, Episode_t: 5, Action: 2, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1294, loss: 116045.328125
[INFO] Global_t: 1294, Episode_t: 6, Action: 10, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1295, loss: 287124.84375
[INFO] Global_t: 1295, Episode_t: 7, Action: 6, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 1296, loss: 289023.96875
[INFO] Global_t: 1296, Episode_t: 8, Action: 11, Reward: 3.67, Epsilon: 0.01
 65%|██████▍   | 1296/2000 [42:30<20:12,  1.72s/it]
[INFO] Global step: 1296, Cumulative rewards: 37.29432, Runtime (s): 2550.47
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.2742016315460205
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.476436138153076
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.764169931411743
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.9177165031433105
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8697965145111084
average cummulative reward vector is:  [0.15619026 0.13445231 0.14199945 0.13673224 0.14493306]
average cummulative reward is:  0.1428614678062811
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 162, nodes: 191, edges: 564
[INFO] model update: t: 1297, loss: 50357.046875
[INFO] Global_t: 1297, Episode_t: 1, Action: 3, Reward: 7.02, Epsilon: 0.01
[INFO] model update: t: 1298, loss: 85666.71875
[INFO] Global_t: 1298, Episode_t: 2, Action: 0, Reward: 5.78, Epsilon: 0.01
[INFO] model update: t: 1299, loss: 225553.453125
[INFO] Global_t: 1299, Episode_t: 3, Action: 2, Reward: 5.41, Epsilon: 0.01
[INFO] model update: t: 1300, loss: 154404.984375
[INFO] Global_t: 1300, Episode_t: 4, Action: 1, Reward: 5.02, Epsilon: 0.01
[INFO] model update: t: 1301, loss: 10084.54296875
[INFO] Global_t: 1301, Episode_t: 5, Action: 4, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1302, loss: 98485.484375
[INFO] Global_t: 1302, Episode_t: 6, Action: 23, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1303, loss: 261216.4375
[INFO] Global_t: 1303, Episode_t: 7, Action: 12, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1304, loss: 445298.5
[INFO] Global_t: 1304, Episode_t: 8, Action: 5, Reward: 3.51, Epsilon: 0.01
 65%|██████▌   | 1304/2000 [42:56<25:16,  2.18s/it]
[INFO] Global step: 1304, Cumulative rewards: 37.7922, Runtime (s): 2576.42
------------------------------------------------------------
 
graph: 163, nodes: 213, edges: 629
[INFO] model update: t: 1305, loss: 559576.0
[INFO] Global_t: 1305, Episode_t: 1, Action: 5, Reward: 7.39, Epsilon: 0.01
[INFO] model update: t: 1306, loss: 184736.3125
[INFO] Global_t: 1306, Episode_t: 2, Action: 7, Reward: 5.80, Epsilon: 0.01
[INFO] model update: t: 1307, loss: 25782.796875
[INFO] Global_t: 1307, Episode_t: 3, Action: 11, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1308, loss: 27673.244140625
[INFO] Global_t: 1308, Episode_t: 4, Action: 3, Reward: 5.59, Epsilon: 0.01
[INFO] model update: t: 1309, loss: 101080.1875
[INFO] Global_t: 1309, Episode_t: 5, Action: 9, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1310, loss: 139761.703125
[INFO] Global_t: 1310, Episode_t: 6, Action: 2, Reward: 6.90, Epsilon: 0.01
[INFO] model update: t: 1311, loss: 57041.6484375
[INFO] Global_t: 1311, Episode_t: 7, Action: 1, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1312, loss: 35742.26171875
[INFO] Global_t: 1312, Episode_t: 8, Action: 0, Reward: 4.39, Epsilon: 0.01
 66%|██████▌   | 1312/2000 [43:02<19:58,  1.74s/it]
[INFO] Global step: 1312, Cumulative rewards: 42.48984, Runtime (s): 2582.22
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.044692754745483
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.184609413146973
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6660103797912598
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.7654430866241455
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.0231006145477295
average cummulative reward vector is:  [0.14725474 0.12364306 0.13783798 0.13816822 0.14804704]
average cummulative reward is:  0.1389902075699111
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 164, nodes: 182, edges: 537
[INFO] model update: t: 1313, loss: 101401.3203125
[INFO] Global_t: 1313, Episode_t: 1, Action: 4, Reward: 5.81, Epsilon: 0.01
[INFO] model update: t: 1314, loss: 94474.9765625
[INFO] Global_t: 1314, Episode_t: 2, Action: 3, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1315, loss: 38138.55859375
[INFO] Global_t: 1315, Episode_t: 3, Action: 0, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 1316, loss: 127740.1875
[INFO] Global_t: 1316, Episode_t: 4, Action: 8, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 1317, loss: 443917.375
[INFO] Global_t: 1317, Episode_t: 5, Action: 1, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1318, loss: 796259.0
[INFO] Global_t: 1318, Episode_t: 6, Action: 9, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1319, loss: 584375.625
[INFO] Global_t: 1319, Episode_t: 7, Action: 5, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1320, loss: 25235.1484375
[INFO] Global_t: 1320, Episode_t: 8, Action: 6, Reward: 3.37, Epsilon: 0.01
 66%|██████▌   | 1320/2000 [43:27<24:23,  2.15s/it]
[INFO] Global step: 1320, Cumulative rewards: 33.4266, Runtime (s): 2607.07
------------------------------------------------------------
 
graph: 165, nodes: 180, edges: 531
[INFO] model update: t: 1321, loss: 863622.5625
[INFO] Global_t: 1321, Episode_t: 1, Action: 8, Reward: 5.55, Epsilon: 0.01
[INFO] model update: t: 1322, loss: 2841720.0
[INFO] Global_t: 1322, Episode_t: 2, Action: 2, Reward: 5.27, Epsilon: 0.01
[INFO] model update: t: 1323, loss: 4278741.0
[INFO] Global_t: 1323, Episode_t: 3, Action: 0, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 1324, loss: 1744319.75
[INFO] Global_t: 1324, Episode_t: 4, Action: 3, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1325, loss: 232157.5
[INFO] Global_t: 1325, Episode_t: 5, Action: 4, Reward: 6.26, Epsilon: 0.01
[INFO] model update: t: 1326, loss: 3303139.75
[INFO] Global_t: 1326, Episode_t: 6, Action: 5, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1327, loss: 4699121.5
[INFO] Global_t: 1327, Episode_t: 7, Action: 9, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1328, loss: 2242273.5
[INFO] Global_t: 1328, Episode_t: 8, Action: 10, Reward: 3.27, Epsilon: 0.01
 66%|██████▋   | 1328/2000 [43:32<19:07,  1.71s/it]
[INFO] Global step: 1328, Cumulative rewards: 38.0874, Runtime (s): 2612.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.10736608505249
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.649958372116089
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.98950457572937
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.259488344192505
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.376866579055786
average cummulative reward vector is:  [0.14853605 0.13944931 0.15257951 0.13625561 0.14770726]
average cummulative reward is:  0.14490554638500147
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 166, nodes: 185, edges: 544
[INFO] model update: t: 1329, loss: 288492.125
[INFO] Global_t: 1329, Episode_t: 1, Action: 3, Reward: 7.04, Epsilon: 0.01
[INFO] model update: t: 1330, loss: 325600.0625
[INFO] Global_t: 1330, Episode_t: 2, Action: 0, Reward: 5.30, Epsilon: 0.01
[INFO] model update: t: 1331, loss: 2477812.25
[INFO] Global_t: 1331, Episode_t: 3, Action: 2, Reward: 4.95, Epsilon: 0.01
[INFO] model update: t: 1332, loss: 8813779.0
[INFO] Global_t: 1332, Episode_t: 4, Action: 8, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1333, loss: 19352438.0
[INFO] Global_t: 1333, Episode_t: 5, Action: 10, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1334, loss: 27869792.0
[INFO] Global_t: 1334, Episode_t: 6, Action: 20, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1335, loss: 15101088.0
[INFO] Global_t: 1335, Episode_t: 7, Action: 5, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1336, loss: 5098496.5
[INFO] Global_t: 1336, Episode_t: 8, Action: 7, Reward: 3.39, Epsilon: 0.01
 67%|██████▋   | 1336/2000 [43:58<23:54,  2.16s/it]
[INFO] Global step: 1336, Cumulative rewards: 36.07092, Runtime (s): 2638.17
------------------------------------------------------------
 
graph: 167, nodes: 181, edges: 533
[INFO] model update: t: 1337, loss: 133644.46875
[INFO] Global_t: 1337, Episode_t: 1, Action: 3, Reward: 6.85, Epsilon: 0.01
[INFO] model update: t: 1338, loss: 5167747.0
[INFO] Global_t: 1338, Episode_t: 2, Action: 0, Reward: 5.27, Epsilon: 0.01
[INFO] model update: t: 1339, loss: 12120332.0
[INFO] Global_t: 1339, Episode_t: 3, Action: 1, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1340, loss: 8752251.0
[INFO] Global_t: 1340, Episode_t: 4, Action: 8, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1341, loss: 1672984.75
[INFO] Global_t: 1341, Episode_t: 5, Action: 7, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1342, loss: 440570.96875
[INFO] Global_t: 1342, Episode_t: 6, Action: 10, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1343, loss: 5531991.0
[INFO] Global_t: 1343, Episode_t: 7, Action: 43, Reward: 2.67, Epsilon: 0.01
[INFO] model update: t: 1344, loss: 8687586.0
[INFO] Global_t: 1344, Episode_t: 8, Action: 13, Reward: 2.71, Epsilon: 0.01
 67%|██████▋   | 1344/2000 [44:03<18:30,  1.69s/it]
[INFO] Global step: 1344, Cumulative rewards: 34.63272, Runtime (s): 2643.01
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.221339464187622
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.231830596923828
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.07352876663208
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.508946180343628
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.4932756423950195
average cummulative reward vector is:  [0.15294842 0.13381019 0.14761749 0.14396799 0.14858468]
average cummulative reward is:  0.14538575213003502
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 168, nodes: 201, edges: 594
[INFO] model update: t: 1345, loss: 8915590.0
[INFO] Global_t: 1345, Episode_t: 1, Action: 6, Reward: 6.54, Epsilon: 0.01
[INFO] model update: t: 1346, loss: 3512599.0
[INFO] Global_t: 1346, Episode_t: 2, Action: 4, Reward: 5.40, Epsilon: 0.01
[INFO] model update: t: 1347, loss: 58160.3125
[INFO] Global_t: 1347, Episode_t: 3, Action: 3, Reward: 5.24, Epsilon: 0.01
[INFO] model update: t: 1348, loss: 3105947.0
[INFO] Global_t: 1348, Episode_t: 4, Action: 1, Reward: 6.87, Epsilon: 0.01
[INFO] model update: t: 1349, loss: 5166583.0
[INFO] Global_t: 1349, Episode_t: 5, Action: 0, Reward: 4.60, Epsilon: 0.01
[INFO] model update: t: 1350, loss: 2342408.0
[INFO] Global_t: 1350, Episode_t: 6, Action: 2, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1351, loss: 220900.859375
[INFO] Global_t: 1351, Episode_t: 7, Action: 8, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1352, loss: 332812.3125
[INFO] Global_t: 1352, Episode_t: 8, Action: 10, Reward: 3.81, Epsilon: 0.01
 68%|██████▊   | 1352/2000 [44:29<23:28,  2.17s/it]
[INFO] Global step: 1352, Cumulative rewards: 40.656839999999995, Runtime (s): 2669.37
------------------------------------------------------------
 
graph: 169, nodes: 215, edges: 635
[INFO] model update: t: 1353, loss: 1057984.5
[INFO] Global_t: 1353, Episode_t: 1, Action: 4, Reward: 7.31, Epsilon: 0.01
[INFO] model update: t: 1354, loss: 750161.3125
[INFO] Global_t: 1354, Episode_t: 2, Action: 1, Reward: 6.21, Epsilon: 0.01
[INFO] model update: t: 1355, loss: 156397.34375
[INFO] Global_t: 1355, Episode_t: 3, Action: 3, Reward: 6.17, Epsilon: 0.01
[INFO] model update: t: 1356, loss: 103388.9375
[INFO] Global_t: 1356, Episode_t: 4, Action: 7, Reward: 5.83, Epsilon: 0.01
[INFO] model update: t: 1357, loss: 480076.34375
[INFO] Global_t: 1357, Episode_t: 5, Action: 2, Reward: 4.78, Epsilon: 0.01
[INFO] model update: t: 1358, loss: 281456.46875
[INFO] Global_t: 1358, Episode_t: 6, Action: 13, Reward: 4.07, Epsilon: 0.01
[INFO] model update: t: 1359, loss: 71474.265625
[INFO] Global_t: 1359, Episode_t: 7, Action: 9, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 1360, loss: 431069.15625
[INFO] Global_t: 1360, Episode_t: 8, Action: 20, Reward: 3.58, Epsilon: 0.01
 68%|██████▊   | 1360/2000 [44:35<18:32,  1.74s/it]
[INFO] Global step: 1360, Cumulative rewards: 41.86776, Runtime (s): 2675.13
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9705209732055664
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.210859537124634
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9708573818206787
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.1233603954315186
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.607038259506226
average cummulative reward vector is:  [0.14271526 0.13281296 0.14387432 0.13198388 0.15639516]
average cummulative reward is:  0.1415563165711488
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 170, nodes: 206, edges: 609
[INFO] model update: t: 1361, loss: 599718.8125
[INFO] Global_t: 1361, Episode_t: 1, Action: 1, Reward: 7.42, Epsilon: 0.01
[INFO] model update: t: 1362, loss: 245183.5
[INFO] Global_t: 1362, Episode_t: 2, Action: 3, Reward: 5.34, Epsilon: 0.01
[INFO] model update: t: 1363, loss: 77132.8046875
[INFO] Global_t: 1363, Episode_t: 3, Action: 4, Reward: 4.83, Epsilon: 0.01
[INFO] model update: t: 1364, loss: 783482.4375
[INFO] Global_t: 1364, Episode_t: 4, Action: 0, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1365, loss: 1111483.0
[INFO] Global_t: 1365, Episode_t: 5, Action: 7, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1366, loss: 454886.9375
[INFO] Global_t: 1366, Episode_t: 6, Action: 2, Reward: 5.88, Epsilon: 0.01
[INFO] model update: t: 1367, loss: 116056.9609375
[INFO] Global_t: 1367, Episode_t: 7, Action: 6, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1368, loss: 1676645.25
[INFO] Global_t: 1368, Episode_t: 8, Action: 10, Reward: 3.89, Epsilon: 0.01
 68%|██████▊   | 1368/2000 [45:01<23:06,  2.19s/it]
[INFO] Global step: 1368, Cumulative rewards: 40.43244, Runtime (s): 2701.21
------------------------------------------------------------
 
graph: 171, nodes: 202, edges: 597
[INFO] model update: t: 1369, loss: 5025262.0
[INFO] Global_t: 1369, Episode_t: 1, Action: 4, Reward: 7.33, Epsilon: 0.01
[INFO] model update: t: 1370, loss: 5502433.0
[INFO] Global_t: 1370, Episode_t: 2, Action: 3, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 1371, loss: 1880001.25
[INFO] Global_t: 1371, Episode_t: 3, Action: 5, Reward: 4.75, Epsilon: 0.01
[INFO] model update: t: 1372, loss: 165107.59375
[INFO] Global_t: 1372, Episode_t: 4, Action: 0, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1373, loss: 3371647.0
[INFO] Global_t: 1373, Episode_t: 5, Action: 11, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1374, loss: 5483296.0
[INFO] Global_t: 1374, Episode_t: 6, Action: 9, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 1375, loss: 3185484.5
[INFO] Global_t: 1375, Episode_t: 7, Action: 14, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1376, loss: 119745.7421875
[INFO] Global_t: 1376, Episode_t: 8, Action: 30, Reward: 2.90, Epsilon: 0.01
 69%|██████▉   | 1376/2000 [45:06<18:00,  1.73s/it]
[INFO] Global step: 1376, Cumulative rewards: 36.04188, Runtime (s): 2706.44
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.786871910095215
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.203529357910156
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0268940925598145
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.138791084289551
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.146564722061157
average cummulative reward vector is:  [0.13947737 0.13384977 0.13707869 0.13286332 0.14385699]
average cummulative reward is:  0.1374252264936965
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 172, nodes: 206, edges: 609
[INFO] model update: t: 1377, loss: 1223963.25
[INFO] Global_t: 1377, Episode_t: 1, Action: 7, Reward: 6.75, Epsilon: 0.01
[INFO] model update: t: 1378, loss: 2769915.25
[INFO] Global_t: 1378, Episode_t: 2, Action: 5, Reward: 5.95, Epsilon: 0.01
[INFO] model update: t: 1379, loss: 1857161.0
[INFO] Global_t: 1379, Episode_t: 3, Action: 0, Reward: 7.74, Epsilon: 0.01
[INFO] model update: t: 1380, loss: 77006.71875
[INFO] Global_t: 1380, Episode_t: 4, Action: 3, Reward: 5.63, Epsilon: 0.01
[INFO] model update: t: 1381, loss: 1618139.0
[INFO] Global_t: 1381, Episode_t: 5, Action: 1, Reward: 5.29, Epsilon: 0.01
[INFO] model update: t: 1382, loss: 4177789.0
[INFO] Global_t: 1382, Episode_t: 6, Action: 6, Reward: 5.03, Epsilon: 0.01
[INFO] model update: t: 1383, loss: 2354116.0
[INFO] Global_t: 1383, Episode_t: 7, Action: 16, Reward: 4.98, Epsilon: 0.01
[INFO] model update: t: 1384, loss: 44310.62109375
[INFO] Global_t: 1384, Episode_t: 8, Action: 4, Reward: 4.21, Epsilon: 0.01
 69%|██████▉   | 1384/2000 [45:32<22:26,  2.19s/it]
[INFO] Global step: 1384, Cumulative rewards: 45.58127999999999, Runtime (s): 2732.39
------------------------------------------------------------
 
graph: 173, nodes: 217, edges: 641
[INFO] model update: t: 1385, loss: 1463677.625
[INFO] Global_t: 1385, Episode_t: 1, Action: 3, Reward: 7.75, Epsilon: 0.01
[INFO] model update: t: 1386, loss: 2557146.75
[INFO] Global_t: 1386, Episode_t: 2, Action: 0, Reward: 7.47, Epsilon: 0.01
[INFO] model update: t: 1387, loss: 787296.375
[INFO] Global_t: 1387, Episode_t: 3, Action: 7, Reward: 7.17, Epsilon: 0.01
[INFO] model update: t: 1388, loss: 571328.5625
[INFO] Global_t: 1388, Episode_t: 4, Action: 6, Reward: 7.09, Epsilon: 0.01
[INFO] model update: t: 1389, loss: 3104601.75
[INFO] Global_t: 1389, Episode_t: 5, Action: 4, Reward: 7.97, Epsilon: 0.01
[INFO] model update: t: 1390, loss: 704854.875
[INFO] Global_t: 1390, Episode_t: 6, Action: 11, Reward: 6.26, Epsilon: 0.01
[INFO] model update: t: 1391, loss: 254130.96875
[INFO] Global_t: 1391, Episode_t: 7, Action: 1, Reward: 5.11, Epsilon: 0.01
[INFO] model update: t: 1392, loss: 1319485.75
[INFO] Global_t: 1392, Episode_t: 8, Action: 9, Reward: 4.21, Epsilon: 0.01
 70%|██████▉   | 1392/2000 [45:38<17:48,  1.76s/it]
[INFO] Global step: 1392, Cumulative rewards: 53.015640000000005, Runtime (s): 2738.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8763670921325684
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.544184684753418
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8361713886260986
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.270737171173096
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.4534687995910645
average cummulative reward vector is:  [0.14067737 0.13579606 0.14471967 0.13484626 0.14745672]
average cummulative reward is:  0.14069921749587308
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 174, nodes: 217, edges: 640
[INFO] model update: t: 1393, loss: 977518.375
[INFO] Global_t: 1393, Episode_t: 1, Action: 3, Reward: 6.83, Epsilon: 0.01
[INFO] model update: t: 1394, loss: 82623.8515625
[INFO] Global_t: 1394, Episode_t: 2, Action: 6, Reward: 6.12, Epsilon: 0.01
[INFO] model update: t: 1395, loss: 417409.53125
[INFO] Global_t: 1395, Episode_t: 3, Action: 2, Reward: 5.84, Epsilon: 0.01
[INFO] model update: t: 1396, loss: 408310.40625
[INFO] Global_t: 1396, Episode_t: 4, Action: 4, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 1397, loss: 136903.390625
[INFO] Global_t: 1397, Episode_t: 5, Action: 9, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1398, loss: 186945.34375
[INFO] Global_t: 1398, Episode_t: 6, Action: 1, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1399, loss: 155135.40625
[INFO] Global_t: 1399, Episode_t: 7, Action: 10, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1400, loss: 25027.43359375
[INFO] Global_t: 1400, Episode_t: 8, Action: 16, Reward: 4.14, Epsilon: 0.01

[INFO] Global step: 1400, Cumulative rewards: 42.298559999999995, Runtime (s): 2764.53
------------------------------------------------------------
 
 70%|███████   | 1400/2000 [46:04<22:04,  2.21s/it]graph: 175, nodes: 200, edges: 591
[INFO] model update: t: 1401, loss: 108474.6015625
[INFO] Global_t: 1401, Episode_t: 1, Action: 2, Reward: 7.03, Epsilon: 0.01
[INFO] model update: t: 1402, loss: 285883.375
[INFO] Global_t: 1402, Episode_t: 2, Action: 11, Reward: 5.68, Epsilon: 0.01
[INFO] model update: t: 1403, loss: 252870.4375
[INFO] Global_t: 1403, Episode_t: 3, Action: 3, Reward: 5.04, Epsilon: 0.01
[INFO] model update: t: 1404, loss: 55284.5078125
[INFO] Global_t: 1404, Episode_t: 4, Action: 14, Reward: 4.96, Epsilon: 0.01
[INFO] model update: t: 1405, loss: 210670.109375
[INFO] Global_t: 1405, Episode_t: 5, Action: 4, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 1406, loss: 342870.28125
[INFO] Global_t: 1406, Episode_t: 6, Action: 6, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1407, loss: 219052.453125
[INFO] Global_t: 1407, Episode_t: 7, Action: 0, Reward: 3.57, Epsilon: 0.01
[INFO] model update: t: 1408, loss: 29130.2421875
[INFO] Global_t: 1408, Episode_t: 8, Action: 9, Reward: 3.28, Epsilon: 0.01
 70%|███████   | 1408/2000 [46:09<17:15,  1.75s/it]
[INFO] Global step: 1408, Cumulative rewards: 39.44928000000001, Runtime (s): 2769.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.310640811920166
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.308910608291626
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.691194534301758
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.134886741638184
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.418130397796631
average cummulative reward vector is:  [0.157285   0.13070116 0.14063033 0.13223738 0.14437016]
average cummulative reward is:  0.1410448059488305
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 176, nodes: 180, edges: 531
[INFO] model update: t: 1409, loss: 66132.734375
[INFO] Global_t: 1409, Episode_t: 1, Action: 2, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 1410, loss: 193941.71875
[INFO] Global_t: 1410, Episode_t: 2, Action: 4, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 1411, loss: 148467.890625
[INFO] Global_t: 1411, Episode_t: 3, Action: 5, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1412, loss: 30686.716796875
[INFO] Global_t: 1412, Episode_t: 4, Action: 6, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1413, loss: 60360.84375
[INFO] Global_t: 1413, Episode_t: 5, Action: 3, Reward: 5.58, Epsilon: 0.01
[INFO] model update: t: 1414, loss: 148136.125
[INFO] Global_t: 1414, Episode_t: 6, Action: 9, Reward: 3.69, Epsilon: 0.01
[INFO] model update: t: 1415, loss: 48126.5703125
[INFO] Global_t: 1415, Episode_t: 7, Action: 1, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1416, loss: 25328.552734375
[INFO] Global_t: 1416, Episode_t: 8, Action: 12, Reward: 3.41, Epsilon: 0.01
 71%|███████   | 1416/2000 [46:34<21:02,  2.16s/it]
[INFO] Global step: 1416, Cumulative rewards: 35.409479999999995, Runtime (s): 2794.92
------------------------------------------------------------
 
graph: 177, nodes: 192, edges: 567
[INFO] model update: t: 1417, loss: 32257.63671875
[INFO] Global_t: 1417, Episode_t: 1, Action: 3, Reward: 6.43, Epsilon: 0.01
[INFO] model update: t: 1418, loss: 18676.455078125
[INFO] Global_t: 1418, Episode_t: 2, Action: 6, Reward: 5.50, Epsilon: 0.01
[INFO] model update: t: 1419, loss: 16730.296875
[INFO] Global_t: 1419, Episode_t: 3, Action: 4, Reward: 5.02, Epsilon: 0.01
[INFO] model update: t: 1420, loss: 28221.10546875
[INFO] Global_t: 1420, Episode_t: 4, Action: 2, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1421, loss: 21856.6953125
[INFO] Global_t: 1421, Episode_t: 5, Action: 9, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1422, loss: 18213.669921875
[INFO] Global_t: 1422, Episode_t: 6, Action: 7, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 1423, loss: 11179.9990234375
[INFO] Global_t: 1423, Episode_t: 7, Action: 13, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1424, loss: 16290.185546875
[INFO] Global_t: 1424, Episode_t: 8, Action: 12, Reward: 3.86, Epsilon: 0.01
 71%|███████   | 1424/2000 [46:39<16:08,  1.68s/it]
[INFO] Global step: 1424, Cumulative rewards: 36.5688, Runtime (s): 2799.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.851682662963867
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.313394546508789
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.544310092926025
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.148950576782227
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.356529235839844
average cummulative reward vector is:  [0.13966474 0.13608032 0.15766366 0.13210257 0.15189382]
average cummulative reward is:  0.1434810218832248
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 178, nodes: 209, edges: 618
[INFO] model update: t: 1425, loss: 30585.86328125
[INFO] Global_t: 1425, Episode_t: 1, Action: 3, Reward: 7.48, Epsilon: 0.01
[INFO] model update: t: 1426, loss: 27676.267578125
[INFO] Global_t: 1426, Episode_t: 2, Action: 2, Reward: 6.11, Epsilon: 0.01
[INFO] model update: t: 1427, loss: 23717.595703125
[INFO] Global_t: 1427, Episode_t: 3, Action: 4, Reward: 5.49, Epsilon: 0.01
[INFO] model update: t: 1428, loss: 66121.0546875
[INFO] Global_t: 1428, Episode_t: 4, Action: 8, Reward: 5.44, Epsilon: 0.01
[INFO] model update: t: 1429, loss: 136786.8125
[INFO] Global_t: 1429, Episode_t: 5, Action: 7, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1430, loss: 255065.859375
[INFO] Global_t: 1430, Episode_t: 6, Action: 11, Reward: 4.18, Epsilon: 0.01
[INFO] model update: t: 1431, loss: 299627.40625
[INFO] Global_t: 1431, Episode_t: 7, Action: 0, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1432, loss: 170519.5625
[INFO] Global_t: 1432, Episode_t: 8, Action: 21, Reward: 3.71, Epsilon: 0.01
 72%|███████▏  | 1432/2000 [47:05<20:23,  2.15s/it]
[INFO] Global step: 1432, Cumulative rewards: 42.04512, Runtime (s): 2825.48
------------------------------------------------------------
 
graph: 179, nodes: 205, edges: 606
[INFO] model update: t: 1433, loss: 42003.3125
[INFO] Global_t: 1433, Episode_t: 1, Action: 3, Reward: 7.63, Epsilon: 0.01
[INFO] model update: t: 1434, loss: 74316.484375
[INFO] Global_t: 1434, Episode_t: 2, Action: 8, Reward: 5.48, Epsilon: 0.01
[INFO] model update: t: 1435, loss: 372087.1875
[INFO] Global_t: 1435, Episode_t: 3, Action: 7, Reward: 4.80, Epsilon: 0.01
[INFO] model update: t: 1436, loss: 445062.25
[INFO] Global_t: 1436, Episode_t: 4, Action: 1, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 1437, loss: 73309.8515625
[INFO] Global_t: 1437, Episode_t: 5, Action: 10, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1438, loss: 53607.1796875
[INFO] Global_t: 1438, Episode_t: 6, Action: 2, Reward: 4.58, Epsilon: 0.01
[INFO] model update: t: 1439, loss: 228601.390625
[INFO] Global_t: 1439, Episode_t: 7, Action: 0, Reward: 5.42, Epsilon: 0.01
[INFO] model update: t: 1440, loss: 151653.125
[INFO] Global_t: 1440, Episode_t: 8, Action: 150, Reward: 1.28, Epsilon: 0.01
 72%|███████▏  | 1440/2000 [47:11<16:06,  1.73s/it]
[INFO] Global step: 1440, Cumulative rewards: 38.19131999999999, Runtime (s): 2831.31
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.05889368057251
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.3599114418029785
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.148998498916626
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.47506308555603
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.510778427124023
average cummulative reward vector is:  [0.14706263 0.13641019 0.14638087 0.14217874 0.15850914]
average cummulative reward is:  0.14610831383675515
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 180, nodes: 202, edges: 596
[INFO] model update: t: 1441, loss: 35548.625
[INFO] Global_t: 1441, Episode_t: 1, Action: 0, Reward: 6.04, Epsilon: 0.01
[INFO] model update: t: 1442, loss: 46829.4375
[INFO] Global_t: 1442, Episode_t: 2, Action: 5, Reward: 5.62, Epsilon: 0.01
[INFO] model update: t: 1443, loss: 85026.515625
[INFO] Global_t: 1443, Episode_t: 3, Action: 4, Reward: 5.22, Epsilon: 0.01
[INFO] model update: t: 1444, loss: 58156.0
[INFO] Global_t: 1444, Episode_t: 4, Action: 1, Reward: 4.80, Epsilon: 0.01
[INFO] model update: t: 1445, loss: 19837.0859375
[INFO] Global_t: 1445, Episode_t: 5, Action: 3, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 1446, loss: 34797.86328125
[INFO] Global_t: 1446, Episode_t: 6, Action: 6, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 1447, loss: 63505.54296875
[INFO] Global_t: 1447, Episode_t: 7, Action: 9, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1448, loss: 27465.923828125
[INFO] Global_t: 1448, Episode_t: 8, Action: 7, Reward: 5.10, Epsilon: 0.01
 72%|███████▏  | 1448/2000 [47:37<20:07,  2.19s/it]
[INFO] Global step: 1448, Cumulative rewards: 40.294799999999995, Runtime (s): 2857.43
------------------------------------------------------------
 
graph: 181, nodes: 205, edges: 606
[INFO] model update: t: 1449, loss: 30650.72265625
[INFO] Global_t: 1449, Episode_t: 1, Action: 4, Reward: 6.79, Epsilon: 0.01
[INFO] model update: t: 1450, loss: 21280.46484375
[INFO] Global_t: 1450, Episode_t: 2, Action: 5, Reward: 7.00, Epsilon: 0.01
[INFO] model update: t: 1451, loss: 21325.4140625
[INFO] Global_t: 1451, Episode_t: 3, Action: 0, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1452, loss: 33700.91796875
[INFO] Global_t: 1452, Episode_t: 4, Action: 3, Reward: 6.15, Epsilon: 0.01
[INFO] model update: t: 1453, loss: 23559.66796875
[INFO] Global_t: 1453, Episode_t: 5, Action: 2, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1454, loss: 17271.7265625
[INFO] Global_t: 1454, Episode_t: 6, Action: 1, Reward: 5.71, Epsilon: 0.01
[INFO] model update: t: 1455, loss: 64417.34375
[INFO] Global_t: 1455, Episode_t: 7, Action: 6, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1456, loss: 48062.0546875
[INFO] Global_t: 1456, Episode_t: 8, Action: 16, Reward: 3.53, Epsilon: 0.01
 73%|███████▎  | 1456/2000 [47:43<15:47,  1.74s/it]
[INFO] Global step: 1456, Cumulative rewards: 43.11755999999999, Runtime (s): 2863.02
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.782696485519409
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.2224812507629395
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.184189796447754
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.163697719573975
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.282497882843018
average cummulative reward vector is:  [0.13838368 0.1323537  0.14398934 0.13081846 0.15020511]
average cummulative reward is:  0.1391500595294664
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 182, nodes: 205, edges: 606
[INFO] model update: t: 1457, loss: 25594.0078125
[INFO] Global_t: 1457, Episode_t: 1, Action: 4, Reward: 7.30, Epsilon: 0.01
[INFO] model update: t: 1458, loss: 27299.6640625
[INFO] Global_t: 1458, Episode_t: 2, Action: 7, Reward: 5.74, Epsilon: 0.01
[INFO] model update: t: 1459, loss: 52710.30078125
[INFO] Global_t: 1459, Episode_t: 3, Action: 1, Reward: 6.18, Epsilon: 0.01
[INFO] model update: t: 1460, loss: 100169.6640625
[INFO] Global_t: 1460, Episode_t: 4, Action: 11, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1461, loss: 187134.28125
[INFO] Global_t: 1461, Episode_t: 5, Action: 3, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1462, loss: 153616.46875
[INFO] Global_t: 1462, Episode_t: 6, Action: 0, Reward: 6.67, Epsilon: 0.01
[INFO] model update: t: 1463, loss: 16959.2109375
[INFO] Global_t: 1463, Episode_t: 7, Action: 23, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1464, loss: 96891.359375
[INFO] Global_t: 1464, Episode_t: 8, Action: 8, Reward: 3.80, Epsilon: 0.01
 73%|███████▎  | 1464/2000 [48:09<19:35,  2.19s/it]
[INFO] Global step: 1464, Cumulative rewards: 43.69008, Runtime (s): 2889.00
------------------------------------------------------------
 
graph: 183, nodes: 217, edges: 642
[INFO] model update: t: 1465, loss: 100410.4296875
[INFO] Global_t: 1465, Episode_t: 1, Action: 5, Reward: 9.52, Epsilon: 0.01
[INFO] model update: t: 1466, loss: 30925.71875
[INFO] Global_t: 1466, Episode_t: 2, Action: 3, Reward: 8.21, Epsilon: 0.01
[INFO] model update: t: 1467, loss: 134562.453125
[INFO] Global_t: 1467, Episode_t: 3, Action: 1, Reward: 5.89, Epsilon: 0.01
[INFO] model update: t: 1468, loss: 363215.40625
[INFO] Global_t: 1468, Episode_t: 4, Action: 0, Reward: 6.21, Epsilon: 0.01
[INFO] model update: t: 1469, loss: 311760.15625
[INFO] Global_t: 1469, Episode_t: 5, Action: 10, Reward: 5.43, Epsilon: 0.01
[INFO] model update: t: 1470, loss: 287785.4375
[INFO] Global_t: 1470, Episode_t: 6, Action: 6, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1471, loss: 64739.4765625
[INFO] Global_t: 1471, Episode_t: 7, Action: 9, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1472, loss: 95559.15625
[INFO] Global_t: 1472, Episode_t: 8, Action: 7, Reward: 3.79, Epsilon: 0.01
 74%|███████▎  | 1472/2000 [48:15<15:37,  1.78s/it]
[INFO] Global step: 1472, Cumulative rewards: 47.7834, Runtime (s): 2895.41
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.351978778839111
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.638476133346558
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.017826080322266
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.373374938964844
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.467066764831543
average cummulative reward vector is:  [0.15462763 0.13289306 0.15202541 0.13838528 0.15394946]
average cummulative reward is:  0.14637616794199834
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 184, nodes: 196, edges: 579
[INFO] model update: t: 1473, loss: 672769.6875
[INFO] Global_t: 1473, Episode_t: 1, Action: 2, Reward: 7.18, Epsilon: 0.01
[INFO] model update: t: 1474, loss: 1427851.0
[INFO] Global_t: 1474, Episode_t: 2, Action: 3, Reward: 7.46, Epsilon: 0.01
[INFO] model update: t: 1475, loss: 2472427.0
[INFO] Global_t: 1475, Episode_t: 3, Action: 6, Reward: 5.77, Epsilon: 0.01
[INFO] model update: t: 1476, loss: 2973782.5
[INFO] Global_t: 1476, Episode_t: 4, Action: 0, Reward: 5.72, Epsilon: 0.01
[INFO] model update: t: 1477, loss: 647380.625
[INFO] Global_t: 1477, Episode_t: 5, Action: 12, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 1478, loss: 546880.0
[INFO] Global_t: 1478, Episode_t: 6, Action: 5, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1479, loss: 2777021.75
[INFO] Global_t: 1479, Episode_t: 7, Action: 14, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1480, loss: 2735912.0
[INFO] Global_t: 1480, Episode_t: 8, Action: 9, Reward: 3.77, Epsilon: 0.01
 74%|███████▍  | 1480/2000 [48:43<19:45,  2.28s/it]
[INFO] Global step: 1480, Cumulative rewards: 43.543079999999996, Runtime (s): 2923.07
------------------------------------------------------------
 
graph: 185, nodes: 180, edges: 530
[INFO] model update: t: 1481, loss: 2087065.5
[INFO] Global_t: 1481, Episode_t: 1, Action: 2, Reward: 5.60, Epsilon: 0.01
[INFO] model update: t: 1482, loss: 439644.21875
[INFO] Global_t: 1482, Episode_t: 2, Action: 5, Reward: 4.82, Epsilon: 0.01
[INFO] model update: t: 1483, loss: 184186.65625
[INFO] Global_t: 1483, Episode_t: 3, Action: 4, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1484, loss: 1603790.75
[INFO] Global_t: 1484, Episode_t: 4, Action: 8, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1485, loss: 3326751.5
[INFO] Global_t: 1485, Episode_t: 5, Action: 3, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1486, loss: 940670.25
[INFO] Global_t: 1486, Episode_t: 6, Action: 10, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 1487, loss: 362950.78125
[INFO] Global_t: 1487, Episode_t: 7, Action: 30, Reward: 3.31, Epsilon: 0.01
[INFO] model update: t: 1488, loss: 4064878.5
[INFO] Global_t: 1488, Episode_t: 8, Action: 1, Reward: 3.18, Epsilon: 0.01
 74%|███████▍  | 1488/2000 [48:48<15:14,  1.79s/it]
[INFO] Global step: 1488, Cumulative rewards: 33.980880000000006, Runtime (s): 2928.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.0045764446258545
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.421910285949707
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9434306621551514
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.65819525718689
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.111695289611816
average cummulative reward vector is:  [0.13904105 0.1312838  0.14893361 0.14635304 0.14209919]
average cummulative reward is:  0.1415421372833634
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 186, nodes: 210, edges: 621
[INFO] model update: t: 1489, loss: 8054250.0
[INFO] Global_t: 1489, Episode_t: 1, Action: 5, Reward: 7.64, Epsilon: 0.01
[INFO] model update: t: 1490, loss: 12648262.0
[INFO] Global_t: 1490, Episode_t: 2, Action: 3, Reward: 7.27, Epsilon: 0.01
[INFO] model update: t: 1491, loss: 11572184.0
[INFO] Global_t: 1491, Episode_t: 3, Action: 2, Reward: 6.40, Epsilon: 0.01
[INFO] model update: t: 1492, loss: 10546101.0
[INFO] Global_t: 1492, Episode_t: 4, Action: 4, Reward: 6.70, Epsilon: 0.01
[INFO] model update: t: 1493, loss: 3312827.0
[INFO] Global_t: 1493, Episode_t: 5, Action: 0, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1494, loss: 895760.625
[INFO] Global_t: 1494, Episode_t: 6, Action: 6, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 1495, loss: 11297378.0
[INFO] Global_t: 1495, Episode_t: 7, Action: 8, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 1496, loss: 16737606.0
[INFO] Global_t: 1496, Episode_t: 8, Action: 26, Reward: 3.35, Epsilon: 0.01
 75%|███████▍  | 1496/2000 [49:14<18:57,  2.26s/it]
[INFO] Global step: 1496, Cumulative rewards: 45.04464000000001, Runtime (s): 2955.00
------------------------------------------------------------
 
graph: 187, nodes: 210, edges: 621
[INFO] model update: t: 1497, loss: 3777933.0
[INFO] Global_t: 1497, Episode_t: 1, Action: 4, Reward: 8.72, Epsilon: 0.01
[INFO] model update: t: 1498, loss: 461844.53125
[INFO] Global_t: 1498, Episode_t: 2, Action: 0, Reward: 6.63, Epsilon: 0.01
[INFO] model update: t: 1499, loss: 5900944.0
[INFO] Global_t: 1499, Episode_t: 3, Action: 2, Reward: 6.43, Epsilon: 0.01
[INFO] model update: t: 1500, loss: 8700850.0
[INFO] Global_t: 1500, Episode_t: 4, Action: 5, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 1501, loss: 5408938.5
[INFO] Global_t: 1501, Episode_t: 5, Action: 8, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1502, loss: 704338.875
[INFO] Global_t: 1502, Episode_t: 6, Action: 3, Reward: 8.18, Epsilon: 0.01
[INFO] model update: t: 1503, loss: 1074557.375
[INFO] Global_t: 1503, Episode_t: 7, Action: 11, Reward: 4.85, Epsilon: 0.01
[INFO] model update: t: 1504, loss: 4120095.75
[INFO] Global_t: 1504, Episode_t: 8, Action: 10, Reward: 4.42, Epsilon: 0.01
 75%|███████▌  | 1504/2000 [49:21<15:04,  1.82s/it]
[INFO] Global step: 1504, Cumulative rewards: 49.95119999999999, Runtime (s): 2961.48
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.213762998580933
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.266777515411377
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.042309284210205
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.92730450630188
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.012398958206177
average cummulative reward vector is:  [0.14981474 0.12779375 0.15165683 0.13920911 0.14533575]
average cummulative reward is:  0.14276203645618057
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 188, nodes: 198, edges: 585
[INFO] model update: t: 1505, loss: 1182088.75
[INFO] Global_t: 1505, Episode_t: 1, Action: 4, Reward: 6.63, Epsilon: 0.01
[INFO] model update: t: 1506, loss: 242702.265625
[INFO] Global_t: 1506, Episode_t: 2, Action: 3, Reward: 7.00, Epsilon: 0.01
[INFO] model update: t: 1507, loss: 2719636.5
[INFO] Global_t: 1507, Episode_t: 3, Action: 2, Reward: 5.32, Epsilon: 0.01
[INFO] model update: t: 1508, loss: 3079290.0
[INFO] Global_t: 1508, Episode_t: 4, Action: 6, Reward: 4.29, Epsilon: 0.01
[INFO] model update: t: 1509, loss: 918282.9375
[INFO] Global_t: 1509, Episode_t: 5, Action: 19, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1510, loss: 168435.96875
[INFO] Global_t: 1510, Episode_t: 6, Action: 8, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1511, loss: 1684210.75
[INFO] Global_t: 1511, Episode_t: 7, Action: 10, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 1512, loss: 2407199.0
[INFO] Global_t: 1512, Episode_t: 8, Action: 18, Reward: 3.89, Epsilon: 0.01
 76%|███████▌  | 1512/2000 [49:48<18:39,  2.29s/it]
[INFO] Global step: 1512, Cumulative rewards: 38.8584, Runtime (s): 2988.61
------------------------------------------------------------
 
graph: 189, nodes: 180, edges: 531
[INFO] model update: t: 1513, loss: 1147098.75
[INFO] Global_t: 1513, Episode_t: 1, Action: 3, Reward: 7.72, Epsilon: 0.01
[INFO] model update: t: 1514, loss: 21701.318359375
[INFO] Global_t: 1514, Episode_t: 2, Action: 2, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1515, loss: 770641.5
[INFO] Global_t: 1515, Episode_t: 3, Action: 12, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1516, loss: 1463443.75
[INFO] Global_t: 1516, Episode_t: 4, Action: 7, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1517, loss: 773091.0625
[INFO] Global_t: 1517, Episode_t: 5, Action: 1, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1518, loss: 33784.25390625
[INFO] Global_t: 1518, Episode_t: 6, Action: 9, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1519, loss: 1011052.5
[INFO] Global_t: 1519, Episode_t: 7, Action: 8, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 1520, loss: 1465828.0
[INFO] Global_t: 1520, Episode_t: 8, Action: 5, Reward: 3.10, Epsilon: 0.01
 76%|███████▌  | 1520/2000 [49:53<14:16,  1.79s/it]
[INFO] Global step: 1520, Cumulative rewards: 36.043440000000004, Runtime (s): 2993.40
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.2071545124053955
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.81678581237793
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.079530477523804
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.979130983352661
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.42068886756897
average cummulative reward vector is:  [0.14375447 0.1325206  0.14913689 0.14010164 0.15719919]
average cummulative reward is:  0.14454255796887394
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 190, nodes: 194, edges: 573
[INFO] model update: t: 1521, loss: 186231.75
[INFO] Global_t: 1521, Episode_t: 1, Action: 4, Reward: 6.80, Epsilon: 0.01
[INFO] model update: t: 1522, loss: 258091.0
[INFO] Global_t: 1522, Episode_t: 2, Action: 1, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1523, loss: 1049094.25
[INFO] Global_t: 1523, Episode_t: 3, Action: 0, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1524, loss: 774462.5
[INFO] Global_t: 1524, Episode_t: 4, Action: 6, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1525, loss: 22720.09765625
[INFO] Global_t: 1525, Episode_t: 5, Action: 3, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1526, loss: 499436.625
[INFO] Global_t: 1526, Episode_t: 6, Action: 13, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1527, loss: 459840.625
[INFO] Global_t: 1527, Episode_t: 7, Action: 16, Reward: 4.07, Epsilon: 0.01
[INFO] model update: t: 1528, loss: 88214.6875
[INFO] Global_t: 1528, Episode_t: 8, Action: 9, Reward: 3.59, Epsilon: 0.01
 76%|███████▋  | 1528/2000 [50:21<18:04,  2.30s/it]
[INFO] Global step: 1528, Cumulative rewards: 35.355239999999995, Runtime (s): 3021.36
------------------------------------------------------------
 
graph: 191, nodes: 183, edges: 539
[INFO] model update: t: 1529, loss: 98045.125
[INFO] Global_t: 1529, Episode_t: 1, Action: 1, Reward: 7.24, Epsilon: 0.01
[INFO] model update: t: 1530, loss: 399321.0
[INFO] Global_t: 1530, Episode_t: 2, Action: 4, Reward: 6.63, Epsilon: 0.01
[INFO] model update: t: 1531, loss: 253293.171875
[INFO] Global_t: 1531, Episode_t: 3, Action: 0, Reward: 5.53, Epsilon: 0.01
[INFO] model update: t: 1532, loss: 85532.5234375
[INFO] Global_t: 1532, Episode_t: 4, Action: 7, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1533, loss: 796914.5625
[INFO] Global_t: 1533, Episode_t: 5, Action: 3, Reward: 6.28, Epsilon: 0.01
[INFO] model update: t: 1534, loss: 909943.75
[INFO] Global_t: 1534, Episode_t: 6, Action: 17, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1535, loss: 266693.3125
[INFO] Global_t: 1535, Episode_t: 7, Action: 5, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1536, loss: 173074.578125
[INFO] Global_t: 1536, Episode_t: 8, Action: 12, Reward: 3.10, Epsilon: 0.01
 77%|███████▋  | 1536/2000 [50:27<14:06,  1.82s/it]
[INFO] Global step: 1536, Cumulative rewards: 40.30644, Runtime (s): 3027.12
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.228864431381226
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.588600397109985
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.08000111579895
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.962879419326782
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.347710847854614
average cummulative reward vector is:  [0.14032237 0.14115718 0.15123552 0.13908832 0.15696855]
average cummulative reward is:  0.14575438592335352
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 192, nodes: 214, edges: 633
[INFO] model update: t: 1537, loss: 1036786.3125
[INFO] Global_t: 1537, Episode_t: 1, Action: 3, Reward: 6.84, Epsilon: 0.01
[INFO] model update: t: 1538, loss: 524882.375
[INFO] Global_t: 1538, Episode_t: 2, Action: 4, Reward: 6.21, Epsilon: 0.01
[INFO] model update: t: 1539, loss: 143795.75
[INFO] Global_t: 1539, Episode_t: 3, Action: 5, Reward: 5.82, Epsilon: 0.01
[INFO] model update: t: 1540, loss: 1721920.5
[INFO] Global_t: 1540, Episode_t: 4, Action: 8, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1541, loss: 1775077.375
[INFO] Global_t: 1541, Episode_t: 5, Action: 6, Reward: 6.76, Epsilon: 0.01
[INFO] model update: t: 1542, loss: 558946.625
[INFO] Global_t: 1542, Episode_t: 6, Action: 13, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1543, loss: 105633.0
[INFO] Global_t: 1543, Episode_t: 7, Action: 15, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1544, loss: 994385.125
[INFO] Global_t: 1544, Episode_t: 8, Action: 2, Reward: 3.85, Epsilon: 0.01
 77%|███████▋  | 1544/2000 [50:55<17:45,  2.34s/it]
[INFO] Global step: 1544, Cumulative rewards: 41.917199999999994, Runtime (s): 3055.37
------------------------------------------------------------
 
graph: 193, nodes: 218, edges: 645
[INFO] model update: t: 1545, loss: 621311.5
[INFO] Global_t: 1545, Episode_t: 1, Action: 4, Reward: 7.57, Epsilon: 0.01
[INFO] model update: t: 1546, loss: 13761.51953125
[INFO] Global_t: 1546, Episode_t: 2, Action: 3, Reward: 6.94, Epsilon: 0.01
[INFO] model update: t: 1547, loss: 952499.5
[INFO] Global_t: 1547, Episode_t: 3, Action: 2, Reward: 6.03, Epsilon: 0.01
[INFO] model update: t: 1548, loss: 2660529.0
[INFO] Global_t: 1548, Episode_t: 4, Action: 5, Reward: 4.40, Epsilon: 0.01
[INFO] model update: t: 1549, loss: 2900066.75
[INFO] Global_t: 1549, Episode_t: 5, Action: 14, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1550, loss: 18184.10546875
[INFO] Global_t: 1550, Episode_t: 6, Action: 11, Reward: 4.28, Epsilon: 0.01
[INFO] model update: t: 1551, loss: 2961835.5
[INFO] Global_t: 1551, Episode_t: 7, Action: 6, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1552, loss: 4221478.0
[INFO] Global_t: 1552, Episode_t: 8, Action: 0, Reward: 5.45, Epsilon: 0.01
 78%|███████▊  | 1552/2000 [51:00<13:45,  1.84s/it]
[INFO] Global step: 1552, Cumulative rewards: 43.04784, Runtime (s): 3060.90
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.41962194442749
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.1099865436553955
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.585830450057983
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.612178325653076
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.127351522445679
average cummulative reward vector is:  [0.14386447 0.12775602 0.14742432 0.14074907 0.14883737]
average cummulative reward is:  0.14172624803091566
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 194, nodes: 213, edges: 630
[INFO] model update: t: 1553, loss: 3375338.0
[INFO] Global_t: 1553, Episode_t: 1, Action: 4, Reward: 7.54, Epsilon: 0.01
[INFO] model update: t: 1554, loss: 288149.125
[INFO] Global_t: 1554, Episode_t: 2, Action: 7, Reward: 5.93, Epsilon: 0.01
[INFO] model update: t: 1555, loss: 1022245.375
[INFO] Global_t: 1555, Episode_t: 3, Action: 6, Reward: 5.36, Epsilon: 0.01
[INFO] model update: t: 1556, loss: 3360306.0
[INFO] Global_t: 1556, Episode_t: 4, Action: 127, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1557, loss: 3121523.0
[INFO] Global_t: 1557, Episode_t: 5, Action: 2, Reward: 6.21, Epsilon: 0.01
[INFO] model update: t: 1558, loss: 884135.0
[INFO] Global_t: 1558, Episode_t: 6, Action: 1, Reward: 7.70, Epsilon: 0.01
[INFO] model update: t: 1559, loss: 194718.390625
[INFO] Global_t: 1559, Episode_t: 7, Action: 9, Reward: 6.01, Epsilon: 0.01
[INFO] model update: t: 1560, loss: 1971781.0
[INFO] Global_t: 1560, Episode_t: 8, Action: 5, Reward: 4.55, Epsilon: 0.01
 78%|███████▊  | 1560/2000 [51:29<17:23,  2.37s/it]
[INFO] Global step: 1560, Cumulative rewards: 44.79864, Runtime (s): 3089.77
------------------------------------------------------------
 
graph: 195, nodes: 189, edges: 558
[INFO] model update: t: 1561, loss: 1219884.75
[INFO] Global_t: 1561, Episode_t: 1, Action: 4, Reward: 6.58, Epsilon: 0.01
[INFO] model update: t: 1562, loss: 27670.533203125
[INFO] Global_t: 1562, Episode_t: 2, Action: 8, Reward: 5.49, Epsilon: 0.01
[INFO] model update: t: 1563, loss: 760902.3125
[INFO] Global_t: 1563, Episode_t: 3, Action: 0, Reward: 6.02, Epsilon: 0.01
[INFO] model update: t: 1564, loss: 2194161.0
[INFO] Global_t: 1564, Episode_t: 4, Action: 3, Reward: 5.93, Epsilon: 0.01
[INFO] model update: t: 1565, loss: 1387990.875
[INFO] Global_t: 1565, Episode_t: 5, Action: 9, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1566, loss: 121033.6171875
[INFO] Global_t: 1566, Episode_t: 6, Action: 2, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1567, loss: 600319.625
[INFO] Global_t: 1567, Episode_t: 7, Action: 12, Reward: 3.23, Epsilon: 0.01
[INFO] model update: t: 1568, loss: 1567651.25
[INFO] Global_t: 1568, Episode_t: 8, Action: 13, Reward: 2.98, Epsilon: 0.01
 78%|███████▊  | 1568/2000 [51:35<13:29,  1.87s/it]
[INFO] Global step: 1568, Cumulative rewards: 38.0076, Runtime (s): 3095.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.240067005157471
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.776352405548096
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.008016109466553
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.048064470291138
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.6644606590271
average cummulative reward vector is:  [0.14967921 0.13854236 0.14359563 0.12666729 0.15724866]
average cummulative reward is:  0.14314662913726642
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 196, nodes: 208, edges: 615
[INFO] model update: t: 1569, loss: 771775.25
[INFO] Global_t: 1569, Episode_t: 1, Action: 3, Reward: 8.17, Epsilon: 0.01
[INFO] model update: t: 1570, loss: 51566.1328125
[INFO] Global_t: 1570, Episode_t: 2, Action: 2, Reward: 5.58, Epsilon: 0.01
[INFO] model update: t: 1571, loss: 192159.6875
[INFO] Global_t: 1571, Episode_t: 3, Action: 7, Reward: 5.48, Epsilon: 0.01
[INFO] model update: t: 1572, loss: 402648.9375
[INFO] Global_t: 1572, Episode_t: 4, Action: 8, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1573, loss: 232515.65625
[INFO] Global_t: 1573, Episode_t: 5, Action: 0, Reward: 5.16, Epsilon: 0.01
[INFO] model update: t: 1574, loss: 45301.80859375
[INFO] Global_t: 1574, Episode_t: 6, Action: 5, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1575, loss: 112024.09375
[INFO] Global_t: 1575, Episode_t: 7, Action: 9, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1576, loss: 254879.5625
[INFO] Global_t: 1576, Episode_t: 8, Action: 1, Reward: 3.44, Epsilon: 0.01
 79%|███████▉  | 1576/2000 [52:02<16:32,  2.34s/it]
[INFO] Global step: 1576, Cumulative rewards: 39.72564, Runtime (s): 3122.86
------------------------------------------------------------
 
graph: 197, nodes: 197, edges: 582
[INFO] model update: t: 1577, loss: 229956.34375
[INFO] Global_t: 1577, Episode_t: 1, Action: 3, Reward: 6.78, Epsilon: 0.01
[INFO] model update: t: 1578, loss: 59883.11328125
[INFO] Global_t: 1578, Episode_t: 2, Action: 0, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 1579, loss: 42357.9609375
[INFO] Global_t: 1579, Episode_t: 3, Action: 5, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1580, loss: 172345.9375
[INFO] Global_t: 1580, Episode_t: 4, Action: 8, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 1581, loss: 156303.78125
[INFO] Global_t: 1581, Episode_t: 5, Action: 2, Reward: 4.29, Epsilon: 0.01
[INFO] model update: t: 1582, loss: 38605.65234375
[INFO] Global_t: 1582, Episode_t: 6, Action: 4, Reward: 5.49, Epsilon: 0.01
[INFO] model update: t: 1583, loss: 21036.333984375
[INFO] Global_t: 1583, Episode_t: 7, Action: 9, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1584, loss: 49116.4375
[INFO] Global_t: 1584, Episode_t: 8, Action: 10, Reward: 3.82, Epsilon: 0.01
 79%|███████▉  | 1584/2000 [52:08<12:42,  1.83s/it]
[INFO] Global step: 1584, Cumulative rewards: 38.893319999999996, Runtime (s): 3128.07
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.33256459236145
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.580915451049805
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0133161544799805
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.82809042930603
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.057048559188843
average cummulative reward vector is:  [0.15058132 0.12979444 0.14814863 0.13694603 0.14607876]
average cummulative reward is:  0.14230983711838857
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 198, nodes: 187, edges: 552
[INFO] model update: t: 1585, loss: 46810.5234375
[INFO] Global_t: 1585, Episode_t: 1, Action: 4, Reward: 7.76, Epsilon: 0.01
[INFO] model update: t: 1586, loss: 18618.359375
[INFO] Global_t: 1586, Episode_t: 2, Action: 0, Reward: 6.07, Epsilon: 0.01
[INFO] model update: t: 1587, loss: 27361.001953125
[INFO] Global_t: 1587, Episode_t: 3, Action: 1, Reward: 5.34, Epsilon: 0.01
[INFO] model update: t: 1588, loss: 10657.623046875
[INFO] Global_t: 1588, Episode_t: 4, Action: 3, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 1589, loss: 13528.21484375
[INFO] Global_t: 1589, Episode_t: 5, Action: 7, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1590, loss: 5988.8251953125
[INFO] Global_t: 1590, Episode_t: 6, Action: 5, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1591, loss: 20684.20703125
[INFO] Global_t: 1591, Episode_t: 7, Action: 16, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1592, loss: 30868.912109375
[INFO] Global_t: 1592, Episode_t: 8, Action: 11, Reward: 3.22, Epsilon: 0.01
 80%|███████▉  | 1592/2000 [52:36<16:04,  2.36s/it]
[INFO] Global step: 1592, Cumulative rewards: 38.75099999999999, Runtime (s): 3156.90
------------------------------------------------------------
 
graph: 199, nodes: 216, edges: 638
[INFO] model update: t: 1593, loss: 81362.6484375
[INFO] Global_t: 1593, Episode_t: 1, Action: 1, Reward: 7.73, Epsilon: 0.01
[INFO] model update: t: 1594, loss: 94850.7890625
[INFO] Global_t: 1594, Episode_t: 2, Action: 40, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1595, loss: 100731.25
[INFO] Global_t: 1595, Episode_t: 3, Action: 4, Reward: 5.52, Epsilon: 0.01
[INFO] model update: t: 1596, loss: 70071.5390625
[INFO] Global_t: 1596, Episode_t: 4, Action: 3, Reward: 5.27, Epsilon: 0.01
[INFO] model update: t: 1597, loss: 14575.880859375
[INFO] Global_t: 1597, Episode_t: 5, Action: 2, Reward: 5.61, Epsilon: 0.01
[INFO] model update: t: 1598, loss: 49283.9453125
[INFO] Global_t: 1598, Episode_t: 6, Action: 10, Reward: 4.99, Epsilon: 0.01
[INFO] model update: t: 1599, loss: 241801.8125
[INFO] Global_t: 1599, Episode_t: 7, Action: 6, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1600, loss: 336724.0625
[INFO] Global_t: 1600, Episode_t: 8, Action: 8, Reward: 4.23, Epsilon: 0.01
 80%|████████  | 1600/2000 [52:42<12:24,  1.86s/it]
[INFO] Global step: 1600, Cumulative rewards: 40.221120000000006, Runtime (s): 3162.38
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.436802864074707
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.230437278747559
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.628297805786133
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.773996353149414
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.122472047805786
average cummulative reward vector is:  [0.14686158 0.13000671 0.13430328 0.13793668 0.13925726]
average cummulative reward is:  0.13767310218127257
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  1
graph: 0, nodes: 180, edges: 531
[INFO] model update: t: 1601, loss: 430648.4375
[INFO] Global_t: 1601, Episode_t: 1, Action: 2, Reward: 5.43, Epsilon: 0.01
[INFO] model update: t: 1602, loss: 371455.625
[INFO] Global_t: 1602, Episode_t: 2, Action: 3, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 1603, loss: 173538.515625
[INFO] Global_t: 1603, Episode_t: 3, Action: 1, Reward: 5.92, Epsilon: 0.01
[INFO] model update: t: 1604, loss: 19873.669921875
[INFO] Global_t: 1604, Episode_t: 4, Action: 7, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1605, loss: 231951.28125
[INFO] Global_t: 1605, Episode_t: 5, Action: 5, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1606, loss: 191010.484375
[INFO] Global_t: 1606, Episode_t: 6, Action: 12, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1607, loss: 69087.0625
[INFO] Global_t: 1607, Episode_t: 7, Action: 9, Reward: 4.31, Epsilon: 0.01
[INFO] model update: t: 1608, loss: 14739.9951171875
[INFO] Global_t: 1608, Episode_t: 8, Action: 8, Reward: 3.98, Epsilon: 0.01
 80%|████████  | 1608/2000 [53:08<14:56,  2.29s/it]
[INFO] Global step: 1608, Cumulative rewards: 37.59648, Runtime (s): 3188.64
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] model update: t: 1609, loss: 30778.880859375
[INFO] Global_t: 1609, Episode_t: 1, Action: 3, Reward: 8.07, Epsilon: 0.01
[INFO] model update: t: 1610, loss: 15847.22265625
[INFO] Global_t: 1610, Episode_t: 2, Action: 1, Reward: 6.45, Epsilon: 0.01
[INFO] model update: t: 1611, loss: 8683.814453125
[INFO] Global_t: 1611, Episode_t: 3, Action: 4, Reward: 5.68, Epsilon: 0.01
[INFO] model update: t: 1612, loss: 19644.466796875
[INFO] Global_t: 1612, Episode_t: 4, Action: 155, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 1613, loss: 12323.951171875
[INFO] Global_t: 1613, Episode_t: 5, Action: 5, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1614, loss: 9018.6865234375
[INFO] Global_t: 1614, Episode_t: 6, Action: 0, Reward: 6.57, Epsilon: 0.01
[INFO] model update: t: 1615, loss: 16300.263671875
[INFO] Global_t: 1615, Episode_t: 7, Action: 12, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1616, loss: 9556.541015625
[INFO] Global_t: 1616, Episode_t: 8, Action: 8, Reward: 3.47, Epsilon: 0.01
 81%|████████  | 1616/2000 [53:14<11:37,  1.82s/it]
[INFO] Global step: 1616, Cumulative rewards: 39.80615999999999, Runtime (s): 3194.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.638043165206909
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.240964651107788
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.028301239013672
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.92877721786499
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.25193977355957
average cummulative reward vector is:  [0.14824868 0.13067685 0.14665656 0.13914743 0.14599409]
average cummulative reward is:  0.14214472187349494
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] model update: t: 1617, loss: 13617.4052734375
[INFO] Global_t: 1617, Episode_t: 1, Action: 7, Reward: 7.32, Epsilon: 0.01
[INFO] model update: t: 1618, loss: 23902.720703125
[INFO] Global_t: 1618, Episode_t: 2, Action: 2, Reward: 6.99, Epsilon: 0.01
[INFO] model update: t: 1619, loss: 12087.0146484375
[INFO] Global_t: 1619, Episode_t: 3, Action: 4, Reward: 6.49, Epsilon: 0.01
[INFO] model update: t: 1620, loss: 34166.984375
[INFO] Global_t: 1620, Episode_t: 4, Action: 1, Reward: 8.09, Epsilon: 0.01
[INFO] model update: t: 1621, loss: 87485.0703125
[INFO] Global_t: 1621, Episode_t: 5, Action: 3, Reward: 7.83, Epsilon: 0.01
[INFO] model update: t: 1622, loss: 136721.3125
[INFO] Global_t: 1622, Episode_t: 6, Action: 15, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1623, loss: 179511.84375
[INFO] Global_t: 1623, Episode_t: 7, Action: 10, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1624, loss: 39250.12109375
[INFO] Global_t: 1624, Episode_t: 8, Action: 6, Reward: 3.91, Epsilon: 0.01
 81%|████████  | 1624/2000 [53:42<14:40,  2.34s/it]
[INFO] Global step: 1624, Cumulative rewards: 49.82664, Runtime (s): 3222.88
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] model update: t: 1625, loss: 63562.44140625
[INFO] Global_t: 1625, Episode_t: 1, Action: 3, Reward: 7.09, Epsilon: 0.01
[INFO] model update: t: 1626, loss: 267054.125
[INFO] Global_t: 1626, Episode_t: 2, Action: 6, Reward: 6.94, Epsilon: 0.01
[INFO] model update: t: 1627, loss: 312956.25
[INFO] Global_t: 1627, Episode_t: 3, Action: 4, Reward: 5.73, Epsilon: 0.01
[INFO] model update: t: 1628, loss: 123628.578125
[INFO] Global_t: 1628, Episode_t: 4, Action: 8, Reward: 7.09, Epsilon: 0.01
[INFO] model update: t: 1629, loss: 17845.974609375
[INFO] Global_t: 1629, Episode_t: 5, Action: 7, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 1630, loss: 23681.73046875
[INFO] Global_t: 1630, Episode_t: 6, Action: 1, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 1631, loss: 34243.91015625
[INFO] Global_t: 1631, Episode_t: 7, Action: 2, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1632, loss: 19923.2578125
[INFO] Global_t: 1632, Episode_t: 8, Action: 5, Reward: 3.61, Epsilon: 0.01
 82%|████████▏ | 1632/2000 [53:48<11:14,  1.83s/it]
[INFO] Global step: 1632, Cumulative rewards: 42.93228, Runtime (s): 3228.07
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.680821418762207
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.58043909072876
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.964279651641846
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.307631492614746
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.513439416885376
average cummulative reward vector is:  [0.14974474 0.13480972 0.15357377 0.13311332 0.15224597]
average cummulative reward is:  0.14469750301101514
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] model update: t: 1633, loss: 10279.7421875
[INFO] Global_t: 1633, Episode_t: 1, Action: 6, Reward: 6.02, Epsilon: 0.01
[INFO] model update: t: 1634, loss: 25257.958984375
[INFO] Global_t: 1634, Episode_t: 2, Action: 0, Reward: 5.30, Epsilon: 0.01
[INFO] model update: t: 1635, loss: 28355.705078125
[INFO] Global_t: 1635, Episode_t: 3, Action: 5, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1636, loss: 22276.212890625
[INFO] Global_t: 1636, Episode_t: 4, Action: 3, Reward: 6.03, Epsilon: 0.01
[INFO] model update: t: 1637, loss: 60647.0859375
[INFO] Global_t: 1637, Episode_t: 5, Action: 7, Reward: 4.34, Epsilon: 0.01
[INFO] model update: t: 1638, loss: 139159.78125
[INFO] Global_t: 1638, Episode_t: 6, Action: 8, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1639, loss: 80607.265625
[INFO] Global_t: 1639, Episode_t: 7, Action: 9, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1640, loss: 18568.35546875
[INFO] Global_t: 1640, Episode_t: 8, Action: 10, Reward: 3.56, Epsilon: 0.01
 82%|████████▏ | 1640/2000 [54:15<13:57,  2.33s/it]
[INFO] Global step: 1640, Cumulative rewards: 38.386799999999994, Runtime (s): 3255.88
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] model update: t: 1641, loss: 17140.7890625
[INFO] Global_t: 1641, Episode_t: 1, Action: 4, Reward: 7.52, Epsilon: 0.01
[INFO] model update: t: 1642, loss: 30860.650390625
[INFO] Global_t: 1642, Episode_t: 2, Action: 1, Reward: 6.73, Epsilon: 0.01
[INFO] model update: t: 1643, loss: 10329.8505859375
[INFO] Global_t: 1643, Episode_t: 3, Action: 0, Reward: 5.60, Epsilon: 0.01
[INFO] model update: t: 1644, loss: 44043.79296875
[INFO] Global_t: 1644, Episode_t: 4, Action: 9, Reward: 6.52, Epsilon: 0.01
[INFO] model update: t: 1645, loss: 108583.609375
[INFO] Global_t: 1645, Episode_t: 5, Action: 6, Reward: 4.34, Epsilon: 0.01
[INFO] model update: t: 1646, loss: 55441.42578125
[INFO] Global_t: 1646, Episode_t: 6, Action: 8, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1647, loss: 19417.7578125
[INFO] Global_t: 1647, Episode_t: 7, Action: 3, Reward: 5.28, Epsilon: 0.01
[INFO] model update: t: 1648, loss: 142818.078125
[INFO] Global_t: 1648, Episode_t: 8, Action: 2, Reward: 4.19, Epsilon: 0.01
 82%|████████▏ | 1648/2000 [54:22<10:54,  1.86s/it]
[INFO] Global step: 1648, Cumulative rewards: 44.81868, Runtime (s): 3262.01
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.889796018600464
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.1999547481536865
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.243181467056274
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.316055536270142
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.4754719734191895
average cummulative reward vector is:  [0.13422211 0.12369329 0.14662432 0.13215537 0.14392339]
average cummulative reward is:  0.1361236940337271
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 1649, loss: 169230.46875
[INFO] Global_t: 1649, Episode_t: 1, Action: 4, Reward: 6.96, Epsilon: 0.01
[INFO] model update: t: 1650, loss: 117255.15625
[INFO] Global_t: 1650, Episode_t: 2, Action: 2, Reward: 5.03, Epsilon: 0.01
[INFO] model update: t: 1651, loss: 65661.671875
[INFO] Global_t: 1651, Episode_t: 3, Action: 5, Reward: 4.93, Epsilon: 0.01
[INFO] model update: t: 1652, loss: 25196.390625
[INFO] Global_t: 1652, Episode_t: 4, Action: 3, Reward: 7.37, Epsilon: 0.01
[INFO] model update: t: 1653, loss: 10549.962890625
[INFO] Global_t: 1653, Episode_t: 5, Action: 13, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1654, loss: 9964.5263671875
[INFO] Global_t: 1654, Episode_t: 6, Action: 0, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1655, loss: 24395.875
[INFO] Global_t: 1655, Episode_t: 7, Action: 11, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1656, loss: 48498.40234375
[INFO] Global_t: 1656, Episode_t: 8, Action: 17, Reward: 4.06, Epsilon: 0.01
 83%|████████▎ | 1656/2000 [54:48<13:05,  2.28s/it]
[INFO] Global step: 1656, Cumulative rewards: 39.35291999999999, Runtime (s): 3288.18
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 1657, loss: 61830.7734375
[INFO] Global_t: 1657, Episode_t: 1, Action: 8, Reward: 5.64, Epsilon: 0.01
[INFO] model update: t: 1658, loss: 33972.02734375
[INFO] Global_t: 1658, Episode_t: 2, Action: 5, Reward: 6.17, Epsilon: 0.01
[INFO] model update: t: 1659, loss: 13016.142578125
[INFO] Global_t: 1659, Episode_t: 3, Action: 0, Reward: 5.75, Epsilon: 0.01
[INFO] model update: t: 1660, loss: 92932.71875
[INFO] Global_t: 1660, Episode_t: 4, Action: 3, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 1661, loss: 263198.46875
[INFO] Global_t: 1661, Episode_t: 5, Action: 14, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1662, loss: 487199.96875
[INFO] Global_t: 1662, Episode_t: 6, Action: 6, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1663, loss: 298389.03125
[INFO] Global_t: 1663, Episode_t: 7, Action: 4, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1664, loss: 13528.03515625
[INFO] Global_t: 1664, Episode_t: 8, Action: 10, Reward: 2.97, Epsilon: 0.01
 83%|████████▎ | 1664/2000 [54:53<10:01,  1.79s/it]
[INFO] Global step: 1664, Cumulative rewards: 35.56872, Runtime (s): 3293.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.221279144287109
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.4349822998046875
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.632429361343384
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.51605486869812
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.203952074050903
average cummulative reward vector is:  [0.14415526 0.13133009 0.15119973 0.13906402 0.1415871 ]
average cummulative reward is:  0.14146723959844518
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 1665, loss: 430381.0
[INFO] Global_t: 1665, Episode_t: 1, Action: 1, Reward: 6.30, Epsilon: 0.01
[INFO] model update: t: 1666, loss: 933877.9375
[INFO] Global_t: 1666, Episode_t: 2, Action: 0, Reward: 5.60, Epsilon: 0.01
[INFO] model update: t: 1667, loss: 278257.0
[INFO] Global_t: 1667, Episode_t: 3, Action: 3, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 1668, loss: 15648.197265625
[INFO] Global_t: 1668, Episode_t: 4, Action: 8, Reward: 4.41, Epsilon: 0.01
[INFO] model update: t: 1669, loss: 210391.125
[INFO] Global_t: 1669, Episode_t: 5, Action: 4, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1670, loss: 67930.9765625
[INFO] Global_t: 1670, Episode_t: 6, Action: 9, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1671, loss: 25909.9921875
[INFO] Global_t: 1671, Episode_t: 7, Action: 10, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1672, loss: 129952.59375
[INFO] Global_t: 1672, Episode_t: 8, Action: 11, Reward: 2.87, Epsilon: 0.01
 84%|████████▎ | 1672/2000 [55:20<12:23,  2.27s/it]
[INFO] Global step: 1672, Cumulative rewards: 36.07907999999999, Runtime (s): 3320.33
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 1673, loss: 242974.09375
[INFO] Global_t: 1673, Episode_t: 1, Action: 3, Reward: 7.77, Epsilon: 0.01
[INFO] model update: t: 1674, loss: 431615.125
[INFO] Global_t: 1674, Episode_t: 2, Action: 2, Reward: 5.83, Epsilon: 0.01
[INFO] model update: t: 1675, loss: 508949.96875
[INFO] Global_t: 1675, Episode_t: 3, Action: 4, Reward: 6.14, Epsilon: 0.01
[INFO] model update: t: 1676, loss: 151401.8125
[INFO] Global_t: 1676, Episode_t: 4, Action: 6, Reward: 5.19, Epsilon: 0.01
[INFO] model update: t: 1677, loss: 21469.16015625
[INFO] Global_t: 1677, Episode_t: 5, Action: 5, Reward: 4.58, Epsilon: 0.01
[INFO] model update: t: 1678, loss: 318035.8125
[INFO] Global_t: 1678, Episode_t: 6, Action: 0, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1679, loss: 445850.90625
[INFO] Global_t: 1679, Episode_t: 7, Action: 8, Reward: 4.77, Epsilon: 0.01
[INFO] model update: t: 1680, loss: 162636.546875
[INFO] Global_t: 1680, Episode_t: 8, Action: 14, Reward: 3.74, Epsilon: 0.01
 84%|████████▍ | 1680/2000 [55:31<10:38,  1.99s/it]
[INFO] Global step: 1680, Cumulative rewards: 42.36576, Runtime (s): 3331.24
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.414957046508789
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.245662689208984
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.195859909057617
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.979291200637817
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.078911066055298
average cummulative reward vector is:  [0.13820263 0.12803519 0.15302404 0.13832874 0.14645161]
average cummulative reward is:  0.14080844234019246
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 1681, loss: 25707.88671875
[INFO] Global_t: 1681, Episode_t: 1, Action: 2, Reward: 5.41, Epsilon: 0.01
[INFO] model update: t: 1682, loss: 19444.4296875
[INFO] Global_t: 1682, Episode_t: 2, Action: 4, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1683, loss: 87044.0703125
[INFO] Global_t: 1683, Episode_t: 3, Action: 1, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1684, loss: 218395.34375
[INFO] Global_t: 1684, Episode_t: 4, Action: 9, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1685, loss: 220849.5
[INFO] Global_t: 1685, Episode_t: 5, Action: 3, Reward: 3.39, Epsilon: 0.01
[INFO] model update: t: 1686, loss: 24243.890625
[INFO] Global_t: 1686, Episode_t: 6, Action: 8, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1687, loss: 164696.0625
[INFO] Global_t: 1687, Episode_t: 7, Action: 16, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1688, loss: 762741.625
[INFO] Global_t: 1688, Episode_t: 8, Action: 27, Reward: 3.48, Epsilon: 0.01
 84%|████████▍ | 1688/2000 [55:58<12:40,  2.44s/it]
[INFO] Global step: 1688, Cumulative rewards: 32.49252, Runtime (s): 3358.99
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 1689, loss: 1086094.25
[INFO] Global_t: 1689, Episode_t: 1, Action: 4, Reward: 6.28, Epsilon: 0.01
[INFO] model update: t: 1690, loss: 236477.890625
[INFO] Global_t: 1690, Episode_t: 2, Action: 3, Reward: 6.49, Epsilon: 0.01
[INFO] model update: t: 1691, loss: 164468.5
[INFO] Global_t: 1691, Episode_t: 3, Action: 1, Reward: 5.73, Epsilon: 0.01
[INFO] model update: t: 1692, loss: 970617.5625
[INFO] Global_t: 1692, Episode_t: 4, Action: 2, Reward: 4.77, Epsilon: 0.01
[INFO] model update: t: 1693, loss: 1689982.75
[INFO] Global_t: 1693, Episode_t: 5, Action: 9, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1694, loss: 515789.75
[INFO] Global_t: 1694, Episode_t: 6, Action: 10, Reward: 4.34, Epsilon: 0.01
[INFO] model update: t: 1695, loss: 119074.5859375
[INFO] Global_t: 1695, Episode_t: 7, Action: 7, Reward: 4.08, Epsilon: 0.01
 85%|████████▍ | 1696/2000 [56:19<12:30,  2.47s/it][INFO] model update: t: 1696, loss: 1134173.625
[INFO] Global_t: 1696, Episode_t: 8, Action: 6, Reward: 4.03, Epsilon: 0.01

[INFO] Global step: 1696, Cumulative rewards: 39.94524, Runtime (s): 3379.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.473881721496582
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.9151365756988525
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.07050085067749
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.512196063995361
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.752084732055664
average cummulative reward vector is:  [0.14302211 0.13477176 0.14729918 0.13763435 0.15136129]
average cummulative reward is:  0.14281773619345184
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 1697, loss: 1050182.25
[INFO] Global_t: 1697, Episode_t: 1, Action: 2, Reward: 6.73, Epsilon: 0.01
[INFO] model update: t: 1698, loss: 462879.4375
[INFO] Global_t: 1698, Episode_t: 2, Action: 0, Reward: 5.99, Epsilon: 0.01
[INFO] model update: t: 1699, loss: 8390.857421875
[INFO] Global_t: 1699, Episode_t: 3, Action: 3, Reward: 5.93, Epsilon: 0.01
[INFO] model update: t: 1700, loss: 262196.75
[INFO] Global_t: 1700, Episode_t: 4, Action: 1, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1701, loss: 719797.4375
[INFO] Global_t: 1701, Episode_t: 5, Action: 9, Reward: 4.41, Epsilon: 0.01
[INFO] model update: t: 1702, loss: 818991.125
[INFO] Global_t: 1702, Episode_t: 6, Action: 6, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1703, loss: 482310.125
[INFO] Global_t: 1703, Episode_t: 7, Action: 4, Reward: 3.60, Epsilon: 0.01
 85%|████████▌ | 1704/2000 [56:55<15:13,  3.09s/it][INFO] model update: t: 1704, loss: 23193.142578125
[INFO] Global_t: 1704, Episode_t: 8, Action: 10, Reward: 5.32, Epsilon: 0.01

[INFO] Global step: 1704, Cumulative rewards: 40.783319999999996, Runtime (s): 3415.53
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 1705, loss: 268510.71875
[INFO] Global_t: 1705, Episode_t: 1, Action: 4, Reward: 6.56, Epsilon: 0.01
[INFO] model update: t: 1706, loss: 741182.375
[INFO] Global_t: 1706, Episode_t: 2, Action: 2, Reward: 5.86, Epsilon: 0.01
[INFO] model update: t: 1707, loss: 923640.625
[INFO] Global_t: 1707, Episode_t: 3, Action: 0, Reward: 5.31, Epsilon: 0.01
[INFO] model update: t: 1708, loss: 494290.78125
[INFO] Global_t: 1708, Episode_t: 4, Action: 3, Reward: 6.00, Epsilon: 0.01
[INFO] model update: t: 1709, loss: 204773.9375
[INFO] Global_t: 1709, Episode_t: 5, Action: 7, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1710, loss: 15249.392578125
[INFO] Global_t: 1710, Episode_t: 6, Action: 1, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1711, loss: 136887.46875
[INFO] Global_t: 1711, Episode_t: 7, Action: 5, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1712, loss: 487601.75
[INFO] Global_t: 1712, Episode_t: 8, Action: 11, Reward: 4.45, Epsilon: 0.01
 86%|████████▌ | 1712/2000 [57:09<12:50,  2.68s/it]
[INFO] Global step: 1712, Cumulative rewards: 41.01744000000001, Runtime (s): 3429.27
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.747317790985107
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.52800178527832
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.655058860778809
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.612191200256348
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.362756967544556
average cummulative reward vector is:  [0.14364421 0.13578611 0.15223661 0.1365278  0.14910484]
average cummulative reward is:  0.14345991522145599
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 1713, loss: 1069036.5
[INFO] Global_t: 1713, Episode_t: 1, Action: 2, Reward: 6.93, Epsilon: 0.01
[INFO] model update: t: 1714, loss: 2393653.0
[INFO] Global_t: 1714, Episode_t: 2, Action: 3, Reward: 5.97, Epsilon: 0.01
[INFO] model update: t: 1715, loss: 3098393.5
[INFO] Global_t: 1715, Episode_t: 3, Action: 4, Reward: 5.78, Epsilon: 0.01
[INFO] model update: t: 1716, loss: 1360758.125
[INFO] Global_t: 1716, Episode_t: 4, Action: 8, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1717, loss: 52067.2265625
[INFO] Global_t: 1717, Episode_t: 5, Action: 7, Reward: 4.28, Epsilon: 0.01
[INFO] model update: t: 1718, loss: 786745.5
[INFO] Global_t: 1718, Episode_t: 6, Action: 13, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1719, loss: 1932536.75
[INFO] Global_t: 1719, Episode_t: 7, Action: 11, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1720, loss: 1748009.75
[INFO] Global_t: 1720, Episode_t: 8, Action: 9, Reward: 3.77, Epsilon: 0.01
 86%|████████▌ | 1720/2000 [57:37<13:38,  2.92s/it]
[INFO] Global step: 1720, Cumulative rewards: 39.75419999999999, Runtime (s): 3457.31
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 1721, loss: 759688.375
[INFO] Global_t: 1721, Episode_t: 1, Action: 2, Reward: 6.10, Epsilon: 0.01
[INFO] model update: t: 1722, loss: 30769.84375
[INFO] Global_t: 1722, Episode_t: 2, Action: 4, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 1723, loss: 350324.5625
[INFO] Global_t: 1723, Episode_t: 3, Action: 3, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1724, loss: 1054513.25
[INFO] Global_t: 1724, Episode_t: 4, Action: 5, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1725, loss: 637496.375
[INFO] Global_t: 1725, Episode_t: 5, Action: 16, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 1726, loss: 193561.6875
[INFO] Global_t: 1726, Episode_t: 6, Action: 14, Reward: 1.75, Epsilon: 0.01
[INFO] model update: t: 1727, loss: 24642.61328125
[INFO] Global_t: 1727, Episode_t: 7, Action: 7, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1728, loss: 184635.65625
[INFO] Global_t: 1728, Episode_t: 8, Action: 1, Reward: 3.17, Epsilon: 0.01
 86%|████████▋ | 1728/2000 [57:43<10:19,  2.28s/it]
[INFO] Global step: 1728, Cumulative rewards: 32.73156, Runtime (s): 3463.45
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.296154022216797
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.559125185012817
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.136481285095215
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.224898815155029
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.411823272705078
average cummulative reward vector is:  [0.14713026 0.13053565 0.15360546 0.13063294 0.147225  ]
average cummulative reward is:  0.14182586394243019
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 1729, loss: 233361.65625
[INFO] Global_t: 1729, Episode_t: 1, Action: 5, Reward: 6.97, Epsilon: 0.01
[INFO] model update: t: 1730, loss: 129399.7109375
[INFO] Global_t: 1730, Episode_t: 2, Action: 0, Reward: 7.83, Epsilon: 0.01
[INFO] model update: t: 1731, loss: 70072.96875
[INFO] Global_t: 1731, Episode_t: 3, Action: 1, Reward: 7.54, Epsilon: 0.01
[INFO] model update: t: 1732, loss: 39222.6328125
[INFO] Global_t: 1732, Episode_t: 4, Action: 4, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1733, loss: 14045.912109375
[INFO] Global_t: 1733, Episode_t: 5, Action: 3, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1734, loss: 15819.392578125
[INFO] Global_t: 1734, Episode_t: 6, Action: 8, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 1735, loss: 32059.97265625
[INFO] Global_t: 1735, Episode_t: 7, Action: 18, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 1736, loss: 81845.265625
[INFO] Global_t: 1736, Episode_t: 8, Action: 23, Reward: 3.63, Epsilon: 0.01
 87%|████████▋ | 1736/2000 [58:10<11:27,  2.61s/it]
[INFO] Global step: 1736, Cumulative rewards: 41.15867999999999, Runtime (s): 3490.42
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 1737, loss: 135832.125
[INFO] Global_t: 1737, Episode_t: 1, Action: 7, Reward: 5.30, Epsilon: 0.01
[INFO] model update: t: 1738, loss: 185695.421875
[INFO] Global_t: 1738, Episode_t: 2, Action: 4, Reward: 4.82, Epsilon: 0.01
[INFO] model update: t: 1739, loss: 229150.21875
[INFO] Global_t: 1739, Episode_t: 3, Action: 1, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1740, loss: 259803.875
[INFO] Global_t: 1740, Episode_t: 4, Action: 5, Reward: 4.78, Epsilon: 0.01
[INFO] model update: t: 1741, loss: 73819.5625
[INFO] Global_t: 1741, Episode_t: 5, Action: 15, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1742, loss: 64247.7109375
[INFO] Global_t: 1742, Episode_t: 6, Action: 6, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1743, loss: 201529.59375
[INFO] Global_t: 1743, Episode_t: 7, Action: 8, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1744, loss: 145934.0
[INFO] Global_t: 1744, Episode_t: 8, Action: 0, Reward: 3.85, Epsilon: 0.01
 87%|████████▋ | 1744/2000 [58:31<11:04,  2.60s/it]
[INFO] Global step: 1744, Cumulative rewards: 34.65444, Runtime (s): 3511.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.891493797302246
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.387264728546143
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8414883613586426
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.782531976699829
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.218066692352295
average cummulative reward vector is:  [0.14380789 0.13501273 0.14243443 0.13931589 0.15049274]
average cummulative reward is:  0.1422127364467566
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 1745, loss: 56283.45703125
[INFO] Global_t: 1745, Episode_t: 1, Action: 2, Reward: 6.17, Epsilon: 0.01
[INFO] model update: t: 1746, loss: 54272.02734375
[INFO] Global_t: 1746, Episode_t: 2, Action: 3, Reward: 8.88, Epsilon: 0.01
[INFO] model update: t: 1747, loss: 340002.8125
[INFO] Global_t: 1747, Episode_t: 3, Action: 5, Reward: 5.45, Epsilon: 0.01
[INFO] model update: t: 1748, loss: 742050.3125
[INFO] Global_t: 1748, Episode_t: 4, Action: 9, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1749, loss: 421933.8125
[INFO] Global_t: 1749, Episode_t: 5, Action: 6, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1750, loss: 41924.640625
[INFO] Global_t: 1750, Episode_t: 6, Action: 4, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1751, loss: 100027.8359375
[INFO] Global_t: 1751, Episode_t: 7, Action: 84, Reward: 1.31, Epsilon: 0.01
[INFO] model update: t: 1752, loss: 393632.40625
[INFO] Global_t: 1752, Episode_t: 8, Action: 20, Reward: 4.04, Epsilon: 0.01
 88%|████████▊ | 1752/2000 [59:01<12:16,  2.97s/it]
[INFO] Global step: 1752, Cumulative rewards: 38.7138, Runtime (s): 3541.73
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 1753, loss: 553305.1875
[INFO] Global_t: 1753, Episode_t: 1, Action: 3, Reward: 8.30, Epsilon: 0.01
[INFO] model update: t: 1754, loss: 471069.34375
[INFO] Global_t: 1754, Episode_t: 2, Action: 2, Reward: 6.30, Epsilon: 0.01
[INFO] model update: t: 1755, loss: 369053.75
[INFO] Global_t: 1755, Episode_t: 3, Action: 6, Reward: 6.91, Epsilon: 0.01
[INFO] model update: t: 1756, loss: 291238.8125
[INFO] Global_t: 1756, Episode_t: 4, Action: 7, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1757, loss: 76580.4296875
[INFO] Global_t: 1757, Episode_t: 5, Action: 8, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 1758, loss: 22418.103515625
[INFO] Global_t: 1758, Episode_t: 6, Action: 4, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1759, loss: 30386.14453125
[INFO] Global_t: 1759, Episode_t: 7, Action: 1, Reward: 4.99, Epsilon: 0.01
[INFO] model update: t: 1760, loss: 25093.171875
[INFO] Global_t: 1760, Episode_t: 8, Action: 10, Reward: 3.90, Epsilon: 0.01
 88%|████████▊ | 1760/2000 [59:07<09:12,  2.30s/it]
[INFO] Global step: 1760, Cumulative rewards: 42.862919999999995, Runtime (s): 3547.68
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.34562611579895
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.505803346633911
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0689780712127686
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.130594968795776
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.542630910873413
average cummulative reward vector is:  [0.15345263 0.12911528 0.15349016 0.12668692 0.1436664 ]
average cummulative reward is:  0.14128227740569285
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 1761, loss: 39816.8515625
[INFO] Global_t: 1761, Episode_t: 1, Action: 3, Reward: 6.30, Epsilon: 0.01
[INFO] model update: t: 1762, loss: 85134.7109375
[INFO] Global_t: 1762, Episode_t: 2, Action: 2, Reward: 6.74, Epsilon: 0.01
[INFO] model update: t: 1763, loss: 143962.78125
[INFO] Global_t: 1763, Episode_t: 3, Action: 4, Reward: 7.42, Epsilon: 0.01
[INFO] model update: t: 1764, loss: 131337.046875
[INFO] Global_t: 1764, Episode_t: 4, Action: 1, Reward: 5.67, Epsilon: 0.01
[INFO] model update: t: 1765, loss: 66137.1328125
[INFO] Global_t: 1765, Episode_t: 5, Action: 5, Reward: 5.08, Epsilon: 0.01
[INFO] model update: t: 1766, loss: 12712.248046875
[INFO] Global_t: 1766, Episode_t: 6, Action: 8, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1767, loss: 194926.75
[INFO] Global_t: 1767, Episode_t: 7, Action: 17, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1768, loss: 432111.0625
[INFO] Global_t: 1768, Episode_t: 8, Action: 6, Reward: 4.65, Epsilon: 0.01
 88%|████████▊ | 1768/2000 [59:40<10:55,  2.82s/it]
[INFO] Global step: 1768, Cumulative rewards: 44.94, Runtime (s): 3580.04
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 1769, loss: 430570.5625
[INFO] Global_t: 1769, Episode_t: 1, Action: 3, Reward: 6.50, Epsilon: 0.01
[INFO] model update: t: 1770, loss: 48154.1015625
[INFO] Global_t: 1770, Episode_t: 2, Action: 4, Reward: 5.49, Epsilon: 0.01
[INFO] model update: t: 1771, loss: 145554.9375
[INFO] Global_t: 1771, Episode_t: 3, Action: 1, Reward: 4.97, Epsilon: 0.01
[INFO] model update: t: 1772, loss: 561959.375
[INFO] Global_t: 1772, Episode_t: 4, Action: 10, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 1773, loss: 791138.5
[INFO] Global_t: 1773, Episode_t: 5, Action: 7, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 1774, loss: 436998.25
[INFO] Global_t: 1774, Episode_t: 6, Action: 15, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1775, loss: 18897.048828125
[INFO] Global_t: 1775, Episode_t: 7, Action: 5, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 1776, loss: 334562.71875
[INFO] Global_t: 1776, Episode_t: 8, Action: 8, Reward: 3.11, Epsilon: 0.01
 89%|████████▉ | 1776/2000 [59:45<08:05,  2.17s/it]
[INFO] Global step: 1776, Cumulative rewards: 35.39688, Runtime (s): 3585.13
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.318414688110352
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.410414457321167
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.342763423919678
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.650518178939819
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.382456541061401
average cummulative reward vector is:  [0.14303079 0.13535463 0.14915874 0.13792593 0.15779086]
average cummulative reward is:  0.14465219141344116
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 1777, loss: 1134635.75
[INFO] Global_t: 1777, Episode_t: 1, Action: 3, Reward: 7.41, Epsilon: 0.01
[INFO] model update: t: 1778, loss: 908975.3125
[INFO] Global_t: 1778, Episode_t: 2, Action: 0, Reward: 6.72, Epsilon: 0.01
[INFO] model update: t: 1779, loss: 407184.96875
[INFO] Global_t: 1779, Episode_t: 3, Action: 6, Reward: 5.60, Epsilon: 0.01
[INFO] model update: t: 1780, loss: 46314.015625
[INFO] Global_t: 1780, Episode_t: 4, Action: 5, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1781, loss: 185740.234375
[INFO] Global_t: 1781, Episode_t: 5, Action: 4, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1782, loss: 726065.125
[INFO] Global_t: 1782, Episode_t: 6, Action: 7, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1783, loss: 1111933.75
[INFO] Global_t: 1783, Episode_t: 7, Action: 8, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1784, loss: 677191.5
[INFO] Global_t: 1784, Episode_t: 8, Action: 13, Reward: 3.37, Epsilon: 0.01
 89%|████████▉ | 1784/2000 [1:00:18<10:00,  2.78s/it]
[INFO] Global step: 1784, Cumulative rewards: 39.89340000000001, Runtime (s): 3618.75
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 1785, loss: 159409.453125
[INFO] Global_t: 1785, Episode_t: 1, Action: 3, Reward: 6.66, Epsilon: 0.01
[INFO] model update: t: 1786, loss: 20369.81640625
[INFO] Global_t: 1786, Episode_t: 2, Action: 5, Reward: 6.21, Epsilon: 0.01
[INFO] model update: t: 1787, loss: 273646.75
[INFO] Global_t: 1787, Episode_t: 3, Action: 4, Reward: 6.87, Epsilon: 0.01
[INFO] model update: t: 1788, loss: 496362.375
[INFO] Global_t: 1788, Episode_t: 4, Action: 2, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 1789, loss: 541998.3125
[INFO] Global_t: 1789, Episode_t: 5, Action: 1, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 1790, loss: 366733.0
[INFO] Global_t: 1790, Episode_t: 6, Action: 8, Reward: 5.65, Epsilon: 0.01
[INFO] model update: t: 1791, loss: 365884.03125
[INFO] Global_t: 1791, Episode_t: 7, Action: 0, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1792, loss: 487004.21875
[INFO] Global_t: 1792, Episode_t: 8, Action: 13, Reward: 3.87, Epsilon: 0.01
 90%|████████▉ | 1792/2000 [1:00:25<07:40,  2.21s/it]
[INFO] Global step: 1792, Cumulative rewards: 43.70604, Runtime (s): 3625.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.391079902648926
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.202145338058472
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.145499229431152
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.61228609085083
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.251197814941406
average cummulative reward vector is:  [0.14671868 0.13036296 0.15403279 0.13083738 0.1495164 ]
average cummulative reward is:  0.14229364301715353
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 1793, loss: 873410.0625
[INFO] Global_t: 1793, Episode_t: 1, Action: 5, Reward: 6.84, Epsilon: 0.01
[INFO] model update: t: 1794, loss: 1908853.5
[INFO] Global_t: 1794, Episode_t: 2, Action: 2, Reward: 5.87, Epsilon: 0.01
[INFO] model update: t: 1795, loss: 2413763.0
[INFO] Global_t: 1795, Episode_t: 3, Action: 7, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1796, loss: 435221.0625
[INFO] Global_t: 1796, Episode_t: 4, Action: 3, Reward: 4.58, Epsilon: 0.01
[INFO] model update: t: 1797, loss: 225110.625
[INFO] Global_t: 1797, Episode_t: 5, Action: 4, Reward: 4.84, Epsilon: 0.01
[INFO] model update: t: 1798, loss: 1988183.5
[INFO] Global_t: 1798, Episode_t: 6, Action: 124, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1799, loss: 3943256.25
[INFO] Global_t: 1799, Episode_t: 7, Action: 10, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1800, loss: 2949041.5
[INFO] Global_t: 1800, Episode_t: 8, Action: 11, Reward: 3.77, Epsilon: 0.01
 90%|█████████ | 1800/2000 [1:00:53<08:35,  2.58s/it]
[INFO] Global step: 1800, Cumulative rewards: 35.91383999999999, Runtime (s): 3653.28
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 1801, loss: 305933.96875
[INFO] Global_t: 1801, Episode_t: 1, Action: 3, Reward: 6.75, Epsilon: 0.01
[INFO] model update: t: 1802, loss: 492815.21875
[INFO] Global_t: 1802, Episode_t: 2, Action: 1, Reward: 6.04, Epsilon: 0.01
[INFO] model update: t: 1803, loss: 2377416.0
[INFO] Global_t: 1803, Episode_t: 3, Action: 2, Reward: 4.99, Epsilon: 0.01
[INFO] model update: t: 1804, loss: 3497267.0
[INFO] Global_t: 1804, Episode_t: 4, Action: 4, Reward: 4.95, Epsilon: 0.01
[INFO] model update: t: 1805, loss: 2146370.5
[INFO] Global_t: 1805, Episode_t: 5, Action: 5, Reward: 6.03, Epsilon: 0.01
[INFO] model update: t: 1806, loss: 249704.25
[INFO] Global_t: 1806, Episode_t: 6, Action: 8, Reward: 4.30, Epsilon: 0.01
[INFO] model update: t: 1807, loss: 237592.78125
[INFO] Global_t: 1807, Episode_t: 7, Action: 6, Reward: 6.69, Epsilon: 0.01
[INFO] model update: t: 1808, loss: 849411.8125
[INFO] Global_t: 1808, Episode_t: 8, Action: 10, Reward: 4.25, Epsilon: 0.01
 90%|█████████ | 1808/2000 [1:00:58<06:23,  2.00s/it]
[INFO] Global step: 1808, Cumulative rewards: 44.00772, Runtime (s): 3658.51
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.554842948913574
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.327115058898926
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.487812280654907
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.160568952560425
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9922027587890625
average cummulative reward vector is:  [0.15079789 0.13357245 0.14861202 0.12953528 0.14706909]
average cummulative reward is:  0.14191734733876127
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 1809, loss: 774622.5
[INFO] Global_t: 1809, Episode_t: 1, Action: 3, Reward: 7.83, Epsilon: 0.01
[INFO] model update: t: 1810, loss: 638179.625
[INFO] Global_t: 1810, Episode_t: 2, Action: 4, Reward: 5.50, Epsilon: 0.01
[INFO] model update: t: 1811, loss: 700691.6875
[INFO] Global_t: 1811, Episode_t: 3, Action: 0, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1812, loss: 804994.75
[INFO] Global_t: 1812, Episode_t: 4, Action: 12, Reward: 5.01, Epsilon: 0.01
[INFO] model update: t: 1813, loss: 679647.125
[INFO] Global_t: 1813, Episode_t: 5, Action: 24, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1814, loss: 230972.5
[INFO] Global_t: 1814, Episode_t: 6, Action: 8, Reward: 3.73, Epsilon: 0.01
[INFO] model update: t: 1815, loss: 50894.90625
[INFO] Global_t: 1815, Episode_t: 7, Action: 1, Reward: 3.69, Epsilon: 0.01
[INFO] model update: t: 1816, loss: 10714.84765625
[INFO] Global_t: 1816, Episode_t: 8, Action: 11, Reward: 3.77, Epsilon: 0.01
 91%|█████████ | 1816/2000 [1:01:24<07:19,  2.39s/it]
[INFO] Global step: 1816, Cumulative rewards: 36.8712, Runtime (s): 3684.95
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 1817, loss: 77320.40625
[INFO] Global_t: 1817, Episode_t: 1, Action: 2, Reward: 6.18, Epsilon: 0.01
[INFO] model update: t: 1818, loss: 96969.015625
[INFO] Global_t: 1818, Episode_t: 2, Action: 3, Reward: 5.12, Epsilon: 0.01
[INFO] model update: t: 1819, loss: 130094.046875
[INFO] Global_t: 1819, Episode_t: 3, Action: 10, Reward: 4.84, Epsilon: 0.01
[INFO] model update: t: 1820, loss: 234558.25
[INFO] Global_t: 1820, Episode_t: 4, Action: 5, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1821, loss: 336178.4375
[INFO] Global_t: 1821, Episode_t: 5, Action: 4, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1822, loss: 388667.875
[INFO] Global_t: 1822, Episode_t: 6, Action: 1, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1823, loss: 292969.34375
[INFO] Global_t: 1823, Episode_t: 7, Action: 0, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 1824, loss: 44849.203125
[INFO] Global_t: 1824, Episode_t: 8, Action: 6, Reward: 3.74, Epsilon: 0.01
 91%|█████████ | 1824/2000 [1:01:29<05:24,  1.84s/it]
[INFO] Global step: 1824, Cumulative rewards: 36.20663999999999, Runtime (s): 3689.44
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.228587865829468
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.316230535507202
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.358257293701172
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.518167972564697
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9875190258026123
average cummulative reward vector is:  [0.14226895 0.13365463 0.14971858 0.14032874 0.14728871]
average cummulative reward is:  0.14265192084563996
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 1825, loss: 67547.375
[INFO] Global_t: 1825, Episode_t: 1, Action: 3, Reward: 7.03, Epsilon: 0.01
[INFO] model update: t: 1826, loss: 348629.0
[INFO] Global_t: 1826, Episode_t: 2, Action: 6, Reward: 6.21, Epsilon: 0.01
[INFO] model update: t: 1827, loss: 660132.125
[INFO] Global_t: 1827, Episode_t: 3, Action: 2, Reward: 5.05, Epsilon: 0.01
[INFO] model update: t: 1828, loss: 505254.375
[INFO] Global_t: 1828, Episode_t: 4, Action: 4, Reward: 4.85, Epsilon: 0.01
[INFO] model update: t: 1829, loss: 405015.125
[INFO] Global_t: 1829, Episode_t: 5, Action: 5, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1830, loss: 183248.09375
[INFO] Global_t: 1830, Episode_t: 6, Action: 1, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 1831, loss: 62335.87109375
[INFO] Global_t: 1831, Episode_t: 7, Action: 0, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 1832, loss: 11771.1220703125
[INFO] Global_t: 1832, Episode_t: 8, Action: 8, Reward: 3.53, Epsilon: 0.01
 92%|█████████▏| 1832/2000 [1:01:56<06:24,  2.29s/it]
[INFO] Global step: 1832, Cumulative rewards: 38.71812, Runtime (s): 3716.13
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 1833, loss: 60018.82421875
[INFO] Global_t: 1833, Episode_t: 1, Action: 1, Reward: 7.38, Epsilon: 0.01
[INFO] model update: t: 1834, loss: 68002.078125
[INFO] Global_t: 1834, Episode_t: 2, Action: 4, Reward: 6.49, Epsilon: 0.01
[INFO] model update: t: 1835, loss: 43521.0546875
[INFO] Global_t: 1835, Episode_t: 3, Action: 3, Reward: 6.37, Epsilon: 0.01
[INFO] model update: t: 1836, loss: 11652.623046875
[INFO] Global_t: 1836, Episode_t: 4, Action: 5, Reward: 5.15, Epsilon: 0.01
[INFO] model update: t: 1837, loss: 12113.669921875
[INFO] Global_t: 1837, Episode_t: 5, Action: 2, Reward: 6.61, Epsilon: 0.01
[INFO] model update: t: 1838, loss: 21874.1328125
[INFO] Global_t: 1838, Episode_t: 6, Action: 6, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1839, loss: 35055.77734375
[INFO] Global_t: 1839, Episode_t: 7, Action: 9, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1840, loss: 26822.310546875
[INFO] Global_t: 1840, Episode_t: 8, Action: 8, Reward: 3.28, Epsilon: 0.01
 92%|█████████▏| 1840/2000 [1:02:01<04:46,  1.79s/it]
[INFO] Global step: 1840, Cumulative rewards: 43.27296, Runtime (s): 3721.21
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.421057224273682
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.38586688041687
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.3055291175842285
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.99570631980896
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.101069211959839
average cummulative reward vector is:  [0.14989    0.13599491 0.14811093 0.12561846 0.15081774]
average cummulative reward is:  0.14208640724971305
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 1841, loss: 6230.12939453125
[INFO] Global_t: 1841, Episode_t: 1, Action: 1, Reward: 7.02, Epsilon: 0.01
[INFO] model update: t: 1842, loss: 20036.47265625
[INFO] Global_t: 1842, Episode_t: 2, Action: 5, Reward: 5.84, Epsilon: 0.01
[INFO] model update: t: 1843, loss: 84513.375
[INFO] Global_t: 1843, Episode_t: 3, Action: 3, Reward: 6.57, Epsilon: 0.01
[INFO] model update: t: 1844, loss: 251269.84375
[INFO] Global_t: 1844, Episode_t: 4, Action: 7, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 1845, loss: 509319.6875
[INFO] Global_t: 1845, Episode_t: 5, Action: 8, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1846, loss: 1122800.25
[INFO] Global_t: 1846, Episode_t: 6, Action: 16, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1847, loss: 1482320.125
[INFO] Global_t: 1847, Episode_t: 7, Action: 2, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1848, loss: 845331.875
[INFO] Global_t: 1848, Episode_t: 8, Action: 0, Reward: 5.02, Epsilon: 0.01
 92%|█████████▏| 1848/2000 [1:02:28<05:45,  2.27s/it]
[INFO] Global step: 1848, Cumulative rewards: 43.159679999999994, Runtime (s): 3748.27
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 1849, loss: 59109.734375
[INFO] Global_t: 1849, Episode_t: 1, Action: 4, Reward: 6.52, Epsilon: 0.01
[INFO] model update: t: 1850, loss: 233226.96875
[INFO] Global_t: 1850, Episode_t: 2, Action: 5, Reward: 5.21, Epsilon: 0.01
[INFO] model update: t: 1851, loss: 1052830.375
[INFO] Global_t: 1851, Episode_t: 3, Action: 6, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 1852, loss: 1831634.125
[INFO] Global_t: 1852, Episode_t: 4, Action: 10, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 1853, loss: 2509704.25
[INFO] Global_t: 1853, Episode_t: 5, Action: 0, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1854, loss: 582095.0625
[INFO] Global_t: 1854, Episode_t: 6, Action: 20, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 1855, loss: 24597.62109375
[INFO] Global_t: 1855, Episode_t: 7, Action: 3, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1856, loss: 841159.8125
[INFO] Global_t: 1856, Episode_t: 8, Action: 2, Reward: 5.52, Epsilon: 0.01

[INFO] Global step: 1856, Cumulative rewards: 39.704519999999995, Runtime (s): 3753.08
 93%|█████████▎| 1856/2000 [1:02:33<04:14,  1.77s/it]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.331738233566284
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.534312963485718
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.130927801132202
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.1555280685424805
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.068915605545044
average cummulative reward vector is:  [0.13813421 0.14046852 0.14236831 0.13243435 0.15009946]
average cummulative reward is:  0.14070096864314943
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 1857, loss: 2758380.75
[INFO] Global_t: 1857, Episode_t: 1, Action: 1, Reward: 6.73, Epsilon: 0.01
[INFO] model update: t: 1858, loss: 3675355.75
[INFO] Global_t: 1858, Episode_t: 2, Action: 3, Reward: 7.40, Epsilon: 0.01
[INFO] model update: t: 1859, loss: 2204147.0
[INFO] Global_t: 1859, Episode_t: 3, Action: 0, Reward: 5.33, Epsilon: 0.01
[INFO] model update: t: 1860, loss: 1584570.875
[INFO] Global_t: 1860, Episode_t: 4, Action: 4, Reward: 5.62, Epsilon: 0.01
[INFO] model update: t: 1861, loss: 2222295.5
[INFO] Global_t: 1861, Episode_t: 5, Action: 2, Reward: 6.34, Epsilon: 0.01
[INFO] model update: t: 1862, loss: 3461261.0
[INFO] Global_t: 1862, Episode_t: 6, Action: 10, Reward: 4.27, Epsilon: 0.01
[INFO] model update: t: 1863, loss: 4215445.5
[INFO] Global_t: 1863, Episode_t: 7, Action: 5, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1864, loss: 2617587.25
[INFO] Global_t: 1864, Episode_t: 8, Action: 9, Reward: 3.67, Epsilon: 0.01
 93%|█████████▎| 1864/2000 [1:03:00<05:07,  2.26s/it]
[INFO] Global step: 1864, Cumulative rewards: 43.25544, Runtime (s): 3780.32
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 1865, loss: 546833.0
[INFO] Global_t: 1865, Episode_t: 1, Action: 4, Reward: 6.82, Epsilon: 0.01
[INFO] model update: t: 1866, loss: 315322.875
[INFO] Global_t: 1866, Episode_t: 2, Action: 6, Reward: 5.74, Epsilon: 0.01
[INFO] model update: t: 1867, loss: 2259789.0
[INFO] Global_t: 1867, Episode_t: 3, Action: 5, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1868, loss: 6231710.0
[INFO] Global_t: 1868, Episode_t: 4, Action: 3, Reward: 6.42, Epsilon: 0.01
[INFO] model update: t: 1869, loss: 10507512.0
[INFO] Global_t: 1869, Episode_t: 5, Action: 1, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1870, loss: 15541076.0
[INFO] Global_t: 1870, Episode_t: 6, Action: 2, Reward: 5.57, Epsilon: 0.01
[INFO] model update: t: 1871, loss: 16465601.0
[INFO] Global_t: 1871, Episode_t: 7, Action: 14, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1872, loss: 21303648.0
[INFO] Global_t: 1872, Episode_t: 8, Action: 7, Reward: 4.00, Epsilon: 0.01
 94%|█████████▎| 1872/2000 [1:03:05<03:46,  1.77s/it]
[INFO] Global step: 1872, Cumulative rewards: 41.98656, Runtime (s): 3785.29
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.176441431045532
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.083484411239624
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.506643056869507
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.606833219528198
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.030992031097412
average cummulative reward vector is:  [0.13867053 0.12703843 0.15089399 0.14125234 0.1491422 ]
average cummulative reward is:  0.14139949641248542
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 1873, loss: 27422554.0
[INFO] Global_t: 1873, Episode_t: 1, Action: 5, Reward: 7.46, Epsilon: 0.01
[INFO] model update: t: 1874, loss: 24687632.0
[INFO] Global_t: 1874, Episode_t: 2, Action: 13, Reward: 5.35, Epsilon: 0.01
[INFO] model update: t: 1875, loss: 1836905.5
[INFO] Global_t: 1875, Episode_t: 3, Action: 3, Reward: 8.10, Epsilon: 0.01
[INFO] model update: t: 1876, loss: 7393064.0
[INFO] Global_t: 1876, Episode_t: 4, Action: 1, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1877, loss: 28619674.0
[INFO] Global_t: 1877, Episode_t: 5, Action: 4, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 1878, loss: 153970560.0
[INFO] Global_t: 1878, Episode_t: 6, Action: 7, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1879, loss: 1052809664.0
[INFO] Global_t: 1879, Episode_t: 7, Action: 6, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1880, loss: 1001862912.0
[INFO] Global_t: 1880, Episode_t: 8, Action: 8, Reward: 3.49, Epsilon: 0.01
 94%|█████████▍| 1880/2000 [1:03:32<04:30,  2.26s/it]
[INFO] Global step: 1880, Cumulative rewards: 42.043440000000004, Runtime (s): 3812.41
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 1881, loss: 743632.9375
[INFO] Global_t: 1881, Episode_t: 1, Action: 0, Reward: 6.33, Epsilon: 0.01
[INFO] model update: t: 1882, loss: 935930240.0
[INFO] Global_t: 1882, Episode_t: 2, Action: 3, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1883, loss: 506376512.0
[INFO] Global_t: 1883, Episode_t: 3, Action: 4, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1884, loss: 164187984.0
[INFO] Global_t: 1884, Episode_t: 4, Action: 2, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1885, loss: 370454464.0
[INFO] Global_t: 1885, Episode_t: 5, Action: 8, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1886, loss: 196302528.0
[INFO] Global_t: 1886, Episode_t: 6, Action: 13, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1887, loss: 109788296.0
[INFO] Global_t: 1887, Episode_t: 7, Action: 17, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 1888, loss: 289508576.0
[INFO] Global_t: 1888, Episode_t: 8, Action: 11, Reward: 2.89, Epsilon: 0.01
 94%|█████████▍| 1888/2000 [1:03:36<03:14,  1.74s/it]
[INFO] Global step: 1888, Cumulative rewards: 33.25608, Runtime (s): 3816.75
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.208924055099487
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.04221773147583
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.885826826095581
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.1188719272613525
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7066102027893066
average cummulative reward vector is:  [0.13629368 0.12704815 0.1417918  0.12403925 0.1378086 ]
average cummulative reward is:  0.13339629802486982
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 1889, loss: 3530279.75
[INFO] Global_t: 1889, Episode_t: 1, Action: 2, Reward: 6.25, Epsilon: 0.01
[INFO] model update: t: 1890, loss: 119208400.0
[INFO] Global_t: 1890, Episode_t: 2, Action: 5, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 1891, loss: 154933312.0
[INFO] Global_t: 1891, Episode_t: 3, Action: 1, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1892, loss: 31209640.0
[INFO] Global_t: 1892, Episode_t: 4, Action: 7, Reward: 3.39, Epsilon: 0.01
[INFO] model update: t: 1893, loss: 19178652.0
[INFO] Global_t: 1893, Episode_t: 5, Action: 15, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1894, loss: 88659360.0
[INFO] Global_t: 1894, Episode_t: 6, Action: 13, Reward: 2.59, Epsilon: 0.01
[INFO] model update: t: 1895, loss: 23294330.0
[INFO] Global_t: 1895, Episode_t: 7, Action: 24, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1896, loss: 5476801536.0
[INFO] Global_t: 1896, Episode_t: 8, Action: 23, Reward: 2.62, Epsilon: 0.01
 95%|█████████▍| 1896/2000 [1:04:01<03:42,  2.14s/it]
[INFO] Global step: 1896, Cumulative rewards: 29.338559999999998, Runtime (s): 3841.40
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 1897, loss: 12109445120.0
[INFO] Global_t: 1897, Episode_t: 1, Action: 24, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 1898, loss: 374103424.0
[INFO] Global_t: 1898, Episode_t: 2, Action: 21, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1899, loss: 58692892.0
[INFO] Global_t: 1899, Episode_t: 3, Action: 15, Reward: 4.29, Epsilon: 0.01
[INFO] model update: t: 1900, loss: 112216864.0
[INFO] Global_t: 1900, Episode_t: 4, Action: 39, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1901, loss: 132382736.0
[INFO] Global_t: 1901, Episode_t: 5, Action: 0, Reward: 5.19, Epsilon: 0.01
[INFO] model update: t: 1902, loss: 149807168.0
[INFO] Global_t: 1902, Episode_t: 6, Action: 12, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 1903, loss: 70820368.0
[INFO] Global_t: 1903, Episode_t: 7, Action: 27, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1904, loss: 260838208.0
[INFO] Global_t: 1904, Episode_t: 8, Action: 10, Reward: 3.50, Epsilon: 0.01
 95%|█████████▌| 1904/2000 [1:04:05<02:38,  1.65s/it]
[INFO] Global step: 1904, Cumulative rewards: 30.7632, Runtime (s): 3845.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6100547313690186
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.678086757659912
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.532292604446411
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.0537965297698975
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8410751819610596
average cummulative reward vector is:  [0.12920026 0.12465532 0.13113689 0.11673645 0.14327177]
average cummulative reward is:  0.12900013905390995
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 1905, loss: 73386416.0
[INFO] Global_t: 1905, Episode_t: 1, Action: 11, Reward: 5.40, Epsilon: 0.01
[INFO] model update: t: 1906, loss: 32880924.0
[INFO] Global_t: 1906, Episode_t: 2, Action: 3, Reward: 7.26, Epsilon: 0.01
[INFO] model update: t: 1907, loss: 126183408.0
[INFO] Global_t: 1907, Episode_t: 3, Action: 2, Reward: 6.73, Epsilon: 0.01
[INFO] model update: t: 1908, loss: 25839500.0
[INFO] Global_t: 1908, Episode_t: 4, Action: 4, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 1909, loss: 21481468.0
[INFO] Global_t: 1909, Episode_t: 5, Action: 15, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 1910, loss: 72193456.0
[INFO] Global_t: 1910, Episode_t: 6, Action: 13, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1911, loss: 29449056.0
[INFO] Global_t: 1911, Episode_t: 7, Action: 19, Reward: 3.39, Epsilon: 0.01
[INFO] model update: t: 1912, loss: 2791687.5
[INFO] Global_t: 1912, Episode_t: 8, Action: 191, Reward: 1.31, Epsilon: 0.01
 96%|█████████▌| 1912/2000 [1:04:30<03:03,  2.08s/it]
[INFO] Global step: 1912, Cumulative rewards: 37.563, Runtime (s): 3870.12
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 1913, loss: 40774456.0
[INFO] Global_t: 1913, Episode_t: 1, Action: 0, Reward: 6.43, Epsilon: 0.01
[INFO] model update: t: 1914, loss: 25251628.0
[INFO] Global_t: 1914, Episode_t: 2, Action: 116, Reward: 1.20, Epsilon: 0.01
[INFO] model update: t: 1915, loss: 2510692.0
[INFO] Global_t: 1915, Episode_t: 3, Action: 155, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 1916, loss: 23193684.0
[INFO] Global_t: 1916, Episode_t: 4, Action: 81, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1917, loss: 26372816.0
[INFO] Global_t: 1917, Episode_t: 5, Action: 113, Reward: 1.09, Epsilon: 0.01
[INFO] model update: t: 1918, loss: 5236952.0
[INFO] Global_t: 1918, Episode_t: 6, Action: 79, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1919, loss: 3130221.5
[INFO] Global_t: 1919, Episode_t: 7, Action: 175, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1920, loss: 10197745.0
[INFO] Global_t: 1920, Episode_t: 8, Action: 135, Reward: 1.29, Epsilon: 0.01
 96%|█████████▌| 1920/2000 [1:04:33<02:07,  1.59s/it]
[INFO] Global step: 1920, Cumulative rewards: 15.709679999999999, Runtime (s): 3873.60
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8000366687774658
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9009108543395996
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.102102756500244
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9388818740844727
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.616774320602417
average cummulative reward vector is:  [0.06733921 0.06307986 0.1184653  0.05545187 0.06243172]
average cummulative reward is:  0.0733535923545722
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 1921, loss: 15612200.0
[INFO] Global_t: 1921, Episode_t: 1, Action: 168, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1922, loss: 4941928.0
[INFO] Global_t: 1922, Episode_t: 2, Action: 14, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1923, loss: 429015.5625
[INFO] Global_t: 1923, Episode_t: 3, Action: 67, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1924, loss: 5389028.0
[INFO] Global_t: 1924, Episode_t: 4, Action: 167, Reward: 1.32, Epsilon: 0.01
[INFO] model update: t: 1925, loss: 8591540.0
[INFO] Global_t: 1925, Episode_t: 5, Action: 143, Reward: 1.28, Epsilon: 0.01
[INFO] model update: t: 1926, loss: 5909798.5
[INFO] Global_t: 1926, Episode_t: 6, Action: 178, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1927, loss: 111247.25
[INFO] Global_t: 1927, Episode_t: 7, Action: 146, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1928, loss: 4058503.75
[INFO] Global_t: 1928, Episode_t: 8, Action: 148, Reward: 1.57, Epsilon: 0.01
 96%|█████████▋| 1928/2000 [1:04:46<01:53,  1.58s/it]
[INFO] Global step: 1928, Cumulative rewards: 11.952479999999998, Runtime (s): 3886.11
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 1929, loss: 6666254.0
[INFO] Global_t: 1929, Episode_t: 1, Action: 55, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1930, loss: 5113864.0
[INFO] Global_t: 1930, Episode_t: 2, Action: 95, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1931, loss: 507724.9375
[INFO] Global_t: 1931, Episode_t: 3, Action: 152, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1932, loss: 2215685.5
[INFO] Global_t: 1932, Episode_t: 4, Action: 155, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1933, loss: 3957809.0
[INFO] Global_t: 1933, Episode_t: 5, Action: 146, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1934, loss: 3740165.5
[INFO] Global_t: 1934, Episode_t: 6, Action: 50, Reward: 1.89, Epsilon: 0.01
[INFO] model update: t: 1935, loss: 1705074.875
[INFO] Global_t: 1935, Episode_t: 7, Action: 86, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1936, loss: 807216.75
[INFO] Global_t: 1936, Episode_t: 8, Action: 68, Reward: 1.72, Epsilon: 0.01
 97%|█████████▋| 1936/2000 [1:04:48<01:16,  1.19s/it]
[INFO] Global step: 1936, Cumulative rewards: 12.971039999999999, Runtime (s): 3888.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.828540325164795
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.3015201091766357
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.706470251083374
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7657701969146729
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.6023478507995605
average cummulative reward vector is:  [0.07078184 0.06329792 0.06660628 0.05933131 0.06182392]
average cummulative reward is:  0.0643682552134666
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 1937, loss: 2486397.0
[INFO] Global_t: 1937, Episode_t: 1, Action: 125, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 1938, loss: 3493246.75
[INFO] Global_t: 1938, Episode_t: 2, Action: 110, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1939, loss: 1385829.75
[INFO] Global_t: 1939, Episode_t: 3, Action: 133, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1940, loss: 227068.609375
[INFO] Global_t: 1940, Episode_t: 4, Action: 200, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1941, loss: 1124720.25
[INFO] Global_t: 1941, Episode_t: 5, Action: 78, Reward: 1.71, Epsilon: 0.01
[INFO] model update: t: 1942, loss: 2335276.0
[INFO] Global_t: 1942, Episode_t: 6, Action: 148, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1943, loss: 813388.1875
[INFO] Global_t: 1943, Episode_t: 7, Action: 213, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1944, loss: 150241.6875
[INFO] Global_t: 1944, Episode_t: 8, Action: 217, Reward: 1.42, Epsilon: 0.01
 97%|█████████▋| 1944/2000 [1:05:00<01:11,  1.28s/it]
[INFO] Global step: 1944, Cumulative rewards: 13.846200000000001, Runtime (s): 3900.22
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 1945, loss: 578104.625
[INFO] Global_t: 1945, Episode_t: 1, Action: 132, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 1946, loss: 1288629.25
[INFO] Global_t: 1946, Episode_t: 2, Action: 125, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1947, loss: 1376270.0
[INFO] Global_t: 1947, Episode_t: 3, Action: 143, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1948, loss: 207482.015625
[INFO] Global_t: 1948, Episode_t: 4, Action: 83, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1949, loss: 352073.625
[INFO] Global_t: 1949, Episode_t: 5, Action: 27, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1950, loss: 836300.0
[INFO] Global_t: 1950, Episode_t: 6, Action: 130, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1951, loss: 999960.625
[INFO] Global_t: 1951, Episode_t: 7, Action: 90, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1952, loss: 362615.65625
[INFO] Global_t: 1952, Episode_t: 8, Action: 179, Reward: 1.36, Epsilon: 0.01
 98%|█████████▊| 1952/2000 [1:05:02<00:47,  1.00it/s]
[INFO] Global step: 1952, Cumulative rewards: 12.18732, Runtime (s): 3902.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6961736679077148
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.1488471031188965
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.8941290378570557
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.636291265487671
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.6091103553771973
average cummulative reward vector is:  [0.06351579 0.07081227 0.0738112  0.0554021  0.06244543]
average cummulative reward is:  0.06519735861785206
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 1953, loss: 181525.0
[INFO] Global_t: 1953, Episode_t: 1, Action: 121, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1954, loss: 622822.0
[INFO] Global_t: 1954, Episode_t: 2, Action: 100, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1955, loss: 475291.9375
[INFO] Global_t: 1955, Episode_t: 3, Action: 71, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1956, loss: 298648.03125
[INFO] Global_t: 1956, Episode_t: 4, Action: 191, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1957, loss: 64201.41015625
[INFO] Global_t: 1957, Episode_t: 5, Action: 153, Reward: 1.88, Epsilon: 0.01
[INFO] model update: t: 1958, loss: 205750.484375
[INFO] Global_t: 1958, Episode_t: 6, Action: 77, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1959, loss: 417721.375
[INFO] Global_t: 1959, Episode_t: 7, Action: 192, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1960, loss: 239984.28125
[INFO] Global_t: 1960, Episode_t: 8, Action: 131, Reward: 1.63, Epsilon: 0.01
 98%|█████████▊| 1960/2000 [1:05:14<00:45,  1.14s/it]
[INFO] Global step: 1960, Cumulative rewards: 13.86792, Runtime (s): 3914.72
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 1961, loss: 93177.078125
[INFO] Global_t: 1961, Episode_t: 1, Action: 143, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 1962, loss: 65241.12890625
[INFO] Global_t: 1962, Episode_t: 2, Action: 163, Reward: 1.60, Epsilon: 0.01
[INFO] model update: t: 1963, loss: 170229.75
[INFO] Global_t: 1963, Episode_t: 3, Action: 48, Reward: 1.27, Epsilon: 0.01
[INFO] model update: t: 1964, loss: 300218.4375
[INFO] Global_t: 1964, Episode_t: 4, Action: 113, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1965, loss: 232775.4375
[INFO] Global_t: 1965, Episode_t: 5, Action: 130, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1966, loss: 96878.3125
[INFO] Global_t: 1966, Episode_t: 6, Action: 55, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1967, loss: 145155.46875
[INFO] Global_t: 1967, Episode_t: 7, Action: 65, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1968, loss: 402891.375
[INFO] Global_t: 1968, Episode_t: 8, Action: 109, Reward: 1.38, Epsilon: 0.01
 98%|█████████▊| 1968/2000 [1:05:16<00:28,  1.13it/s]
[INFO] Global step: 1968, Cumulative rewards: 11.7618, Runtime (s): 3916.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8745980262756348
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7867627143859863
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.8022832870483398
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.995373249053955
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.8398306369781494
average cummulative reward vector is:  [0.07351605 0.05876806 0.0697582  0.05461916 0.07256102]
average cummulative reward is:  0.0658444970584654
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 1969, loss: 163062.0625
[INFO] Global_t: 1969, Episode_t: 1, Action: 103, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 1970, loss: 57131.625
[INFO] Global_t: 1970, Episode_t: 2, Action: 166, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1971, loss: 155630.28125
[INFO] Global_t: 1971, Episode_t: 3, Action: 47, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 1972, loss: 108059.375
[INFO] Global_t: 1972, Episode_t: 4, Action: 128, Reward: 1.68, Epsilon: 0.01
[INFO] model update: t: 1973, loss: 236930.90625
[INFO] Global_t: 1973, Episode_t: 5, Action: 145, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 1974, loss: 41668.01953125
[INFO] Global_t: 1974, Episode_t: 6, Action: 168, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 1975, loss: 78435.296875
[INFO] Global_t: 1975, Episode_t: 7, Action: 57, Reward: 1.31, Epsilon: 0.01
[INFO] model update: t: 1976, loss: 85320.2890625
[INFO] Global_t: 1976, Episode_t: 8, Action: 124, Reward: 1.88, Epsilon: 0.01
 99%|█████████▉| 1976/2000 [1:05:29<00:25,  1.08s/it]
[INFO] Global step: 1976, Cumulative rewards: 13.20612, Runtime (s): 3929.26
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 1977, loss: 174091.78125
[INFO] Global_t: 1977, Episode_t: 1, Action: 148, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1978, loss: 110077.5546875
[INFO] Global_t: 1978, Episode_t: 2, Action: 91, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1979, loss: 30429.130859375
[INFO] Global_t: 1979, Episode_t: 3, Action: 79, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1980, loss: 78567.65625
[INFO] Global_t: 1980, Episode_t: 4, Action: 40, Reward: 1.38, Epsilon: 0.01
[INFO] model update: t: 1981, loss: 72368.9765625
[INFO] Global_t: 1981, Episode_t: 5, Action: 47, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 1982, loss: 134162.734375
[INFO] Global_t: 1982, Episode_t: 6, Action: 78, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1983, loss: 53336.61328125
[INFO] Global_t: 1983, Episode_t: 7, Action: 171, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1984, loss: 41677.3671875
[INFO] Global_t: 1984, Episode_t: 8, Action: 75, Reward: 1.57, Epsilon: 0.01
 99%|█████████▉| 1984/2000 [1:05:31<00:13,  1.19it/s]
[INFO] Global step: 1984, Cumulative rewards: 12.53988, Runtime (s): 3931.64
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.208455801010132
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.029555559158325
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6658341884613037
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6181674003601074
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.659179449081421
average cummulative reward vector is:  [0.07212026 0.06691389 0.06517596 0.05304836 0.06588468]
average cummulative reward is:  0.06462863004725455
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 1985, loss: 105834.921875
[INFO] Global_t: 1985, Episode_t: 1, Action: 108, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 1986, loss: 62375.0234375
[INFO] Global_t: 1986, Episode_t: 2, Action: 169, Reward: 1.48, Epsilon: 0.01
[INFO] model update: t: 1987, loss: 83522.46875
[INFO] Global_t: 1987, Episode_t: 3, Action: 141, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1988, loss: 76584.125
[INFO] Global_t: 1988, Episode_t: 4, Action: 126, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1989, loss: 58924.12890625
[INFO] Global_t: 1989, Episode_t: 5, Action: 143, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1990, loss: 67241.4375
[INFO] Global_t: 1990, Episode_t: 6, Action: 153, Reward: 1.24, Epsilon: 0.01
[INFO] model update: t: 1991, loss: 18292.669921875
[INFO] Global_t: 1991, Episode_t: 7, Action: 83, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1992, loss: 66638.4921875
[INFO] Global_t: 1992, Episode_t: 8, Action: 166, Reward: 1.69, Epsilon: 0.01
100%|█████████▉| 1992/2000 [1:05:43<00:08,  1.02s/it]
[INFO] Global step: 1992, Cumulative rewards: 12.46656, Runtime (s): 3943.04
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 1993, loss: 37221.34375
[INFO] Global_t: 1993, Episode_t: 1, Action: 2, Reward: 1.42, Epsilon: 0.01
[INFO] model update: t: 1994, loss: 53206.078125
[INFO] Global_t: 1994, Episode_t: 2, Action: 175, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1995, loss: 40882.8515625
[INFO] Global_t: 1995, Episode_t: 3, Action: 100, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 1996, loss: 27317.56640625
[INFO] Global_t: 1996, Episode_t: 4, Action: 187, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1997, loss: 17825.783203125
[INFO] Global_t: 1997, Episode_t: 5, Action: 46, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 1998, loss: 30276.09765625
[INFO] Global_t: 1998, Episode_t: 6, Action: 212, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 1999, loss: 32879.0
[INFO] Global_t: 1999, Episode_t: 7, Action: 120, Reward: 2.11, Epsilon: 0.01

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.746446132659912
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9208104610443115
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.7646632194519043
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8689911365509033
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.055901527404785
average cummulative reward vector is:  [0.06735579 0.06309259 0.06849262 0.06268364 0.07016989]
average cummulative reward is:  0.06635890847000557
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  2
[DEBUG 17:09:55] my_main Finished after 1:06:18.
[INFO 17:09:55] Experiments Completed after 1:06:18
