[INFO 16:03:32] Experiments Running command 'my_main'
[INFO 16:03:32] Experiments Started run with ID "3"
[DEBUG 16:03:32] Experiments Starting Heartbeat
[DEBUG 16:03:32] my_main Started
Loading train graph:  powerlaw
train graphs in total:  200
Loading test graph:  powerlaw
merged graphs length:  205
/home/docker/app/src/agent/colge/utils/config.py:10: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  model_config = yaml.load(config_file)
  0%|          | 0/2000 [00:00<?, ?it/s]epoch:  0
graph: 0, nodes: 180, edges: 531
[INFO] Global_t: 1, Episode_t: 1, Action: 50, Reward: 2.34, Epsilon: 0.99
[INFO] Global_t: 2, Episode_t: 2, Action: 82, Reward: 1.56, Epsilon: 0.99
[INFO] Global_t: 3, Episode_t: 3, Action: 98, Reward: 1.62, Epsilon: 0.99
[INFO] Global_t: 4, Episode_t: 4, Action: 105, Reward: 1.60, Epsilon: 0.99
[INFO] Global_t: 5, Episode_t: 5, Action: 160, Reward: 1.00, Epsilon: 0.99
[INFO] Global_t: 6, Episode_t: 6, Action: 46, Reward: 2.02, Epsilon: 0.99
[INFO] Global_t: 7, Episode_t: 7, Action: 126, Reward: 1.65, Epsilon: 0.98
[INFO] Global_t: 8, Episode_t: 8, Action: 29, Reward: 1.49, Epsilon: 0.98

[INFO] Global step: 8, Cumulative rewards: 13.265640000000001, Runtime (s): 2.38
------------------------------------------------------------
 
  0%|          | 8/2000 [00:02<09:51,  3.37it/s]graph: 1, nodes: 217, edges: 642
[INFO] Global_t: 9, Episode_t: 1, Action: 19, Reward: 2.93, Epsilon: 0.98
[INFO] Global_t: 10, Episode_t: 2, Action: 182, Reward: 1.79, Epsilon: 0.98
[INFO] Global_t: 11, Episode_t: 3, Action: 206, Reward: 1.26, Epsilon: 0.98
[INFO] Global_t: 12, Episode_t: 4, Action: 30, Reward: 2.99, Epsilon: 0.98
[INFO] Global_t: 13, Episode_t: 5, Action: 0, Reward: 6.20, Epsilon: 0.98
[INFO] Global_t: 14, Episode_t: 6, Action: 140, Reward: 1.17, Epsilon: 0.98
[INFO] Global_t: 15, Episode_t: 7, Action: 74, Reward: 1.32, Epsilon: 0.98
[INFO] Global_t: 16, Episode_t: 8, Action: 167, Reward: 1.08, Epsilon: 0.98

[INFO] Global step: 16, Cumulative rewards: 18.726, Runtime (s): 6.30
  1%|          | 16/2000 [00:06<11:44,  2.82it/s]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.106693983078003
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9545197486877441
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.3554656505584717
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9044439792633057
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0348124504089355
average cummulative reward vector is:  [0.08062632 0.06650787 0.09600055 0.06452196 0.07937473]
average cummulative reward is:  0.07740628528150992
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] Global_t: 17, Episode_t: 1, Action: 5, Reward: 3.24, Epsilon: 0.97
[INFO] Global_t: 18, Episode_t: 2, Action: 199, Reward: 1.79, Epsilon: 0.97
[INFO] Global_t: 19, Episode_t: 3, Action: 77, Reward: 1.16, Epsilon: 0.97
[INFO] Global_t: 20, Episode_t: 4, Action: 177, Reward: 1.42, Epsilon: 0.97
[INFO] Global_t: 21, Episode_t: 5, Action: 205, Reward: 0.92, Epsilon: 0.97
[INFO] Global_t: 22, Episode_t: 6, Action: 157, Reward: 1.30, Epsilon: 0.97
[INFO] Global_t: 23, Episode_t: 7, Action: 193, Reward: 1.44, Epsilon: 0.97
[INFO] Global_t: 24, Episode_t: 8, Action: 104, Reward: 2.08, Epsilon: 0.97

[INFO] Global step: 24, Cumulative rewards: 13.334520000000001, Runtime (s): 20.04
  1%|          | 24/2000 [00:20<25:09,  1.31it/s]------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] Global_t: 25, Episode_t: 1, Action: 18, Reward: 3.49, Epsilon: 0.97
[INFO] Global_t: 26, Episode_t: 2, Action: 127, Reward: 1.51, Epsilon: 0.97
[INFO] Global_t: 27, Episode_t: 3, Action: 122, Reward: 1.62, Epsilon: 0.96
[INFO] Global_t: 28, Episode_t: 4, Action: 46, Reward: 2.80, Epsilon: 0.96
[INFO] Global_t: 29, Episode_t: 5, Action: 155, Reward: 1.60, Epsilon: 0.96
[INFO] Global_t: 30, Episode_t: 6, Action: 162, Reward: 1.14, Epsilon: 0.96
[INFO] Global_t: 31, Episode_t: 7, Action: 89, Reward: 1.55, Epsilon: 0.96
[INFO] Global_t: 32, Episode_t: 8, Action: 188, Reward: 1.18, Epsilon: 0.96

[INFO] Global step: 32, Cumulative rewards: 14.887559999999999, Runtime (s): 23.35
------------------------------------------------------------
 
  2%|▏         | 32/2000 [00:23<21:36,  1.52it/s]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.107447624206543
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9032344818115234
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.9427931308746338
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0794005393981934
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.9544684886932373
average cummulative reward vector is:  [0.08186605 0.06359051 0.07442213 0.06708855 0.07550645]
average cummulative reward is:  0.07249473921063032
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] Global_t: 33, Episode_t: 1, Action: 131, Reward: 1.09, Epsilon: 0.96
[INFO] Global_t: 34, Episode_t: 2, Action: 35, Reward: 2.49, Epsilon: 0.96
[INFO] Global_t: 35, Episode_t: 3, Action: 54, Reward: 2.04, Epsilon: 0.96
[INFO] Global_t: 36, Episode_t: 4, Action: 49, Reward: 2.14, Epsilon: 0.96
[INFO] Global_t: 37, Episode_t: 5, Action: 64, Reward: 1.70, Epsilon: 0.95
[INFO] Global_t: 38, Episode_t: 6, Action: 32, Reward: 1.88, Epsilon: 0.95
[INFO] Global_t: 39, Episode_t: 7, Action: 76, Reward: 1.67, Epsilon: 0.95
[INFO] Global_t: 40, Episode_t: 8, Action: 50, Reward: 1.35, Epsilon: 0.95
  2%|▏         | 40/2000 [00:36<30:47,  1.06it/s]
[INFO] Global step: 40, Cumulative rewards: 14.380199999999999, Runtime (s): 36.19
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] Global_t: 41, Episode_t: 1, Action: 190, Reward: 1.74, Epsilon: 0.95
[INFO] Global_t: 42, Episode_t: 2, Action: 51, Reward: 2.50, Epsilon: 0.95
[INFO] Global_t: 43, Episode_t: 3, Action: 180, Reward: 1.69, Epsilon: 0.95
[INFO] Global_t: 44, Episode_t: 4, Action: 156, Reward: 1.88, Epsilon: 0.95
[INFO] Global_t: 45, Episode_t: 5, Action: 86, Reward: 1.71, Epsilon: 0.95
[INFO] Global_t: 46, Episode_t: 6, Action: 68, Reward: 1.34, Epsilon: 0.95
[INFO] Global_t: 47, Episode_t: 7, Action: 111, Reward: 2.15, Epsilon: 0.94
[INFO] Global_t: 48, Episode_t: 8, Action: 59, Reward: 1.42, Epsilon: 0.94
  2%|▏         | 48/2000 [00:39<25:08,  1.29it/s]
[INFO] Global step: 48, Cumulative rewards: 14.41992, Runtime (s): 39.20
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.2779922485351562
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.981781244277954
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.257540225982666
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9684133529663086
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.0533411502838135
average cummulative reward vector is:  [0.08659947 0.06498449 0.09062732 0.0662535  0.0776207 ]
average cummulative reward is:  0.07721709808539026
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 49, loss: 421433147392.0
[INFO] Global_t: 49, Episode_t: 1, Action: 179, Reward: 1.82, Epsilon: 0.94
[INFO] model update: t: 50, loss: 1128496496640.0
[INFO] Global_t: 50, Episode_t: 2, Action: 174, Reward: 1.37, Epsilon: 0.94
[INFO] model update: t: 51, loss: 633151422464.0
[INFO] Global_t: 51, Episode_t: 3, Action: 51, Reward: 2.38, Epsilon: 0.94
[INFO] model update: t: 52, loss: 145992777728.0
[INFO] Global_t: 52, Episode_t: 4, Action: 187, Reward: 1.71, Epsilon: 0.94
[INFO] model update: t: 53, loss: 1168881483776.0
[INFO] Global_t: 53, Episode_t: 5, Action: 84, Reward: 1.30, Epsilon: 0.94
[INFO] model update: t: 54, loss: 188582330368.0
[INFO] Global_t: 54, Episode_t: 6, Action: 103, Reward: 1.58, Epsilon: 0.94
[INFO] model update: t: 55, loss: 79168913408.0
[INFO] Global_t: 55, Episode_t: 7, Action: 3, Reward: 7.26, Epsilon: 0.94
[INFO] model update: t: 56, loss: 262041239552.0
[INFO] Global_t: 56, Episode_t: 8, Action: 121, Reward: 2.03, Epsilon: 0.94
  3%|▎         | 56/2000 [00:53<34:37,  1.07s/it]
[INFO] Global step: 56, Cumulative rewards: 19.4544, Runtime (s): 53.27
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 57, loss: 247991795712.0
[INFO] Global_t: 57, Episode_t: 1, Action: 10, Reward: 3.79, Epsilon: 0.94
[INFO] model update: t: 58, loss: 206484570112.0
[INFO] Global_t: 58, Episode_t: 2, Action: 35, Reward: 3.08, Epsilon: 0.93
[INFO] model update: t: 59, loss: 112996761600.0
[INFO] Global_t: 59, Episode_t: 3, Action: 107, Reward: 1.14, Epsilon: 0.93
[INFO] model update: t: 60, loss: 4756511744.0
[INFO] Global_t: 60, Episode_t: 4, Action: 115, Reward: 1.58, Epsilon: 0.93
[INFO] model update: t: 61, loss: 37177270272.0
[INFO] Global_t: 61, Episode_t: 5, Action: 42, Reward: 2.60, Epsilon: 0.93
[INFO] model update: t: 62, loss: 88937365504.0
[INFO] Global_t: 62, Episode_t: 6, Action: 105, Reward: 1.24, Epsilon: 0.93
[INFO] model update: t: 63, loss: 52172668928.0
[INFO] Global_t: 63, Episode_t: 7, Action: 74, Reward: 1.99, Epsilon: 0.93
[INFO] model update: t: 64, loss: 8058185216.0
[INFO] Global_t: 64, Episode_t: 8, Action: 158, Reward: 1.16, Epsilon: 0.93
  3%|▎         | 64/2000 [00:56<28:06,  1.15it/s]
[INFO] Global step: 64, Cumulative rewards: 16.590120000000002, Runtime (s): 56.56
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.153097629547119
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.226830959320068
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.627739429473877
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.042435884475708
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9170408248901367
average cummulative reward vector is:  [0.14565079 0.13235185 0.13470301 0.12675701 0.14301452]
average cummulative reward is:  0.13649543445296872
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 65, loss: 3099815424.0
[INFO] Global_t: 65, Episode_t: 1, Action: 90, Reward: 1.38, Epsilon: 0.93
[INFO] model update: t: 66, loss: 21967222784.0
[INFO] Global_t: 66, Episode_t: 2, Action: 60, Reward: 1.65, Epsilon: 0.93
[INFO] model update: t: 67, loss: 33628653568.0
[INFO] Global_t: 67, Episode_t: 3, Action: 10, Reward: 4.54, Epsilon: 0.93
[INFO] model update: t: 68, loss: 22090397696.0
[INFO] Global_t: 68, Episode_t: 4, Action: 3, Reward: 4.96, Epsilon: 0.92
[INFO] model update: t: 69, loss: 10364078080.0
[INFO] Global_t: 69, Episode_t: 5, Action: 83, Reward: 1.40, Epsilon: 0.92
[INFO] model update: t: 70, loss: 1642519552.0
[INFO] Global_t: 70, Episode_t: 6, Action: 8, Reward: 3.06, Epsilon: 0.92
[INFO] model update: t: 71, loss: 254637152.0
[INFO] Global_t: 71, Episode_t: 7, Action: 89, Reward: 1.23, Epsilon: 0.92
[INFO] model update: t: 72, loss: 3720113408.0
[INFO] Global_t: 72, Episode_t: 8, Action: 160, Reward: 0.83, Epsilon: 0.92
  4%|▎         | 72/2000 [01:21<50:08,  1.56s/it]
[INFO] Global step: 72, Cumulative rewards: 19.051560000000002, Runtime (s): 81.90
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 73, loss: 7084236800.0
[INFO] Global_t: 73, Episode_t: 1, Action: 95, Reward: 1.64, Epsilon: 0.92
[INFO] model update: t: 74, loss: 9442758656.0
[INFO] Global_t: 74, Episode_t: 2, Action: 172, Reward: 1.71, Epsilon: 0.92
[INFO] model update: t: 75, loss: 6936851456.0
[INFO] Global_t: 75, Episode_t: 3, Action: 21, Reward: 3.85, Epsilon: 0.92
[INFO] model update: t: 76, loss: 4287839744.0
[INFO] Global_t: 76, Episode_t: 4, Action: 26, Reward: 1.79, Epsilon: 0.92
[INFO] model update: t: 77, loss: 1361728000.0
[INFO] Global_t: 77, Episode_t: 5, Action: 29, Reward: 2.77, Epsilon: 0.92
[INFO] model update: t: 78, loss: 99117384.0
[INFO] Global_t: 78, Episode_t: 6, Action: 2, Reward: 5.61, Epsilon: 0.91
[INFO] model update: t: 79, loss: 244432432.0
[INFO] Global_t: 79, Episode_t: 7, Action: 47, Reward: 1.30, Epsilon: 0.91
[INFO] model update: t: 80, loss: 1098217472.0
[INFO] Global_t: 80, Episode_t: 8, Action: 119, Reward: 1.46, Epsilon: 0.91
  4%|▍         | 80/2000 [01:25<39:51,  1.25s/it]
[INFO] Global step: 80, Cumulative rewards: 20.13072, Runtime (s): 85.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.0144641399383545
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.946176528930664
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.960134983062744
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.225454807281494
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.883364677429199
average cummulative reward vector is:  [0.14097316 0.1210287  0.14550902 0.13009509 0.14179973]
average cummulative reward is:  0.13588114052652456
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 81, loss: 2013215104.0
[INFO] Global_t: 81, Episode_t: 1, Action: 61, Reward: 2.18, Epsilon: 0.91
[INFO] model update: t: 82, loss: 2983868928.0
[INFO] Global_t: 82, Episode_t: 2, Action: 166, Reward: 1.23, Epsilon: 0.91
[INFO] model update: t: 83, loss: 2886468608.0
[INFO] Global_t: 83, Episode_t: 3, Action: 33, Reward: 2.13, Epsilon: 0.91
[INFO] model update: t: 84, loss: 2030201728.0
[INFO] Global_t: 84, Episode_t: 4, Action: 147, Reward: 1.34, Epsilon: 0.91
[INFO] model update: t: 85, loss: 972535424.0
[INFO] Global_t: 85, Episode_t: 5, Action: 170, Reward: 0.93, Epsilon: 0.91
[INFO] model update: t: 86, loss: 229927024.0
[INFO] Global_t: 86, Episode_t: 6, Action: 94, Reward: 1.44, Epsilon: 0.91
[INFO] model update: t: 87, loss: 2204644.25
[INFO] Global_t: 87, Episode_t: 7, Action: 5, Reward: 3.31, Epsilon: 0.91
[INFO] model update: t: 88, loss: 171375968.0
[INFO] Global_t: 88, Episode_t: 8, Action: 117, Reward: 1.25, Epsilon: 0.90
  4%|▍         | 88/2000 [01:49<55:46,  1.75s/it]
[INFO] Global step: 88, Cumulative rewards: 13.815119999999999, Runtime (s): 109.42
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 89, loss: 508399808.0
[INFO] Global_t: 89, Episode_t: 1, Action: 105, Reward: 1.95, Epsilon: 0.90
[INFO] model update: t: 90, loss: 792244672.0
[INFO] Global_t: 90, Episode_t: 2, Action: 37, Reward: 2.91, Epsilon: 0.90
[INFO] model update: t: 91, loss: 1052401088.0
[INFO] Global_t: 91, Episode_t: 3, Action: 139, Reward: 1.92, Epsilon: 0.90
[INFO] model update: t: 92, loss: 999819904.0
[INFO] Global_t: 92, Episode_t: 4, Action: 9, Reward: 4.80, Epsilon: 0.90
[INFO] model update: t: 93, loss: 455044288.0
[INFO] Global_t: 93, Episode_t: 5, Action: 109, Reward: 1.64, Epsilon: 0.90
[INFO] model update: t: 94, loss: 137948560.0
[INFO] Global_t: 94, Episode_t: 6, Action: 32, Reward: 2.26, Epsilon: 0.90
[INFO] model update: t: 95, loss: 7526335.0
[INFO] Global_t: 95, Episode_t: 7, Action: 149, Reward: 1.17, Epsilon: 0.90
[INFO] model update: t: 96, loss: 183597232.0
[INFO] Global_t: 96, Episode_t: 8, Action: 160, Reward: 1.51, Epsilon: 0.90
  5%|▍         | 96/2000 [01:54<44:50,  1.41s/it]
[INFO] Global step: 96, Cumulative rewards: 18.17616, Runtime (s): 114.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4877803325653076
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8734071254730225
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.740525245666504
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6447811126708984
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7728188037872314
average cummulative reward vector is:  [0.12357132 0.11869907 0.13875929 0.11432547 0.13616694]
average cummulative reward is:  0.12630441645092497
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 97, loss: 85540016.0
[INFO] Global_t: 97, Episode_t: 1, Action: 9, Reward: 5.42, Epsilon: 0.90
[INFO] model update: t: 98, loss: 252426864.0
[INFO] Global_t: 98, Episode_t: 2, Action: 129, Reward: 2.11, Epsilon: 0.89
[INFO] model update: t: 99, loss: 5370599.0
[INFO] Global_t: 99, Episode_t: 3, Action: 141, Reward: 1.29, Epsilon: 0.89
[INFO] model update: t: 100, loss: 197634848.0
[INFO] Global_t: 100, Episode_t: 4, Action: 183, Reward: 1.23, Epsilon: 0.89
[INFO] model update: t: 101, loss: 27844148.0
[INFO] Global_t: 101, Episode_t: 5, Action: 17, Reward: 3.57, Epsilon: 0.89
[INFO] model update: t: 102, loss: 158306160.0
[INFO] Global_t: 102, Episode_t: 6, Action: 64, Reward: 1.61, Epsilon: 0.89
[INFO] model update: t: 103, loss: 3770849.5
[INFO] Global_t: 103, Episode_t: 7, Action: 74, Reward: 2.04, Epsilon: 0.89
[INFO] model update: t: 104, loss: 136413344.0
[INFO] Global_t: 104, Episode_t: 8, Action: 4, Reward: 3.91, Epsilon: 0.89
  5%|▌         | 104/2000 [02:17<58:27,  1.85s/it]
[INFO] Global step: 104, Cumulative rewards: 21.185760000000002, Runtime (s): 137.37
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 105, loss: 7381583.0
[INFO] Global_t: 105, Episode_t: 1, Action: 129, Reward: 1.91, Epsilon: 0.89
[INFO] model update: t: 106, loss: 85784192.0
[INFO] Global_t: 106, Episode_t: 2, Action: 112, Reward: 1.41, Epsilon: 0.89
[INFO] model update: t: 107, loss: 49305864.0
[INFO] Global_t: 107, Episode_t: 3, Action: 155, Reward: 2.08, Epsilon: 0.89
[INFO] model update: t: 108, loss: 38113248.0
[INFO] Global_t: 108, Episode_t: 4, Action: 171, Reward: 1.48, Epsilon: 0.89
[INFO] model update: t: 109, loss: 84655152.0
[INFO] Global_t: 109, Episode_t: 5, Action: 139, Reward: 1.30, Epsilon: 0.88
[INFO] model update: t: 110, loss: 1095593.25
[INFO] Global_t: 110, Episode_t: 6, Action: 1, Reward: 4.66, Epsilon: 0.88
[INFO] model update: t: 111, loss: 87774016.0
[INFO] Global_t: 111, Episode_t: 7, Action: 12, Reward: 2.69, Epsilon: 0.88
[INFO] model update: t: 112, loss: 8619800.0
[INFO] Global_t: 112, Episode_t: 8, Action: 3, Reward: 5.45, Epsilon: 0.88
  6%|▌         | 112/2000 [02:22<46:24,  1.47s/it]
[INFO] Global step: 112, Cumulative rewards: 20.98968, Runtime (s): 142.17
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.791659116744995
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.988110303878784
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9279162883758545
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8600008487701416
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7962381839752197
average cummulative reward vector is:  [0.13612289 0.12097454 0.14457923 0.12219743 0.13633011]
average cummulative reward is:  0.1320408408359961
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 113, loss: 24476822.0
[INFO] Global_t: 113, Episode_t: 1, Action: 41, Reward: 2.33, Epsilon: 0.88
[INFO] model update: t: 114, loss: 29979746.0
[INFO] Global_t: 114, Episode_t: 2, Action: 37, Reward: 2.21, Epsilon: 0.88
[INFO] model update: t: 115, loss: 2900074.0
[INFO] Global_t: 115, Episode_t: 3, Action: 117, Reward: 1.75, Epsilon: 0.88
[INFO] model update: t: 116, loss: 25416716.0
[INFO] Global_t: 116, Episode_t: 4, Action: 170, Reward: 1.41, Epsilon: 0.88
[INFO] model update: t: 117, loss: 10435484.0
[INFO] Global_t: 117, Episode_t: 5, Action: 24, Reward: 1.89, Epsilon: 0.88
[INFO] model update: t: 118, loss: 10315844.0
[INFO] Global_t: 118, Episode_t: 6, Action: 96, Reward: 1.48, Epsilon: 0.88
[INFO] model update: t: 119, loss: 24478016.0
[INFO] Global_t: 119, Episode_t: 7, Action: 9, Reward: 3.65, Epsilon: 0.87
[INFO] model update: t: 120, loss: 1168562.875
[INFO] Global_t: 120, Episode_t: 8, Action: 52, Reward: 2.00, Epsilon: 0.87
  6%|▌         | 120/2000 [02:45<59:27,  1.90s/it]
[INFO] Global step: 120, Cumulative rewards: 16.72116, Runtime (s): 165.24
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 121, loss: 21463408.0
[INFO] Global_t: 121, Episode_t: 1, Action: 12, Reward: 3.64, Epsilon: 0.87
[INFO] model update: t: 122, loss: 4220053.0
[INFO] Global_t: 122, Episode_t: 2, Action: 144, Reward: 1.92, Epsilon: 0.87
[INFO] model update: t: 123, loss: 7028842.5
[INFO] Global_t: 123, Episode_t: 3, Action: 105, Reward: 1.48, Epsilon: 0.87
[INFO] model update: t: 124, loss: 9924260.0
[INFO] Global_t: 124, Episode_t: 4, Action: 109, Reward: 1.56, Epsilon: 0.87
[INFO] model update: t: 125, loss: 1007029.5625
[INFO] Global_t: 125, Episode_t: 5, Action: 83, Reward: 1.69, Epsilon: 0.87
[INFO] model update: t: 126, loss: 9126432.0
[INFO] Global_t: 126, Episode_t: 6, Action: 127, Reward: 1.18, Epsilon: 0.87
[INFO] model update: t: 127, loss: 2898985.0
[INFO] Global_t: 127, Episode_t: 7, Action: 184, Reward: 1.55, Epsilon: 0.87
[INFO] model update: t: 128, loss: 2035204.5
[INFO] Global_t: 128, Episode_t: 8, Action: 21, Reward: 2.66, Epsilon: 0.87
  6%|▋         | 128/2000 [02:48<45:14,  1.45s/it]
[INFO] Global step: 128, Cumulative rewards: 15.6864, Runtime (s): 168.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.223723649978638
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6157941818237305
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7494332790374756
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.13010311126709
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.496993064880371
average cummulative reward vector is:  [0.14715211 0.11335486 0.14141475 0.12503621 0.12776801]
average cummulative reward is:  0.13094518923571777
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 129, loss: 6433214.0
[INFO] Global_t: 129, Episode_t: 1, Action: 169, Reward: 1.74, Epsilon: 0.86
[INFO] model update: t: 130, loss: 1313104.25
[INFO] Global_t: 130, Episode_t: 2, Action: 45, Reward: 2.15, Epsilon: 0.86
[INFO] model update: t: 131, loss: 3009529.5
[INFO] Global_t: 131, Episode_t: 3, Action: 183, Reward: 2.39, Epsilon: 0.86
[INFO] model update: t: 132, loss: 4655546.0
[INFO] Global_t: 132, Episode_t: 4, Action: 40, Reward: 2.43, Epsilon: 0.86
[INFO] model update: t: 133, loss: 442857.0625
[INFO] Global_t: 133, Episode_t: 5, Action: 3, Reward: 3.57, Epsilon: 0.86
[INFO] model update: t: 134, loss: 3474547.25
[INFO] Global_t: 134, Episode_t: 6, Action: 63, Reward: 1.05, Epsilon: 0.86
[INFO] model update: t: 135, loss: 1816465.25
[INFO] Global_t: 135, Episode_t: 7, Action: 14, Reward: 2.91, Epsilon: 0.86
[INFO] model update: t: 136, loss: 545282.9375
[INFO] Global_t: 136, Episode_t: 8, Action: 81, Reward: 1.57, Epsilon: 0.86
  7%|▋         | 136/2000 [03:12<59:33,  1.92s/it]
[INFO] Global step: 136, Cumulative rewards: 17.801639999999995, Runtime (s): 192.54
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 137, loss: 2839030.25
[INFO] Global_t: 137, Episode_t: 1, Action: 40, Reward: 1.65, Epsilon: 0.86
[INFO] model update: t: 138, loss: 1149763.0
[INFO] Global_t: 138, Episode_t: 2, Action: 17, Reward: 2.58, Epsilon: 0.86
[INFO] model update: t: 139, loss: 1969679.5
[INFO] Global_t: 139, Episode_t: 3, Action: 3, Reward: 3.47, Epsilon: 0.85
[INFO] model update: t: 140, loss: 2318902.25
[INFO] Global_t: 140, Episode_t: 4, Action: 133, Reward: 1.73, Epsilon: 0.85
[INFO] model update: t: 141, loss: 218554.21875
[INFO] Global_t: 141, Episode_t: 5, Action: 89, Reward: 1.58, Epsilon: 0.85
[INFO] model update: t: 142, loss: 3262098.0
[INFO] Global_t: 142, Episode_t: 6, Action: 111, Reward: 1.82, Epsilon: 0.85
[INFO] model update: t: 143, loss: 861602.25
[INFO] Global_t: 143, Episode_t: 7, Action: 120, Reward: 1.12, Epsilon: 0.85
[INFO] model update: t: 144, loss: 1351430.375
[INFO] Global_t: 144, Episode_t: 8, Action: 47, Reward: 2.46, Epsilon: 0.85
  7%|▋         | 144/2000 [03:16<46:25,  1.50s/it]
[INFO] Global step: 144, Cumulative rewards: 16.41192, Runtime (s): 196.78
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.978163957595825
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5712852478027344
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6534664630889893
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8288354873657227
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8484671115875244
average cummulative reward vector is:  [0.13995184 0.1120956  0.1351877  0.1172222  0.13767204]
average cummulative reward is:  0.12842587762951654
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 145, loss: 1455308.0
[INFO] Global_t: 145, Episode_t: 1, Action: 4, Reward: 4.97, Epsilon: 0.85
[INFO] model update: t: 146, loss: 563850.0
[INFO] Global_t: 146, Episode_t: 2, Action: 139, Reward: 1.22, Epsilon: 0.85
[INFO] model update: t: 147, loss: 1531061.375
[INFO] Global_t: 147, Episode_t: 3, Action: 187, Reward: 1.48, Epsilon: 0.85
[INFO] model update: t: 148, loss: 758674.875
[INFO] Global_t: 148, Episode_t: 4, Action: 144, Reward: 2.33, Epsilon: 0.85
[INFO] model update: t: 149, loss: 434090.375
[INFO] Global_t: 149, Episode_t: 5, Action: 6, Reward: 4.97, Epsilon: 0.84
[INFO] model update: t: 150, loss: 613685.875
[INFO] Global_t: 150, Episode_t: 6, Action: 43, Reward: 2.09, Epsilon: 0.84
[INFO] model update: t: 151, loss: 514395.5625
[INFO] Global_t: 151, Episode_t: 7, Action: 166, Reward: 1.11, Epsilon: 0.84
[INFO] model update: t: 152, loss: 609360.5
[INFO] Global_t: 152, Episode_t: 8, Action: 15, Reward: 2.63, Epsilon: 0.84

[INFO] Global step: 152, Cumulative rewards: 20.80044, Runtime (s): 219.89
------------------------------------------------------------
 
  8%|▊         | 152/2000 [03:39<59:03,  1.92s/it]graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 153, loss: 283109.125
[INFO] Global_t: 153, Episode_t: 1, Action: 49, Reward: 2.36, Epsilon: 0.84
[INFO] model update: t: 154, loss: 290224.6875
[INFO] Global_t: 154, Episode_t: 2, Action: 4, Reward: 4.87, Epsilon: 0.84
[INFO] model update: t: 155, loss: 224547.125
[INFO] Global_t: 155, Episode_t: 3, Action: 189, Reward: 1.02, Epsilon: 0.84
[INFO] model update: t: 156, loss: 268042.90625
[INFO] Global_t: 156, Episode_t: 4, Action: 13, Reward: 4.18, Epsilon: 0.84
[INFO] model update: t: 157, loss: 336977.71875
[INFO] Global_t: 157, Episode_t: 5, Action: 8, Reward: 3.72, Epsilon: 0.84
[INFO] model update: t: 158, loss: 303084.5
[INFO] Global_t: 158, Episode_t: 6, Action: 37, Reward: 1.91, Epsilon: 0.84
[INFO] model update: t: 159, loss: 370265.09375
[INFO] Global_t: 159, Episode_t: 7, Action: 106, Reward: 1.54, Epsilon: 0.84
[INFO] model update: t: 160, loss: 295502.75
[INFO] Global_t: 160, Episode_t: 8, Action: 152, Reward: 1.50, Epsilon: 0.83
  8%|▊         | 160/2000 [03:45<47:05,  1.54s/it]
[INFO] Global step: 160, Cumulative rewards: 21.106079999999995, Runtime (s): 225.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7064359188079834
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.650810480117798
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8144752979278564
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.736584186553955
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6132161617279053
average cummulative reward vector is:  [0.13177921 0.11128079 0.14074754 0.11677336 0.12700753]
average cummulative reward is:  0.12551768598293223
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 161, loss: 241270.0625
[INFO] Global_t: 161, Episode_t: 1, Action: 156, Reward: 1.21, Epsilon: 0.83
[INFO] model update: t: 162, loss: 540602.0
[INFO] Global_t: 162, Episode_t: 2, Action: 209, Reward: 2.05, Epsilon: 0.83
[INFO] model update: t: 163, loss: 382926.125
[INFO] Global_t: 163, Episode_t: 3, Action: 65, Reward: 2.57, Epsilon: 0.83
[INFO] model update: t: 164, loss: 529131.3125
[INFO] Global_t: 164, Episode_t: 4, Action: 13, Reward: 4.46, Epsilon: 0.83
[INFO] model update: t: 165, loss: 155691.09375
[INFO] Global_t: 165, Episode_t: 5, Action: 172, Reward: 1.28, Epsilon: 0.83
[INFO] model update: t: 166, loss: 244576.90625
[INFO] Global_t: 166, Episode_t: 6, Action: 158, Reward: 1.19, Epsilon: 0.83
[INFO] model update: t: 167, loss: 276141.0625
[INFO] Global_t: 167, Episode_t: 7, Action: 210, Reward: 1.38, Epsilon: 0.83
[INFO] model update: t: 168, loss: 168162.375
[INFO] Global_t: 168, Episode_t: 8, Action: 188, Reward: 1.73, Epsilon: 0.83
  8%|▊         | 168/2000 [04:08<59:12,  1.94s/it]
[INFO] Global step: 168, Cumulative rewards: 15.865079999999999, Runtime (s): 248.10
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 169, loss: 380124.78125
[INFO] Global_t: 169, Episode_t: 1, Action: 116, Reward: 1.43, Epsilon: 0.83
[INFO] model update: t: 170, loss: 315781.96875
[INFO] Global_t: 170, Episode_t: 2, Action: 8, Reward: 3.98, Epsilon: 0.82
[INFO] model update: t: 171, loss: 124290.890625
[INFO] Global_t: 171, Episode_t: 3, Action: 6, Reward: 3.58, Epsilon: 0.82
[INFO] model update: t: 172, loss: 218482.34375
[INFO] Global_t: 172, Episode_t: 4, Action: 78, Reward: 1.71, Epsilon: 0.82
[INFO] model update: t: 173, loss: 120765.1875
[INFO] Global_t: 173, Episode_t: 5, Action: 17, Reward: 1.35, Epsilon: 0.82
[INFO] model update: t: 174, loss: 246870.03125
[INFO] Global_t: 174, Episode_t: 6, Action: 71, Reward: 1.39, Epsilon: 0.82
[INFO] model update: t: 175, loss: 536182.375
[INFO] Global_t: 175, Episode_t: 7, Action: 69, Reward: 1.03, Epsilon: 0.82
[INFO] model update: t: 176, loss: 259483.28125
[INFO] Global_t: 176, Episode_t: 8, Action: 9, Reward: 2.05, Epsilon: 0.82
  9%|▉         | 176/2000 [04:12<46:44,  1.54s/it]
[INFO] Global step: 176, Cumulative rewards: 16.509, Runtime (s): 252.89
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9128944873809814
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.038295745849609
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8252410888671875
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.61191463470459
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7705187797546387
average cummulative reward vector is:  [0.13959263 0.12544861 0.1368877  0.11490981 0.13565833]
average cummulative reward is:  0.13049941880510735
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 177, loss: 692697.25
[INFO] Global_t: 177, Episode_t: 1, Action: 21, Reward: 2.64, Epsilon: 0.82
[INFO] model update: t: 178, loss: 182229.015625
[INFO] Global_t: 178, Episode_t: 2, Action: 152, Reward: 1.61, Epsilon: 0.82
[INFO] model update: t: 179, loss: 313548.3125
[INFO] Global_t: 179, Episode_t: 3, Action: 1, Reward: 4.22, Epsilon: 0.82
[INFO] model update: t: 180, loss: 165455.5
[INFO] Global_t: 180, Episode_t: 4, Action: 70, Reward: 1.83, Epsilon: 0.81
[INFO] model update: t: 181, loss: 143604.53125
[INFO] Global_t: 181, Episode_t: 5, Action: 175, Reward: 1.69, Epsilon: 0.81
[INFO] model update: t: 182, loss: 401059.0625
[INFO] Global_t: 182, Episode_t: 6, Action: 73, Reward: 1.76, Epsilon: 0.81
[INFO] model update: t: 183, loss: 200796.640625
[INFO] Global_t: 183, Episode_t: 7, Action: 22, Reward: 1.87, Epsilon: 0.81
[INFO] model update: t: 184, loss: 566836.625
[INFO] Global_t: 184, Episode_t: 8, Action: 85, Reward: 1.05, Epsilon: 0.81
  9%|▉         | 184/2000 [04:42<1:05:36,  2.17s/it]
[INFO] Global step: 184, Cumulative rewards: 16.6812, Runtime (s): 282.01
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 185, loss: 108955.078125
[INFO] Global_t: 185, Episode_t: 1, Action: 14, Reward: 3.84, Epsilon: 0.81
[INFO] model update: t: 186, loss: 619933.625
[INFO] Global_t: 186, Episode_t: 2, Action: 64, Reward: 2.12, Epsilon: 0.81
[INFO] model update: t: 187, loss: 147750.15625
[INFO] Global_t: 187, Episode_t: 3, Action: 63, Reward: 1.19, Epsilon: 0.81
[INFO] model update: t: 188, loss: 363715.0
[INFO] Global_t: 188, Episode_t: 4, Action: 18, Reward: 3.56, Epsilon: 0.81
[INFO] model update: t: 189, loss: 237992.8125
[INFO] Global_t: 189, Episode_t: 5, Action: 104, Reward: 2.62, Epsilon: 0.81
[INFO] model update: t: 190, loss: 324445.1875
[INFO] Global_t: 190, Episode_t: 6, Action: 44, Reward: 1.85, Epsilon: 0.80
[INFO] model update: t: 191, loss: 231810.53125
[INFO] Global_t: 191, Episode_t: 7, Action: 9, Reward: 2.81, Epsilon: 0.80
[INFO] model update: t: 192, loss: 231072.9375
[INFO] Global_t: 192, Episode_t: 8, Action: 124, Reward: 1.81, Epsilon: 0.80
 10%|▉         | 192/2000 [04:46<51:07,  1.70s/it]  
[INFO] Global step: 192, Cumulative rewards: 19.80528, Runtime (s): 286.79
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.512007236480713
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.226098299026489
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.682893991470337
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.694866418838501
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.890256881713867
average cummulative reward vector is:  [0.12371421 0.12892037 0.13891448 0.1156021  0.13742258]
average cummulative reward is:  0.12891474904398054
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 193, loss: 170535.75
[INFO] Global_t: 193, Episode_t: 1, Action: 172, Reward: 1.15, Epsilon: 0.80
[INFO] model update: t: 194, loss: 135967.34375
[INFO] Global_t: 194, Episode_t: 2, Action: 52, Reward: 2.05, Epsilon: 0.80
[INFO] model update: t: 195, loss: 320174.3125
[INFO] Global_t: 195, Episode_t: 3, Action: 134, Reward: 1.42, Epsilon: 0.80
[INFO] model update: t: 196, loss: 110811.25
[INFO] Global_t: 196, Episode_t: 4, Action: 71, Reward: 1.88, Epsilon: 0.80
[INFO] model update: t: 197, loss: 124224.265625
[INFO] Global_t: 197, Episode_t: 5, Action: 23, Reward: 1.60, Epsilon: 0.80
[INFO] model update: t: 198, loss: 78504.3125
[INFO] Global_t: 198, Episode_t: 6, Action: 81, Reward: 1.68, Epsilon: 0.80
[INFO] model update: t: 199, loss: 138815.21875
[INFO] Global_t: 199, Episode_t: 7, Action: 190, Reward: 1.58, Epsilon: 0.80
[INFO] model update: t: 200, loss: 108188.3046875
[INFO] Global_t: 200, Episode_t: 8, Action: 77, Reward: 2.15, Epsilon: 0.79
 10%|█         | 200/2000 [05:09<1:01:23,  2.05s/it]
[INFO] Global step: 200, Cumulative rewards: 13.50384, Runtime (s): 309.69
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 201, loss: 108496.1171875
[INFO] Global_t: 201, Episode_t: 1, Action: 138, Reward: 2.34, Epsilon: 0.79
[INFO] model update: t: 202, loss: 83212.5625
[INFO] Global_t: 202, Episode_t: 2, Action: 180, Reward: 2.03, Epsilon: 0.79
[INFO] model update: t: 203, loss: 64414.33984375
[INFO] Global_t: 203, Episode_t: 3, Action: 50, Reward: 1.70, Epsilon: 0.79
[INFO] model update: t: 204, loss: 111213.8671875
[INFO] Global_t: 204, Episode_t: 4, Action: 42, Reward: 2.48, Epsilon: 0.79
[INFO] model update: t: 205, loss: 83367.171875
[INFO] Global_t: 205, Episode_t: 5, Action: 54, Reward: 1.89, Epsilon: 0.79
[INFO] model update: t: 206, loss: 91602.5703125
[INFO] Global_t: 206, Episode_t: 6, Action: 154, Reward: 1.57, Epsilon: 0.79
[INFO] model update: t: 207, loss: 58730.86328125
[INFO] Global_t: 207, Episode_t: 7, Action: 14, Reward: 3.29, Epsilon: 0.79
[INFO] model update: t: 208, loss: 115448.65625
[INFO] Global_t: 208, Episode_t: 8, Action: 25, Reward: 2.61, Epsilon: 0.79
 10%|█         | 208/2000 [05:13<47:14,  1.58s/it]  
[INFO] Global step: 208, Cumulative rewards: 17.91348, Runtime (s): 313.66
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.710968017578125
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8636465072631836
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.577211856842041
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.593296766281128
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.2549707889556885
average cummulative reward vector is:  [0.13124526 0.12056042 0.13097049 0.11333341 0.11764086]
average cummulative reward is:  0.1227500886115694
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 209, loss: 64618.515625
[INFO] Global_t: 209, Episode_t: 1, Action: 4, Reward: 6.20, Epsilon: 0.79
[INFO] model update: t: 210, loss: 92914.0
[INFO] Global_t: 210, Episode_t: 2, Action: 0, Reward: 4.28, Epsilon: 0.79
[INFO] model update: t: 211, loss: 85735.625
[INFO] Global_t: 211, Episode_t: 3, Action: 2, Reward: 3.37, Epsilon: 0.78
[INFO] model update: t: 212, loss: 82560.9140625
[INFO] Global_t: 212, Episode_t: 4, Action: 116, Reward: 1.61, Epsilon: 0.78
[INFO] model update: t: 213, loss: 120866.2421875
[INFO] Global_t: 213, Episode_t: 5, Action: 1, Reward: 2.43, Epsilon: 0.78
[INFO] model update: t: 214, loss: 103989.1796875
[INFO] Global_t: 214, Episode_t: 6, Action: 108, Reward: 1.18, Epsilon: 0.78
[INFO] model update: t: 215, loss: 84715.765625
[INFO] Global_t: 215, Episode_t: 7, Action: 84, Reward: 0.86, Epsilon: 0.78
[INFO] model update: t: 216, loss: 74607.3515625
[INFO] Global_t: 216, Episode_t: 8, Action: 24, Reward: 2.36, Epsilon: 0.78
 11%|█         | 216/2000 [05:37<59:46,  2.01s/it]
[INFO] Global step: 216, Cumulative rewards: 22.28736, Runtime (s): 337.75
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 217, loss: 134732.203125
[INFO] Global_t: 217, Episode_t: 1, Action: 5, Reward: 5.19, Epsilon: 0.78
[INFO] model update: t: 218, loss: 93950.484375
[INFO] Global_t: 218, Episode_t: 2, Action: 6, Reward: 4.38, Epsilon: 0.78
[INFO] model update: t: 219, loss: 74119.9375
[INFO] Global_t: 219, Episode_t: 3, Action: 130, Reward: 1.34, Epsilon: 0.78
[INFO] model update: t: 220, loss: 57486.48046875
[INFO] Global_t: 220, Episode_t: 4, Action: 138, Reward: 1.64, Epsilon: 0.78
[INFO] model update: t: 221, loss: 66836.90625
[INFO] Global_t: 221, Episode_t: 5, Action: 106, Reward: 1.24, Epsilon: 0.77
[INFO] model update: t: 222, loss: 71042.3203125
[INFO] Global_t: 222, Episode_t: 6, Action: 191, Reward: 0.86, Epsilon: 0.77
[INFO] model update: t: 223, loss: 52879.5859375
[INFO] Global_t: 223, Episode_t: 7, Action: 161, Reward: 1.00, Epsilon: 0.77
[INFO] model update: t: 224, loss: 57937.109375
[INFO] Global_t: 224, Episode_t: 8, Action: 1, Reward: 3.16, Epsilon: 0.77
 11%|█         | 224/2000 [05:42<47:26,  1.60s/it]
[INFO] Global step: 224, Cumulative rewards: 18.8112, Runtime (s): 342.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8008131980895996
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.695401191711426
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.580361843109131
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6123170852661133
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4476537704467773
average cummulative reward vector is:  [0.13548368 0.11551852 0.12724208 0.11483738 0.12454005]
average cummulative reward is:  0.12352434323455763
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 225, loss: 54571.3671875
[INFO] Global_t: 225, Episode_t: 1, Action: 108, Reward: 1.64, Epsilon: 0.77
[INFO] model update: t: 226, loss: 81836.609375
[INFO] Global_t: 226, Episode_t: 2, Action: 17, Reward: 2.25, Epsilon: 0.77
[INFO] model update: t: 227, loss: 102619.5703125
[INFO] Global_t: 227, Episode_t: 3, Action: 30, Reward: 2.40, Epsilon: 0.77
[INFO] model update: t: 228, loss: 42398.7421875
[INFO] Global_t: 228, Episode_t: 4, Action: 126, Reward: 1.18, Epsilon: 0.77
[INFO] model update: t: 229, loss: 55567.91796875
[INFO] Global_t: 229, Episode_t: 5, Action: 6, Reward: 6.20, Epsilon: 0.77
[INFO] model update: t: 230, loss: 38232.94921875
[INFO] Global_t: 230, Episode_t: 6, Action: 178, Reward: 1.13, Epsilon: 0.77
[INFO] model update: t: 231, loss: 53554.578125
[INFO] Global_t: 231, Episode_t: 7, Action: 175, Reward: 1.54, Epsilon: 0.76
[INFO] model update: t: 232, loss: 48796.7265625
[INFO] Global_t: 232, Episode_t: 8, Action: 115, Reward: 1.55, Epsilon: 0.76
 12%|█▏        | 232/2000 [06:05<58:16,  1.98s/it]
[INFO] Global step: 232, Cumulative rewards: 17.89224, Runtime (s): 365.79
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 233, loss: 20142.74609375
[INFO] Global_t: 233, Episode_t: 1, Action: 131, Reward: 1.64, Epsilon: 0.76
[INFO] model update: t: 234, loss: 56680.9140625
[INFO] Global_t: 234, Episode_t: 2, Action: 70, Reward: 2.40, Epsilon: 0.76
[INFO] model update: t: 235, loss: 37126.83984375
[INFO] Global_t: 235, Episode_t: 3, Action: 163, Reward: 1.40, Epsilon: 0.76
[INFO] model update: t: 236, loss: 98387.921875
[INFO] Global_t: 236, Episode_t: 4, Action: 153, Reward: 1.83, Epsilon: 0.76
[INFO] model update: t: 237, loss: 19230.328125
[INFO] Global_t: 237, Episode_t: 5, Action: 175, Reward: 2.10, Epsilon: 0.76
[INFO] model update: t: 238, loss: 60916.45703125
[INFO] Global_t: 238, Episode_t: 6, Action: 77, Reward: 1.37, Epsilon: 0.76
[INFO] model update: t: 239, loss: 27026.5078125
[INFO] Global_t: 239, Episode_t: 7, Action: 8, Reward: 2.86, Epsilon: 0.76
[INFO] model update: t: 240, loss: 79303.1875
[INFO] Global_t: 240, Episode_t: 8, Action: 7, Reward: 3.45, Epsilon: 0.76
 12%|█▏        | 240/2000 [06:10<45:21,  1.55s/it]
[INFO] Global step: 240, Cumulative rewards: 17.05452, Runtime (s): 370.10
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.794044017791748
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.767113208770752
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3408632278442383
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6880407333374023
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.497447967529297
average cummulative reward vector is:  [0.132785   0.1164044  0.12253361 0.10982383 0.12801048]
average cummulative reward is:  0.12191146407043876
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 241, loss: 33325.62890625
[INFO] Global_t: 241, Episode_t: 1, Action: 162, Reward: 1.43, Epsilon: 0.75
[INFO] model update: t: 242, loss: 98170.453125
[INFO] Global_t: 242, Episode_t: 2, Action: 46, Reward: 2.00, Epsilon: 0.75
[INFO] model update: t: 243, loss: 40773.953125
[INFO] Global_t: 243, Episode_t: 3, Action: 195, Reward: 1.19, Epsilon: 0.75
[INFO] model update: t: 244, loss: 107890.4375
[INFO] Global_t: 244, Episode_t: 4, Action: 150, Reward: 1.42, Epsilon: 0.75
[INFO] model update: t: 245, loss: 26347.82421875
[INFO] Global_t: 245, Episode_t: 5, Action: 187, Reward: 1.17, Epsilon: 0.75
[INFO] model update: t: 246, loss: 56390.4296875
[INFO] Global_t: 246, Episode_t: 6, Action: 124, Reward: 1.85, Epsilon: 0.75
[INFO] model update: t: 247, loss: 29934.234375
[INFO] Global_t: 247, Episode_t: 7, Action: 65, Reward: 1.89, Epsilon: 0.75
[INFO] model update: t: 248, loss: 42105.3984375
[INFO] Global_t: 248, Episode_t: 8, Action: 29, Reward: 1.79, Epsilon: 0.75
 12%|█▏        | 248/2000 [06:31<54:44,  1.87s/it]
[INFO] Global step: 248, Cumulative rewards: 12.7476, Runtime (s): 391.23
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 249, loss: 36396.2890625
[INFO] Global_t: 249, Episode_t: 1, Action: 42, Reward: 2.36, Epsilon: 0.75
[INFO] model update: t: 250, loss: 59701.3828125
[INFO] Global_t: 250, Episode_t: 2, Action: 100, Reward: 1.72, Epsilon: 0.75
[INFO] model update: t: 251, loss: 40511.6640625
[INFO] Global_t: 251, Episode_t: 3, Action: 3, Reward: 5.07, Epsilon: 0.74
[INFO] model update: t: 252, loss: 59401.3203125
[INFO] Global_t: 252, Episode_t: 4, Action: 6, Reward: 4.70, Epsilon: 0.74
[INFO] model update: t: 253, loss: 44147.515625
[INFO] Global_t: 253, Episode_t: 5, Action: 138, Reward: 0.96, Epsilon: 0.74
[INFO] model update: t: 254, loss: 30511.939453125
[INFO] Global_t: 254, Episode_t: 6, Action: 165, Reward: 1.02, Epsilon: 0.74
[INFO] model update: t: 255, loss: 49663.5703125
[INFO] Global_t: 255, Episode_t: 7, Action: 35, Reward: 2.39, Epsilon: 0.74
[INFO] model update: t: 256, loss: 36144.9609375
[INFO] Global_t: 256, Episode_t: 8, Action: 126, Reward: 0.98, Epsilon: 0.74
 13%|█▎        | 256/2000 [06:36<43:40,  1.50s/it]
[INFO] Global step: 256, Cumulative rewards: 19.205039999999993, Runtime (s): 396.31
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.946596384048462
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.065159559249878
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8248040676116943
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.988487720489502
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.853426456451416
average cummulative reward vector is:  [0.13771711 0.12371944 0.13761475 0.12423037 0.13885215]
average cummulative reward is:  0.1324267656350746
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 257, loss: 158861.234375
[INFO] Global_t: 257, Episode_t: 1, Action: 64, Reward: 2.36, Epsilon: 0.74
[INFO] model update: t: 258, loss: 21930.8828125
[INFO] Global_t: 258, Episode_t: 2, Action: 5, Reward: 5.09, Epsilon: 0.74
[INFO] model update: t: 259, loss: 51157.9921875
[INFO] Global_t: 259, Episode_t: 3, Action: 7, Reward: 4.19, Epsilon: 0.74
[INFO] model update: t: 260, loss: 17621.60546875
[INFO] Global_t: 260, Episode_t: 4, Action: 18, Reward: 3.46, Epsilon: 0.74
[INFO] model update: t: 261, loss: 43761.04296875
[INFO] Global_t: 261, Episode_t: 5, Action: 191, Reward: 1.22, Epsilon: 0.74
[INFO] model update: t: 262, loss: 33069.40625
[INFO] Global_t: 262, Episode_t: 6, Action: 130, Reward: 0.99, Epsilon: 0.73
[INFO] model update: t: 263, loss: 34355.0546875
[INFO] Global_t: 263, Episode_t: 7, Action: 59, Reward: 2.74, Epsilon: 0.73
[INFO] model update: t: 264, loss: 12565.642578125
[INFO] Global_t: 264, Episode_t: 8, Action: 127, Reward: 1.47, Epsilon: 0.73
 13%|█▎        | 264/2000 [07:00<57:00,  1.97s/it]
[INFO] Global step: 264, Cumulative rewards: 21.52356, Runtime (s): 420.80
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 265, loss: 44272.37890625
[INFO] Global_t: 265, Episode_t: 1, Action: 34, Reward: 1.77, Epsilon: 0.73
[INFO] model update: t: 266, loss: 31428.12890625
[INFO] Global_t: 266, Episode_t: 2, Action: 163, Reward: 1.16, Epsilon: 0.73
[INFO] model update: t: 267, loss: 44487.2890625
[INFO] Global_t: 267, Episode_t: 3, Action: 17, Reward: 4.58, Epsilon: 0.73
[INFO] model update: t: 268, loss: 38117.8125
[INFO] Global_t: 268, Episode_t: 4, Action: 141, Reward: 1.77, Epsilon: 0.73
[INFO] model update: t: 269, loss: 27571.59375
[INFO] Global_t: 269, Episode_t: 5, Action: 180, Reward: 0.97, Epsilon: 0.73
[INFO] model update: t: 270, loss: 31036.357421875
[INFO] Global_t: 270, Episode_t: 6, Action: 7, Reward: 4.01, Epsilon: 0.73
[INFO] model update: t: 271, loss: 75430.09375
[INFO] Global_t: 271, Episode_t: 7, Action: 172, Reward: 1.35, Epsilon: 0.73
[INFO] model update: t: 272, loss: 27755.626953125
[INFO] Global_t: 272, Episode_t: 8, Action: 184, Reward: 1.45, Epsilon: 0.72
 14%|█▎        | 272/2000 [07:05<44:45,  1.55s/it]
[INFO] Global step: 272, Cumulative rewards: 17.05476, Runtime (s): 425.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.841811418533325
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6371030807495117
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7537178993225098
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4779412746429443
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.58796763420105
average cummulative reward vector is:  [0.13405868 0.11214931 0.13555519 0.1088257  0.13142581]
average cummulative reward is:  0.12440293768182098
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 273, loss: 55836.44140625
[INFO] Global_t: 273, Episode_t: 1, Action: 204, Reward: 1.25, Epsilon: 0.72
[INFO] model update: t: 274, loss: 46116.33203125
[INFO] Global_t: 274, Episode_t: 2, Action: 1, Reward: 5.57, Epsilon: 0.72
[INFO] model update: t: 275, loss: 32417.53125
[INFO] Global_t: 275, Episode_t: 3, Action: 26, Reward: 4.00, Epsilon: 0.72
[INFO] model update: t: 276, loss: 42424.3359375
[INFO] Global_t: 276, Episode_t: 4, Action: 88, Reward: 1.44, Epsilon: 0.72
[INFO] model update: t: 277, loss: 19515.359375
[INFO] Global_t: 277, Episode_t: 5, Action: 91, Reward: 1.17, Epsilon: 0.72
[INFO] model update: t: 278, loss: 27188.265625
[INFO] Global_t: 278, Episode_t: 6, Action: 8, Reward: 3.04, Epsilon: 0.72
[INFO] model update: t: 279, loss: 14821.703125
[INFO] Global_t: 279, Episode_t: 7, Action: 4, Reward: 3.03, Epsilon: 0.72
[INFO] model update: t: 280, loss: 25714.015625
[INFO] Global_t: 280, Episode_t: 8, Action: 18, Reward: 2.35, Epsilon: 0.72
 14%|█▍        | 280/2000 [07:29<56:34,  1.97s/it]
[INFO] Global step: 280, Cumulative rewards: 21.853199999999998, Runtime (s): 449.08
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 281, loss: 28468.42578125
[INFO] Global_t: 281, Episode_t: 1, Action: 8, Reward: 4.48, Epsilon: 0.72
[INFO] model update: t: 282, loss: 36224.5234375
[INFO] Global_t: 282, Episode_t: 2, Action: 65, Reward: 1.56, Epsilon: 0.71
[INFO] model update: t: 283, loss: 15575.6474609375
[INFO] Global_t: 283, Episode_t: 3, Action: 179, Reward: 1.53, Epsilon: 0.71
[INFO] model update: t: 284, loss: 45098.83203125
[INFO] Global_t: 284, Episode_t: 4, Action: 186, Reward: 1.17, Epsilon: 0.71
[INFO] model update: t: 285, loss: 56414.1640625
[INFO] Global_t: 285, Episode_t: 5, Action: 175, Reward: 1.30, Epsilon: 0.71
[INFO] model update: t: 286, loss: 41058.57421875
[INFO] Global_t: 286, Episode_t: 6, Action: 101, Reward: 1.36, Epsilon: 0.71
[INFO] model update: t: 287, loss: 101835.6953125
[INFO] Global_t: 287, Episode_t: 7, Action: 80, Reward: 1.42, Epsilon: 0.71
[INFO] model update: t: 288, loss: 19603.6328125
[INFO] Global_t: 288, Episode_t: 8, Action: 68, Reward: 1.22, Epsilon: 0.71
 14%|█▍        | 288/2000 [07:33<43:51,  1.54s/it]
[INFO] Global step: 288, Cumulative rewards: 14.042400000000002, Runtime (s): 453.23
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.210510730743408
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.3015453815460205
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.165545225143433
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8794023990631104
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.888979196548462
average cummulative reward vector is:  [0.13793474 0.12000764 0.13994481 0.1206757  0.14233118]
average cummulative reward is:  0.13217881364088838
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 289, loss: 42120.16796875
[INFO] Global_t: 289, Episode_t: 1, Action: 102, Reward: 1.60, Epsilon: 0.71
[INFO] model update: t: 290, loss: 28628.615234375
[INFO] Global_t: 290, Episode_t: 2, Action: 5, Reward: 5.59, Epsilon: 0.71
[INFO] model update: t: 291, loss: 26883.462890625
[INFO] Global_t: 291, Episode_t: 3, Action: 140, Reward: 1.30, Epsilon: 0.71
[INFO] model update: t: 292, loss: 40634.0703125
[INFO] Global_t: 292, Episode_t: 4, Action: 9, Reward: 4.12, Epsilon: 0.70
[INFO] model update: t: 293, loss: 22286.81640625
[INFO] Global_t: 293, Episode_t: 5, Action: 17, Reward: 1.71, Epsilon: 0.70
[INFO] model update: t: 294, loss: 39779.859375
[INFO] Global_t: 294, Episode_t: 6, Action: 122, Reward: 0.97, Epsilon: 0.70
[INFO] model update: t: 295, loss: 16505.36328125
[INFO] Global_t: 295, Episode_t: 7, Action: 96, Reward: 1.15, Epsilon: 0.70
[INFO] model update: t: 296, loss: 21682.896484375
[INFO] Global_t: 296, Episode_t: 8, Action: 1, Reward: 2.23, Epsilon: 0.70
 15%|█▍        | 296/2000 [07:59<58:18,  2.05s/it]
[INFO] Global step: 296, Cumulative rewards: 18.67512, Runtime (s): 479.28
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 297, loss: 17051.21875
[INFO] Global_t: 297, Episode_t: 1, Action: 155, Reward: 2.04, Epsilon: 0.70
[INFO] model update: t: 298, loss: 26272.1171875
[INFO] Global_t: 298, Episode_t: 2, Action: 81, Reward: 1.61, Epsilon: 0.70
[INFO] model update: t: 299, loss: 20058.08984375
[INFO] Global_t: 299, Episode_t: 3, Action: 88, Reward: 2.30, Epsilon: 0.70
[INFO] model update: t: 300, loss: 23590.361328125
[INFO] Global_t: 300, Episode_t: 4, Action: 12, Reward: 4.49, Epsilon: 0.70
[INFO] model update: t: 301, loss: 27101.9609375
[INFO] Global_t: 301, Episode_t: 5, Action: 172, Reward: 1.93, Epsilon: 0.70
[INFO] model update: t: 302, loss: 16482.7578125
[INFO] Global_t: 302, Episode_t: 6, Action: 101, Reward: 2.14, Epsilon: 0.70
[INFO] model update: t: 303, loss: 27693.490234375
[INFO] Global_t: 303, Episode_t: 7, Action: 116, Reward: 1.51, Epsilon: 0.69
[INFO] model update: t: 304, loss: 21604.154296875
[INFO] Global_t: 304, Episode_t: 8, Action: 187, Reward: 1.33, Epsilon: 0.69
 15%|█▌        | 304/2000 [08:02<44:33,  1.58s/it]
[INFO] Global step: 304, Cumulative rewards: 17.35764, Runtime (s): 482.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9279849529266357
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9627716541290283
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.616840124130249
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.937121868133545
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5228512287139893
average cummulative reward vector is:  [0.13434289 0.12228218 0.13220219 0.12249556 0.12818038]
average cummulative reward is:  0.12790063870937346
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 305, loss: 24260.48046875
[INFO] Global_t: 305, Episode_t: 1, Action: 60, Reward: 2.25, Epsilon: 0.69
[INFO] model update: t: 306, loss: 10766.4404296875
[INFO] Global_t: 306, Episode_t: 2, Action: 146, Reward: 1.62, Epsilon: 0.69
[INFO] model update: t: 307, loss: 28737.66796875
[INFO] Global_t: 307, Episode_t: 3, Action: 9, Reward: 5.04, Epsilon: 0.69
[INFO] model update: t: 308, loss: 25838.53515625
[INFO] Global_t: 308, Episode_t: 4, Action: 11, Reward: 4.83, Epsilon: 0.69
[INFO] model update: t: 309, loss: 19656.53515625
[INFO] Global_t: 309, Episode_t: 5, Action: 160, Reward: 1.36, Epsilon: 0.69
[INFO] model update: t: 310, loss: 10916.427734375
[INFO] Global_t: 310, Episode_t: 6, Action: 91, Reward: 1.02, Epsilon: 0.69
[INFO] model update: t: 311, loss: 24753.75390625
[INFO] Global_t: 311, Episode_t: 7, Action: 97, Reward: 1.55, Epsilon: 0.69
[INFO] model update: t: 312, loss: 20734.0390625
[INFO] Global_t: 312, Episode_t: 8, Action: 2, Reward: 3.98, Epsilon: 0.69
 16%|█▌        | 312/2000 [08:28<57:33,  2.05s/it]
[INFO] Global step: 312, Cumulative rewards: 21.65532, Runtime (s): 508.13
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 313, loss: 18432.1640625
[INFO] Global_t: 313, Episode_t: 1, Action: 146, Reward: 1.38, Epsilon: 0.68
[INFO] model update: t: 314, loss: 26499.015625
[INFO] Global_t: 314, Episode_t: 2, Action: 46, Reward: 2.39, Epsilon: 0.68
[INFO] model update: t: 315, loss: 15037.95703125
[INFO] Global_t: 315, Episode_t: 3, Action: 153, Reward: 1.91, Epsilon: 0.68
[INFO] model update: t: 316, loss: 68202.890625
[INFO] Global_t: 316, Episode_t: 4, Action: 48, Reward: 1.94, Epsilon: 0.68
[INFO] model update: t: 317, loss: 53562.1015625
[INFO] Global_t: 317, Episode_t: 5, Action: 5, Reward: 3.91, Epsilon: 0.68
[INFO] model update: t: 318, loss: 44741.18359375
[INFO] Global_t: 318, Episode_t: 6, Action: 8, Reward: 2.78, Epsilon: 0.68
[INFO] model update: t: 319, loss: 66393.546875
[INFO] Global_t: 319, Episode_t: 7, Action: 3, Reward: 2.91, Epsilon: 0.68
[INFO] model update: t: 320, loss: 38394.8203125
[INFO] Global_t: 320, Episode_t: 8, Action: 10, Reward: 4.39, Epsilon: 0.68
 16%|█▌        | 320/2000 [08:32<44:37,  1.59s/it]
[INFO] Global step: 320, Cumulative rewards: 21.60492, Runtime (s): 512.43
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6034655570983887
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8243324756622314
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.736937999725342
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.900578022003174
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6743645668029785
average cummulative reward vector is:  [0.12578263 0.11734144 0.13673388 0.11754276 0.13531532]
average cummulative reward is:  0.12654320522710885
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 321, loss: 92730.0
[INFO] Global_t: 321, Episode_t: 1, Action: 59, Reward: 2.31, Epsilon: 0.68
[INFO] model update: t: 322, loss: 29133.3671875
[INFO] Global_t: 322, Episode_t: 2, Action: 118, Reward: 1.38, Epsilon: 0.68
[INFO] model update: t: 323, loss: 80628.3515625
[INFO] Global_t: 323, Episode_t: 3, Action: 49, Reward: 2.07, Epsilon: 0.67
[INFO] model update: t: 324, loss: 25642.3984375
[INFO] Global_t: 324, Episode_t: 4, Action: 86, Reward: 1.60, Epsilon: 0.67
[INFO] model update: t: 325, loss: 123668.90625
[INFO] Global_t: 325, Episode_t: 5, Action: 5, Reward: 5.08, Epsilon: 0.67
[INFO] model update: t: 326, loss: 21254.849609375
[INFO] Global_t: 326, Episode_t: 6, Action: 4, Reward: 3.60, Epsilon: 0.67
[INFO] model update: t: 327, loss: 123108.359375
[INFO] Global_t: 327, Episode_t: 7, Action: 22, Reward: 2.54, Epsilon: 0.67
[INFO] model update: t: 328, loss: 28289.1953125
[INFO] Global_t: 328, Episode_t: 8, Action: 10, Reward: 3.20, Epsilon: 0.67
 16%|█▋        | 328/2000 [08:54<54:11,  1.94s/it]
[INFO] Global step: 328, Cumulative rewards: 21.783, Runtime (s): 534.55
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 329, loss: 77603.59375
[INFO] Global_t: 329, Episode_t: 1, Action: 14, Reward: 2.55, Epsilon: 0.67
[INFO] model update: t: 330, loss: 25009.865234375
[INFO] Global_t: 330, Episode_t: 2, Action: 4, Reward: 4.34, Epsilon: 0.67
[INFO] model update: t: 331, loss: 72070.203125
[INFO] Global_t: 331, Episode_t: 3, Action: 7, Reward: 3.37, Epsilon: 0.67
[INFO] model update: t: 332, loss: 47362.5625
[INFO] Global_t: 332, Episode_t: 4, Action: 152, Reward: 1.54, Epsilon: 0.67
[INFO] model update: t: 333, loss: 49184.1875
[INFO] Global_t: 333, Episode_t: 5, Action: 25, Reward: 2.02, Epsilon: 0.66
[INFO] model update: t: 334, loss: 61318.52734375
[INFO] Global_t: 334, Episode_t: 6, Action: 8, Reward: 2.34, Epsilon: 0.66
[INFO] model update: t: 335, loss: 29197.09375
[INFO] Global_t: 335, Episode_t: 7, Action: 115, Reward: 1.07, Epsilon: 0.66
[INFO] model update: t: 336, loss: 56215.671875
[INFO] Global_t: 336, Episode_t: 8, Action: 26, Reward: 1.29, Epsilon: 0.66
 17%|█▋        | 336/2000 [09:00<43:27,  1.57s/it]
[INFO] Global step: 336, Cumulative rewards: 18.522, Runtime (s): 540.03
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9141290187835693
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.934913396835327
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5858631134033203
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7109193801879883
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.398615598678589
average cummulative reward vector is:  [0.13779868 0.11961852 0.13126694 0.11667266 0.11699812]
average cummulative reward is:  0.12447098489014538
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 337, loss: 15801.927734375
[INFO] Global_t: 337, Episode_t: 1, Action: 1, Reward: 5.63, Epsilon: 0.66
[INFO] model update: t: 338, loss: 45272.328125
[INFO] Global_t: 338, Episode_t: 2, Action: 157, Reward: 1.63, Epsilon: 0.66
[INFO] model update: t: 339, loss: 21892.974609375
[INFO] Global_t: 339, Episode_t: 3, Action: 47, Reward: 3.39, Epsilon: 0.66
[INFO] model update: t: 340, loss: 59716.19921875
[INFO] Global_t: 340, Episode_t: 4, Action: 48, Reward: 2.25, Epsilon: 0.66
[INFO] model update: t: 341, loss: 28686.501953125
[INFO] Global_t: 341, Episode_t: 5, Action: 42, Reward: 1.86, Epsilon: 0.66
[INFO] model update: t: 342, loss: 20155.87109375
[INFO] Global_t: 342, Episode_t: 6, Action: 158, Reward: 1.31, Epsilon: 0.66
[INFO] model update: t: 343, loss: 15231.361328125
[INFO] Global_t: 343, Episode_t: 7, Action: 68, Reward: 1.98, Epsilon: 0.65
[INFO] model update: t: 344, loss: 9627.26171875
[INFO] Global_t: 344, Episode_t: 8, Action: 166, Reward: 1.44, Epsilon: 0.65
 17%|█▋        | 344/2000 [09:22<53:42,  1.95s/it]
[INFO] Global step: 344, Cumulative rewards: 19.506600000000002, Runtime (s): 562.68
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 345, loss: 12771.951171875
[INFO] Global_t: 345, Episode_t: 1, Action: 5, Reward: 4.88, Epsilon: 0.65
[INFO] model update: t: 346, loss: 14076.943359375
[INFO] Global_t: 346, Episode_t: 2, Action: 112, Reward: 1.48, Epsilon: 0.65
[INFO] model update: t: 347, loss: 22118.5703125
[INFO] Global_t: 347, Episode_t: 3, Action: 124, Reward: 1.75, Epsilon: 0.65
[INFO] model update: t: 348, loss: 12999.9541015625
[INFO] Global_t: 348, Episode_t: 4, Action: 13, Reward: 3.73, Epsilon: 0.65
[INFO] model update: t: 349, loss: 9130.2802734375
[INFO] Global_t: 349, Episode_t: 5, Action: 4, Reward: 3.80, Epsilon: 0.65
[INFO] model update: t: 350, loss: 12575.365234375
[INFO] Global_t: 350, Episode_t: 6, Action: 6, Reward: 2.86, Epsilon: 0.65
[INFO] model update: t: 351, loss: 13954.5341796875
[INFO] Global_t: 351, Episode_t: 7, Action: 8, Reward: 3.11, Epsilon: 0.65
[INFO] model update: t: 352, loss: 21812.576171875
[INFO] Global_t: 352, Episode_t: 8, Action: 22, Reward: 2.26, Epsilon: 0.65
 18%|█▊        | 352/2000 [09:26<41:50,  1.52s/it]
[INFO] Global step: 352, Cumulative rewards: 23.88348, Runtime (s): 566.98
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7460243701934814
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.108994245529175
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.839839220046997
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.661569595336914
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6230766773223877
average cummulative reward vector is:  [0.13171395 0.12615324 0.1389306  0.11516963 0.12744651]
average cummulative reward is:  0.12788278414932527
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 353, loss: 55227.28125
[INFO] Global_t: 353, Episode_t: 1, Action: 140, Reward: 1.29, Epsilon: 0.65
[INFO] model update: t: 354, loss: 37081.328125
[INFO] Global_t: 354, Episode_t: 2, Action: 91, Reward: 1.82, Epsilon: 0.64
[INFO] model update: t: 355, loss: 21230.734375
[INFO] Global_t: 355, Episode_t: 3, Action: 8, Reward: 3.07, Epsilon: 0.64
[INFO] model update: t: 356, loss: 23192.384765625
[INFO] Global_t: 356, Episode_t: 4, Action: 7, Reward: 4.26, Epsilon: 0.64
[INFO] model update: t: 357, loss: 30968.466796875
[INFO] Global_t: 357, Episode_t: 5, Action: 153, Reward: 1.57, Epsilon: 0.64
[INFO] model update: t: 358, loss: 90721.03125
[INFO] Global_t: 358, Episode_t: 6, Action: 142, Reward: 1.84, Epsilon: 0.64
[INFO] model update: t: 359, loss: 23658.6171875
[INFO] Global_t: 359, Episode_t: 7, Action: 148, Reward: 1.40, Epsilon: 0.64
[INFO] model update: t: 360, loss: 26478.96875
[INFO] Global_t: 360, Episode_t: 8, Action: 25, Reward: 3.44, Epsilon: 0.64
 18%|█▊        | 360/2000 [09:49<52:43,  1.93s/it]
[INFO] Global step: 360, Cumulative rewards: 18.68676, Runtime (s): 589.98
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 361, loss: 30334.626953125
[INFO] Global_t: 361, Episode_t: 1, Action: 93, Reward: 1.58, Epsilon: 0.64
[INFO] model update: t: 362, loss: 7964.14794921875
[INFO] Global_t: 362, Episode_t: 2, Action: 101, Reward: 1.29, Epsilon: 0.64
[INFO] model update: t: 363, loss: 24841.29296875
[INFO] Global_t: 363, Episode_t: 3, Action: 59, Reward: 2.15, Epsilon: 0.64
[INFO] model update: t: 364, loss: 22889.5234375
[INFO] Global_t: 364, Episode_t: 4, Action: 75, Reward: 1.67, Epsilon: 0.63
[INFO] model update: t: 365, loss: 10343.44140625
[INFO] Global_t: 365, Episode_t: 5, Action: 5, Reward: 4.18, Epsilon: 0.63
[INFO] model update: t: 366, loss: 28724.8359375
[INFO] Global_t: 366, Episode_t: 6, Action: 11, Reward: 3.11, Epsilon: 0.63
[INFO] model update: t: 367, loss: 25493.0625
[INFO] Global_t: 367, Episode_t: 7, Action: 4, Reward: 3.49, Epsilon: 0.63
[INFO] model update: t: 368, loss: 15326.375
[INFO] Global_t: 368, Episode_t: 8, Action: 2, Reward: 3.43, Epsilon: 0.63
 18%|█▊        | 368/2000 [09:57<44:36,  1.64s/it]
[INFO] Global step: 368, Cumulative rewards: 20.897640000000003, Runtime (s): 597.70
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7367284297943115
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8786568641662598
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.633854389190674
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8166086673736572
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.025757312774658
average cummulative reward vector is:  [0.13282921 0.12128032 0.13345683 0.12134977 0.14231183]
average cummulative reward is:  0.13024559190272245
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 369, loss: 17418.248046875
[INFO] Global_t: 369, Episode_t: 1, Action: 159, Reward: 1.27, Epsilon: 0.63
[INFO] model update: t: 370, loss: 30031.646484375
[INFO] Global_t: 370, Episode_t: 2, Action: 9, Reward: 4.60, Epsilon: 0.63
[INFO] model update: t: 371, loss: 27881.96875
[INFO] Global_t: 371, Episode_t: 3, Action: 2, Reward: 5.53, Epsilon: 0.63
[INFO] model update: t: 372, loss: 18399.71875
[INFO] Global_t: 372, Episode_t: 4, Action: 127, Reward: 1.09, Epsilon: 0.63
[INFO] model update: t: 373, loss: 16704.833984375
[INFO] Global_t: 373, Episode_t: 5, Action: 36, Reward: 0.97, Epsilon: 0.63
[INFO] model update: t: 374, loss: 11689.0419921875
[INFO] Global_t: 374, Episode_t: 6, Action: 98, Reward: 1.22, Epsilon: 0.62
[INFO] model update: t: 375, loss: 33753.5546875
[INFO] Global_t: 375, Episode_t: 7, Action: 3, Reward: 4.24, Epsilon: 0.62
[INFO] model update: t: 376, loss: 40577.4296875
[INFO] Global_t: 376, Episode_t: 8, Action: 21, Reward: 2.06, Epsilon: 0.62
 19%|█▉        | 376/2000 [10:23<57:13,  2.11s/it]
[INFO] Global step: 376, Cumulative rewards: 20.97144, Runtime (s): 623.47
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 377, loss: 51812.6484375
[INFO] Global_t: 377, Episode_t: 1, Action: 5, Reward: 4.63, Epsilon: 0.62
[INFO] model update: t: 378, loss: 82808.765625
[INFO] Global_t: 378, Episode_t: 2, Action: 17, Reward: 3.75, Epsilon: 0.62
[INFO] model update: t: 379, loss: 28511.044921875
[INFO] Global_t: 379, Episode_t: 3, Action: 4, Reward: 3.72, Epsilon: 0.62
[INFO] model update: t: 380, loss: 110499.4609375
[INFO] Global_t: 380, Episode_t: 4, Action: 159, Reward: 1.59, Epsilon: 0.62
[INFO] model update: t: 381, loss: 32941.28125
[INFO] Global_t: 381, Episode_t: 5, Action: 181, Reward: 0.83, Epsilon: 0.62
[INFO] model update: t: 382, loss: 22501.849609375
[INFO] Global_t: 382, Episode_t: 6, Action: 74, Reward: 1.31, Epsilon: 0.62
[INFO] model update: t: 383, loss: 29903.787109375
[INFO] Global_t: 383, Episode_t: 7, Action: 73, Reward: 1.87, Epsilon: 0.62
[INFO] model update: t: 384, loss: 45061.66015625
[INFO] Global_t: 384, Episode_t: 8, Action: 54, Reward: 1.41, Epsilon: 0.61

 19%|█▉        | 384/2000 [10:29<45:51,  1.70s/it]6079999999998, Runtime (s): 629.40
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6294479370117188
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.068265438079834
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7410547733306885
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7566471099853516
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.579843282699585
average cummulative reward vector is:  [0.12977447 0.12462037 0.1391459  0.11822547 0.12476129]
average cummulative reward is:  0.12730550066124507
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 385, loss: 42348.7265625
[INFO] Global_t: 385, Episode_t: 1, Action: 141, Reward: 1.42, Epsilon: 0.61
[INFO] model update: t: 386, loss: 31381.560546875
[INFO] Global_t: 386, Episode_t: 2, Action: 145, Reward: 1.64, Epsilon: 0.61
[INFO] model update: t: 387, loss: 26518.646484375
[INFO] Global_t: 387, Episode_t: 3, Action: 16, Reward: 3.71, Epsilon: 0.61
[INFO] model update: t: 388, loss: 20787.521484375
[INFO] Global_t: 388, Episode_t: 4, Action: 33, Reward: 1.46, Epsilon: 0.61
[INFO] model update: t: 389, loss: 23031.630859375
[INFO] Global_t: 389, Episode_t: 5, Action: 12, Reward: 1.64, Epsilon: 0.61
[INFO] model update: t: 390, loss: 15055.150390625
[INFO] Global_t: 390, Episode_t: 6, Action: 11, Reward: 3.52, Epsilon: 0.61
[INFO] model update: t: 391, loss: 63640.9453125
[INFO] Global_t: 391, Episode_t: 7, Action: 102, Reward: 1.17, Epsilon: 0.61
[INFO] model update: t: 392, loss: 89212.7890625
[INFO] Global_t: 392, Episode_t: 8, Action: 5, Reward: 2.51, Epsilon: 0.61
 20%|█▉        | 392/2000 [10:58<1:01:31,  2.30s/it]
[INFO] Global step: 392, Cumulative rewards: 17.082720000000002, Runtime (s): 658.84
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 393, loss: 15997.201171875
[INFO] Global_t: 393, Episode_t: 1, Action: 87, Reward: 2.48, Epsilon: 0.61
[INFO] model update: t: 394, loss: 48713.35546875
[INFO] Global_t: 394, Episode_t: 2, Action: 5, Reward: 4.98, Epsilon: 0.60
[INFO] model update: t: 395, loss: 64578.296875
[INFO] Global_t: 395, Episode_t: 3, Action: 6, Reward: 4.19, Epsilon: 0.60
[INFO] model update: t: 396, loss: 19833.94921875
[INFO] Global_t: 396, Episode_t: 4, Action: 18, Reward: 3.77, Epsilon: 0.60
[INFO] model update: t: 397, loss: 26901.51953125
[INFO] Global_t: 397, Episode_t: 5, Action: 13, Reward: 2.01, Epsilon: 0.60
[INFO] model update: t: 398, loss: 32580.220703125
[INFO] Global_t: 398, Episode_t: 6, Action: 154, Reward: 1.40, Epsilon: 0.60
[INFO] model update: t: 399, loss: 34814.6875
[INFO] Global_t: 399, Episode_t: 7, Action: 17, Reward: 2.34, Epsilon: 0.60
[INFO] model update: t: 400, loss: 82357.640625
[INFO] Global_t: 400, Episode_t: 8, Action: 8, Reward: 2.56, Epsilon: 0.60
 20%|██        | 400/2000 [11:06<50:15,  1.88s/it]  
[INFO] Global step: 400, Cumulative rewards: 23.7216, Runtime (s): 666.25
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9492220878601074
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4530608654022217
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.732903242111206
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9707014560699463
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6547768115997314
average cummulative reward vector is:  [0.13529237 0.10709282 0.13864153 0.12208808 0.13314866]
average cummulative reward is:  0.12725269251517993
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 401, loss: 13623.076171875
[INFO] Global_t: 401, Episode_t: 1, Action: 150, Reward: 1.48, Epsilon: 0.60
[INFO] model update: t: 402, loss: 49822.2265625
[INFO] Global_t: 402, Episode_t: 2, Action: 7, Reward: 4.59, Epsilon: 0.60
[INFO] model update: t: 403, loss: 117018.0078125
[INFO] Global_t: 403, Episode_t: 3, Action: 207, Reward: 1.29, Epsilon: 0.60
[INFO] model update: t: 404, loss: 55504.53125
[INFO] Global_t: 404, Episode_t: 4, Action: 87, Reward: 2.07, Epsilon: 0.60
[INFO] model update: t: 405, loss: 33118.3359375
[INFO] Global_t: 405, Episode_t: 5, Action: 9, Reward: 4.48, Epsilon: 0.59
[INFO] model update: t: 406, loss: 106277.15625
[INFO] Global_t: 406, Episode_t: 6, Action: 12, Reward: 4.00, Epsilon: 0.59
[INFO] model update: t: 407, loss: 8085.552734375
[INFO] Global_t: 407, Episode_t: 7, Action: 26, Reward: 1.38, Epsilon: 0.59
[INFO] model update: t: 408, loss: 156758.515625
[INFO] Global_t: 408, Episode_t: 8, Action: 120, Reward: 1.78, Epsilon: 0.59
 20%|██        | 408/2000 [11:31<59:45,  2.25s/it]
[INFO] Global step: 408, Cumulative rewards: 21.075480000000002, Runtime (s): 691.13
------------------------------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 409, loss: 51930.38671875
[INFO] Global_t: 409, Episode_t: 1, Action: 6, Reward: 4.42, Epsilon: 0.59
[INFO] model update: t: 410, loss: 93581.046875
[INFO] Global_t: 410, Episode_t: 2, Action: 26, Reward: 2.97, Epsilon: 0.59
[INFO] model update: t: 411, loss: 108623.9296875
[INFO] Global_t: 411, Episode_t: 3, Action: 165, Reward: 1.64, Epsilon: 0.59
[INFO] model update: t: 412, loss: 23032.25
[INFO] Global_t: 412, Episode_t: 4, Action: 21, Reward: 3.79, Epsilon: 0.59
[INFO] model update: t: 413, loss: 125035.890625
[INFO] Global_t: 413, Episode_t: 5, Action: 156, Reward: 1.58, Epsilon: 0.59
[INFO] model update: t: 414, loss: 16972.20703125
[INFO] Global_t: 414, Episode_t: 6, Action: 12, Reward: 2.53, Epsilon: 0.59
[INFO] model update: t: 415, loss: 220082.328125
[INFO] Global_t: 415, Episode_t: 7, Action: 144, Reward: 1.15, Epsilon: 0.58
[INFO] model update: t: 416, loss: 92176.71875
[INFO] Global_t: 416, Episode_t: 8, Action: 134, Reward: 1.16, Epsilon: 0.58

[INFO] Global step: 416, Cumulative rewards: 19.249079999999996, Runtime (s): 698.16
------------------------------------------------------------
 
 21%|██        | 416/2000 [11:38<48:34,  1.84s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.795987129211426
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6432840824127197
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7067909240722656
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9227383136749268
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.623413324356079
average cummulative reward vector is:  [0.13153895 0.11341343 0.13507186 0.12408435 0.13133333]
average cummulative reward is:  0.12708838206911405
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 417, loss: 79643.2421875
[INFO] Global_t: 417, Episode_t: 1, Action: 20, Reward: 4.03, Epsilon: 0.58
[INFO] model update: t: 418, loss: 168357.5625
[INFO] Global_t: 418, Episode_t: 2, Action: 16, Reward: 4.13, Epsilon: 0.58
[INFO] model update: t: 419, loss: 21271.29296875
[INFO] Global_t: 419, Episode_t: 3, Action: 149, Reward: 1.66, Epsilon: 0.58
[INFO] model update: t: 420, loss: 270223.59375
[INFO] Global_t: 420, Episode_t: 4, Action: 77, Reward: 1.59, Epsilon: 0.58
[INFO] model update: t: 421, loss: 225550.0
[INFO] Global_t: 421, Episode_t: 5, Action: 24, Reward: 3.49, Epsilon: 0.58
[INFO] model update: t: 422, loss: 88660.609375
[INFO] Global_t: 422, Episode_t: 6, Action: 36, Reward: 1.63, Epsilon: 0.58
[INFO] model update: t: 423, loss: 273478.78125
[INFO] Global_t: 423, Episode_t: 7, Action: 17, Reward: 3.15, Epsilon: 0.58
[INFO] model update: t: 424, loss: 6904.91943359375
[INFO] Global_t: 424, Episode_t: 8, Action: 59, Reward: 1.75, Epsilon: 0.58
 21%|██        | 424/2000 [12:01<57:00,  2.17s/it]
[INFO] Global step: 424, Cumulative rewards: 21.424079999999996, Runtime (s): 721.69
------------------------------------------------------------
 
graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 425, loss: 426427.9375
[INFO] Global_t: 425, Episode_t: 1, Action: 8, Reward: 4.54, Epsilon: 0.57
[INFO] model update: t: 426, loss: 485482.90625
[INFO] Global_t: 426, Episode_t: 2, Action: 4, Reward: 4.63, Epsilon: 0.57
[INFO] model update: t: 427, loss: 250604.109375
[INFO] Global_t: 427, Episode_t: 3, Action: 142, Reward: 2.16, Epsilon: 0.57
[INFO] model update: t: 428, loss: 1325958.75
[INFO] Global_t: 428, Episode_t: 4, Action: 9, Reward: 3.83, Epsilon: 0.57
[INFO] model update: t: 429, loss: 352922.75
[INFO] Global_t: 429, Episode_t: 5, Action: 134, Reward: 1.05, Epsilon: 0.57
[INFO] model update: t: 430, loss: 500514.75
[INFO] Global_t: 430, Episode_t: 6, Action: 141, Reward: 0.81, Epsilon: 0.57
[INFO] model update: t: 431, loss: 931342.75
[INFO] Global_t: 431, Episode_t: 7, Action: 7, Reward: 3.48, Epsilon: 0.57
[INFO] model update: t: 432, loss: 33119.1484375
[INFO] Global_t: 432, Episode_t: 8, Action: 42, Reward: 2.07, Epsilon: 0.57
 22%|██▏       | 432/2000 [12:07<45:35,  1.74s/it]
[INFO] Global step: 432, Cumulative rewards: 22.576800000000002, Runtime (s): 727.69
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.950336217880249
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9415717124938965
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7520506381988525
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3327338695526123
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6465766429901123
average cummulative reward vector is:  [0.13195789 0.12100764 0.13759372 0.10454673 0.13429059]
average cummulative reward is:  0.12587931396850754
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 433, loss: 689892.75
[INFO] Global_t: 433, Episode_t: 1, Action: 74, Reward: 2.27, Epsilon: 0.57
[INFO] model update: t: 434, loss: 667312.125
[INFO] Global_t: 434, Episode_t: 2, Action: 119, Reward: 1.30, Epsilon: 0.57
[INFO] model update: t: 435, loss: 15982.53125
[INFO] Global_t: 435, Episode_t: 3, Action: 11, Reward: 4.03, Epsilon: 0.56
[INFO] model update: t: 436, loss: 515373.9375
[INFO] Global_t: 436, Episode_t: 4, Action: 19, Reward: 3.46, Epsilon: 0.56
[INFO] model update: t: 437, loss: 242511.5
[INFO] Global_t: 437, Episode_t: 5, Action: 5, Reward: 2.31, Epsilon: 0.56
[INFO] model update: t: 438, loss: 108361.21875
[INFO] Global_t: 438, Episode_t: 6, Action: 103, Reward: 1.19, Epsilon: 0.56
[INFO] model update: t: 439, loss: 201784.46875
[INFO] Global_t: 439, Episode_t: 7, Action: 64, Reward: 1.59, Epsilon: 0.56
[INFO] model update: t: 440, loss: 39152.9296875
[INFO] Global_t: 440, Episode_t: 8, Action: 1, Reward: 2.91, Epsilon: 0.56
 22%|██▏       | 440/2000 [12:31<55:19,  2.13s/it]
[INFO] Global step: 440, Cumulative rewards: 19.060919999999996, Runtime (s): 751.86
------------------------------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 441, loss: 131514.84375
[INFO] Global_t: 441, Episode_t: 1, Action: 138, Reward: 1.34, Epsilon: 0.56
[INFO] model update: t: 442, loss: 104204.3828125
[INFO] Global_t: 442, Episode_t: 2, Action: 103, Reward: 1.85, Epsilon: 0.56
[INFO] model update: t: 443, loss: 80664.0234375
[INFO] Global_t: 443, Episode_t: 3, Action: 87, Reward: 2.63, Epsilon: 0.56
[INFO] model update: t: 444, loss: 275535.8125
[INFO] Global_t: 444, Episode_t: 4, Action: 172, Reward: 1.15, Epsilon: 0.56
[INFO] model update: t: 445, loss: 90569.59375
[INFO] Global_t: 445, Episode_t: 5, Action: 12, Reward: 4.02, Epsilon: 0.55
[INFO] model update: t: 446, loss: 97848.09375
[INFO] Global_t: 446, Episode_t: 6, Action: 6, Reward: 3.91, Epsilon: 0.55
[INFO] model update: t: 447, loss: 213853.328125
[INFO] Global_t: 447, Episode_t: 7, Action: 160, Reward: 1.36, Epsilon: 0.55
[INFO] model update: t: 448, loss: 14764.5673828125
[INFO] Global_t: 448, Episode_t: 8, Action: 13, Reward: 3.60, Epsilon: 0.55
 22%|██▏       | 448/2000 [12:35<42:15,  1.63s/it]
[INFO] Global step: 448, Cumulative rewards: 19.85844, Runtime (s): 755.71
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.640185832977295
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8834874629974365
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4954135417938232
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6006505489349365
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.638132095336914
average cummulative reward vector is:  [0.12877842 0.1181125  0.13022404 0.10581145 0.13196586]
average cummulative reward is:  0.12297845471633265
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 449, loss: 246119.875
[INFO] Global_t: 449, Episode_t: 1, Action: 0, Reward: 4.91, Epsilon: 0.55
[INFO] model update: t: 450, loss: 141725.1875
[INFO] Global_t: 450, Episode_t: 2, Action: 116, Reward: 1.31, Epsilon: 0.55
[INFO] model update: t: 451, loss: 25594.353515625
[INFO] Global_t: 451, Episode_t: 3, Action: 81, Reward: 1.68, Epsilon: 0.55
[INFO] model update: t: 452, loss: 77730.4921875
[INFO] Global_t: 452, Episode_t: 4, Action: 130, Reward: 1.00, Epsilon: 0.55
[INFO] model update: t: 453, loss: 106744.4921875
[INFO] Global_t: 453, Episode_t: 5, Action: 108, Reward: 1.18, Epsilon: 0.55
[INFO] model update: t: 454, loss: 17780.091796875
[INFO] Global_t: 454, Episode_t: 6, Action: 1, Reward: 3.34, Epsilon: 0.55
[INFO] model update: t: 455, loss: 132491.9375
[INFO] Global_t: 455, Episode_t: 7, Action: 8, Reward: 3.04, Epsilon: 0.55
[INFO] model update: t: 456, loss: 124476.71875
[INFO] Global_t: 456, Episode_t: 8, Action: 32, Reward: 1.95, Epsilon: 0.54
 23%|██▎       | 456/2000 [12:58<51:26,  2.00s/it]
[INFO] Global step: 456, Cumulative rewards: 18.407400000000003, Runtime (s): 778.53
------------------------------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 457, loss: 9768.541015625
[INFO] Global_t: 457, Episode_t: 1, Action: 4, Reward: 4.59, Epsilon: 0.54
[INFO] model update: t: 458, loss: 41789.8125
[INFO] Global_t: 458, Episode_t: 2, Action: 1, Reward: 4.84, Epsilon: 0.54
[INFO] model update: t: 459, loss: 14175.986328125
[INFO] Global_t: 459, Episode_t: 3, Action: 18, Reward: 3.37, Epsilon: 0.54
[INFO] model update: t: 460, loss: 59280.25
[INFO] Global_t: 460, Episode_t: 4, Action: 58, Reward: 1.95, Epsilon: 0.54
[INFO] model update: t: 461, loss: 39652.1015625
[INFO] Global_t: 461, Episode_t: 5, Action: 94, Reward: 1.16, Epsilon: 0.54
[INFO] model update: t: 462, loss: 7831.017578125
[INFO] Global_t: 462, Episode_t: 6, Action: 70, Reward: 0.71, Epsilon: 0.54
[INFO] model update: t: 463, loss: 29313.90625
[INFO] Global_t: 463, Episode_t: 7, Action: 7, Reward: 3.20, Epsilon: 0.54
[INFO] model update: t: 464, loss: 23001.578125
[INFO] Global_t: 464, Episode_t: 8, Action: 30, Reward: 2.84, Epsilon: 0.54
 23%|██▎       | 464/2000 [13:04<41:28,  1.62s/it]
[INFO] Global step: 464, Cumulative rewards: 22.666679999999996, Runtime (s): 784.41
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4965274333953857
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.014135360717773
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5743398666381836
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6738476753234863
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8502604961395264
average cummulative reward vector is:  [0.12182711 0.12152315 0.13217022 0.11496379 0.13209704]
average cummulative reward is:  0.12451626000960454
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 465, loss: 40347.02734375
[INFO] Global_t: 465, Episode_t: 1, Action: 189, Reward: 1.71, Epsilon: 0.54
[INFO] model update: t: 466, loss: 70265.8203125
[INFO] Global_t: 466, Episode_t: 2, Action: 30, Reward: 2.73, Epsilon: 0.53
[INFO] model update: t: 467, loss: 15098.7705078125
[INFO] Global_t: 467, Episode_t: 3, Action: 4, Reward: 4.26, Epsilon: 0.53
[INFO] model update: t: 468, loss: 24130.7578125
[INFO] Global_t: 468, Episode_t: 4, Action: 0, Reward: 4.44, Epsilon: 0.53
[INFO] model update: t: 469, loss: 51504.84375
[INFO] Global_t: 469, Episode_t: 5, Action: 89, Reward: 1.22, Epsilon: 0.53
[INFO] model update: t: 470, loss: 20539.76953125
[INFO] Global_t: 470, Episode_t: 6, Action: 37, Reward: 2.41, Epsilon: 0.53
[INFO] model update: t: 471, loss: 51717.23828125
[INFO] Global_t: 471, Episode_t: 7, Action: 105, Reward: 1.73, Epsilon: 0.53
[INFO] model update: t: 472, loss: 23768.166015625
[INFO] Global_t: 472, Episode_t: 8, Action: 24, Reward: 2.36, Epsilon: 0.53
 24%|██▎       | 472/2000 [13:27<51:22,  2.02s/it]
[INFO] Global step: 472, Cumulative rewards: 20.850479999999997, Runtime (s): 807.97
------------------------------------------------------------
 
graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 473, loss: 17671.302734375
[INFO] Global_t: 473, Episode_t: 1, Action: 96, Reward: 1.34, Epsilon: 0.53
[INFO] model update: t: 474, loss: 13190.1171875
[INFO] Global_t: 474, Episode_t: 2, Action: 43, Reward: 2.03, Epsilon: 0.53
[INFO] model update: t: 475, loss: 18288.216796875
[INFO] Global_t: 475, Episode_t: 3, Action: 174, Reward: 1.50, Epsilon: 0.53
[INFO] model update: t: 476, loss: 21243.55859375
[INFO] Global_t: 476, Episode_t: 4, Action: 3, Reward: 4.91, Epsilon: 0.52
[INFO] model update: t: 477, loss: 18801.298828125
[INFO] Global_t: 477, Episode_t: 5, Action: 122, Reward: 1.44, Epsilon: 0.52
[INFO] model update: t: 478, loss: 35314.51171875
[INFO] Global_t: 478, Episode_t: 6, Action: 4, Reward: 3.88, Epsilon: 0.52
[INFO] model update: t: 479, loss: 50168.85546875
[INFO] Global_t: 479, Episode_t: 7, Action: 45, Reward: 3.36, Epsilon: 0.52
[INFO] model update: t: 480, loss: 27652.90625
[INFO] Global_t: 480, Episode_t: 8, Action: 172, Reward: 1.27, Epsilon: 0.52
 24%|██▍       | 480/2000 [13:31<39:19,  1.55s/it]
[INFO] Global step: 480, Cumulative rewards: 19.7232, Runtime (s): 811.70
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.970031261444092
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7823739051818848
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8948440551757812
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.82686448097229
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5749621391296387
average cummulative reward vector is:  [0.14076211 0.11806458 0.13976967 0.11903715 0.13011344]
average cummulative reward is:  0.12954939022411283
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 481, loss: 66631.203125
[INFO] Global_t: 481, Episode_t: 1, Action: 98, Reward: 1.35, Epsilon: 0.52
[INFO] model update: t: 482, loss: 17466.16796875
[INFO] Global_t: 482, Episode_t: 2, Action: 54, Reward: 2.02, Epsilon: 0.52
[INFO] model update: t: 483, loss: 27469.0546875
[INFO] Global_t: 483, Episode_t: 3, Action: 2, Reward: 4.04, Epsilon: 0.52
[INFO] model update: t: 484, loss: 42719.828125
[INFO] Global_t: 484, Episode_t: 4, Action: 79, Reward: 1.48, Epsilon: 0.52
[INFO] model update: t: 485, loss: 9672.119140625
[INFO] Global_t: 485, Episode_t: 5, Action: 7, Reward: 2.72, Epsilon: 0.52
[INFO] model update: t: 486, loss: 59959.28515625
[INFO] Global_t: 486, Episode_t: 6, Action: 81, Reward: 1.57, Epsilon: 0.51
[INFO] model update: t: 487, loss: 25212.16796875
[INFO] Global_t: 487, Episode_t: 7, Action: 6, Reward: 2.79, Epsilon: 0.51
[INFO] model update: t: 488, loss: 15274.6328125
[INFO] Global_t: 488, Episode_t: 8, Action: 0, Reward: 2.93, Epsilon: 0.51
 24%|██▍       | 488/2000 [13:55<49:47,  1.98s/it]
[INFO] Global step: 488, Cumulative rewards: 18.898799999999998, Runtime (s): 835.42
------------------------------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 489, loss: 25990.189453125
[INFO] Global_t: 489, Episode_t: 1, Action: 1, Reward: 5.64, Epsilon: 0.51
[INFO] model update: t: 490, loss: 11983.103515625
[INFO] Global_t: 490, Episode_t: 2, Action: 142, Reward: 1.48, Epsilon: 0.51
[INFO] model update: t: 491, loss: 26691.81640625
[INFO] Global_t: 491, Episode_t: 3, Action: 87, Reward: 2.01, Epsilon: 0.51
[INFO] model update: t: 492, loss: 32802.5625
[INFO] Global_t: 492, Episode_t: 4, Action: 69, Reward: 2.03, Epsilon: 0.51
[INFO] model update: t: 493, loss: 18113.2421875
[INFO] Global_t: 493, Episode_t: 5, Action: 15, Reward: 3.07, Epsilon: 0.51
[INFO] model update: t: 494, loss: 59085.9296875
[INFO] Global_t: 494, Episode_t: 6, Action: 42, Reward: 3.09, Epsilon: 0.51
[INFO] model update: t: 495, loss: 64819.52734375
[INFO] Global_t: 495, Episode_t: 7, Action: 132, Reward: 1.33, Epsilon: 0.51
[INFO] model update: t: 496, loss: 62460.828125
[INFO] Global_t: 496, Episode_t: 8, Action: 60, Reward: 1.54, Epsilon: 0.50
 25%|██▍       | 496/2000 [14:01<40:08,  1.60s/it]
[INFO] Global step: 496, Cumulative rewards: 20.19768, Runtime (s): 841.24
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.788120985031128
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.056812286376953
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.750854253768921
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4222359657287598
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.768453359603882
average cummulative reward vector is:  [0.12963184 0.12324583 0.13549044 0.10801752 0.13868414]
average cummulative reward is:  0.12701395514929975
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 497, loss: 17359.90625
[INFO] Global_t: 497, Episode_t: 1, Action: 178, Reward: 1.31, Epsilon: 0.50
[INFO] model update: t: 498, loss: 33977.23046875
[INFO] Global_t: 498, Episode_t: 2, Action: 0, Reward: 4.72, Epsilon: 0.50
[INFO] model update: t: 499, loss: 43227.58984375
[INFO] Global_t: 499, Episode_t: 3, Action: 153, Reward: 1.00, Epsilon: 0.50
[INFO] model update: t: 500, loss: 25707.107421875
[INFO] Global_t: 500, Episode_t: 4, Action: 83, Reward: 1.82, Epsilon: 0.50
[INFO] model update: t: 501, loss: 33348.3359375
[INFO] Global_t: 501, Episode_t: 5, Action: 15, Reward: 2.54, Epsilon: 0.50
[INFO] model update: t: 502, loss: 13985.2578125
[INFO] Global_t: 502, Episode_t: 6, Action: 3, Reward: 3.10, Epsilon: 0.50
[INFO] model update: t: 503, loss: 13818.5263671875
[INFO] Global_t: 503, Episode_t: 7, Action: 16, Reward: 2.68, Epsilon: 0.50
[INFO] model update: t: 504, loss: 23607.296875
[INFO] Global_t: 504, Episode_t: 8, Action: 8, Reward: 2.77, Epsilon: 0.50
 25%|██▌       | 504/2000 [14:24<49:19,  1.98s/it]
[INFO] Global step: 504, Cumulative rewards: 19.93512, Runtime (s): 864.11
------------------------------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 505, loss: 4859.32421875
[INFO] Global_t: 505, Episode_t: 1, Action: 6, Reward: 4.72, Epsilon: 0.50
[INFO] model update: t: 506, loss: 14793.83984375
[INFO] Global_t: 506, Episode_t: 2, Action: 0, Reward: 3.78, Epsilon: 0.50
[INFO] model update: t: 507, loss: 20115.05078125
[INFO] Global_t: 507, Episode_t: 3, Action: 145, Reward: 1.95, Epsilon: 0.49
[INFO] model update: t: 508, loss: 24740.75390625
[INFO] Global_t: 508, Episode_t: 4, Action: 15, Reward: 3.85, Epsilon: 0.49
[INFO] model update: t: 509, loss: 12149.77734375
[INFO] Global_t: 509, Episode_t: 5, Action: 4, Reward: 2.16, Epsilon: 0.49
[INFO] model update: t: 510, loss: 83367.421875
[INFO] Global_t: 510, Episode_t: 6, Action: 88, Reward: 1.37, Epsilon: 0.49
[INFO] model update: t: 511, loss: 82140.53125
[INFO] Global_t: 511, Episode_t: 7, Action: 133, Reward: 1.37, Epsilon: 0.49
[INFO] model update: t: 512, loss: 42927.41015625
[INFO] Global_t: 512, Episode_t: 8, Action: 174, Reward: 0.97, Epsilon: 0.49
 26%|██▌       | 512/2000 [14:29<39:03,  1.57s/it]
[INFO] Global step: 512, Cumulative rewards: 20.1624, Runtime (s): 869.17
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7221860885620117
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.982084274291992
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.666735887527466
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.840855598449707
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.739772319793701
average cummulative reward vector is:  [0.12809684 0.11963843 0.13296858 0.11168341 0.135975  ]
average cummulative reward is:  0.12567245169622301
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 513, loss: 193726.9375
[INFO] Global_t: 513, Episode_t: 1, Action: 112, Reward: 2.03, Epsilon: 0.49
[INFO] model update: t: 514, loss: 34239.375
[INFO] Global_t: 514, Episode_t: 2, Action: 67, Reward: 2.94, Epsilon: 0.49
[INFO] model update: t: 515, loss: 178206.75
[INFO] Global_t: 515, Episode_t: 3, Action: 19, Reward: 2.40, Epsilon: 0.49
[INFO] model update: t: 516, loss: 613680.1875
[INFO] Global_t: 516, Episode_t: 4, Action: 9, Reward: 3.85, Epsilon: 0.49
[INFO] model update: t: 517, loss: 496968.03125
[INFO] Global_t: 517, Episode_t: 5, Action: 0, Reward: 4.29, Epsilon: 0.48
[INFO] model update: t: 518, loss: 35910.28515625
[INFO] Global_t: 518, Episode_t: 6, Action: 4, Reward: 5.63, Epsilon: 0.48
[INFO] model update: t: 519, loss: 163195.4375
[INFO] Global_t: 519, Episode_t: 7, Action: 2, Reward: 4.19, Epsilon: 0.48
[INFO] model update: t: 520, loss: 190260.609375
[INFO] Global_t: 520, Episode_t: 8, Action: 7, Reward: 3.15, Epsilon: 0.48
 26%|██▌       | 520/2000 [14:52<49:02,  1.99s/it]
[INFO] Global step: 520, Cumulative rewards: 28.48512, Runtime (s): 892.80
------------------------------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 521, loss: 50357.20703125
[INFO] Global_t: 521, Episode_t: 1, Action: 8, Reward: 5.06, Epsilon: 0.48
[INFO] model update: t: 522, loss: 341900.4375
[INFO] Global_t: 522, Episode_t: 2, Action: 4, Reward: 5.04, Epsilon: 0.48
[INFO] model update: t: 523, loss: 69642.28125
[INFO] Global_t: 523, Episode_t: 3, Action: 203, Reward: 1.13, Epsilon: 0.48
[INFO] model update: t: 524, loss: 125153.5625
[INFO] Global_t: 524, Episode_t: 4, Action: 87, Reward: 1.09, Epsilon: 0.48
[INFO] model update: t: 525, loss: 240752.578125
[INFO] Global_t: 525, Episode_t: 5, Action: 13, Reward: 3.30, Epsilon: 0.48
[INFO] model update: t: 526, loss: 64459.8359375
[INFO] Global_t: 526, Episode_t: 6, Action: 10, Reward: 3.46, Epsilon: 0.48
[INFO] model update: t: 527, loss: 32861.609375
[INFO] Global_t: 527, Episode_t: 7, Action: 11, Reward: 3.60, Epsilon: 0.47
[INFO] model update: t: 528, loss: 121068.2421875
[INFO] Global_t: 528, Episode_t: 8, Action: 6, Reward: 2.86, Epsilon: 0.47
 26%|██▋       | 528/2000 [14:57<38:30,  1.57s/it]
[INFO] Global step: 528, Cumulative rewards: 25.5402, Runtime (s): 897.54
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.369462728500366
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.891556739807129
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6443326473236084
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7502543926239014
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.751237154006958
average cummulative reward vector is:  [0.12090132 0.11890972 0.13372678 0.11787079 0.12633038]
average cummulative reward is:  0.12354779694091789
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 529, loss: 56256.3203125
[INFO] Global_t: 529, Episode_t: 1, Action: 182, Reward: 1.23, Epsilon: 0.47
[INFO] model update: t: 530, loss: 10239.470703125
[INFO] Global_t: 530, Episode_t: 2, Action: 3, Reward: 5.54, Epsilon: 0.47
[INFO] model update: t: 531, loss: 90320.7734375
[INFO] Global_t: 531, Episode_t: 3, Action: 12, Reward: 3.23, Epsilon: 0.47
[INFO] model update: t: 532, loss: 179414.125
[INFO] Global_t: 532, Episode_t: 4, Action: 134, Reward: 1.47, Epsilon: 0.47
[INFO] model update: t: 533, loss: 164866.328125
[INFO] Global_t: 533, Episode_t: 5, Action: 139, Reward: 1.25, Epsilon: 0.47
[INFO] model update: t: 534, loss: 25673.953125
[INFO] Global_t: 534, Episode_t: 6, Action: 76, Reward: 1.13, Epsilon: 0.47
[INFO] model update: t: 535, loss: 41099.6953125
[INFO] Global_t: 535, Episode_t: 7, Action: 2, Reward: 2.26, Epsilon: 0.47
[INFO] model update: t: 536, loss: 53690.375
[INFO] Global_t: 536, Episode_t: 8, Action: 20, Reward: 1.46, Epsilon: 0.47
 27%|██▋       | 536/2000 [15:21<48:20,  1.98s/it]
[INFO] Global step: 536, Cumulative rewards: 17.55492, Runtime (s): 921.08
------------------------------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 537, loss: 27782.5078125
[INFO] Global_t: 537, Episode_t: 1, Action: 76, Reward: 1.59, Epsilon: 0.46
[INFO] model update: t: 538, loss: 23389.087890625
[INFO] Global_t: 538, Episode_t: 2, Action: 61, Reward: 2.02, Epsilon: 0.46
[INFO] model update: t: 539, loss: 123156.1875
[INFO] Global_t: 539, Episode_t: 3, Action: 6, Reward: 3.87, Epsilon: 0.46
[INFO] model update: t: 540, loss: 257256.65625
[INFO] Global_t: 540, Episode_t: 4, Action: 83, Reward: 2.08, Epsilon: 0.46
[INFO] model update: t: 541, loss: 212330.609375
[INFO] Global_t: 541, Episode_t: 5, Action: 5, Reward: 3.46, Epsilon: 0.46
[INFO] model update: t: 542, loss: 23259.373046875
[INFO] Global_t: 542, Episode_t: 6, Action: 42, Reward: 2.85, Epsilon: 0.46
[INFO] model update: t: 543, loss: 69671.15625
[INFO] Global_t: 543, Episode_t: 7, Action: 14, Reward: 1.82, Epsilon: 0.46
[INFO] model update: t: 544, loss: 112636.046875
[INFO] Global_t: 544, Episode_t: 8, Action: 87, Reward: 1.74, Epsilon: 0.46
 27%|██▋       | 544/2000 [15:24<37:02,  1.53s/it]
[INFO] Global step: 544, Cumulative rewards: 19.422839999999997, Runtime (s): 924.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9076406955718994
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.153017044067383
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8525242805480957
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.550443410873413
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.789614200592041
average cummulative reward vector is:  [0.13905184 0.12526921 0.13874044 0.1108472  0.13367231]
average cummulative reward is:  0.12951620006326708
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 545, loss: 14157.392578125
[INFO] Global_t: 545, Episode_t: 1, Action: 195, Reward: 1.32, Epsilon: 0.46
[INFO] model update: t: 546, loss: 91671.3203125
[INFO] Global_t: 546, Episode_t: 2, Action: 165, Reward: 1.36, Epsilon: 0.46
[INFO] model update: t: 547, loss: 160939.4375
[INFO] Global_t: 547, Episode_t: 3, Action: 86, Reward: 1.53, Epsilon: 0.45
[INFO] model update: t: 548, loss: 72405.6328125
[INFO] Global_t: 548, Episode_t: 4, Action: 3, Reward: 4.83, Epsilon: 0.45
[INFO] model update: t: 549, loss: 14288.9619140625
[INFO] Global_t: 549, Episode_t: 5, Action: 68, Reward: 1.23, Epsilon: 0.45
[INFO] model update: t: 550, loss: 75805.3828125
[INFO] Global_t: 550, Episode_t: 6, Action: 27, Reward: 1.95, Epsilon: 0.45
[INFO] model update: t: 551, loss: 140912.65625
[INFO] Global_t: 551, Episode_t: 7, Action: 10, Reward: 3.33, Epsilon: 0.45
[INFO] model update: t: 552, loss: 8080.65478515625
[INFO] Global_t: 552, Episode_t: 8, Action: 137, Reward: 1.64, Epsilon: 0.45
 28%|██▊       | 552/2000 [15:48<47:10,  1.95s/it]
[INFO] Global step: 552, Cumulative rewards: 17.18328, Runtime (s): 948.43
------------------------------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 553, loss: 148184.46875
[INFO] Global_t: 553, Episode_t: 1, Action: 172, Reward: 1.33, Epsilon: 0.45
[INFO] model update: t: 554, loss: 82764.9453125
[INFO] Global_t: 554, Episode_t: 2, Action: 11, Reward: 4.51, Epsilon: 0.45
[INFO] model update: t: 555, loss: 7731.83935546875
[INFO] Global_t: 555, Episode_t: 3, Action: 73, Reward: 2.14, Epsilon: 0.45
[INFO] model update: t: 556, loss: 17986.13671875
[INFO] Global_t: 556, Episode_t: 4, Action: 18, Reward: 3.91, Epsilon: 0.45
[INFO] model update: t: 557, loss: 22699.08984375
[INFO] Global_t: 557, Episode_t: 5, Action: 9, Reward: 3.06, Epsilon: 0.45
[INFO] model update: t: 558, loss: 8474.169921875
[INFO] Global_t: 558, Episode_t: 6, Action: 176, Reward: 1.04, Epsilon: 0.44
[INFO] model update: t: 559, loss: 21521.1171875
[INFO] Global_t: 559, Episode_t: 7, Action: 22, Reward: 2.20, Epsilon: 0.44
[INFO] model update: t: 560, loss: 17250.3359375
[INFO] Global_t: 560, Episode_t: 8, Action: 185, Reward: 1.40, Epsilon: 0.44
 28%|██▊       | 560/2000 [15:52<36:50,  1.53s/it]
[INFO] Global step: 560, Cumulative rewards: 19.58688, Runtime (s): 952.88
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.956378221511841
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8564293384552
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9719247817993164
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9589247703552246
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4316420555114746
average cummulative reward vector is:  [0.13813368 0.11984144 0.14224863 0.12205023 0.12055081]
average cummulative reward is:  0.12856495867439313
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 561, loss: 10076.7900390625
[INFO] Global_t: 561, Episode_t: 1, Action: 158, Reward: 1.29, Epsilon: 0.44
[INFO] model update: t: 562, loss: 21884.14453125
[INFO] Global_t: 562, Episode_t: 2, Action: 2, Reward: 4.63, Epsilon: 0.44
[INFO] model update: t: 563, loss: 11411.29296875
[INFO] Global_t: 563, Episode_t: 3, Action: 30, Reward: 3.28, Epsilon: 0.44
[INFO] model update: t: 564, loss: 19319.94140625
[INFO] Global_t: 564, Episode_t: 4, Action: 17, Reward: 3.84, Epsilon: 0.44
[INFO] model update: t: 565, loss: 66067.8515625
[INFO] Global_t: 565, Episode_t: 5, Action: 12, Reward: 2.23, Epsilon: 0.44
[INFO] model update: t: 566, loss: 9605.998046875
[INFO] Global_t: 566, Episode_t: 6, Action: 6, Reward: 2.61, Epsilon: 0.44
[INFO] model update: t: 567, loss: 43753.23828125
[INFO] Global_t: 567, Episode_t: 7, Action: 21, Reward: 2.59, Epsilon: 0.44
[INFO] model update: t: 568, loss: 48351.875
[INFO] Global_t: 568, Episode_t: 8, Action: 23, Reward: 2.12, Epsilon: 0.43
 28%|██▊       | 568/2000 [16:16<46:40,  1.96s/it]
[INFO] Global step: 568, Cumulative rewards: 22.59648, Runtime (s): 976.38
------------------------------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 569, loss: 34828.8828125
[INFO] Global_t: 569, Episode_t: 1, Action: 8, Reward: 5.05, Epsilon: 0.43
[INFO] model update: t: 570, loss: 73126.609375
[INFO] Global_t: 570, Episode_t: 2, Action: 111, Reward: 1.55, Epsilon: 0.43
[INFO] model update: t: 571, loss: 44928.609375
[INFO] Global_t: 571, Episode_t: 3, Action: 5, Reward: 4.60, Epsilon: 0.43
[INFO] model update: t: 572, loss: 34048.140625
[INFO] Global_t: 572, Episode_t: 4, Action: 1, Reward: 4.59, Epsilon: 0.43
[INFO] model update: t: 573, loss: 40950.7265625
[INFO] Global_t: 573, Episode_t: 5, Action: 15, Reward: 2.71, Epsilon: 0.43
[INFO] model update: t: 574, loss: 92761.0078125
[INFO] Global_t: 574, Episode_t: 6, Action: 7, Reward: 2.27, Epsilon: 0.43
[INFO] model update: t: 575, loss: 63552.86328125
[INFO] Global_t: 575, Episode_t: 7, Action: 3, Reward: 4.35, Epsilon: 0.43
[INFO] model update: t: 576, loss: 17887.0703125
[INFO] Global_t: 576, Episode_t: 8, Action: 13, Reward: 2.13, Epsilon: 0.43
 29%|██▉       | 576/2000 [16:21<36:58,  1.56s/it]
[INFO] Global step: 576, Cumulative rewards: 27.249119999999994, Runtime (s): 981.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7463934421539307
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.745779037475586
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.822521209716797
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.941422700881958
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.761998414993286
average cummulative reward vector is:  [0.13081553 0.11523171 0.14100301 0.11778294 0.1386578 ]
average cummulative reward is:  0.12869819687347833
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 577, loss: 17967.509765625
[INFO] Global_t: 577, Episode_t: 1, Action: 6, Reward: 4.75, Epsilon: 0.43
[INFO] model update: t: 578, loss: 49539.875
[INFO] Global_t: 578, Episode_t: 2, Action: 181, Reward: 1.09, Epsilon: 0.42
[INFO] model update: t: 579, loss: 49937.578125
[INFO] Global_t: 579, Episode_t: 3, Action: 107, Reward: 1.99, Epsilon: 0.42
[INFO] model update: t: 580, loss: 60698.8046875
[INFO] Global_t: 580, Episode_t: 4, Action: 4, Reward: 4.34, Epsilon: 0.42
[INFO] model update: t: 581, loss: 53580.70703125
[INFO] Global_t: 581, Episode_t: 5, Action: 190, Reward: 1.74, Epsilon: 0.42
[INFO] model update: t: 582, loss: 28649.31640625
[INFO] Global_t: 582, Episode_t: 6, Action: 5, Reward: 3.45, Epsilon: 0.42
[INFO] model update: t: 583, loss: 33671.82421875
[INFO] Global_t: 583, Episode_t: 7, Action: 153, Reward: 1.28, Epsilon: 0.42
[INFO] model update: t: 584, loss: 75238.609375
[INFO] Global_t: 584, Episode_t: 8, Action: 10, Reward: 2.74, Epsilon: 0.42
 29%|██▉       | 584/2000 [16:45<46:42,  1.98s/it]
[INFO] Global step: 584, Cumulative rewards: 21.37836, Runtime (s): 1005.12
------------------------------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 585, loss: 26541.1640625
[INFO] Global_t: 585, Episode_t: 1, Action: 2, Reward: 5.02, Epsilon: 0.42
[INFO] model update: t: 586, loss: 24959.115234375
[INFO] Global_t: 586, Episode_t: 2, Action: 129, Reward: 1.47, Epsilon: 0.42
[INFO] model update: t: 587, loss: 130456.984375
[INFO] Global_t: 587, Episode_t: 3, Action: 47, Reward: 2.76, Epsilon: 0.42
[INFO] model update: t: 588, loss: 107889.1484375
[INFO] Global_t: 588, Episode_t: 4, Action: 107, Reward: 1.67, Epsilon: 0.41
[INFO] model update: t: 589, loss: 10597.4296875
[INFO] Global_t: 589, Episode_t: 5, Action: 1, Reward: 3.40, Epsilon: 0.41
[INFO] model update: t: 590, loss: 75893.484375
[INFO] Global_t: 590, Episode_t: 6, Action: 10, Reward: 1.96, Epsilon: 0.41
[INFO] model update: t: 591, loss: 149938.625
[INFO] Global_t: 591, Episode_t: 7, Action: 8, Reward: 2.12, Epsilon: 0.41
[INFO] model update: t: 592, loss: 62598.0078125
[INFO] Global_t: 592, Episode_t: 8, Action: 13, Reward: 2.71, Epsilon: 0.41
 30%|██▉       | 592/2000 [16:51<38:06,  1.62s/it]
[INFO] Global step: 592, Cumulative rewards: 21.1128, Runtime (s): 1011.48
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.903043746948242
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.957314968109131
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5279541015625
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5155065059661865
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.633371591567993
average cummulative reward vector is:  [0.13571    0.12172083 0.12810656 0.10240467 0.13327312]
average cummulative reward is:  0.12424303637742973
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 593, loss: 17880.521484375
[INFO] Global_t: 593, Episode_t: 1, Action: 196, Reward: 1.17, Epsilon: 0.41
[INFO] model update: t: 594, loss: 125723.71875
[INFO] Global_t: 594, Episode_t: 2, Action: 32, Reward: 3.96, Epsilon: 0.41
[INFO] model update: t: 595, loss: 63119.40625
[INFO] Global_t: 595, Episode_t: 3, Action: 13, Reward: 5.32, Epsilon: 0.41
[INFO] model update: t: 596, loss: 33219.1171875
[INFO] Global_t: 596, Episode_t: 4, Action: 12, Reward: 4.07, Epsilon: 0.41
[INFO] model update: t: 597, loss: 208979.03125
[INFO] Global_t: 597, Episode_t: 5, Action: 180, Reward: 1.19, Epsilon: 0.41
[INFO] model update: t: 598, loss: 177499.875
[INFO] Global_t: 598, Episode_t: 6, Action: 198, Reward: 0.77, Epsilon: 0.40
[INFO] model update: t: 599, loss: 53723.79296875
[INFO] Global_t: 599, Episode_t: 7, Action: 0, Reward: 3.22, Epsilon: 0.40
[INFO] model update: t: 600, loss: 541058.25
[INFO] Global_t: 600, Episode_t: 8, Action: 65, Reward: 1.18, Epsilon: 0.40
 30%|███       | 600/2000 [17:15<47:50,  2.05s/it]
[INFO] Global step: 600, Cumulative rewards: 20.865959999999998, Runtime (s): 1035.84
------------------------------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 601, loss: 562013.6875
[INFO] Global_t: 601, Episode_t: 1, Action: 169, Reward: 2.06, Epsilon: 0.40
[INFO] model update: t: 602, loss: 13793.5234375
[INFO] Global_t: 602, Episode_t: 2, Action: 8, Reward: 4.09, Epsilon: 0.40
[INFO] model update: t: 603, loss: 434250.4375
[INFO] Global_t: 603, Episode_t: 3, Action: 27, Reward: 1.13, Epsilon: 0.40
[INFO] model update: t: 604, loss: 736655.625
[INFO] Global_t: 604, Episode_t: 4, Action: 50, Reward: 2.49, Epsilon: 0.40
[INFO] model update: t: 605, loss: 583854.8125
[INFO] Global_t: 605, Episode_t: 5, Action: 102, Reward: 1.04, Epsilon: 0.40
[INFO] model update: t: 606, loss: 71550.9375
[INFO] Global_t: 606, Episode_t: 6, Action: 193, Reward: 1.36, Epsilon: 0.40
[INFO] model update: t: 607, loss: 67090.7578125
[INFO] Global_t: 607, Episode_t: 7, Action: 2, Reward: 3.44, Epsilon: 0.40
[INFO] model update: t: 608, loss: 97959.4140625
[INFO] Global_t: 608, Episode_t: 8, Action: 136, Reward: 1.07, Epsilon: 0.40
 30%|███       | 608/2000 [17:20<37:25,  1.61s/it]
[INFO] Global step: 608, Cumulative rewards: 16.67832, Runtime (s): 1040.59
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6866607666015625
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7744596004486084
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5920395851135254
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8318521976470947
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6543214321136475
average cummulative reward vector is:  [0.13183053 0.11280602 0.13193087 0.11931706 0.12559919]
average cummulative reward is:  0.12429673375488026
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 609, loss: 41302.8046875
[INFO] Global_t: 609, Episode_t: 1, Action: 42, Reward: 3.15, Epsilon: 0.39
[INFO] model update: t: 610, loss: 6119.1103515625
[INFO] Global_t: 610, Episode_t: 2, Action: 6, Reward: 4.84, Epsilon: 0.39
[INFO] model update: t: 611, loss: 63626.01171875
[INFO] Global_t: 611, Episode_t: 3, Action: 101, Reward: 2.14, Epsilon: 0.39
[INFO] model update: t: 612, loss: 71649.390625
[INFO] Global_t: 612, Episode_t: 4, Action: 13, Reward: 3.85, Epsilon: 0.39
[INFO] model update: t: 613, loss: 5943.30517578125
[INFO] Global_t: 613, Episode_t: 5, Action: 12, Reward: 2.61, Epsilon: 0.39
[INFO] model update: t: 614, loss: 64857.9375
[INFO] Global_t: 614, Episode_t: 6, Action: 4, Reward: 2.27, Epsilon: 0.39
[INFO] model update: t: 615, loss: 152727.78125
[INFO] Global_t: 615, Episode_t: 7, Action: 7, Reward: 2.49, Epsilon: 0.39
[INFO] model update: t: 616, loss: 130229.6640625
[INFO] Global_t: 616, Episode_t: 8, Action: 5, Reward: 2.38, Epsilon: 0.39
 31%|███       | 616/2000 [17:44<46:36,  2.02s/it]
[INFO] Global step: 616, Cumulative rewards: 23.7396, Runtime (s): 1064.36
------------------------------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 617, loss: 24461.90234375
[INFO] Global_t: 617, Episode_t: 1, Action: 92, Reward: 2.32, Epsilon: 0.39
[INFO] model update: t: 618, loss: 75669.8515625
[INFO] Global_t: 618, Episode_t: 2, Action: 10, Reward: 4.70, Epsilon: 0.39
[INFO] model update: t: 619, loss: 196077.953125
[INFO] Global_t: 619, Episode_t: 3, Action: 152, Reward: 1.72, Epsilon: 0.38
[INFO] model update: t: 620, loss: 246510.078125
[INFO] Global_t: 620, Episode_t: 4, Action: 5, Reward: 4.28, Epsilon: 0.38
[INFO] model update: t: 621, loss: 157581.53125
[INFO] Global_t: 621, Episode_t: 5, Action: 7, Reward: 2.77, Epsilon: 0.38
[INFO] model update: t: 622, loss: 27621.30078125
[INFO] Global_t: 622, Episode_t: 6, Action: 18, Reward: 2.89, Epsilon: 0.38
[INFO] model update: t: 623, loss: 125446.578125
[INFO] Global_t: 623, Episode_t: 7, Action: 60, Reward: 1.31, Epsilon: 0.38
[INFO] model update: t: 624, loss: 113604.0
[INFO] Global_t: 624, Episode_t: 8, Action: 8, Reward: 2.36, Epsilon: 0.38
 31%|███       | 624/2000 [17:49<36:57,  1.61s/it]
[INFO] Global step: 624, Cumulative rewards: 22.353839999999998, Runtime (s): 1069.62
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3508787155151367
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.916091203689575
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6259210109710693
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5991299152374268
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4797439575195312
average cummulative reward vector is:  [0.11833921 0.11901227 0.12950191 0.11169579 0.12050968]
average cummulative reward is:  0.11981177268500369
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 625, loss: 48789.1484375
[INFO] Global_t: 625, Episode_t: 1, Action: 114, Reward: 2.05, Epsilon: 0.38
[INFO] model update: t: 626, loss: 536784.75
[INFO] Global_t: 626, Episode_t: 2, Action: 9, Reward: 4.76, Epsilon: 0.38
[INFO] model update: t: 627, loss: 2119815.5
[INFO] Global_t: 627, Episode_t: 3, Action: 102, Reward: 1.28, Epsilon: 0.38
[INFO] model update: t: 628, loss: 3207037.5
[INFO] Global_t: 628, Episode_t: 4, Action: 184, Reward: 1.13, Epsilon: 0.38
[INFO] model update: t: 629, loss: 2026347.375
[INFO] Global_t: 629, Episode_t: 5, Action: 110, Reward: 1.47, Epsilon: 0.37
[INFO] model update: t: 630, loss: 450865.1875
[INFO] Global_t: 630, Episode_t: 6, Action: 34, Reward: 1.08, Epsilon: 0.37
[INFO] model update: t: 631, loss: 52995.625
[INFO] Global_t: 631, Episode_t: 7, Action: 3, Reward: 2.79, Epsilon: 0.37
[INFO] model update: t: 632, loss: 615008.0625
[INFO] Global_t: 632, Episode_t: 8, Action: 118, Reward: 1.11, Epsilon: 0.37
 32%|███▏      | 632/2000 [18:11<44:34,  1.96s/it]
[INFO] Global step: 632, Cumulative rewards: 15.667559999999998, Runtime (s): 1091.67
------------------------------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 633, loss: 819499.9375
[INFO] Global_t: 633, Episode_t: 1, Action: 0, Reward: 4.12, Epsilon: 0.37
[INFO] model update: t: 634, loss: 299994.1875
[INFO] Global_t: 634, Episode_t: 2, Action: 102, Reward: 1.27, Epsilon: 0.37
[INFO] model update: t: 635, loss: 345310.3125
[INFO] Global_t: 635, Episode_t: 3, Action: 5, Reward: 4.64, Epsilon: 0.37
[INFO] model update: t: 636, loss: 1785582.5
[INFO] Global_t: 636, Episode_t: 4, Action: 4, Reward: 3.90, Epsilon: 0.37
[INFO] model update: t: 637, loss: 583870.75
[INFO] Global_t: 637, Episode_t: 5, Action: 24, Reward: 3.65, Epsilon: 0.37
[INFO] model update: t: 638, loss: 244800.734375
[INFO] Global_t: 638, Episode_t: 6, Action: 25, Reward: 3.07, Epsilon: 0.37
[INFO] model update: t: 639, loss: 1577214.0
[INFO] Global_t: 639, Episode_t: 7, Action: 11, Reward: 2.80, Epsilon: 0.36
[INFO] model update: t: 640, loss: 2248922.0
[INFO] Global_t: 640, Episode_t: 8, Action: 41, Reward: 2.30, Epsilon: 0.36
 32%|███▏      | 640/2000 [18:16<34:47,  1.54s/it]
[INFO] Global step: 640, Cumulative rewards: 25.759680000000003, Runtime (s): 1096.11
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.75530743598938
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7455642223358154
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.873136281967163
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6213903427124023
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.777932643890381
average cummulative reward vector is:  [0.12680605 0.11580764 0.13527623 0.11335958 0.13698629]
average cummulative reward is:  0.12564715815809951
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 641, loss: 837543.625
[INFO] Global_t: 641, Episode_t: 1, Action: 5, Reward: 5.50, Epsilon: 0.36
[INFO] model update: t: 642, loss: 114700.9921875
[INFO] Global_t: 642, Episode_t: 2, Action: 1, Reward: 4.12, Epsilon: 0.36
[INFO] model update: t: 643, loss: 1631795.75
[INFO] Global_t: 643, Episode_t: 3, Action: 20, Reward: 3.66, Epsilon: 0.36
[INFO] model update: t: 644, loss: 3456698.0
[INFO] Global_t: 644, Episode_t: 4, Action: 11, Reward: 3.41, Epsilon: 0.36
[INFO] model update: t: 645, loss: 1442819.875
[INFO] Global_t: 645, Episode_t: 5, Action: 7, Reward: 4.08, Epsilon: 0.36
[INFO] model update: t: 646, loss: 104068.6328125
[INFO] Global_t: 646, Episode_t: 6, Action: 80, Reward: 1.43, Epsilon: 0.36
[INFO] model update: t: 647, loss: 418164.90625
[INFO] Global_t: 647, Episode_t: 7, Action: 197, Reward: 1.58, Epsilon: 0.36
[INFO] model update: t: 648, loss: 1061836.25
[INFO] Global_t: 648, Episode_t: 8, Action: 32, Reward: 3.77, Epsilon: 0.36
 32%|███▏      | 648/2000 [18:39<43:54,  1.95s/it]
[INFO] Global step: 648, Cumulative rewards: 27.534000000000002, Runtime (s): 1119.42
------------------------------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 649, loss: 720116.0
[INFO] Global_t: 649, Episode_t: 1, Action: 9, Reward: 4.99, Epsilon: 0.35
[INFO] model update: t: 650, loss: 31094.189453125
[INFO] Global_t: 650, Episode_t: 2, Action: 109, Reward: 1.38, Epsilon: 0.35
[INFO] model update: t: 651, loss: 389652.6875
[INFO] Global_t: 651, Episode_t: 3, Action: 0, Reward: 4.32, Epsilon: 0.35
[INFO] model update: t: 652, loss: 1455269.25
[INFO] Global_t: 652, Episode_t: 4, Action: 5, Reward: 3.73, Epsilon: 0.35
[INFO] model update: t: 653, loss: 1595093.75
[INFO] Global_t: 653, Episode_t: 5, Action: 35, Reward: 2.26, Epsilon: 0.35
[INFO] model update: t: 654, loss: 366905.0625
[INFO] Global_t: 654, Episode_t: 6, Action: 8, Reward: 2.64, Epsilon: 0.35
[INFO] model update: t: 655, loss: 1138330.875
[INFO] Global_t: 655, Episode_t: 7, Action: 16, Reward: 2.61, Epsilon: 0.35
[INFO] model update: t: 656, loss: 6336209.0
[INFO] Global_t: 656, Episode_t: 8, Action: 32, Reward: 2.46, Epsilon: 0.35
 33%|███▎      | 656/2000 [18:43<34:20,  1.53s/it]
[INFO] Global step: 656, Cumulative rewards: 24.38724, Runtime (s): 1123.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.591562271118164
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.810168981552124
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.726057767868042
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.878870964050293
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.574021577835083
average cummulative reward vector is:  [0.12898211 0.11002963 0.13245    0.11807897 0.12940995]
average cummulative reward is:  0.1237901306183927
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
[INFO] model update: t: 657, loss: 6497608.0
[INFO] Global_t: 657, Episode_t: 1, Action: 20, Reward: 3.44, Epsilon: 0.35
[INFO] model update: t: 658, loss: 43581.28125
[INFO] Global_t: 658, Episode_t: 2, Action: 6, Reward: 3.99, Epsilon: 0.35
[INFO] model update: t: 659, loss: 4186638.0
[INFO] Global_t: 659, Episode_t: 3, Action: 11, Reward: 3.63, Epsilon: 0.35
[INFO] model update: t: 660, loss: 3186053.75
[INFO] Global_t: 660, Episode_t: 4, Action: 106, Reward: 1.31, Epsilon: 0.34
[INFO] model update: t: 661, loss: 455749.53125
[INFO] Global_t: 661, Episode_t: 5, Action: 145, Reward: 1.10, Epsilon: 0.34
[INFO] model update: t: 662, loss: 5347501.0
[INFO] Global_t: 662, Episode_t: 6, Action: 4, Reward: 3.09, Epsilon: 0.34
[INFO] model update: t: 663, loss: 3705481.0
[INFO] Global_t: 663, Episode_t: 7, Action: 3, Reward: 3.42, Epsilon: 0.34
[INFO] model update: t: 664, loss: 487308.0625
[INFO] Global_t: 664, Episode_t: 8, Action: 10, Reward: 2.96, Epsilon: 0.34
 33%|███▎      | 664/2000 [19:06<42:51,  1.92s/it]
[INFO] Global step: 664, Cumulative rewards: 22.928519999999995, Runtime (s): 1146.63
------------------------------------------------------------
 
graph: 83, nodes: 198, edges: 584
[INFO] model update: t: 665, loss: 6262329.5
[INFO] Global_t: 665, Episode_t: 1, Action: 9, Reward: 4.26, Epsilon: 0.34
[INFO] model update: t: 666, loss: 2260787.0
[INFO] Global_t: 666, Episode_t: 2, Action: 105, Reward: 1.92, Epsilon: 0.34
[INFO] model update: t: 667, loss: 871433.875
[INFO] Global_t: 667, Episode_t: 3, Action: 94, Reward: 1.70, Epsilon: 0.34
[INFO] model update: t: 668, loss: 5097964.0
[INFO] Global_t: 668, Episode_t: 4, Action: 4, Reward: 5.22, Epsilon: 0.34
[INFO] model update: t: 669, loss: 2490344.0
[INFO] Global_t: 669, Episode_t: 5, Action: 12, Reward: 2.81, Epsilon: 0.34
[INFO] model update: t: 670, loss: 2180199.0
[INFO] Global_t: 670, Episode_t: 6, Action: 6, Reward: 2.81, Epsilon: 0.33
[INFO] model update: t: 671, loss: 6631578.0
[INFO] Global_t: 671, Episode_t: 7, Action: 13, Reward: 2.82, Epsilon: 0.33
[INFO] model update: t: 672, loss: 287595.5625
[INFO] Global_t: 672, Episode_t: 8, Action: 14, Reward: 2.84, Epsilon: 0.33
 34%|███▎      | 672/2000 [19:11<33:54,  1.53s/it]
[INFO] Global step: 672, Cumulative rewards: 24.394319999999993, Runtime (s): 1151.57
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7693064212799072
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9342234134674072
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7078287601470947
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.831995725631714
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.050585031509399
average cummulative reward vector is:  [0.13471079 0.11780231 0.13292186 0.11755421 0.13338978]
average cummulative reward is:  0.1272757905531419
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 84, nodes: 205, edges: 606
[INFO] model update: t: 673, loss: 8334384.0
[INFO] Global_t: 673, Episode_t: 1, Action: 15, Reward: 4.07, Epsilon: 0.33
[INFO] model update: t: 674, loss: 3495937.0
[INFO] Global_t: 674, Episode_t: 2, Action: 7, Reward: 4.68, Epsilon: 0.33
[INFO] model update: t: 675, loss: 1382271.875
[INFO] Global_t: 675, Episode_t: 3, Action: 98, Reward: 1.25, Epsilon: 0.33
[INFO] model update: t: 676, loss: 8419451.0
[INFO] Global_t: 676, Episode_t: 4, Action: 136, Reward: 1.53, Epsilon: 0.33
[INFO] model update: t: 677, loss: 6338580.0
[INFO] Global_t: 677, Episode_t: 5, Action: 27, Reward: 3.26, Epsilon: 0.33
[INFO] model update: t: 678, loss: 20319.177734375
[INFO] Global_t: 678, Episode_t: 6, Action: 196, Reward: 1.38, Epsilon: 0.33
[INFO] model update: t: 679, loss: 4714566.0
[INFO] Global_t: 679, Episode_t: 7, Action: 26, Reward: 2.87, Epsilon: 0.33
[INFO] model update: t: 680, loss: 2668523.0
[INFO] Global_t: 680, Episode_t: 8, Action: 9, Reward: 2.60, Epsilon: 0.32
 34%|███▍      | 680/2000 [19:35<43:10,  1.96s/it]
[INFO] Global step: 680, Cumulative rewards: 21.637679999999996, Runtime (s): 1175.29
------------------------------------------------------------
 
graph: 85, nodes: 212, edges: 627
[INFO] model update: t: 681, loss: 224671.359375
[INFO] Global_t: 681, Episode_t: 1, Action: 12, Reward: 4.49, Epsilon: 0.32
[INFO] model update: t: 682, loss: 2066872.0
[INFO] Global_t: 682, Episode_t: 2, Action: 10, Reward: 4.86, Epsilon: 0.32
[INFO] model update: t: 683, loss: 292921.0625
[INFO] Global_t: 683, Episode_t: 3, Action: 6, Reward: 4.58, Epsilon: 0.32
[INFO] model update: t: 684, loss: 5050886.0
[INFO] Global_t: 684, Episode_t: 4, Action: 17, Reward: 3.77, Epsilon: 0.32
[INFO] model update: t: 685, loss: 1690535.25
[INFO] Global_t: 685, Episode_t: 5, Action: 23, Reward: 2.60, Epsilon: 0.32
[INFO] model update: t: 686, loss: 4111187.0
[INFO] Global_t: 686, Episode_t: 6, Action: 2, Reward: 2.76, Epsilon: 0.32
[INFO] model update: t: 687, loss: 8404906.0
[INFO] Global_t: 687, Episode_t: 7, Action: 0, Reward: 2.67, Epsilon: 0.32
[INFO] model update: t: 688, loss: 721800.625
[INFO] Global_t: 688, Episode_t: 8, Action: 11, Reward: 2.42, Epsilon: 0.32
 34%|███▍      | 688/2000 [19:40<34:23,  1.57s/it]
[INFO] Global step: 688, Cumulative rewards: 28.145759999999996, Runtime (s): 1180.60
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.000232696533203
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.781339168548584
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9529802799224854
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.953460216522217
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.955777168273926
average cummulative reward vector is:  [0.14012447 0.11805093 0.13779945 0.12347033 0.13205887]
average cummulative reward is:  0.13030081024651893
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 86, nodes: 200, edges: 591
[INFO] model update: t: 689, loss: 4332674.0
[INFO] Global_t: 689, Episode_t: 1, Action: 1, Reward: 4.12, Epsilon: 0.32
[INFO] model update: t: 690, loss: 4578695.0
[INFO] Global_t: 690, Episode_t: 2, Action: 84, Reward: 2.04, Epsilon: 0.31
[INFO] model update: t: 691, loss: 243817.28125
[INFO] Global_t: 691, Episode_t: 3, Action: 0, Reward: 4.65, Epsilon: 0.31
[INFO] model update: t: 692, loss: 4434032.5
[INFO] Global_t: 692, Episode_t: 4, Action: 3, Reward: 4.69, Epsilon: 0.31
[INFO] model update: t: 693, loss: 205798.328125
[INFO] Global_t: 693, Episode_t: 5, Action: 5, Reward: 3.15, Epsilon: 0.31
[INFO] model update: t: 694, loss: 3380999.0
[INFO] Global_t: 694, Episode_t: 6, Action: 12, Reward: 2.78, Epsilon: 0.31
[INFO] model update: t: 695, loss: 1191367.0
[INFO] Global_t: 695, Episode_t: 7, Action: 11, Reward: 3.60, Epsilon: 0.31
[INFO] model update: t: 696, loss: 1447566.75
[INFO] Global_t: 696, Episode_t: 8, Action: 10, Reward: 2.42, Epsilon: 0.31
 35%|███▍      | 696/2000 [20:05<43:53,  2.02s/it]
[INFO] Global step: 696, Cumulative rewards: 27.450000000000003, Runtime (s): 1205.10
------------------------------------------------------------
 
graph: 87, nodes: 218, edges: 645
[INFO] model update: t: 697, loss: 537909.6875
[INFO] Global_t: 697, Episode_t: 1, Action: 8, Reward: 5.21, Epsilon: 0.31
[INFO] model update: t: 698, loss: 2122507.75
[INFO] Global_t: 698, Episode_t: 2, Action: 0, Reward: 4.08, Epsilon: 0.31
[INFO] model update: t: 699, loss: 3167807.5
[INFO] Global_t: 699, Episode_t: 3, Action: 10, Reward: 3.84, Epsilon: 0.31
[INFO] model update: t: 700, loss: 446315.8125
[INFO] Global_t: 700, Episode_t: 4, Action: 42, Reward: 2.31, Epsilon: 0.30
[INFO] model update: t: 701, loss: 3348692.5
[INFO] Global_t: 701, Episode_t: 5, Action: 92, Reward: 1.33, Epsilon: 0.30
[INFO] model update: t: 702, loss: 253757.609375
[INFO] Global_t: 702, Episode_t: 6, Action: 57, Reward: 0.99, Epsilon: 0.30
[INFO] model update: t: 703, loss: 4470890.0
[INFO] Global_t: 703, Episode_t: 7, Action: 6, Reward: 2.42, Epsilon: 0.30
[INFO] model update: t: 704, loss: 423698.8125
[INFO] Global_t: 704, Episode_t: 8, Action: 7, Reward: 2.85, Epsilon: 0.30
 35%|███▌      | 704/2000 [20:11<35:19,  1.64s/it]
[INFO] Global step: 704, Cumulative rewards: 23.01816, Runtime (s): 1211.01
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8009471893310547
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.906913995742798
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.687039375305176
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5844571590423584
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6344692707061768
average cummulative reward vector is:  [0.13322632 0.12110231 0.12819071 0.11133201 0.13266022]
average cummulative reward is:  0.125302313077272
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 88, nodes: 204, edges: 603
[INFO] model update: t: 705, loss: 3669663.5
[INFO] Global_t: 705, Episode_t: 1, Action: 9, Reward: 4.08, Epsilon: 0.30
[INFO] model update: t: 706, loss: 3413398.5
[INFO] Global_t: 706, Episode_t: 2, Action: 16, Reward: 4.05, Epsilon: 0.30
[INFO] model update: t: 707, loss: 264863.25
[INFO] Global_t: 707, Episode_t: 3, Action: 14, Reward: 3.56, Epsilon: 0.30
[INFO] model update: t: 708, loss: 1934291.0
[INFO] Global_t: 708, Episode_t: 4, Action: 12, Reward: 3.43, Epsilon: 0.30
[INFO] model update: t: 709, loss: 309002.5
[INFO] Global_t: 709, Episode_t: 5, Action: 15, Reward: 2.00, Epsilon: 0.30
[INFO] model update: t: 710, loss: 2731506.5
[INFO] Global_t: 710, Episode_t: 6, Action: 17, Reward: 2.65, Epsilon: 0.30
[INFO] model update: t: 711, loss: 79683.7578125
[INFO] Global_t: 711, Episode_t: 7, Action: 7, Reward: 2.68, Epsilon: 0.29
[INFO] model update: t: 712, loss: 1768859.5
[INFO] Global_t: 712, Episode_t: 8, Action: 2, Reward: 2.87, Epsilon: 0.29
 36%|███▌      | 712/2000 [20:34<43:46,  2.04s/it]
[INFO] Global step: 712, Cumulative rewards: 25.32012, Runtime (s): 1234.87
------------------------------------------------------------
 
graph: 89, nodes: 199, edges: 588
[INFO] model update: t: 713, loss: 169013.234375
[INFO] Global_t: 713, Episode_t: 1, Action: 123, Reward: 1.95, Epsilon: 0.29
[INFO] model update: t: 714, loss: 865435.0625
[INFO] Global_t: 714, Episode_t: 2, Action: 14, Reward: 4.36, Epsilon: 0.29
[INFO] model update: t: 715, loss: 77147.0
[INFO] Global_t: 715, Episode_t: 3, Action: 94, Reward: 1.45, Epsilon: 0.29
[INFO] model update: t: 716, loss: 749921.875
[INFO] Global_t: 716, Episode_t: 4, Action: 11, Reward: 4.32, Epsilon: 0.29
[INFO] model update: t: 717, loss: 512830.9375
[INFO] Global_t: 717, Episode_t: 5, Action: 7, Reward: 3.04, Epsilon: 0.29
[INFO] model update: t: 718, loss: 231587.890625
[INFO] Global_t: 718, Episode_t: 6, Action: 69, Reward: 1.70, Epsilon: 0.29
[INFO] model update: t: 719, loss: 271722.25
[INFO] Global_t: 719, Episode_t: 7, Action: 5, Reward: 3.45, Epsilon: 0.29
[INFO] model update: t: 720, loss: 483662.0625
[INFO] Global_t: 720, Episode_t: 8, Action: 3, Reward: 3.07, Epsilon: 0.29
 36%|███▌      | 720/2000 [20:39<34:32,  1.62s/it]
[INFO] Global step: 720, Cumulative rewards: 23.342039999999997, Runtime (s): 1239.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9290573596954346
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8444395065307617
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.479722738265991
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.983839273452759
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.620786666870117
average cummulative reward vector is:  [0.13330289 0.11936134 0.12953607 0.11823645 0.13056048]
average cummulative reward is:  0.12619944707446076
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 90, nodes: 207, edges: 612
[INFO] model update: t: 721, loss: 612959.6875
[INFO] Global_t: 721, Episode_t: 1, Action: 197, Reward: 0.95, Epsilon: 0.28
[INFO] model update: t: 722, loss: 375688.25
[INFO] Global_t: 722, Episode_t: 2, Action: 62, Reward: 2.14, Epsilon: 0.28
[INFO] model update: t: 723, loss: 1209215.375
[INFO] Global_t: 723, Episode_t: 3, Action: 3, Reward: 5.28, Epsilon: 0.28
[INFO] model update: t: 724, loss: 148308.203125
[INFO] Global_t: 724, Episode_t: 4, Action: 9, Reward: 3.83, Epsilon: 0.28
[INFO] model update: t: 725, loss: 576727.0
[INFO] Global_t: 725, Episode_t: 5, Action: 16, Reward: 2.75, Epsilon: 0.28
[INFO] model update: t: 726, loss: 94411.5078125
[INFO] Global_t: 726, Episode_t: 6, Action: 6, Reward: 2.51, Epsilon: 0.28
[INFO] model update: t: 727, loss: 441838.25
[INFO] Global_t: 727, Episode_t: 7, Action: 11, Reward: 1.89, Epsilon: 0.28
[INFO] model update: t: 728, loss: 81610.703125
[INFO] Global_t: 728, Episode_t: 8, Action: 97, Reward: 1.31, Epsilon: 0.28
 36%|███▋      | 728/2000 [21:03<42:55,  2.03s/it]
[INFO] Global step: 728, Cumulative rewards: 20.664119999999997, Runtime (s): 1263.75
------------------------------------------------------------
 
graph: 91, nodes: 198, edges: 585
[INFO] model update: t: 729, loss: 431296.625
[INFO] Global_t: 729, Episode_t: 1, Action: 3, Reward: 6.14, Epsilon: 0.28
[INFO] model update: t: 730, loss: 432771.59375
[INFO] Global_t: 730, Episode_t: 2, Action: 15, Reward: 4.15, Epsilon: 0.28
[INFO] model update: t: 731, loss: 24747.357421875
[INFO] Global_t: 731, Episode_t: 3, Action: 84, Reward: 2.17, Epsilon: 0.27
[INFO] model update: t: 732, loss: 361474.03125
[INFO] Global_t: 732, Episode_t: 4, Action: 0, Reward: 4.08, Epsilon: 0.27
[INFO] model update: t: 733, loss: 25716.7421875
[INFO] Global_t: 733, Episode_t: 5, Action: 59, Reward: 2.02, Epsilon: 0.27
[INFO] model update: t: 734, loss: 460270.1875
[INFO] Global_t: 734, Episode_t: 6, Action: 8, Reward: 1.64, Epsilon: 0.27
[INFO] model update: t: 735, loss: 135686.875
[INFO] Global_t: 735, Episode_t: 7, Action: 9, Reward: 2.69, Epsilon: 0.27
[INFO] model update: t: 736, loss: 230672.734375
[INFO] Global_t: 736, Episode_t: 8, Action: 33, Reward: 1.68, Epsilon: 0.27
 37%|███▋      | 736/2000 [21:09<34:04,  1.62s/it]
[INFO] Global step: 736, Cumulative rewards: 24.566760000000002, Runtime (s): 1269.08
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.1389288902282715
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.872443199157715
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8664894104003906
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.814448356628418
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.823240280151367
average cummulative reward vector is:  [0.13917895 0.11881875 0.14269781 0.11306869 0.13547688]
average cummulative reward is:  0.1298482169770573
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 92, nodes: 183, edges: 539
[INFO] model update: t: 737, loss: 176849.9375
[INFO] Global_t: 737, Episode_t: 1, Action: 3, Reward: 4.80, Epsilon: 0.27
[INFO] model update: t: 738, loss: 151923.40625
[INFO] Global_t: 738, Episode_t: 2, Action: 19, Reward: 2.64, Epsilon: 0.27
[INFO] model update: t: 739, loss: 370621.25
[INFO] Global_t: 739, Episode_t: 3, Action: 22, Reward: 3.47, Epsilon: 0.27
[INFO] model update: t: 740, loss: 86320.9921875
[INFO] Global_t: 740, Episode_t: 4, Action: 12, Reward: 3.92, Epsilon: 0.27
[INFO] model update: t: 741, loss: 412128.75
[INFO] Global_t: 741, Episode_t: 5, Action: 125, Reward: 1.01, Epsilon: 0.26
[INFO] model update: t: 742, loss: 11494.568359375
[INFO] Global_t: 742, Episode_t: 6, Action: 41, Reward: 2.36, Epsilon: 0.26
[INFO] model update: t: 743, loss: 311378.8125
[INFO] Global_t: 743, Episode_t: 7, Action: 104, Reward: 1.27, Epsilon: 0.26
[INFO] model update: t: 744, loss: 21319.212890625
[INFO] Global_t: 744, Episode_t: 8, Action: 25, Reward: 1.89, Epsilon: 0.26
 37%|███▋      | 744/2000 [21:42<50:01,  2.39s/it]
[INFO] Global step: 744, Cumulative rewards: 21.34872, Runtime (s): 1302.61
------------------------------------------------------------
 
graph: 93, nodes: 217, edges: 642
[INFO] model update: t: 745, loss: 352372.3125
[INFO] Global_t: 745, Episode_t: 1, Action: 3, Reward: 4.68, Epsilon: 0.26
[INFO] model update: t: 746, loss: 225469.046875
[INFO] Global_t: 746, Episode_t: 2, Action: 13, Reward: 4.17, Epsilon: 0.26
[INFO] model update: t: 747, loss: 164177.875
[INFO] Global_t: 747, Episode_t: 3, Action: 10, Reward: 4.34, Epsilon: 0.26
[INFO] model update: t: 748, loss: 398964.6875
[INFO] Global_t: 748, Episode_t: 4, Action: 17, Reward: 3.74, Epsilon: 0.26
[INFO] model update: t: 749, loss: 66391.875
[INFO] Global_t: 749, Episode_t: 5, Action: 155, Reward: 1.29, Epsilon: 0.26
[INFO] model update: t: 750, loss: 249130.625
[INFO] Global_t: 750, Episode_t: 6, Action: 4, Reward: 3.00, Epsilon: 0.26
[INFO] model update: t: 751, loss: 160934.03125
[INFO] Global_t: 751, Episode_t: 7, Action: 11, Reward: 2.71, Epsilon: 0.26
[INFO] model update: t: 752, loss: 529535.5625
[INFO] Global_t: 752, Episode_t: 8, Action: 9, Reward: 2.60, Epsilon: 0.25
 38%|███▊      | 752/2000 [21:47<38:34,  1.85s/it]
[INFO] Global step: 752, Cumulative rewards: 26.530799999999996, Runtime (s): 1307.45
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6946096420288086
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.198439359664917
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7322957515716553
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6093032360076904
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.525538444519043
average cummulative reward vector is:  [0.13339237 0.1239831  0.13674945 0.11456192 0.12205618]
average cummulative reward is:  0.12614860450167328
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 94, nodes: 198, edges: 585
[INFO] model update: t: 753, loss: 15593.53515625
[INFO] Global_t: 753, Episode_t: 1, Action: 83, Reward: 2.00, Epsilon: 0.25
[INFO] model update: t: 754, loss: 300736.5
[INFO] Global_t: 754, Episode_t: 2, Action: 31, Reward: 2.28, Epsilon: 0.25
[INFO] model update: t: 755, loss: 24017.029296875
[INFO] Global_t: 755, Episode_t: 3, Action: 15, Reward: 4.62, Epsilon: 0.25
[INFO] model update: t: 756, loss: 305521.21875
[INFO] Global_t: 756, Episode_t: 4, Action: 11, Reward: 4.26, Epsilon: 0.25
[INFO] model update: t: 757, loss: 23372.95703125
[INFO] Global_t: 757, Episode_t: 5, Action: 4, Reward: 3.07, Epsilon: 0.25
[INFO] model update: t: 758, loss: 262325.75
[INFO] Global_t: 758, Episode_t: 6, Action: 0, Reward: 2.49, Epsilon: 0.25
[INFO] model update: t: 759, loss: 9603.3193359375
[INFO] Global_t: 759, Episode_t: 7, Action: 5, Reward: 2.61, Epsilon: 0.25
[INFO] model update: t: 760, loss: 235781.40625
[INFO] Global_t: 760, Episode_t: 8, Action: 159, Reward: 1.10, Epsilon: 0.25
 38%|███▊      | 760/2000 [22:11<45:20,  2.19s/it]
[INFO] Global step: 760, Cumulative rewards: 22.446959999999994, Runtime (s): 1331.35
------------------------------------------------------------
 
graph: 95, nodes: 202, edges: 597
[INFO] model update: t: 761, loss: 26287.666015625
[INFO] Global_t: 761, Episode_t: 1, Action: 94, Reward: 2.17, Epsilon: 0.25
[INFO] model update: t: 762, loss: 399414.25
[INFO] Global_t: 762, Episode_t: 2, Action: 47, Reward: 3.62, Epsilon: 0.24
[INFO] model update: t: 763, loss: 211486.921875
[INFO] Global_t: 763, Episode_t: 3, Action: 13, Reward: 3.95, Epsilon: 0.24
[INFO] model update: t: 764, loss: 229221.15625
[INFO] Global_t: 764, Episode_t: 4, Action: 18, Reward: 3.88, Epsilon: 0.24
[INFO] model update: t: 765, loss: 324642.375
[INFO] Global_t: 765, Episode_t: 5, Action: 5, Reward: 5.24, Epsilon: 0.24
[INFO] model update: t: 766, loss: 96503.125
[INFO] Global_t: 766, Episode_t: 6, Action: 168, Reward: 1.56, Epsilon: 0.24
[INFO] model update: t: 767, loss: 383417.75
[INFO] Global_t: 767, Episode_t: 7, Action: 34, Reward: 2.30, Epsilon: 0.24
[INFO] model update: t: 768, loss: 19268.08984375
[INFO] Global_t: 768, Episode_t: 8, Action: 197, Reward: 1.32, Epsilon: 0.24
 38%|███▊      | 768/2000 [22:17<36:38,  1.78s/it]
[INFO] Global step: 768, Cumulative rewards: 24.04116, Runtime (s): 1337.98
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.0871193408966064
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.963207483291626
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8184311389923096
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8709323406219482
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.957467555999756
average cummulative reward vector is:  [0.14455105 0.12017222 0.14179262 0.11831402 0.13870806]
average cummulative reward is:  0.13270759620246772
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 96, nodes: 200, edges: 591
[INFO] model update: t: 769, loss: 283018.71875
[INFO] Global_t: 769, Episode_t: 1, Action: 6, Reward: 4.86, Epsilon: 0.24
[INFO] model update: t: 770, loss: 21318.5078125
[INFO] Global_t: 770, Episode_t: 2, Action: 4, Reward: 4.25, Epsilon: 0.24
[INFO] model update: t: 771, loss: 262132.453125
[INFO] Global_t: 771, Episode_t: 3, Action: 11, Reward: 3.61, Epsilon: 0.24
[INFO] model update: t: 772, loss: 72696.03125
[INFO] Global_t: 772, Episode_t: 4, Action: 12, Reward: 4.07, Epsilon: 0.23
[INFO] model update: t: 773, loss: 173739.796875
[INFO] Global_t: 773, Episode_t: 5, Action: 32, Reward: 1.95, Epsilon: 0.23
[INFO] model update: t: 774, loss: 46247.4375
[INFO] Global_t: 774, Episode_t: 6, Action: 63, Reward: 1.35, Epsilon: 0.23
[INFO] model update: t: 775, loss: 164869.78125
[INFO] Global_t: 775, Episode_t: 7, Action: 7, Reward: 1.83, Epsilon: 0.23
[INFO] model update: t: 776, loss: 108818.796875
[INFO] Global_t: 776, Episode_t: 8, Action: 13, Reward: 1.94, Epsilon: 0.23
 39%|███▉      | 776/2000 [22:42<44:24,  2.18s/it]
[INFO] Global step: 776, Cumulative rewards: 23.858159999999998, Runtime (s): 1362.73
------------------------------------------------------------
 
graph: 97, nodes: 206, edges: 609
[INFO] model update: t: 777, loss: 137044.296875
[INFO] Global_t: 777, Episode_t: 1, Action: 54, Reward: 2.11, Epsilon: 0.23
[INFO] model update: t: 778, loss: 256137.4375
[INFO] Global_t: 778, Episode_t: 2, Action: 7, Reward: 4.41, Epsilon: 0.23
[INFO] model update: t: 779, loss: 14017.14453125
[INFO] Global_t: 779, Episode_t: 3, Action: 148, Reward: 1.55, Epsilon: 0.23
[INFO] model update: t: 780, loss: 155481.984375
[INFO] Global_t: 780, Episode_t: 4, Action: 9, Reward: 3.65, Epsilon: 0.23
[INFO] model update: t: 781, loss: 74786.703125
[INFO] Global_t: 781, Episode_t: 5, Action: 3, Reward: 3.77, Epsilon: 0.23
[INFO] model update: t: 782, loss: 360207.375
[INFO] Global_t: 782, Episode_t: 6, Action: 56, Reward: 2.62, Epsilon: 0.22
[INFO] model update: t: 783, loss: 33547.6171875
[INFO] Global_t: 783, Episode_t: 7, Action: 10, Reward: 2.84, Epsilon: 0.22
[INFO] model update: t: 784, loss: 366384.9375
[INFO] Global_t: 784, Episode_t: 8, Action: 76, Reward: 1.63, Epsilon: 0.22
 39%|███▉      | 784/2000 [22:47<34:42,  1.71s/it]
[INFO] Global step: 784, Cumulative rewards: 22.59504, Runtime (s): 1367.76
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9195306301116943
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.2672765254974365
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6773414611816406
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.432826280593872
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8747525215148926
average cummulative reward vector is:  [0.13665158 0.12440764 0.13344973 0.10725584 0.13372769]
average cummulative reward is:  0.12709849478115037
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 98, nodes: 206, edges: 607
[INFO] model update: t: 785, loss: 20497.1640625
[INFO] Global_t: 785, Episode_t: 1, Action: 1, Reward: 4.41, Epsilon: 0.22
[INFO] model update: t: 786, loss: 272861.84375
[INFO] Global_t: 786, Episode_t: 2, Action: 166, Reward: 1.74, Epsilon: 0.22
[INFO] model update: t: 787, loss: 21837.046875
[INFO] Global_t: 787, Episode_t: 3, Action: 2, Reward: 4.17, Epsilon: 0.22
[INFO] model update: t: 788, loss: 370778.875
[INFO] Global_t: 788, Episode_t: 4, Action: 98, Reward: 1.52, Epsilon: 0.22
[INFO] model update: t: 789, loss: 54738.5859375
[INFO] Global_t: 789, Episode_t: 5, Action: 17, Reward: 1.92, Epsilon: 0.22
[INFO] model update: t: 790, loss: 304650.4375
[INFO] Global_t: 790, Episode_t: 6, Action: 0, Reward: 2.45, Epsilon: 0.22
[INFO] model update: t: 791, loss: 261384.515625
[INFO] Global_t: 791, Episode_t: 7, Action: 5, Reward: 2.70, Epsilon: 0.22
[INFO] model update: t: 792, loss: 52604.734375
[INFO] Global_t: 792, Episode_t: 8, Action: 123, Reward: 0.94, Epsilon: 0.21
 40%|███▉      | 792/2000 [23:12<42:37,  2.12s/it]
[INFO] Global step: 792, Cumulative rewards: 19.853639999999995, Runtime (s): 1392.24
------------------------------------------------------------
 
graph: 99, nodes: 181, edges: 533
[INFO] model update: t: 793, loss: 307378.9375
[INFO] Global_t: 793, Episode_t: 1, Action: 11, Reward: 4.18, Epsilon: 0.21
[INFO] model update: t: 794, loss: 28668.953125
[INFO] Global_t: 794, Episode_t: 2, Action: 9, Reward: 4.52, Epsilon: 0.21
[INFO] model update: t: 795, loss: 165939.828125
[INFO] Global_t: 795, Episode_t: 3, Action: 80, Reward: 2.11, Epsilon: 0.21
[INFO] model update: t: 796, loss: 78991.734375
[INFO] Global_t: 796, Episode_t: 4, Action: 5, Reward: 4.60, Epsilon: 0.21
[INFO] model update: t: 797, loss: 26228.265625
[INFO] Global_t: 797, Episode_t: 5, Action: 19, Reward: 2.91, Epsilon: 0.21
[INFO] model update: t: 798, loss: 63985.78125
[INFO] Global_t: 798, Episode_t: 6, Action: 28, Reward: 1.43, Epsilon: 0.21
[INFO] model update: t: 799, loss: 19438.201171875
[INFO] Global_t: 799, Episode_t: 7, Action: 42, Reward: 1.46, Epsilon: 0.21
[INFO] model update: t: 800, loss: 31318.341796875
[INFO] Global_t: 800, Episode_t: 8, Action: 100, Reward: 0.83, Epsilon: 0.21

 40%|████      | 800/2000 [23:18<34:00,  1.70s/it]68, Runtime (s): 1398.08
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8251430988311768
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.952479362487793
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.006124496459961
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4664251804351807
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7233285903930664
average cummulative reward vector is:  [0.13651158 0.11977477 0.14379809 0.10913505 0.13228817]
average cummulative reward is:  0.12830153073391273
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 100, nodes: 188, edges: 555
[INFO] model update: t: 801, loss: 19459.1328125
[INFO] Global_t: 801, Episode_t: 1, Action: 4, Reward: 5.01, Epsilon: 0.21
[INFO] model update: t: 802, loss: 36507.84375
[INFO] Global_t: 802, Episode_t: 2, Action: 6, Reward: 4.68, Epsilon: 0.21
[INFO] model update: t: 803, loss: 73699.6640625
[INFO] Global_t: 803, Episode_t: 3, Action: 9, Reward: 4.13, Epsilon: 0.20
[INFO] model update: t: 804, loss: 17506.38671875
[INFO] Global_t: 804, Episode_t: 4, Action: 3, Reward: 4.98, Epsilon: 0.20
[INFO] model update: t: 805, loss: 96877.734375
[INFO] Global_t: 805, Episode_t: 5, Action: 26, Reward: 1.75, Epsilon: 0.20
[INFO] model update: t: 806, loss: 36576.78125
[INFO] Global_t: 806, Episode_t: 6, Action: 93, Reward: 0.97, Epsilon: 0.20
[INFO] model update: t: 807, loss: 13692.16015625
[INFO] Global_t: 807, Episode_t: 7, Action: 2, Reward: 2.00, Epsilon: 0.20
[INFO] model update: t: 808, loss: 27835.509765625
[INFO] Global_t: 808, Episode_t: 8, Action: 19, Reward: 2.59, Epsilon: 0.20
 40%|████      | 808/2000 [23:42<42:00,  2.11s/it]
[INFO] Global step: 808, Cumulative rewards: 26.105880000000003, Runtime (s): 1422.71
------------------------------------------------------------
 
graph: 101, nodes: 211, edges: 624
[INFO] model update: t: 809, loss: 18644.0859375
[INFO] Global_t: 809, Episode_t: 1, Action: 6, Reward: 5.07, Epsilon: 0.20
[INFO] model update: t: 810, loss: 14662.71875
[INFO] Global_t: 810, Episode_t: 2, Action: 14, Reward: 3.93, Epsilon: 0.20
[INFO] model update: t: 811, loss: 25293.01171875
[INFO] Global_t: 811, Episode_t: 3, Action: 4, Reward: 4.78, Epsilon: 0.20
[INFO] model update: t: 812, loss: 17629.248046875
[INFO] Global_t: 812, Episode_t: 4, Action: 10, Reward: 3.83, Epsilon: 0.20
[INFO] model update: t: 813, loss: 34207.5390625
[INFO] Global_t: 813, Episode_t: 5, Action: 12, Reward: 2.08, Epsilon: 0.19
[INFO] model update: t: 814, loss: 16994.76171875
[INFO] Global_t: 814, Episode_t: 6, Action: 189, Reward: 1.23, Epsilon: 0.19
[INFO] model update: t: 815, loss: 12717.67578125
[INFO] Global_t: 815, Episode_t: 7, Action: 101, Reward: 1.59, Epsilon: 0.19
[INFO] model update: t: 816, loss: 16323.623046875
[INFO] Global_t: 816, Episode_t: 8, Action: 11, Reward: 2.65, Epsilon: 0.19

[INFO] Global step: 816, Cumulative rewards: 25.1658, Runtime (s): 1429.31
------------------------------------------------------------
 
 41%|████      | 816/2000 [23:49<34:05,  1.73s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5567195415496826
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.008612394332886
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.025373935699463
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6945502758026123
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.978639602661133
average cummulative reward vector is:  [0.12641605 0.12423079 0.14297404 0.11578435 0.14084651]
average cummulative reward is:  0.13005034691103995
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 102, nodes: 180, edges: 531
[INFO] model update: t: 817, loss: 9634.1552734375
[INFO] Global_t: 817, Episode_t: 1, Action: 7, Reward: 5.19, Epsilon: 0.19
[INFO] model update: t: 818, loss: 16653.005859375
[INFO] Global_t: 818, Episode_t: 2, Action: 10, Reward: 4.00, Epsilon: 0.19
[INFO] model update: t: 819, loss: 13108.6953125
[INFO] Global_t: 819, Episode_t: 3, Action: 5, Reward: 3.57, Epsilon: 0.19
[INFO] model update: t: 820, loss: 19844.3125
[INFO] Global_t: 820, Episode_t: 4, Action: 2, Reward: 3.78, Epsilon: 0.19
[INFO] model update: t: 821, loss: 14275.326171875
[INFO] Global_t: 821, Episode_t: 5, Action: 17, Reward: 2.53, Epsilon: 0.19
[INFO] model update: t: 822, loss: 20729.244140625
[INFO] Global_t: 822, Episode_t: 6, Action: 22, Reward: 2.48, Epsilon: 0.19
[INFO] model update: t: 823, loss: 4066.388427734375
[INFO] Global_t: 823, Episode_t: 7, Action: 30, Reward: 2.27, Epsilon: 0.18
[INFO] model update: t: 824, loss: 18250.630859375
[INFO] Global_t: 824, Episode_t: 8, Action: 170, Reward: 0.86, Epsilon: 0.18
 41%|████      | 824/2000 [24:13<41:20,  2.11s/it]
[INFO] Global step: 824, Cumulative rewards: 24.691079999999996, Runtime (s): 1453.30
------------------------------------------------------------
 
graph: 103, nodes: 187, edges: 551
[INFO] model update: t: 825, loss: 18490.470703125
[INFO] Global_t: 825, Episode_t: 1, Action: 0, Reward: 4.79, Epsilon: 0.18
[INFO] model update: t: 826, loss: 9352.470703125
[INFO] Global_t: 826, Episode_t: 2, Action: 51, Reward: 1.69, Epsilon: 0.18
[INFO] model update: t: 827, loss: 16081.326171875
[INFO] Global_t: 827, Episode_t: 3, Action: 18, Reward: 3.34, Epsilon: 0.18
[INFO] model update: t: 828, loss: 21116.654296875
[INFO] Global_t: 828, Episode_t: 4, Action: 25, Reward: 3.63, Epsilon: 0.18
[INFO] model update: t: 829, loss: 26789.32421875
[INFO] Global_t: 829, Episode_t: 5, Action: 2, Reward: 2.92, Epsilon: 0.18
[INFO] model update: t: 830, loss: 12131.087890625
[INFO] Global_t: 830, Episode_t: 6, Action: 75, Reward: 1.21, Epsilon: 0.18
[INFO] model update: t: 831, loss: 11587.0849609375
[INFO] Global_t: 831, Episode_t: 7, Action: 1, Reward: 2.71, Epsilon: 0.18
[INFO] model update: t: 832, loss: 13588.228515625
[INFO] Global_t: 832, Episode_t: 8, Action: 112, Reward: 0.83, Epsilon: 0.18
 42%|████▏     | 832/2000 [24:20<33:57,  1.74s/it]
[INFO] Global step: 832, Cumulative rewards: 21.1254, Runtime (s): 1460.45
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.016392707824707
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.284059524536133
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7357757091522217
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.55088210105896
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.675863742828369
average cummulative reward vector is:  [0.13436237 0.1227088  0.13932186 0.11287056 0.13032634]
average cummulative reward is:  0.12791798549490624
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 104, nodes: 185, edges: 546
[INFO] model update: t: 833, loss: 22138.5703125
[INFO] Global_t: 833, Episode_t: 1, Action: 33, Reward: 3.99, Epsilon: 0.17
[INFO] model update: t: 834, loss: 14685.3251953125
[INFO] Global_t: 834, Episode_t: 2, Action: 4, Reward: 4.32, Epsilon: 0.17
[INFO] model update: t: 835, loss: 13840.041015625
[INFO] Global_t: 835, Episode_t: 3, Action: 11, Reward: 3.74, Epsilon: 0.17
[INFO] model update: t: 836, loss: 25337.48828125
[INFO] Global_t: 836, Episode_t: 4, Action: 7, Reward: 3.36, Epsilon: 0.17
[INFO] model update: t: 837, loss: 10612.0859375
[INFO] Global_t: 837, Episode_t: 5, Action: 10, Reward: 1.76, Epsilon: 0.17
[INFO] model update: t: 838, loss: 15865.81640625
[INFO] Global_t: 838, Episode_t: 6, Action: 17, Reward: 1.97, Epsilon: 0.17
[INFO] model update: t: 839, loss: 18593.318359375
[INFO] Global_t: 839, Episode_t: 7, Action: 1, Reward: 1.75, Epsilon: 0.17
[INFO] model update: t: 840, loss: 15284.060546875
[INFO] Global_t: 840, Episode_t: 8, Action: 62, Reward: 1.17, Epsilon: 0.17
 42%|████▏     | 840/2000 [24:44<41:11,  2.13s/it]
[INFO] Global step: 840, Cumulative rewards: 22.05768, Runtime (s): 1484.70
------------------------------------------------------------
 
graph: 105, nodes: 180, edges: 531
[INFO] model update: t: 841, loss: 26460.130859375
[INFO] Global_t: 841, Episode_t: 1, Action: 4, Reward: 4.57, Epsilon: 0.17
[INFO] model update: t: 842, loss: 15521.447265625
[INFO] Global_t: 842, Episode_t: 2, Action: 106, Reward: 1.46, Epsilon: 0.17
[INFO] model update: t: 843, loss: 13940.544921875
[INFO] Global_t: 843, Episode_t: 3, Action: 5, Reward: 3.62, Epsilon: 0.16
[INFO] model update: t: 844, loss: 8235.830078125
[INFO] Global_t: 844, Episode_t: 4, Action: 6, Reward: 3.67, Epsilon: 0.16
[INFO] model update: t: 845, loss: 30652.7890625
[INFO] Global_t: 845, Episode_t: 5, Action: 2, Reward: 3.08, Epsilon: 0.16
[INFO] model update: t: 846, loss: 9953.2861328125
[INFO] Global_t: 846, Episode_t: 6, Action: 16, Reward: 2.09, Epsilon: 0.16
[INFO] model update: t: 847, loss: 16657.17578125
[INFO] Global_t: 847, Episode_t: 7, Action: 7, Reward: 2.57, Epsilon: 0.16
[INFO] model update: t: 848, loss: 9126.361328125
[INFO] Global_t: 848, Episode_t: 8, Action: 12, Reward: 2.14, Epsilon: 0.16
 42%|████▏     | 848/2000 [24:49<31:48,  1.66s/it]
[INFO] Global step: 848, Cumulative rewards: 23.213399999999993, Runtime (s): 1489.11
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4355344772338867
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.792597770690918
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5901925563812256
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8911795616149902
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.530698537826538
average cummulative reward vector is:  [0.12216553 0.11798866 0.12820191 0.12148668 0.12996774]
average cummulative reward is:  0.12396210409399548
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 106, nodes: 206, edges: 608
[INFO] model update: t: 849, loss: 34092.59765625
[INFO] Global_t: 849, Episode_t: 1, Action: 0, Reward: 4.21, Epsilon: 0.16
[INFO] model update: t: 850, loss: 43932.328125
[INFO] Global_t: 850, Episode_t: 2, Action: 24, Reward: 3.95, Epsilon: 0.16
[INFO] model update: t: 851, loss: 24227.75
[INFO] Global_t: 851, Episode_t: 3, Action: 19, Reward: 4.39, Epsilon: 0.16
[INFO] model update: t: 852, loss: 47994.4765625
[INFO] Global_t: 852, Episode_t: 4, Action: 17, Reward: 3.47, Epsilon: 0.16
[INFO] model update: t: 853, loss: 23568.12109375
[INFO] Global_t: 853, Episode_t: 5, Action: 8, Reward: 3.11, Epsilon: 0.16
[INFO] model update: t: 854, loss: 14375.89453125
[INFO] Global_t: 854, Episode_t: 6, Action: 10, Reward: 3.09, Epsilon: 0.15
[INFO] model update: t: 855, loss: 16424.7578125
[INFO] Global_t: 855, Episode_t: 7, Action: 28, Reward: 2.57, Epsilon: 0.15
[INFO] model update: t: 856, loss: 13733.5625
[INFO] Global_t: 856, Episode_t: 8, Action: 176, Reward: 1.03, Epsilon: 0.15
 43%|████▎     | 856/2000 [25:12<38:37,  2.03s/it]
[INFO] Global step: 856, Cumulative rewards: 25.817040000000002, Runtime (s): 1512.20
------------------------------------------------------------
 
graph: 107, nodes: 205, edges: 606
[INFO] model update: t: 857, loss: 27797.302734375
[INFO] Global_t: 857, Episode_t: 1, Action: 11, Reward: 3.94, Epsilon: 0.15
[INFO] model update: t: 858, loss: 10479.482421875
[INFO] Global_t: 858, Episode_t: 2, Action: 100, Reward: 1.40, Epsilon: 0.15
[INFO] model update: t: 859, loss: 8393.12109375
[INFO] Global_t: 859, Episode_t: 3, Action: 133, Reward: 1.74, Epsilon: 0.15
[INFO] model update: t: 860, loss: 19864.619140625
[INFO] Global_t: 860, Episode_t: 4, Action: 26, Reward: 3.02, Epsilon: 0.15
[INFO] model update: t: 861, loss: 15044.537109375
[INFO] Global_t: 861, Episode_t: 5, Action: 49, Reward: 2.79, Epsilon: 0.15
[INFO] model update: t: 862, loss: 17711.470703125
[INFO] Global_t: 862, Episode_t: 6, Action: 9, Reward: 2.72, Epsilon: 0.15
[INFO] model update: t: 863, loss: 28478.98828125
[INFO] Global_t: 863, Episode_t: 7, Action: 13, Reward: 2.96, Epsilon: 0.15
[INFO] model update: t: 864, loss: 15738.46875
[INFO] Global_t: 864, Episode_t: 8, Action: 95, Reward: 0.92, Epsilon: 0.14
 43%|████▎     | 864/2000 [25:17<30:26,  1.61s/it]
[INFO] Global step: 864, Cumulative rewards: 19.49016, Runtime (s): 1517.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6035139560699463
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9706013202667236
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.641491651535034
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.825788974761963
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9063222408294678
average cummulative reward vector is:  [0.12189474 0.121575   0.13406066 0.11579509 0.14233602]
average cummulative reward is:  0.1271323015086261
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 108, nodes: 215, edges: 636
[INFO] model update: t: 865, loss: 9556.876953125
[INFO] Global_t: 865, Episode_t: 1, Action: 7, Reward: 4.82, Epsilon: 0.14
[INFO] model update: t: 866, loss: 26346.16015625
[INFO] Global_t: 866, Episode_t: 2, Action: 14, Reward: 4.00, Epsilon: 0.14
[INFO] model update: t: 867, loss: 21781.33984375
[INFO] Global_t: 867, Episode_t: 3, Action: 8, Reward: 4.04, Epsilon: 0.14
[INFO] model update: t: 868, loss: 8988.4462890625
[INFO] Global_t: 868, Episode_t: 4, Action: 6, Reward: 3.92, Epsilon: 0.14
[INFO] model update: t: 869, loss: 11970.359375
[INFO] Global_t: 869, Episode_t: 5, Action: 9, Reward: 3.19, Epsilon: 0.14
[INFO] model update: t: 870, loss: 10593.181640625
[INFO] Global_t: 870, Episode_t: 6, Action: 2, Reward: 2.99, Epsilon: 0.14
[INFO] model update: t: 871, loss: 16583.98046875
[INFO] Global_t: 871, Episode_t: 7, Action: 5, Reward: 2.73, Epsilon: 0.14
[INFO] model update: t: 872, loss: 39326.71875
[INFO] Global_t: 872, Episode_t: 8, Action: 3, Reward: 2.77, Epsilon: 0.14
 44%|████▎     | 872/2000 [25:41<38:01,  2.02s/it]
[INFO] Global step: 872, Cumulative rewards: 28.4712, Runtime (s): 1541.19
------------------------------------------------------------
 
graph: 109, nodes: 186, edges: 549
[INFO] model update: t: 873, loss: 16774.5234375
[INFO] Global_t: 873, Episode_t: 1, Action: 14, Reward: 4.36, Epsilon: 0.14
[INFO] model update: t: 874, loss: 31467.12109375
[INFO] Global_t: 874, Episode_t: 2, Action: 156, Reward: 2.13, Epsilon: 0.13
[INFO] model update: t: 875, loss: 15666.5732421875
[INFO] Global_t: 875, Episode_t: 3, Action: 3, Reward: 5.54, Epsilon: 0.13
[INFO] model update: t: 876, loss: 41576.28515625
[INFO] Global_t: 876, Episode_t: 4, Action: 8, Reward: 3.67, Epsilon: 0.13
[INFO] model update: t: 877, loss: 45318.8671875
[INFO] Global_t: 877, Episode_t: 5, Action: 7, Reward: 2.96, Epsilon: 0.13
[INFO] model update: t: 878, loss: 11474.2890625
[INFO] Global_t: 878, Episode_t: 6, Action: 9, Reward: 2.28, Epsilon: 0.13
[INFO] model update: t: 879, loss: 83797.3125
[INFO] Global_t: 879, Episode_t: 7, Action: 5, Reward: 1.76, Epsilon: 0.13
[INFO] model update: t: 880, loss: 38988.73046875
[INFO] Global_t: 880, Episode_t: 8, Action: 17, Reward: 2.56, Epsilon: 0.13
 44%|████▍     | 880/2000 [25:46<29:58,  1.61s/it]
[INFO] Global step: 880, Cumulative rewards: 25.25748, Runtime (s): 1546.25
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.260770559310913
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.00317645072937
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5697686672210693
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.932863235473633
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.557323694229126
average cummulative reward vector is:  [0.13935632 0.12048611 0.13077869 0.11668879 0.12959758]
average cummulative reward is:  0.12738149622341305
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 110, nodes: 180, edges: 531
[INFO] model update: t: 881, loss: 30902.087890625
[INFO] Global_t: 881, Episode_t: 1, Action: 16, Reward: 2.77, Epsilon: 0.13
[INFO] model update: t: 882, loss: 57940.625
[INFO] Global_t: 882, Episode_t: 2, Action: 12, Reward: 4.24, Epsilon: 0.13
[INFO] model update: t: 883, loss: 15594.68359375
[INFO] Global_t: 883, Episode_t: 3, Action: 5, Reward: 3.92, Epsilon: 0.13
[INFO] model update: t: 884, loss: 36894.4375
[INFO] Global_t: 884, Episode_t: 4, Action: 19, Reward: 3.01, Epsilon: 0.12
[INFO] model update: t: 885, loss: 47777.7890625
[INFO] Global_t: 885, Episode_t: 5, Action: 2, Reward: 3.54, Epsilon: 0.12
[INFO] model update: t: 886, loss: 20189.37890625
[INFO] Global_t: 886, Episode_t: 6, Action: 43, Reward: 2.12, Epsilon: 0.12
[INFO] model update: t: 887, loss: 11608.025390625
[INFO] Global_t: 887, Episode_t: 7, Action: 14, Reward: 3.27, Epsilon: 0.12
[INFO] model update: t: 888, loss: 17186.4453125
[INFO] Global_t: 888, Episode_t: 8, Action: 1, Reward: 2.76, Epsilon: 0.12
 44%|████▍     | 888/2000 [26:10<37:27,  2.02s/it]
[INFO] Global step: 888, Cumulative rewards: 25.620359999999998, Runtime (s): 1570.16
------------------------------------------------------------
 
graph: 111, nodes: 200, edges: 591
[INFO] model update: t: 889, loss: 19576.76171875
[INFO] Global_t: 889, Episode_t: 1, Action: 4, Reward: 5.12, Epsilon: 0.12
[INFO] model update: t: 890, loss: 15301.5263671875
[INFO] Global_t: 890, Episode_t: 2, Action: 2, Reward: 3.34, Epsilon: 0.12
[INFO] model update: t: 891, loss: 42182.37109375
[INFO] Global_t: 891, Episode_t: 3, Action: 9, Reward: 3.39, Epsilon: 0.12
[INFO] model update: t: 892, loss: 11785.123046875
[INFO] Global_t: 892, Episode_t: 4, Action: 10, Reward: 3.22, Epsilon: 0.12
[INFO] model update: t: 893, loss: 26757.89453125
[INFO] Global_t: 893, Episode_t: 5, Action: 11, Reward: 2.33, Epsilon: 0.12
[INFO] model update: t: 894, loss: 30817.259765625
[INFO] Global_t: 894, Episode_t: 6, Action: 24, Reward: 2.16, Epsilon: 0.11
[INFO] model update: t: 895, loss: 32775.74609375
[INFO] Global_t: 895, Episode_t: 7, Action: 1, Reward: 2.47, Epsilon: 0.11
[INFO] model update: t: 896, loss: 79992.6171875
[INFO] Global_t: 896, Episode_t: 8, Action: 12, Reward: 2.61, Epsilon: 0.11
 45%|████▍     | 896/2000 [26:15<29:40,  1.61s/it]
[INFO] Global step: 896, Cumulative rewards: 24.62808, Runtime (s): 1575.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4272847175598145
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.983891487121582
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6932287216186523
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.692711114883423
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.63958740234375
average cummulative reward vector is:  [0.12065368 0.11869861 0.13522896 0.11290888 0.12578145]
average cummulative reward is:  0.1226543174375695
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 112, nodes: 216, edges: 639
[INFO] model update: t: 897, loss: 69373.0234375
[INFO] Global_t: 897, Episode_t: 1, Action: 10, Reward: 3.95, Epsilon: 0.11
[INFO] model update: t: 898, loss: 63432.81640625
[INFO] Global_t: 898, Episode_t: 2, Action: 56, Reward: 3.20, Epsilon: 0.11
[INFO] model update: t: 899, loss: 90822.25
[INFO] Global_t: 899, Episode_t: 3, Action: 23, Reward: 3.74, Epsilon: 0.11
[INFO] model update: t: 900, loss: 54275.1953125
[INFO] Global_t: 900, Episode_t: 4, Action: 8, Reward: 4.04, Epsilon: 0.11
[INFO] model update: t: 901, loss: 13951.39453125
[INFO] Global_t: 901, Episode_t: 5, Action: 5, Reward: 3.39, Epsilon: 0.11
[INFO] model update: t: 902, loss: 25376.75390625
[INFO] Global_t: 902, Episode_t: 6, Action: 13, Reward: 2.60, Epsilon: 0.11
[INFO] model update: t: 903, loss: 24678.142578125
[INFO] Global_t: 903, Episode_t: 7, Action: 11, Reward: 2.63, Epsilon: 0.11
[INFO] model update: t: 904, loss: 63751.50390625
[INFO] Global_t: 904, Episode_t: 8, Action: 42, Reward: 2.39, Epsilon: 0.11
 45%|████▌     | 904/2000 [26:38<36:27,  2.00s/it]
[INFO] Global step: 904, Cumulative rewards: 25.931160000000002, Runtime (s): 1598.58
------------------------------------------------------------
 
graph: 113, nodes: 217, edges: 642
[INFO] model update: t: 905, loss: 41093.33984375
[INFO] Global_t: 905, Episode_t: 1, Action: 5, Reward: 5.84, Epsilon: 0.10
[INFO] model update: t: 906, loss: 69484.6484375
[INFO] Global_t: 906, Episode_t: 2, Action: 6, Reward: 4.81, Epsilon: 0.10
[INFO] model update: t: 907, loss: 59541.265625
[INFO] Global_t: 907, Episode_t: 3, Action: 4, Reward: 4.30, Epsilon: 0.10
[INFO] model update: t: 908, loss: 45097.70703125
[INFO] Global_t: 908, Episode_t: 4, Action: 155, Reward: 1.85, Epsilon: 0.10
[INFO] model update: t: 909, loss: 8773.9111328125
[INFO] Global_t: 909, Episode_t: 5, Action: 7, Reward: 3.30, Epsilon: 0.10
[INFO] model update: t: 910, loss: 73786.3046875
[INFO] Global_t: 910, Episode_t: 6, Action: 24, Reward: 3.06, Epsilon: 0.10
[INFO] model update: t: 911, loss: 77899.4296875
[INFO] Global_t: 911, Episode_t: 7, Action: 11, Reward: 2.80, Epsilon: 0.10
[INFO] model update: t: 912, loss: 40724.80078125
[INFO] Global_t: 912, Episode_t: 8, Action: 2, Reward: 2.79, Epsilon: 0.10
 46%|████▌     | 912/2000 [26:43<28:42,  1.58s/it]
[INFO] Global step: 912, Cumulative rewards: 28.76004, Runtime (s): 1603.55
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8745574951171875
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8244171142578125
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7202999591827393
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.047199726104736
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7225613594055176
average cummulative reward vector is:  [0.13524658 0.11828704 0.12447186 0.1270215  0.1302871 ]
average cummulative reward is:  0.12706281320183982
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 114, nodes: 190, edges: 561
[INFO] model update: t: 913, loss: 139593.078125
[INFO] Global_t: 913, Episode_t: 1, Action: 8, Reward: 4.94, Epsilon: 0.10
[INFO] model update: t: 914, loss: 87951.8203125
[INFO] Global_t: 914, Episode_t: 2, Action: 13, Reward: 3.91, Epsilon: 0.10
[INFO] model update: t: 915, loss: 33703.41015625
[INFO] Global_t: 915, Episode_t: 3, Action: 12, Reward: 3.53, Epsilon: 0.09
[INFO] model update: t: 916, loss: 23543.7265625
[INFO] Global_t: 916, Episode_t: 4, Action: 1, Reward: 3.85, Epsilon: 0.09
[INFO] model update: t: 917, loss: 22617.009765625
[INFO] Global_t: 917, Episode_t: 5, Action: 9, Reward: 1.97, Epsilon: 0.09
[INFO] model update: t: 918, loss: 27048.94921875
[INFO] Global_t: 918, Episode_t: 6, Action: 70, Reward: 1.43, Epsilon: 0.09
[INFO] model update: t: 919, loss: 14977.3486328125
[INFO] Global_t: 919, Episode_t: 7, Action: 7, Reward: 2.35, Epsilon: 0.09
[INFO] model update: t: 920, loss: 48931.46875
[INFO] Global_t: 920, Episode_t: 8, Action: 10, Reward: 2.04, Epsilon: 0.09
 46%|████▌     | 920/2000 [27:08<36:54,  2.05s/it]
[INFO] Global step: 920, Cumulative rewards: 24.033599999999993, Runtime (s): 1628.67
------------------------------------------------------------
 
graph: 115, nodes: 198, edges: 585
[INFO] model update: t: 921, loss: 18318.39453125
[INFO] Global_t: 921, Episode_t: 1, Action: 15, Reward: 3.88, Epsilon: 0.09
[INFO] model update: t: 922, loss: 37416.234375
[INFO] Global_t: 922, Episode_t: 2, Action: 33, Reward: 1.61, Epsilon: 0.09
[INFO] model update: t: 923, loss: 94858.328125
[INFO] Global_t: 923, Episode_t: 3, Action: 22, Reward: 3.56, Epsilon: 0.09
[INFO] model update: t: 924, loss: 110902.5234375
[INFO] Global_t: 924, Episode_t: 4, Action: 9, Reward: 3.39, Epsilon: 0.09
[INFO] model update: t: 925, loss: 10690.6474609375
[INFO] Global_t: 925, Episode_t: 5, Action: 165, Reward: 0.85, Epsilon: 0.08
[INFO] model update: t: 926, loss: 13894.451171875
[INFO] Global_t: 926, Episode_t: 6, Action: 11, Reward: 2.50, Epsilon: 0.08
[INFO] model update: t: 927, loss: 29204.61328125
[INFO] Global_t: 927, Episode_t: 7, Action: 68, Reward: 1.13, Epsilon: 0.08
[INFO] model update: t: 928, loss: 23711.94140625
[INFO] Global_t: 928, Episode_t: 8, Action: 8, Reward: 2.91, Epsilon: 0.08
 46%|████▋     | 928/2000 [27:13<28:46,  1.61s/it]
[INFO] Global step: 928, Cumulative rewards: 19.83612, Runtime (s): 1633.34
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5978288650512695
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.866898775100708
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.004404783248901
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.737426996231079
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.623023271560669
average cummulative reward vector is:  [0.12813447 0.11968935 0.13974836 0.11539977 0.13162876]
average cummulative reward is:  0.1269201431975601
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 116, nodes: 182, edges: 537
[INFO] model update: t: 929, loss: 15138.69140625
[INFO] Global_t: 929, Episode_t: 1, Action: 0, Reward: 4.64, Epsilon: 0.08
[INFO] model update: t: 930, loss: 27163.400390625
[INFO] Global_t: 930, Episode_t: 2, Action: 5, Reward: 3.69, Epsilon: 0.08
[INFO] model update: t: 931, loss: 17418.1796875
[INFO] Global_t: 931, Episode_t: 3, Action: 9, Reward: 3.57, Epsilon: 0.08
[INFO] model update: t: 932, loss: 32022.66796875
[INFO] Global_t: 932, Episode_t: 4, Action: 10, Reward: 3.94, Epsilon: 0.08
[INFO] model update: t: 933, loss: 10980.072265625
[INFO] Global_t: 933, Episode_t: 5, Action: 11, Reward: 1.89, Epsilon: 0.08
[INFO] model update: t: 934, loss: 31002.49609375
[INFO] Global_t: 934, Episode_t: 6, Action: 18, Reward: 2.26, Epsilon: 0.08
[INFO] model update: t: 935, loss: 52947.6796875
[INFO] Global_t: 935, Episode_t: 7, Action: 52, Reward: 1.97, Epsilon: 0.07
[INFO] model update: t: 936, loss: 19742.078125
[INFO] Global_t: 936, Episode_t: 8, Action: 23, Reward: 1.76, Epsilon: 0.07
 47%|████▋     | 936/2000 [27:38<36:37,  2.07s/it]
[INFO] Global step: 936, Cumulative rewards: 23.70528, Runtime (s): 1658.35
------------------------------------------------------------
 
graph: 117, nodes: 196, edges: 579
[INFO] model update: t: 937, loss: 57416.59375
[INFO] Global_t: 937, Episode_t: 1, Action: 8, Reward: 4.71, Epsilon: 0.07
[INFO] model update: t: 938, loss: 31990.52734375
[INFO] Global_t: 938, Episode_t: 2, Action: 7, Reward: 3.91, Epsilon: 0.07
[INFO] model update: t: 939, loss: 34833.015625
[INFO] Global_t: 939, Episode_t: 3, Action: 5, Reward: 3.87, Epsilon: 0.07
[INFO] model update: t: 940, loss: 17390.74609375
[INFO] Global_t: 940, Episode_t: 4, Action: 17, Reward: 3.33, Epsilon: 0.07
[INFO] model update: t: 941, loss: 57899.53515625
[INFO] Global_t: 941, Episode_t: 5, Action: 0, Reward: 4.05, Epsilon: 0.07
[INFO] model update: t: 942, loss: 8460.400390625
[INFO] Global_t: 942, Episode_t: 6, Action: 6, Reward: 3.20, Epsilon: 0.07
[INFO] model update: t: 943, loss: 38184.453125
[INFO] Global_t: 943, Episode_t: 7, Action: 1, Reward: 3.51, Epsilon: 0.07
[INFO] model update: t: 944, loss: 70855.75
[INFO] Global_t: 944, Episode_t: 8, Action: 24, Reward: 2.56, Epsilon: 0.07
 47%|████▋     | 944/2000 [27:42<28:15,  1.61s/it]
[INFO] Global step: 944, Cumulative rewards: 29.13852, Runtime (s): 1662.62
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.172451972961426
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.65680193901062
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8333189487457275
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7168939113616943
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.515320062637329
average cummulative reward vector is:  [0.13747211 0.11373403 0.13577596 0.11400491 0.12620323]
average cummulative reward is:  0.12543804433471925
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 118, nodes: 180, edges: 531
[INFO] model update: t: 945, loss: 13322.205078125
[INFO] Global_t: 945, Episode_t: 1, Action: 5, Reward: 4.71, Epsilon: 0.06
[INFO] model update: t: 946, loss: 100064.171875
[INFO] Global_t: 946, Episode_t: 2, Action: 3, Reward: 4.99, Epsilon: 0.06
[INFO] model update: t: 947, loss: 137256.296875
[INFO] Global_t: 947, Episode_t: 3, Action: 20, Reward: 3.68, Epsilon: 0.06
[INFO] model update: t: 948, loss: 160017.3125
[INFO] Global_t: 948, Episode_t: 4, Action: 13, Reward: 2.42, Epsilon: 0.06
[INFO] model update: t: 949, loss: 49099.6640625
[INFO] Global_t: 949, Episode_t: 5, Action: 4, Reward: 3.00, Epsilon: 0.06
[INFO] model update: t: 950, loss: 36828.36328125
[INFO] Global_t: 950, Episode_t: 6, Action: 49, Reward: 2.35, Epsilon: 0.06
[INFO] model update: t: 951, loss: 95313.1015625
[INFO] Global_t: 951, Episode_t: 7, Action: 29, Reward: 3.00, Epsilon: 0.06
[INFO] model update: t: 952, loss: 51743.65234375
[INFO] Global_t: 952, Episode_t: 8, Action: 14, Reward: 2.64, Epsilon: 0.06
 48%|████▊     | 952/2000 [28:05<34:42,  1.99s/it]
[INFO] Global step: 952, Cumulative rewards: 26.788440000000005, Runtime (s): 1685.64
------------------------------------------------------------
 
graph: 119, nodes: 182, edges: 537
[INFO] model update: t: 953, loss: 197507.046875
[INFO] Global_t: 953, Episode_t: 1, Action: 3, Reward: 4.63, Epsilon: 0.06
[INFO] model update: t: 954, loss: 20767.0625
[INFO] Global_t: 954, Episode_t: 2, Action: 8, Reward: 4.44, Epsilon: 0.06
[INFO] model update: t: 955, loss: 230716.984375
[INFO] Global_t: 955, Episode_t: 3, Action: 14, Reward: 4.19, Epsilon: 0.06
[INFO] model update: t: 956, loss: 60354.953125
[INFO] Global_t: 956, Episode_t: 4, Action: 7, Reward: 4.66, Epsilon: 0.05
[INFO] model update: t: 957, loss: 126532.765625
[INFO] Global_t: 957, Episode_t: 5, Action: 13, Reward: 2.07, Epsilon: 0.05
[INFO] model update: t: 958, loss: 85377.5625
[INFO] Global_t: 958, Episode_t: 6, Action: 12, Reward: 2.76, Epsilon: 0.05
[INFO] model update: t: 959, loss: 95988.796875
[INFO] Global_t: 959, Episode_t: 7, Action: 10, Reward: 2.33, Epsilon: 0.05
[INFO] model update: t: 960, loss: 312394.1875
[INFO] Global_t: 960, Episode_t: 8, Action: 20, Reward: 2.97, Epsilon: 0.05
 48%|████▊     | 960/2000 [28:10<27:02,  1.56s/it]
[INFO] Global step: 960, Cumulative rewards: 28.05588, Runtime (s): 1690.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.879077672958374
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.17090630531311
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.718393564224243
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8227903842926025
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9231603145599365
average cummulative reward vector is:  [0.13770447 0.12045185 0.13879754 0.11391612 0.14083871]
average cummulative reward is:  0.13034173953848308
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 120, nodes: 219, edges: 648
[INFO] model update: t: 961, loss: 172150.21875
[INFO] Global_t: 961, Episode_t: 1, Action: 0, Reward: 4.97, Epsilon: 0.05
[INFO] model update: t: 962, loss: 48815.33203125
[INFO] Global_t: 962, Episode_t: 2, Action: 43, Reward: 3.82, Epsilon: 0.05
[INFO] model update: t: 963, loss: 98606.875
[INFO] Global_t: 963, Episode_t: 3, Action: 17, Reward: 3.27, Epsilon: 0.05
[INFO] model update: t: 964, loss: 36451.390625
[INFO] Global_t: 964, Episode_t: 4, Action: 26, Reward: 3.54, Epsilon: 0.05
[INFO] model update: t: 965, loss: 60364.921875
[INFO] Global_t: 965, Episode_t: 5, Action: 25, Reward: 2.48, Epsilon: 0.05
[INFO] model update: t: 966, loss: 60748.33984375
[INFO] Global_t: 966, Episode_t: 6, Action: 4, Reward: 3.37, Epsilon: 0.04
[INFO] model update: t: 967, loss: 41409.890625
[INFO] Global_t: 967, Episode_t: 7, Action: 3, Reward: 2.98, Epsilon: 0.04
[INFO] model update: t: 968, loss: 48683.95703125
[INFO] Global_t: 968, Episode_t: 8, Action: 20, Reward: 2.71, Epsilon: 0.04
 48%|████▊     | 968/2000 [28:38<37:02,  2.15s/it]
[INFO] Global step: 968, Cumulative rewards: 27.14808, Runtime (s): 1718.46
------------------------------------------------------------
 
graph: 121, nodes: 182, edges: 536
[INFO] model update: t: 969, loss: 22826.873046875
[INFO] Global_t: 969, Episode_t: 1, Action: 10, Reward: 4.86, Epsilon: 0.04
[INFO] model update: t: 970, loss: 40009.875
[INFO] Global_t: 970, Episode_t: 2, Action: 16, Reward: 3.46, Epsilon: 0.04
[INFO] model update: t: 971, loss: 12199.3828125
[INFO] Global_t: 971, Episode_t: 3, Action: 5, Reward: 4.22, Epsilon: 0.04
[INFO] model update: t: 972, loss: 21380.841796875
[INFO] Global_t: 972, Episode_t: 4, Action: 6, Reward: 3.77, Epsilon: 0.04
[INFO] model update: t: 973, loss: 49141.44140625
[INFO] Global_t: 973, Episode_t: 5, Action: 14, Reward: 1.76, Epsilon: 0.04
[INFO] model update: t: 974, loss: 43000.8359375
[INFO] Global_t: 974, Episode_t: 6, Action: 18, Reward: 2.82, Epsilon: 0.04
[INFO] model update: t: 975, loss: 29191.6953125
[INFO] Global_t: 975, Episode_t: 7, Action: 8, Reward: 2.33, Epsilon: 0.04
[INFO] model update: t: 976, loss: 52999.8046875
[INFO] Global_t: 976, Episode_t: 8, Action: 3, Reward: 3.42, Epsilon: 0.03
 49%|████▉     | 976/2000 [28:43<29:00,  1.70s/it]
[INFO] Global step: 976, Cumulative rewards: 26.634960000000003, Runtime (s): 1723.59
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.141138792037964
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8195769786834717
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.521343946456909
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.971553087234497
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.633270740509033
average cummulative reward vector is:  [0.14079842 0.11932338 0.13062596 0.11988645 0.12918145]
average cummulative reward is:  0.12796313143548965
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 122, nodes: 206, edges: 609
[INFO] model update: t: 977, loss: 26563.09765625
[INFO] Global_t: 977, Episode_t: 1, Action: 10, Reward: 4.10, Epsilon: 0.03
[INFO] model update: t: 978, loss: 58804.6484375
[INFO] Global_t: 978, Episode_t: 2, Action: 1, Reward: 5.14, Epsilon: 0.03
[INFO] model update: t: 979, loss: 8618.30859375
[INFO] Global_t: 979, Episode_t: 3, Action: 9, Reward: 3.46, Epsilon: 0.03
[INFO] model update: t: 980, loss: 38486.9296875
[INFO] Global_t: 980, Episode_t: 4, Action: 6, Reward: 4.58, Epsilon: 0.03
[INFO] model update: t: 981, loss: 39560.4609375
[INFO] Global_t: 981, Episode_t: 5, Action: 16, Reward: 2.69, Epsilon: 0.03
[INFO] model update: t: 982, loss: 30151.75390625
[INFO] Global_t: 982, Episode_t: 6, Action: 7, Reward: 4.15, Epsilon: 0.03
[INFO] model update: t: 983, loss: 97057.875
[INFO] Global_t: 983, Episode_t: 7, Action: 12, Reward: 3.32, Epsilon: 0.03
[INFO] model update: t: 984, loss: 20786.283203125
[INFO] Global_t: 984, Episode_t: 8, Action: 26, Reward: 3.28, Epsilon: 0.03
 49%|████▉     | 984/2000 [29:07<35:09,  2.08s/it]
[INFO] Global step: 984, Cumulative rewards: 30.712080000000004, Runtime (s): 1747.22
------------------------------------------------------------
 
graph: 123, nodes: 182, edges: 537
[INFO] model update: t: 985, loss: 40616.5859375
[INFO] Global_t: 985, Episode_t: 1, Action: 3, Reward: 4.24, Epsilon: 0.03
[INFO] model update: t: 986, loss: 61899.7421875
[INFO] Global_t: 986, Episode_t: 2, Action: 4, Reward: 4.44, Epsilon: 0.02
[INFO] model update: t: 987, loss: 9292.1787109375
[INFO] Global_t: 987, Episode_t: 3, Action: 8, Reward: 3.81, Epsilon: 0.02
[INFO] model update: t: 988, loss: 57760.73828125
[INFO] Global_t: 988, Episode_t: 4, Action: 7, Reward: 3.50, Epsilon: 0.02
[INFO] model update: t: 989, loss: 18617.359375
[INFO] Global_t: 989, Episode_t: 5, Action: 2, Reward: 4.87, Epsilon: 0.02
[INFO] model update: t: 990, loss: 38612.515625
[INFO] Global_t: 990, Episode_t: 6, Action: 31, Reward: 3.36, Epsilon: 0.02
[INFO] model update: t: 991, loss: 29625.79296875
[INFO] Global_t: 991, Episode_t: 7, Action: 14, Reward: 3.23, Epsilon: 0.02
[INFO] model update: t: 992, loss: 22189.15234375
[INFO] Global_t: 992, Episode_t: 8, Action: 1, Reward: 4.34, Epsilon: 0.02
 50%|████▉     | 992/2000 [29:10<26:29,  1.58s/it]
[INFO] Global step: 992, Cumulative rewards: 31.775039999999997, Runtime (s): 1750.53
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.593418836593628
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.188143968582153
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6553242206573486
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.020276308059692
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8182737827301025
average cummulative reward vector is:  [0.12718053 0.12532731 0.13352459 0.12705234 0.13084866]
average cummulative reward is:  0.12878668473142307
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 124, nodes: 194, edges: 573
[INFO] model update: t: 993, loss: 105389.078125
[INFO] Global_t: 993, Episode_t: 1, Action: 1, Reward: 5.11, Epsilon: 0.02
[INFO] model update: t: 994, loss: 15430.517578125
[INFO] Global_t: 994, Episode_t: 2, Action: 6, Reward: 5.12, Epsilon: 0.02
[INFO] model update: t: 995, loss: 190538.96875
[INFO] Global_t: 995, Episode_t: 3, Action: 0, Reward: 3.47, Epsilon: 0.02
[INFO] model update: t: 996, loss: 156801.8125
[INFO] Global_t: 996, Episode_t: 4, Action: 2, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 997, loss: 33725.546875
[INFO] Global_t: 997, Episode_t: 5, Action: 7, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 998, loss: 115933.671875
[INFO] Global_t: 998, Episode_t: 6, Action: 24, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 999, loss: 161479.28125
[INFO] Global_t: 999, Episode_t: 7, Action: 8, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 1000, loss: 16107.4521484375
[INFO] Global_t: 1000, Episode_t: 8, Action: 41, Reward: 2.60, Epsilon: 0.01
 50%|█████     | 1000/2000 [29:34<33:17,  2.00s/it]
[INFO] Global step: 1000, Cumulative rewards: 27.86712, Runtime (s): 1774.35
------------------------------------------------------------
 
graph: 125, nodes: 209, edges: 617
[INFO] model update: t: 1001, loss: 101727.609375
[INFO] Global_t: 1001, Episode_t: 1, Action: 8, Reward: 5.34, Epsilon: 0.01
[INFO] model update: t: 1002, loss: 47739.5234375
[INFO] Global_t: 1002, Episode_t: 2, Action: 4, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 1003, loss: 52272.7578125
[INFO] Global_t: 1003, Episode_t: 3, Action: 9, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1004, loss: 63701.03125
[INFO] Global_t: 1004, Episode_t: 4, Action: 13, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 1005, loss: 34893.52734375
[INFO] Global_t: 1005, Episode_t: 5, Action: 2, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1006, loss: 78860.78125
[INFO] Global_t: 1006, Episode_t: 6, Action: 21, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1007, loss: 64069.5546875
[INFO] Global_t: 1007, Episode_t: 7, Action: 17, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1008, loss: 351283.21875
[INFO] Global_t: 1008, Episode_t: 8, Action: 15, Reward: 2.23, Epsilon: 0.01
 50%|█████     | 1008/2000 [29:40<26:58,  1.63s/it]
[INFO] Global step: 1008, Cumulative rewards: 26.920920000000002, Runtime (s): 1780.56
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7072699069976807
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.0997231006622314
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.749512195587158
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5917129516601562
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5953426361083984
average cummulative reward vector is:  [0.13052921 0.11760648 0.13637596 0.11313785 0.1245793 ]
average cummulative reward is:  0.1244457599669018
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 126, nodes: 218, edges: 645
[INFO] model update: t: 1009, loss: 236619.546875
[INFO] Global_t: 1009, Episode_t: 1, Action: 6, Reward: 5.00, Epsilon: 0.01
[INFO] model update: t: 1010, loss: 77252.9453125
[INFO] Global_t: 1010, Episode_t: 2, Action: 38, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 1011, loss: 589542.375
[INFO] Global_t: 1011, Episode_t: 3, Action: 11, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 1012, loss: 300581.125
[INFO] Global_t: 1012, Episode_t: 4, Action: 20, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 1013, loss: 143730.90625
[INFO] Global_t: 1013, Episode_t: 5, Action: 32, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1014, loss: 609285.125
[INFO] Global_t: 1014, Episode_t: 6, Action: 16, Reward: 2.88, Epsilon: 0.01
[INFO] model update: t: 1015, loss: 85356.671875
[INFO] Global_t: 1015, Episode_t: 7, Action: 52, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1016, loss: 177755.0
[INFO] Global_t: 1016, Episode_t: 8, Action: 48, Reward: 2.17, Epsilon: 0.01
 51%|█████     | 1016/2000 [30:03<32:57,  2.01s/it]
[INFO] Global step: 1016, Cumulative rewards: 26.54436, Runtime (s): 1803.70
------------------------------------------------------------
 
graph: 127, nodes: 189, edges: 558
[INFO] model update: t: 1017, loss: 176253.078125
[INFO] Global_t: 1017, Episode_t: 1, Action: 15, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1018, loss: 14541.421875
[INFO] Global_t: 1018, Episode_t: 2, Action: 5, Reward: 5.41, Epsilon: 0.01
[INFO] model update: t: 1019, loss: 97699.9609375
[INFO] Global_t: 1019, Episode_t: 3, Action: 12, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1020, loss: 21370.283203125
[INFO] Global_t: 1020, Episode_t: 4, Action: 11, Reward: 4.31, Epsilon: 0.01
[INFO] model update: t: 1021, loss: 111559.15625
[INFO] Global_t: 1021, Episode_t: 5, Action: 32, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 1022, loss: 171701.140625
[INFO] Global_t: 1022, Episode_t: 6, Action: 44, Reward: 2.94, Epsilon: 0.01
[INFO] model update: t: 1023, loss: 16728.0859375
[INFO] Global_t: 1023, Episode_t: 7, Action: 6, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 1024, loss: 149411.265625
[INFO] Global_t: 1024, Episode_t: 8, Action: 16, Reward: 2.18, Epsilon: 0.01
 51%|█████     | 1024/2000 [30:07<25:27,  1.57s/it]
[INFO] Global step: 1024, Cumulative rewards: 27.773279999999993, Runtime (s): 1807.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.0004661083221436
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8110337257385254
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.106749057769775
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.194960832595825
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.674987554550171
average cummulative reward vector is:  [0.12968342 0.11768241 0.13783279 0.12833505 0.13239973]
average cummulative reward is:  0.12918667865141048
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 128, nodes: 198, edges: 585
[INFO] model update: t: 1025, loss: 33048.94921875
[INFO] Global_t: 1025, Episode_t: 1, Action: 4, Reward: 4.60, Epsilon: 0.01
[INFO] model update: t: 1026, loss: 69458.25
[INFO] Global_t: 1026, Episode_t: 2, Action: 8, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1027, loss: 73042.359375
[INFO] Global_t: 1027, Episode_t: 3, Action: 12, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1028, loss: 18495.90234375
[INFO] Global_t: 1028, Episode_t: 4, Action: 21, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 1029, loss: 40398.609375
[INFO] Global_t: 1029, Episode_t: 5, Action: 5, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1030, loss: 30187.39453125
[INFO] Global_t: 1030, Episode_t: 6, Action: 6, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1031, loss: 130772.578125
[INFO] Global_t: 1031, Episode_t: 7, Action: 22, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1032, loss: 20596.447265625
[INFO] Global_t: 1032, Episode_t: 8, Action: 9, Reward: 1.65, Epsilon: 0.01
 52%|█████▏    | 1032/2000 [30:32<32:42,  2.03s/it]
[INFO] Global step: 1032, Cumulative rewards: 24.31476, Runtime (s): 1832.77
------------------------------------------------------------
 
graph: 129, nodes: 211, edges: 624
[INFO] model update: t: 1033, loss: 51200.28515625
[INFO] Global_t: 1033, Episode_t: 1, Action: 7, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1034, loss: 60270.0234375
[INFO] Global_t: 1034, Episode_t: 2, Action: 16, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 1035, loss: 13136.0341796875
[INFO] Global_t: 1035, Episode_t: 3, Action: 5, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1036, loss: 31047.29296875
[INFO] Global_t: 1036, Episode_t: 4, Action: 8, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 1037, loss: 42336.1328125
[INFO] Global_t: 1037, Episode_t: 5, Action: 23, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1038, loss: 17394.59765625
[INFO] Global_t: 1038, Episode_t: 6, Action: 17, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1039, loss: 21738.84765625
[INFO] Global_t: 1039, Episode_t: 7, Action: 35, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1040, loss: 25185.828125
[INFO] Global_t: 1040, Episode_t: 8, Action: 11, Reward: 1.74, Epsilon: 0.01
 52%|█████▏    | 1040/2000 [30:38<25:57,  1.62s/it]
[INFO] Global step: 1040, Cumulative rewards: 23.475479999999997, Runtime (s): 1838.21
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.013700008392334
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.284332990646362
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.0056047439575195
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5540428161621094
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6811728477478027
average cummulative reward vector is:  [0.13229579 0.12693264 0.14211639 0.11232407 0.13480645]
average cummulative reward is:  0.129695067767732
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 130, nodes: 205, edges: 606
[INFO] model update: t: 1041, loss: 11267.796875
[INFO] Global_t: 1041, Episode_t: 1, Action: 11, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1042, loss: 19102.4453125
[INFO] Global_t: 1042, Episode_t: 2, Action: 4, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1043, loss: 22818.05078125
[INFO] Global_t: 1043, Episode_t: 3, Action: 18, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1044, loss: 18344.560546875
[INFO] Global_t: 1044, Episode_t: 4, Action: 13, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 1045, loss: 30558.4140625
[INFO] Global_t: 1045, Episode_t: 5, Action: 10, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1046, loss: 14994.13671875
[INFO] Global_t: 1046, Episode_t: 6, Action: 8, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1047, loss: 22540.478515625
[INFO] Global_t: 1047, Episode_t: 7, Action: 1, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1048, loss: 44194.328125
[INFO] Global_t: 1048, Episode_t: 8, Action: 27, Reward: 1.18, Epsilon: 0.01
 52%|█████▏    | 1048/2000 [31:03<33:16,  2.10s/it]
[INFO] Global step: 1048, Cumulative rewards: 25.72608, Runtime (s): 1863.84
------------------------------------------------------------
 
graph: 131, nodes: 210, edges: 620
[INFO] model update: t: 1049, loss: 20296.3515625
[INFO] Global_t: 1049, Episode_t: 1, Action: 0, Reward: 5.34, Epsilon: 0.01
[INFO] model update: t: 1050, loss: 13482.4716796875
[INFO] Global_t: 1050, Episode_t: 2, Action: 11, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1051, loss: 8294.7568359375
[INFO] Global_t: 1051, Episode_t: 3, Action: 7, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 1052, loss: 17602.388671875
[INFO] Global_t: 1052, Episode_t: 4, Action: 8, Reward: 4.93, Epsilon: 0.01
[INFO] model update: t: 1053, loss: 11402.689453125
[INFO] Global_t: 1053, Episode_t: 5, Action: 1, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 1054, loss: 6059.27001953125
[INFO] Global_t: 1054, Episode_t: 6, Action: 16, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 1055, loss: 10827.76171875
[INFO] Global_t: 1055, Episode_t: 7, Action: 14, Reward: 1.73, Epsilon: 0.01
[INFO] model update: t: 1056, loss: 18859.41796875
[INFO] Global_t: 1056, Episode_t: 8, Action: 26, Reward: 2.57, Epsilon: 0.01
 53%|█████▎    | 1056/2000 [31:09<26:15,  1.67s/it]
[INFO] Global step: 1056, Cumulative rewards: 27.137039999999995, Runtime (s): 1869.21
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9207003116607666
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.1395440101623535
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.802046775817871
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6637001037597656
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.424437999725342
average cummulative reward vector is:  [0.13297079 0.12552407 0.1274041  0.11130584 0.12614704]
average cummulative reward is:  0.12467036920813243
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 132, nodes: 213, edges: 630
[INFO] model update: t: 1057, loss: 28150.94921875
[INFO] Global_t: 1057, Episode_t: 1, Action: 6, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 1058, loss: 99866.109375
[INFO] Global_t: 1058, Episode_t: 2, Action: 1, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1059, loss: 37639.1875
[INFO] Global_t: 1059, Episode_t: 3, Action: 17, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1060, loss: 29381.65234375
[INFO] Global_t: 1060, Episode_t: 4, Action: 8, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1061, loss: 50439.3671875
[INFO] Global_t: 1061, Episode_t: 5, Action: 33, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1062, loss: 20657.6015625
[INFO] Global_t: 1062, Episode_t: 6, Action: 7, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 1063, loss: 24338.60546875
[INFO] Global_t: 1063, Episode_t: 7, Action: 21, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1064, loss: 39837.359375
[INFO] Global_t: 1064, Episode_t: 8, Action: 19, Reward: 1.65, Epsilon: 0.01
 53%|█████▎    | 1064/2000 [31:34<32:54,  2.11s/it]
[INFO] Global step: 1064, Cumulative rewards: 24.99912, Runtime (s): 1894.29
------------------------------------------------------------
 
graph: 133, nodes: 213, edges: 630
[INFO] model update: t: 1065, loss: 28265.56640625
[INFO] Global_t: 1065, Episode_t: 1, Action: 9, Reward: 5.21, Epsilon: 0.01
[INFO] model update: t: 1066, loss: 40620.12890625
[INFO] Global_t: 1066, Episode_t: 2, Action: 19, Reward: 4.19, Epsilon: 0.01
[INFO] model update: t: 1067, loss: 61287.125
[INFO] Global_t: 1067, Episode_t: 3, Action: 4, Reward: 4.31, Epsilon: 0.01
[INFO] model update: t: 1068, loss: 30873.240234375
[INFO] Global_t: 1068, Episode_t: 4, Action: 13, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1069, loss: 34034.34765625
[INFO] Global_t: 1069, Episode_t: 5, Action: 7, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 1070, loss: 50224.3828125
[INFO] Global_t: 1070, Episode_t: 6, Action: 2, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 1071, loss: 9560.3779296875
[INFO] Global_t: 1071, Episode_t: 7, Action: 29, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1072, loss: 37765.4375
[INFO] Global_t: 1072, Episode_t: 8, Action: 16, Reward: 2.92, Epsilon: 0.01
 54%|█████▎    | 1072/2000 [31:38<25:31,  1.65s/it]
[INFO] Global step: 1072, Cumulative rewards: 28.28904, Runtime (s): 1898.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.088146448135376
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.172686815261841
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5222887992858887
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7910819053649902
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6204516887664795
average cummulative reward vector is:  [0.13127816 0.1277831  0.12903361 0.11573061 0.13216317]
average cummulative reward is:  0.1271977291647224
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 134, nodes: 215, edges: 635
[INFO] model update: t: 1073, loss: 28166.6015625
[INFO] Global_t: 1073, Episode_t: 1, Action: 3, Reward: 5.11, Epsilon: 0.01
[INFO] model update: t: 1074, loss: 13972.162109375
[INFO] Global_t: 1074, Episode_t: 2, Action: 1, Reward: 4.96, Epsilon: 0.01
[INFO] model update: t: 1075, loss: 29502.69921875
[INFO] Global_t: 1075, Episode_t: 3, Action: 33, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1076, loss: 27287.703125
[INFO] Global_t: 1076, Episode_t: 4, Action: 10, Reward: 3.52, Epsilon: 0.01
[INFO] model update: t: 1077, loss: 34449.53125
[INFO] Global_t: 1077, Episode_t: 5, Action: 16, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 1078, loss: 39404.66796875
[INFO] Global_t: 1078, Episode_t: 6, Action: 18, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 1079, loss: 16720.2265625
[INFO] Global_t: 1079, Episode_t: 7, Action: 13, Reward: 3.48, Epsilon: 0.01
[INFO] model update: t: 1080, loss: 41993.13671875
[INFO] Global_t: 1080, Episode_t: 8, Action: 29, Reward: 2.17, Epsilon: 0.01
 54%|█████▍    | 1080/2000 [32:03<31:41,  2.07s/it]
[INFO] Global step: 1080, Cumulative rewards: 28.99128, Runtime (s): 1923.24
------------------------------------------------------------
 
graph: 135, nodes: 211, edges: 624
[INFO] model update: t: 1081, loss: 27898.05859375
[INFO] Global_t: 1081, Episode_t: 1, Action: 7, Reward: 4.72, Epsilon: 0.01
[INFO] model update: t: 1082, loss: 11502.923828125
[INFO] Global_t: 1082, Episode_t: 2, Action: 5, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1083, loss: 35043.41015625
[INFO] Global_t: 1083, Episode_t: 3, Action: 13, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1084, loss: 8680.6396484375
[INFO] Global_t: 1084, Episode_t: 4, Action: 19, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1085, loss: 34948.328125
[INFO] Global_t: 1085, Episode_t: 5, Action: 11, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1086, loss: 17773.7890625
[INFO] Global_t: 1086, Episode_t: 6, Action: 21, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1087, loss: 72651.3359375
[INFO] Global_t: 1087, Episode_t: 7, Action: 0, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1088, loss: 176756.96875
[INFO] Global_t: 1088, Episode_t: 8, Action: 16, Reward: 2.12, Epsilon: 0.01

[INFO] Global step: 1088, Cumulative rewards: 26.832480000000007, Runtime (s): 1928.49
------------------------------------------------------------
 
 54%|█████▍    | 1088/2000 [32:08<24:59,  1.64s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8833377361297607
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8184776306152344
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9389474391937256
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.0814948081970215
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9050047397613525
average cummulative reward vector is:  [0.13953816 0.11184167 0.14466721 0.11942617 0.14348441]
average cummulative reward is:  0.13179152290052143
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 136, nodes: 211, edges: 624
[INFO] model update: t: 1089, loss: 21308.56640625
[INFO] Global_t: 1089, Episode_t: 1, Action: 11, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1090, loss: 70129.15625
[INFO] Global_t: 1090, Episode_t: 2, Action: 6, Reward: 5.22, Epsilon: 0.01
[INFO] model update: t: 1091, loss: 53108.421875
[INFO] Global_t: 1091, Episode_t: 3, Action: 4, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 1092, loss: 46189.5
[INFO] Global_t: 1092, Episode_t: 4, Action: 16, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 1093, loss: 82426.75
[INFO] Global_t: 1093, Episode_t: 5, Action: 3, Reward: 5.82, Epsilon: 0.01
[INFO] model update: t: 1094, loss: 34480.578125
[INFO] Global_t: 1094, Episode_t: 6, Action: 21, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1095, loss: 34412.90625
[INFO] Global_t: 1095, Episode_t: 7, Action: 24, Reward: 3.14, Epsilon: 0.01
[INFO] model update: t: 1096, loss: 128516.21875
[INFO] Global_t: 1096, Episode_t: 8, Action: 58, Reward: 3.32, Epsilon: 0.01
 55%|█████▍    | 1096/2000 [32:31<30:21,  2.02s/it]
[INFO] Global step: 1096, Cumulative rewards: 32.666399999999996, Runtime (s): 1951.55
------------------------------------------------------------
 
graph: 137, nodes: 210, edges: 621
[INFO] model update: t: 1097, loss: 7664.4580078125
[INFO] Global_t: 1097, Episode_t: 1, Action: 5, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 1098, loss: 121692.578125
[INFO] Global_t: 1098, Episode_t: 2, Action: 6, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1099, loss: 97238.5078125
[INFO] Global_t: 1099, Episode_t: 3, Action: 13, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1100, loss: 41603.9453125
[INFO] Global_t: 1100, Episode_t: 4, Action: 8, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 1101, loss: 221508.09375
[INFO] Global_t: 1101, Episode_t: 5, Action: 9, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1102, loss: 143334.78125
[INFO] Global_t: 1102, Episode_t: 6, Action: 35, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 1103, loss: 17106.7578125
[INFO] Global_t: 1103, Episode_t: 7, Action: 12, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1104, loss: 46423.7578125
[INFO] Global_t: 1104, Episode_t: 8, Action: 24, Reward: 2.81, Epsilon: 0.01

[INFO] Global step: 1104, Cumulative rewards: 30.35544, Runtime (s): 1956.96
------------------------------------------------------------
 
 55%|█████▌    | 1104/2000 [32:36<24:05,  1.61s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.521916627883911
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.2353150844573975
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6077537536621094
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5204882621765137
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.177320241928101
average cummulative reward vector is:  [0.12555263 0.12534537 0.1336735  0.10946192 0.13751102]
average cummulative reward is:  0.12630888732206086
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 138, nodes: 185, edges: 545
[INFO] model update: t: 1105, loss: 53676.109375
[INFO] Global_t: 1105, Episode_t: 1, Action: 9, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1106, loss: 26784.357421875
[INFO] Global_t: 1106, Episode_t: 2, Action: 29, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 1107, loss: 22854.525390625
[INFO] Global_t: 1107, Episode_t: 3, Action: 3, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1108, loss: 5608.57177734375
[INFO] Global_t: 1108, Episode_t: 4, Action: 20, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 1109, loss: 24601.720703125
[INFO] Global_t: 1109, Episode_t: 5, Action: 15, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 1110, loss: 22704.369140625
[INFO] Global_t: 1110, Episode_t: 6, Action: 13, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1111, loss: 20949.86328125
[INFO] Global_t: 1111, Episode_t: 7, Action: 12, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1112, loss: 44340.96875
[INFO] Global_t: 1112, Episode_t: 8, Action: 7, Reward: 2.45, Epsilon: 0.01
 56%|█████▌    | 1112/2000 [33:01<30:04,  2.03s/it]
[INFO] Global step: 1112, Cumulative rewards: 24.520680000000002, Runtime (s): 1981.04
------------------------------------------------------------
 
graph: 139, nodes: 184, edges: 543
[INFO] model update: t: 1113, loss: 100475.1875
[INFO] Global_t: 1113, Episode_t: 1, Action: 5, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1114, loss: 48101.57421875
[INFO] Global_t: 1114, Episode_t: 2, Action: 10, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1115, loss: 18976.87890625
[INFO] Global_t: 1115, Episode_t: 3, Action: 3, Reward: 4.43, Epsilon: 0.01
[INFO] model update: t: 1116, loss: 102851.078125
[INFO] Global_t: 1116, Episode_t: 4, Action: 38, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 1117, loss: 12622.548828125
[INFO] Global_t: 1117, Episode_t: 5, Action: 9, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 1118, loss: 83219.4296875
[INFO] Global_t: 1118, Episode_t: 6, Action: 12, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1119, loss: 84130.890625
[INFO] Global_t: 1119, Episode_t: 7, Action: 8, Reward: 3.26, Epsilon: 0.01
[INFO] model update: t: 1120, loss: 17264.724609375
[INFO] Global_t: 1120, Episode_t: 8, Action: 32, Reward: 1.89, Epsilon: 0.01
 56%|█████▌    | 1120/2000 [33:06<23:41,  1.62s/it]
[INFO] Global step: 1120, Cumulative rewards: 25.3764, Runtime (s): 1986.18
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.865359306335449
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.217935562133789
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.02994441986084
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6447067260742188
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.647465229034424
average cummulative reward vector is:  [0.13695474 0.13165509 0.13410792 0.11186075 0.12917527]
average cummulative reward is:  0.12875075388254426
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 140, nodes: 220, edges: 651
[INFO] model update: t: 1121, loss: 64064.8359375
[INFO] Global_t: 1121, Episode_t: 1, Action: 13, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 1122, loss: 96655.21875
[INFO] Global_t: 1122, Episode_t: 2, Action: 12, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 1123, loss: 28060.904296875
[INFO] Global_t: 1123, Episode_t: 3, Action: 30, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 1124, loss: 9294.1875
[INFO] Global_t: 1124, Episode_t: 4, Action: 31, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1125, loss: 21260.875
[INFO] Global_t: 1125, Episode_t: 5, Action: 14, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1126, loss: 8715.76953125
[INFO] Global_t: 1126, Episode_t: 6, Action: 24, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 1127, loss: 39863.1015625
[INFO] Global_t: 1127, Episode_t: 7, Action: 18, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1128, loss: 30691.7890625
[INFO] Global_t: 1128, Episode_t: 8, Action: 2, Reward: 2.19, Epsilon: 0.01
 56%|█████▋    | 1128/2000 [33:30<29:46,  2.05s/it]
[INFO] Global step: 1128, Cumulative rewards: 25.286880000000004, Runtime (s): 2010.66
------------------------------------------------------------
 
graph: 141, nodes: 205, edges: 606
[INFO] model update: t: 1129, loss: 14736.013671875
[INFO] Global_t: 1129, Episode_t: 1, Action: 8, Reward: 4.34, Epsilon: 0.01
[INFO] model update: t: 1130, loss: 61866.46875
[INFO] Global_t: 1130, Episode_t: 2, Action: 32, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1131, loss: 54169.95703125
[INFO] Global_t: 1131, Episode_t: 3, Action: 1, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1132, loss: 17926.44140625
[INFO] Global_t: 1132, Episode_t: 4, Action: 4, Reward: 4.39, Epsilon: 0.01
[INFO] model update: t: 1133, loss: 105468.765625
[INFO] Global_t: 1133, Episode_t: 5, Action: 6, Reward: 4.54, Epsilon: 0.01
[INFO] model update: t: 1134, loss: 71014.625
[INFO] Global_t: 1134, Episode_t: 6, Action: 21, Reward: 3.02, Epsilon: 0.01
[INFO] model update: t: 1135, loss: 27816.73828125
[INFO] Global_t: 1135, Episode_t: 7, Action: 10, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 1136, loss: 96746.9375
[INFO] Global_t: 1136, Episode_t: 8, Action: 9, Reward: 3.09, Epsilon: 0.01
 57%|█████▋    | 1136/2000 [33:34<22:53,  1.59s/it]
[INFO] Global step: 1136, Cumulative rewards: 31.332479999999997, Runtime (s): 2014.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8207201957702637
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.841583490371704
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.597599983215332
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6493473052978516
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.540452718734741
average cummulative reward vector is:  [0.13138421 0.12044653 0.13335984 0.10764439 0.12700806]
average cummulative reward is:  0.12396860628183215
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 142, nodes: 201, edges: 593
[INFO] model update: t: 1137, loss: 24034.6796875
[INFO] Global_t: 1137, Episode_t: 1, Action: 9, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1138, loss: 36360.9453125
[INFO] Global_t: 1138, Episode_t: 2, Action: 0, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1139, loss: 31899.44921875
[INFO] Global_t: 1139, Episode_t: 3, Action: 25, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1140, loss: 15656.5595703125
[INFO] Global_t: 1140, Episode_t: 4, Action: 17, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 1141, loss: 38784.0078125
[INFO] Global_t: 1141, Episode_t: 5, Action: 15, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 1142, loss: 28247.1015625
[INFO] Global_t: 1142, Episode_t: 6, Action: 8, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 1143, loss: 39620.515625
[INFO] Global_t: 1143, Episode_t: 7, Action: 37, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1144, loss: 25762.76953125
[INFO] Global_t: 1144, Episode_t: 8, Action: 6, Reward: 4.58, Epsilon: 0.01
 57%|█████▋    | 1144/2000 [33:57<28:16,  1.98s/it]
[INFO] Global step: 1144, Cumulative rewards: 32.41464, Runtime (s): 2037.98
------------------------------------------------------------
 
graph: 143, nodes: 194, edges: 573
[INFO] model update: t: 1145, loss: 14733.0810546875
[INFO] Global_t: 1145, Episode_t: 1, Action: 5, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1146, loss: 54745.640625
[INFO] Global_t: 1146, Episode_t: 2, Action: 20, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 1147, loss: 23177.68359375
[INFO] Global_t: 1147, Episode_t: 3, Action: 9, Reward: 3.31, Epsilon: 0.01
[INFO] model update: t: 1148, loss: 36706.24609375
[INFO] Global_t: 1148, Episode_t: 4, Action: 2, Reward: 5.08, Epsilon: 0.01
[INFO] model update: t: 1149, loss: 32779.296875
[INFO] Global_t: 1149, Episode_t: 5, Action: 10, Reward: 2.08, Epsilon: 0.01
[INFO] model update: t: 1150, loss: 12752.76171875
[INFO] Global_t: 1150, Episode_t: 6, Action: 3, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 1151, loss: 29629.78515625
[INFO] Global_t: 1151, Episode_t: 7, Action: 7, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1152, loss: 9234.099609375
[INFO] Global_t: 1152, Episode_t: 8, Action: 17, Reward: 2.21, Epsilon: 0.01
 58%|█████▊    | 1152/2000 [34:04<23:12,  1.64s/it]
[INFO] Global step: 1152, Cumulative rewards: 26.663640000000004, Runtime (s): 2044.76
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.062144994735718
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9160125255584717
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.536263942718506
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7608158588409424
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7046210765838623
average cummulative reward vector is:  [0.13497447 0.12285278 0.13177842 0.10831028 0.13311183]
average cummulative reward is:  0.12620555501867115
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 144, nodes: 219, edges: 648
[INFO] model update: t: 1153, loss: 27526.9375
[INFO] Global_t: 1153, Episode_t: 1, Action: 7, Reward: 5.18, Epsilon: 0.01
[INFO] model update: t: 1154, loss: 51187.078125
[INFO] Global_t: 1154, Episode_t: 2, Action: 20, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1155, loss: 12692.5634765625
[INFO] Global_t: 1155, Episode_t: 3, Action: 5, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1156, loss: 26708.640625
[INFO] Global_t: 1156, Episode_t: 4, Action: 8, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1157, loss: 5564.8310546875
[INFO] Global_t: 1157, Episode_t: 5, Action: 11, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 1158, loss: 14660.75390625
[INFO] Global_t: 1158, Episode_t: 6, Action: 1, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1159, loss: 34918.3984375
[INFO] Global_t: 1159, Episode_t: 7, Action: 13, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1160, loss: 41147.85546875
[INFO] Global_t: 1160, Episode_t: 8, Action: 6, Reward: 3.15, Epsilon: 0.01
 58%|█████▊    | 1160/2000 [34:30<29:26,  2.10s/it]
[INFO] Global step: 1160, Cumulative rewards: 29.693039999999996, Runtime (s): 2070.19
------------------------------------------------------------
 
graph: 145, nodes: 217, edges: 642
[INFO] model update: t: 1161, loss: 16618.00390625
[INFO] Global_t: 1161, Episode_t: 1, Action: 8, Reward: 5.67, Epsilon: 0.01
[INFO] model update: t: 1162, loss: 73105.859375
[INFO] Global_t: 1162, Episode_t: 2, Action: 4, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1163, loss: 62287.515625
[INFO] Global_t: 1163, Episode_t: 3, Action: 28, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1164, loss: 19796.65234375
[INFO] Global_t: 1164, Episode_t: 4, Action: 7, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1165, loss: 83430.203125
[INFO] Global_t: 1165, Episode_t: 5, Action: 5, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1166, loss: 56276.12109375
[INFO] Global_t: 1166, Episode_t: 6, Action: 11, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 1167, loss: 48426.1640625
[INFO] Global_t: 1167, Episode_t: 7, Action: 59, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1168, loss: 319710.125
[INFO] Global_t: 1168, Episode_t: 8, Action: 19, Reward: 2.25, Epsilon: 0.01

[INFO] Global step: 1168, Cumulative rewards: 29.065679999999997, Runtime (s): 2075.33
------------------------------------------------------------
 
 58%|█████▊    | 1168/2000 [34:35<23:05,  1.66s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.915515661239624
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8866071701049805
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4752197265625
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9642844200134277
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6289255619049072
average cummulative reward vector is:  [0.12616684 0.11782199 0.13004536 0.11832967 0.13266882]
average cummulative reward is:  0.1250065356277516
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 146, nodes: 207, edges: 612
[INFO] model update: t: 1169, loss: 232324.59375
[INFO] Global_t: 1169, Episode_t: 1, Action: 0, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1170, loss: 35148.953125
[INFO] Global_t: 1170, Episode_t: 2, Action: 2, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1171, loss: 307828.71875
[INFO] Global_t: 1171, Episode_t: 3, Action: 10, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1172, loss: 234388.5625
[INFO] Global_t: 1172, Episode_t: 4, Action: 27, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 1173, loss: 26420.21875
[INFO] Global_t: 1173, Episode_t: 5, Action: 22, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 1174, loss: 41338.5546875
[INFO] Global_t: 1174, Episode_t: 6, Action: 5, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1175, loss: 18900.173828125
[INFO] Global_t: 1175, Episode_t: 7, Action: 7, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1176, loss: 54404.0234375
[INFO] Global_t: 1176, Episode_t: 8, Action: 28, Reward: 2.75, Epsilon: 0.01
 59%|█████▉    | 1176/2000 [35:01<29:43,  2.16s/it]
[INFO] Global step: 1176, Cumulative rewards: 26.10527999999999, Runtime (s): 2101.98
------------------------------------------------------------
 
graph: 147, nodes: 202, edges: 597
[INFO] model update: t: 1177, loss: 116519.7421875
[INFO] Global_t: 1177, Episode_t: 1, Action: 13, Reward: 4.26, Epsilon: 0.01
[INFO] model update: t: 1178, loss: 10977.8017578125
[INFO] Global_t: 1178, Episode_t: 2, Action: 30, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1179, loss: 69795.0703125
[INFO] Global_t: 1179, Episode_t: 3, Action: 32, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 1180, loss: 75756.453125
[INFO] Global_t: 1180, Episode_t: 4, Action: 7, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1181, loss: 20734.46875
[INFO] Global_t: 1181, Episode_t: 5, Action: 11, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1182, loss: 110626.65625
[INFO] Global_t: 1182, Episode_t: 6, Action: 25, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 1183, loss: 17040.99609375
[INFO] Global_t: 1183, Episode_t: 7, Action: 55, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1184, loss: 53137.91796875
[INFO] Global_t: 1184, Episode_t: 8, Action: 18, Reward: 2.94, Epsilon: 0.01
 59%|█████▉    | 1184/2000 [35:09<24:16,  1.78s/it]
[INFO] Global step: 1184, Cumulative rewards: 28.65156, Runtime (s): 2109.17
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.961172580718994
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.555786609649658
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.167040824890137
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8569822311401367
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7253947257995605
average cummulative reward vector is:  [0.13196132 0.11228102 0.13913279 0.12072126 0.1345172 ]
average cummulative reward is:  0.12772271743531127
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 148, nodes: 199, edges: 587
[INFO] model update: t: 1185, loss: 153494.0
[INFO] Global_t: 1185, Episode_t: 1, Action: 9, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 1186, loss: 46303.77734375
[INFO] Global_t: 1186, Episode_t: 2, Action: 8, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1187, loss: 24894.482421875
[INFO] Global_t: 1187, Episode_t: 3, Action: 15, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1188, loss: 198089.421875
[INFO] Global_t: 1188, Episode_t: 4, Action: 18, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1189, loss: 115873.25
[INFO] Global_t: 1189, Episode_t: 5, Action: 4, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1190, loss: 53674.28125
[INFO] Global_t: 1190, Episode_t: 6, Action: 5, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 1191, loss: 363346.65625
[INFO] Global_t: 1191, Episode_t: 7, Action: 12, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1192, loss: 259146.9375
[INFO] Global_t: 1192, Episode_t: 8, Action: 17, Reward: 1.81, Epsilon: 0.01
 60%|█████▉    | 1192/2000 [35:33<29:12,  2.17s/it]
[INFO] Global step: 1192, Cumulative rewards: 25.2216, Runtime (s): 2133.70
------------------------------------------------------------
 
graph: 149, nodes: 208, edges: 615
[INFO] model update: t: 1193, loss: 6868.87451171875
[INFO] Global_t: 1193, Episode_t: 1, Action: 10, Reward: 4.77, Epsilon: 0.01
[INFO] model update: t: 1194, loss: 275811.875
[INFO] Global_t: 1194, Episode_t: 2, Action: 30, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1195, loss: 534457.0625
[INFO] Global_t: 1195, Episode_t: 3, Action: 14, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1196, loss: 80901.109375
[INFO] Global_t: 1196, Episode_t: 4, Action: 18, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1197, loss: 240707.5
[INFO] Global_t: 1197, Episode_t: 5, Action: 6, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1198, loss: 383496.65625
[INFO] Global_t: 1198, Episode_t: 6, Action: 8, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1199, loss: 19336.61328125
[INFO] Global_t: 1199, Episode_t: 7, Action: 50, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 1200, loss: 279019.6875
[INFO] Global_t: 1200, Episode_t: 8, Action: 9, Reward: 2.42, Epsilon: 0.01
 60%|██████    | 1200/2000 [35:38<22:47,  1.71s/it]
[INFO] Global step: 1200, Cumulative rewards: 29.91, Runtime (s): 2138.78
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.091460704803467
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6918563842773438
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.953418254852295
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8565118312835693
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7155892848968506
average cummulative reward vector is:  [0.13392711 0.11548218 0.14585601 0.11557991 0.13435538]
average cummulative reward is:  0.1290401150008375
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 150, nodes: 216, edges: 639
[INFO] model update: t: 1201, loss: 247961.34375
[INFO] Global_t: 1201, Episode_t: 1, Action: 18, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1202, loss: 27304.525390625
[INFO] Global_t: 1202, Episode_t: 2, Action: 14, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1203, loss: 105824.4921875
[INFO] Global_t: 1203, Episode_t: 3, Action: 6, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1204, loss: 301052.4375
[INFO] Global_t: 1204, Episode_t: 4, Action: 1, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 1205, loss: 165418.125
[INFO] Global_t: 1205, Episode_t: 5, Action: 0, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 1206, loss: 29868.5546875
[INFO] Global_t: 1206, Episode_t: 6, Action: 33, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 1207, loss: 352779.15625
[INFO] Global_t: 1207, Episode_t: 7, Action: 7, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1208, loss: 316921.5
[INFO] Global_t: 1208, Episode_t: 8, Action: 15, Reward: 2.42, Epsilon: 0.01
 60%|██████    | 1208/2000 [36:03<28:07,  2.13s/it]
[INFO] Global step: 1208, Cumulative rewards: 25.925279999999997, Runtime (s): 2163.71
------------------------------------------------------------
 
graph: 151, nodes: 204, edges: 601
[INFO] model update: t: 1209, loss: 15091.931640625
[INFO] Global_t: 1209, Episode_t: 1, Action: 3, Reward: 4.92, Epsilon: 0.01
[INFO] model update: t: 1210, loss: 177207.203125
[INFO] Global_t: 1210, Episode_t: 2, Action: 7, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1211, loss: 187646.90625
[INFO] Global_t: 1211, Episode_t: 3, Action: 34, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 1212, loss: 19696.521484375
[INFO] Global_t: 1212, Episode_t: 4, Action: 13, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 1213, loss: 341005.8125
[INFO] Global_t: 1213, Episode_t: 5, Action: 1, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 1214, loss: 716370.25
[INFO] Global_t: 1214, Episode_t: 6, Action: 29, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 1215, loss: 207881.65625
[INFO] Global_t: 1215, Episode_t: 7, Action: 17, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1216, loss: 151960.28125
[INFO] Global_t: 1216, Episode_t: 8, Action: 6, Reward: 2.48, Epsilon: 0.01
 61%|██████    | 1216/2000 [36:08<21:50,  1.67s/it]
[INFO] Global step: 1216, Cumulative rewards: 27.033, Runtime (s): 2168.51
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.669524908065796
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.206628084182739
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.780212163925171
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9571030139923096
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8117265701293945
average cummulative reward vector is:  [0.13022    0.11604931 0.14061885 0.11110164 0.13733065]
average cummulative reward is:  0.12706408773797617
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 152, nodes: 208, edges: 615
[INFO] model update: t: 1217, loss: 681275.0
[INFO] Global_t: 1217, Episode_t: 1, Action: 2, Reward: 4.78, Epsilon: 0.01
[INFO] model update: t: 1218, loss: 19390.4453125
[INFO] Global_t: 1218, Episode_t: 2, Action: 12, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 1219, loss: 419009.5
[INFO] Global_t: 1219, Episode_t: 3, Action: 4, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1220, loss: 394310.59375
[INFO] Global_t: 1220, Episode_t: 4, Action: 5, Reward: 3.52, Epsilon: 0.01
[INFO] model update: t: 1221, loss: 25169.0546875
[INFO] Global_t: 1221, Episode_t: 5, Action: 22, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 1222, loss: 138563.375
[INFO] Global_t: 1222, Episode_t: 6, Action: 9, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 1223, loss: 57928.17578125
[INFO] Global_t: 1223, Episode_t: 7, Action: 19, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 1224, loss: 111238.84375
[INFO] Global_t: 1224, Episode_t: 8, Action: 64, Reward: 2.59, Epsilon: 0.01
 61%|██████    | 1224/2000 [36:32<26:32,  2.05s/it]
[INFO] Global step: 1224, Cumulative rewards: 28.075799999999997, Runtime (s): 2192.01
------------------------------------------------------------
 
graph: 153, nodes: 211, edges: 623
[INFO] model update: t: 1225, loss: 269664.34375
[INFO] Global_t: 1225, Episode_t: 1, Action: 2, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 1226, loss: 6627.876953125
[INFO] Global_t: 1226, Episode_t: 2, Action: 24, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1227, loss: 200949.03125
[INFO] Global_t: 1227, Episode_t: 3, Action: 17, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1228, loss: 74058.875
[INFO] Global_t: 1228, Episode_t: 4, Action: 5, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1229, loss: 51206.4140625
[INFO] Global_t: 1229, Episode_t: 5, Action: 48, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1230, loss: 189473.078125
[INFO] Global_t: 1230, Episode_t: 6, Action: 40, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1231, loss: 121855.234375
[INFO] Global_t: 1231, Episode_t: 7, Action: 46, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1232, loss: 54452.35546875
[INFO] Global_t: 1232, Episode_t: 8, Action: 68, Reward: 2.37, Epsilon: 0.01
 62%|██████▏   | 1232/2000 [36:37<20:57,  1.64s/it]
[INFO] Global step: 1232, Cumulative rewards: 28.943039999999996, Runtime (s): 2197.39
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.933398485183716
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.1062116622924805
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6002016067504883
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5716142654418945
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9662137031555176
average cummulative reward vector is:  [0.13711526 0.11277824 0.13294344 0.11290818 0.13392661]
average cummulative reward is:  0.1259343473989811
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 154, nodes: 189, edges: 558
[INFO] model update: t: 1233, loss: 232899.046875
[INFO] Global_t: 1233, Episode_t: 1, Action: 6, Reward: 4.80, Epsilon: 0.01
[INFO] model update: t: 1234, loss: 21748.26953125
[INFO] Global_t: 1234, Episode_t: 2, Action: 13, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1235, loss: 115917.859375
[INFO] Global_t: 1235, Episode_t: 3, Action: 18, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 1236, loss: 82223.6796875
[INFO] Global_t: 1236, Episode_t: 4, Action: 8, Reward: 3.54, Epsilon: 0.01
[INFO] model update: t: 1237, loss: 110982.3203125
[INFO] Global_t: 1237, Episode_t: 5, Action: 22, Reward: 1.56, Epsilon: 0.01
[INFO] model update: t: 1238, loss: 330086.5
[INFO] Global_t: 1238, Episode_t: 6, Action: 5, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 1239, loss: 7709.02783203125
[INFO] Global_t: 1239, Episode_t: 7, Action: 19, Reward: 1.39, Epsilon: 0.01
[INFO] model update: t: 1240, loss: 212873.796875
[INFO] Global_t: 1240, Episode_t: 8, Action: 42, Reward: 1.90, Epsilon: 0.01
 62%|██████▏   | 1240/2000 [37:01<26:07,  2.06s/it]
[INFO] Global step: 1240, Cumulative rewards: 23.83524, Runtime (s): 2221.81
------------------------------------------------------------
 
graph: 155, nodes: 203, edges: 599
[INFO] model update: t: 1241, loss: 147605.5
[INFO] Global_t: 1241, Episode_t: 1, Action: 5, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1242, loss: 14250.65625
[INFO] Global_t: 1242, Episode_t: 2, Action: 4, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1243, loss: 55030.78515625
[INFO] Global_t: 1243, Episode_t: 3, Action: 32, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1244, loss: 9667.517578125
[INFO] Global_t: 1244, Episode_t: 4, Action: 22, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1245, loss: 36910.671875
[INFO] Global_t: 1245, Episode_t: 5, Action: 2, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1246, loss: 33929.70703125
[INFO] Global_t: 1246, Episode_t: 6, Action: 11, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 1247, loss: 19967.666015625
[INFO] Global_t: 1247, Episode_t: 7, Action: 12, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1248, loss: 101897.578125
[INFO] Global_t: 1248, Episode_t: 8, Action: 38, Reward: 2.93, Epsilon: 0.01
 62%|██████▏   | 1248/2000 [37:07<20:35,  1.64s/it]
[INFO] Global step: 1248, Cumulative rewards: 28.224719999999998, Runtime (s): 2227.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9064438343048096
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.569671392440796
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7373595237731934
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.731105089187622
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6547915935516357
average cummulative reward vector is:  [0.13895895 0.1122669  0.12975246 0.11400935 0.12936667]
average cummulative reward is:  0.12487086339880438
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 156, nodes: 192, edges: 567
[INFO] model update: t: 1249, loss: 114210.828125
[INFO] Global_t: 1249, Episode_t: 1, Action: 2, Reward: 4.60, Epsilon: 0.01
[INFO] model update: t: 1250, loss: 45460.421875
[INFO] Global_t: 1250, Episode_t: 2, Action: 35, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1251, loss: 11814.7861328125
[INFO] Global_t: 1251, Episode_t: 3, Action: 8, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1252, loss: 55878.171875
[INFO] Global_t: 1252, Episode_t: 4, Action: 9, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1253, loss: 31212.1875
[INFO] Global_t: 1253, Episode_t: 5, Action: 33, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1254, loss: 9318.2314453125
[INFO] Global_t: 1254, Episode_t: 6, Action: 5, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1255, loss: 20530.2421875
[INFO] Global_t: 1255, Episode_t: 7, Action: 7, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 1256, loss: 19238.55078125
[INFO] Global_t: 1256, Episode_t: 8, Action: 10, Reward: 2.23, Epsilon: 0.01
 63%|██████▎   | 1256/2000 [37:31<25:23,  2.05s/it]
[INFO] Global step: 1256, Cumulative rewards: 25.301520000000007, Runtime (s): 2251.06
------------------------------------------------------------
 
graph: 157, nodes: 220, edges: 651
[INFO] model update: t: 1257, loss: 21741.505859375
[INFO] Global_t: 1257, Episode_t: 1, Action: 6, Reward: 5.48, Epsilon: 0.01
[INFO] model update: t: 1258, loss: 29335.5390625
[INFO] Global_t: 1258, Episode_t: 2, Action: 21, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1259, loss: 90596.015625
[INFO] Global_t: 1259, Episode_t: 3, Action: 8, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1260, loss: 115892.015625
[INFO] Global_t: 1260, Episode_t: 4, Action: 10, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1261, loss: 9727.8828125
[INFO] Global_t: 1261, Episode_t: 5, Action: 16, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 1262, loss: 144008.984375
[INFO] Global_t: 1262, Episode_t: 6, Action: 1, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1263, loss: 118869.484375
[INFO] Global_t: 1263, Episode_t: 7, Action: 19, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 1264, loss: 25603.41796875
[INFO] Global_t: 1264, Episode_t: 8, Action: 15, Reward: 2.94, Epsilon: 0.01
 63%|██████▎   | 1264/2000 [37:35<19:46,  1.61s/it]
[INFO] Global step: 1264, Cumulative rewards: 30.483959999999996, Runtime (s): 2255.84
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.999131917953491
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7660748958587646
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.377068519592285
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.919750213623047
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7074625492095947
average cummulative reward vector is:  [0.12801158 0.11693032 0.1496071  0.12185421 0.13372957]
average cummulative reward is:  0.13002655646930578
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 158, nodes: 209, edges: 618
[INFO] model update: t: 1265, loss: 199114.359375
[INFO] Global_t: 1265, Episode_t: 1, Action: 6, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1266, loss: 69770.359375
[INFO] Global_t: 1266, Episode_t: 2, Action: 8, Reward: 5.50, Epsilon: 0.01
[INFO] model update: t: 1267, loss: 75989.296875
[INFO] Global_t: 1267, Episode_t: 3, Action: 7, Reward: 4.31, Epsilon: 0.01
[INFO] model update: t: 1268, loss: 252167.59375
[INFO] Global_t: 1268, Episode_t: 4, Action: 5, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1269, loss: 125155.8359375
[INFO] Global_t: 1269, Episode_t: 5, Action: 17, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1270, loss: 37757.78515625
[INFO] Global_t: 1270, Episode_t: 6, Action: 0, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1271, loss: 163476.59375
[INFO] Global_t: 1271, Episode_t: 7, Action: 11, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 1272, loss: 4271.11279296875
[INFO] Global_t: 1272, Episode_t: 8, Action: 14, Reward: 2.51, Epsilon: 0.01
 64%|██████▎   | 1272/2000 [38:00<24:51,  2.05s/it]
[INFO] Global step: 1272, Cumulative rewards: 31.86852, Runtime (s): 2280.37
------------------------------------------------------------
 
graph: 159, nodes: 191, edges: 564
[INFO] model update: t: 1273, loss: 203973.40625
[INFO] Global_t: 1273, Episode_t: 1, Action: 8, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1274, loss: 183856.09375
[INFO] Global_t: 1274, Episode_t: 2, Action: 7, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1275, loss: 11440.744140625
[INFO] Global_t: 1275, Episode_t: 3, Action: 21, Reward: 4.34, Epsilon: 0.01
[INFO] model update: t: 1276, loss: 158639.453125
[INFO] Global_t: 1276, Episode_t: 4, Action: 13, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 1277, loss: 7211.0
[INFO] Global_t: 1277, Episode_t: 5, Action: 9, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1278, loss: 228463.3125
[INFO] Global_t: 1278, Episode_t: 6, Action: 15, Reward: 1.88, Epsilon: 0.01
[INFO] model update: t: 1279, loss: 597023.5
[INFO] Global_t: 1279, Episode_t: 7, Action: 10, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 1280, loss: 19856.109375
[INFO] Global_t: 1280, Episode_t: 8, Action: 22, Reward: 1.59, Epsilon: 0.01

[INFO] Global step: 1280, Cumulative rewards: 24.759959999999992, Runtime (s): 2285.49
------------------------------------------------------------
 
 64%|██████▍   | 1280/2000 [38:05<19:30,  1.63s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.137364625930786
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6266286373138428
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.565112829208374
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8931312561035156
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6533095836639404
average cummulative reward vector is:  [0.13176447 0.11389954 0.13102705 0.10386612 0.12990887]
average cummulative reward is:  0.12209321047292887
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 160, nodes: 220, edges: 650
[INFO] model update: t: 1281, loss: 637747.8125
[INFO] Global_t: 1281, Episode_t: 1, Action: 1, Reward: 5.15, Epsilon: 0.01
[INFO] model update: t: 1282, loss: 2073070.375
[INFO] Global_t: 1282, Episode_t: 2, Action: 2, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1283, loss: 1446606.625
[INFO] Global_t: 1283, Episode_t: 3, Action: 20, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1284, loss: 63583.53125
[INFO] Global_t: 1284, Episode_t: 4, Action: 16, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 1285, loss: 546956.8125
[INFO] Global_t: 1285, Episode_t: 5, Action: 19, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 1286, loss: 715068.25
[INFO] Global_t: 1286, Episode_t: 6, Action: 11, Reward: 2.85, Epsilon: 0.01
[INFO] model update: t: 1287, loss: 8651.2177734375
[INFO] Global_t: 1287, Episode_t: 7, Action: 12, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 1288, loss: 411481.8125
[INFO] Global_t: 1288, Episode_t: 8, Action: 13, Reward: 2.61, Epsilon: 0.01
 64%|██████▍   | 1288/2000 [38:29<24:10,  2.04s/it]
[INFO] Global step: 1288, Cumulative rewards: 28.839960000000005, Runtime (s): 2309.48
------------------------------------------------------------
 
graph: 161, nodes: 194, edges: 573
[INFO] model update: t: 1289, loss: 101251.375
[INFO] Global_t: 1289, Episode_t: 1, Action: 11, Reward: 4.29, Epsilon: 0.01
[INFO] model update: t: 1290, loss: 156237.84375
[INFO] Global_t: 1290, Episode_t: 2, Action: 8, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1291, loss: 514603.5625
[INFO] Global_t: 1291, Episode_t: 3, Action: 10, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1292, loss: 94938.0078125
[INFO] Global_t: 1292, Episode_t: 4, Action: 14, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1293, loss: 176881.625
[INFO] Global_t: 1293, Episode_t: 5, Action: 6, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 1294, loss: 592227.375
[INFO] Global_t: 1294, Episode_t: 6, Action: 18, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1295, loss: 50029.31640625
[INFO] Global_t: 1295, Episode_t: 7, Action: 23, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1296, loss: 222970.046875
[INFO] Global_t: 1296, Episode_t: 8, Action: 5, Reward: 2.05, Epsilon: 0.01
 65%|██████▍   | 1296/2000 [38:34<18:51,  1.61s/it]
[INFO] Global step: 1296, Cumulative rewards: 24.936239999999998, Runtime (s): 2314.30
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.817821741104126
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.857297897338867
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6332168579101562
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7539260387420654
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.025241851806641
average cummulative reward vector is:  [0.13336895 0.11065579 0.13222923 0.1173465  0.13741882]
average cummulative reward is:  0.12620385638190793
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 162, nodes: 191, edges: 564
[INFO] model update: t: 1297, loss: 180924.640625
[INFO] Global_t: 1297, Episode_t: 1, Action: 20, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1298, loss: 105508.828125
[INFO] Global_t: 1298, Episode_t: 2, Action: 4, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1299, loss: 563016.75
[INFO] Global_t: 1299, Episode_t: 3, Action: 12, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1300, loss: 284764.125
[INFO] Global_t: 1300, Episode_t: 4, Action: 18, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1301, loss: 55559.59375
[INFO] Global_t: 1301, Episode_t: 5, Action: 21, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 1302, loss: 470476.6875
[INFO] Global_t: 1302, Episode_t: 6, Action: 11, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 1303, loss: 114125.2734375
[INFO] Global_t: 1303, Episode_t: 7, Action: 14, Reward: 3.14, Epsilon: 0.01
[INFO] model update: t: 1304, loss: 138155.9375
[INFO] Global_t: 1304, Episode_t: 8, Action: 24, Reward: 2.64, Epsilon: 0.01
 65%|██████▌   | 1304/2000 [38:57<23:04,  1.99s/it]
[INFO] Global step: 1304, Cumulative rewards: 27.61812, Runtime (s): 2337.36
------------------------------------------------------------
 
graph: 163, nodes: 213, edges: 629
[INFO] model update: t: 1305, loss: 118300.0703125
[INFO] Global_t: 1305, Episode_t: 1, Action: 6, Reward: 5.02, Epsilon: 0.01
[INFO] model update: t: 1306, loss: 51790.42578125
[INFO] Global_t: 1306, Episode_t: 2, Action: 4, Reward: 4.75, Epsilon: 0.01
[INFO] model update: t: 1307, loss: 208450.765625
[INFO] Global_t: 1307, Episode_t: 3, Action: 18, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1308, loss: 55687.55859375
[INFO] Global_t: 1308, Episode_t: 4, Action: 0, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1309, loss: 69299.28125
[INFO] Global_t: 1309, Episode_t: 5, Action: 1, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 1310, loss: 136154.015625
[INFO] Global_t: 1310, Episode_t: 6, Action: 38, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1311, loss: 35861.2109375
[INFO] Global_t: 1311, Episode_t: 7, Action: 25, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 1312, loss: 290343.125
[INFO] Global_t: 1312, Episode_t: 8, Action: 9, Reward: 3.03, Epsilon: 0.01
 66%|██████▌   | 1312/2000 [39:03<18:30,  1.61s/it]
[INFO] Global step: 1312, Cumulative rewards: 28.883399999999998, Runtime (s): 2343.25
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.517960548400879
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.444148302078247
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.503068208694458
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6348206996917725
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.944275379180908
average cummulative reward vector is:  [0.12531263 0.12655579 0.1252776  0.11323995 0.1368078 ]
average cummulative reward is:  0.1254387526428705
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 164, nodes: 182, edges: 537
[INFO] model update: t: 1313, loss: 117356.640625
[INFO] Global_t: 1313, Episode_t: 1, Action: 5, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1314, loss: 71040.390625
[INFO] Global_t: 1314, Episode_t: 2, Action: 9, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1315, loss: 338830.0625
[INFO] Global_t: 1315, Episode_t: 3, Action: 2, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1316, loss: 130717.28125
[INFO] Global_t: 1316, Episode_t: 4, Action: 13, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 1317, loss: 20580.2109375
[INFO] Global_t: 1317, Episode_t: 5, Action: 18, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1318, loss: 159675.640625
[INFO] Global_t: 1318, Episode_t: 6, Action: 11, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 1319, loss: 148673.875
[INFO] Global_t: 1319, Episode_t: 7, Action: 8, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 1320, loss: 109160.75
[INFO] Global_t: 1320, Episode_t: 8, Action: 1, Reward: 2.81, Epsilon: 0.01
 66%|██████▌   | 1320/2000 [39:26<22:45,  2.01s/it]
[INFO] Global step: 1320, Cumulative rewards: 26.5404, Runtime (s): 2366.68
------------------------------------------------------------
 
graph: 165, nodes: 180, edges: 531
[INFO] model update: t: 1321, loss: 7832.35498046875
[INFO] Global_t: 1321, Episode_t: 1, Action: 5, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1322, loss: 83122.734375
[INFO] Global_t: 1322, Episode_t: 2, Action: 3, Reward: 4.54, Epsilon: 0.01
[INFO] model update: t: 1323, loss: 58536.25390625
[INFO] Global_t: 1323, Episode_t: 3, Action: 10, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1324, loss: 38395.09375
[INFO] Global_t: 1324, Episode_t: 4, Action: 25, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 1325, loss: 204331.71875
[INFO] Global_t: 1325, Episode_t: 5, Action: 9, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 1326, loss: 311721.96875
[INFO] Global_t: 1326, Episode_t: 6, Action: 12, Reward: 1.57, Epsilon: 0.01
[INFO] model update: t: 1327, loss: 7687.12451171875
[INFO] Global_t: 1327, Episode_t: 7, Action: 21, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 1328, loss: 268812.21875
[INFO] Global_t: 1328, Episode_t: 8, Action: 18, Reward: 2.61, Epsilon: 0.01
 66%|██████▋   | 1328/2000 [39:32<17:58,  1.61s/it]
[INFO] Global step: 1328, Cumulative rewards: 24.45048, Runtime (s): 2372.01
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.734177350997925
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.744593858718872
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.143860578536987
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.754631519317627
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7059731483459473
average cummulative reward vector is:  [0.13286553 0.11660625 0.14232158 0.1177785  0.13742796]
average cummulative reward is:  0.12939996453547747
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 166, nodes: 185, edges: 544
[INFO] model update: t: 1329, loss: 181493.3125
[INFO] Global_t: 1329, Episode_t: 1, Action: 10, Reward: 4.43, Epsilon: 0.01
[INFO] model update: t: 1330, loss: 71616.234375
[INFO] Global_t: 1330, Episode_t: 2, Action: 7, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1331, loss: 648022.0625
[INFO] Global_t: 1331, Episode_t: 3, Action: 4, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1332, loss: 852666.3125
[INFO] Global_t: 1332, Episode_t: 4, Action: 8, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1333, loss: 41437.05078125
[INFO] Global_t: 1333, Episode_t: 5, Action: 6, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1334, loss: 1012769.25
[INFO] Global_t: 1334, Episode_t: 6, Action: 16, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 1335, loss: 656550.0625
[INFO] Global_t: 1335, Episode_t: 7, Action: 13, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 1336, loss: 137710.53125
[INFO] Global_t: 1336, Episode_t: 8, Action: 15, Reward: 2.25, Epsilon: 0.01
 67%|██████▋   | 1336/2000 [39:55<22:07,  2.00s/it]
[INFO] Global step: 1336, Cumulative rewards: 24.83784, Runtime (s): 2395.36
------------------------------------------------------------
 
graph: 167, nodes: 181, edges: 533
[INFO] model update: t: 1337, loss: 961089.625
[INFO] Global_t: 1337, Episode_t: 1, Action: 43, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1338, loss: 31841.3984375
[INFO] Global_t: 1338, Episode_t: 2, Action: 13, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1339, loss: 1288833.875
[INFO] Global_t: 1339, Episode_t: 3, Action: 17, Reward: 3.28, Epsilon: 0.01
[INFO] model update: t: 1340, loss: 385145.0
[INFO] Global_t: 1340, Episode_t: 4, Action: 2, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 1341, loss: 540924.125
[INFO] Global_t: 1341, Episode_t: 5, Action: 10, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1342, loss: 1968422.0
[INFO] Global_t: 1342, Episode_t: 6, Action: 7, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 1343, loss: 765216.1875
[INFO] Global_t: 1343, Episode_t: 7, Action: 14, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1344, loss: 558854.25
[INFO] Global_t: 1344, Episode_t: 8, Action: 5, Reward: 3.05, Epsilon: 0.01
 67%|██████▋   | 1344/2000 [39:59<16:52,  1.54s/it]
[INFO] Global step: 1344, Cumulative rewards: 25.21344, Runtime (s): 2399.18
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7912192344665527
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.3770294189453125
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.675677537918091
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.275712013244629
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.575136423110962
average cummulative reward vector is:  [0.12949132 0.1071331  0.13986667 0.11890701 0.13344086]
average cummulative reward is:  0.12576779077376807
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 168, nodes: 201, edges: 594
[INFO] model update: t: 1345, loss: 2461329.75
[INFO] Global_t: 1345, Episode_t: 1, Action: 10, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1346, loss: 1111006.0
[INFO] Global_t: 1346, Episode_t: 2, Action: 13, Reward: 4.30, Epsilon: 0.01
[INFO] model update: t: 1347, loss: 108309.734375
[INFO] Global_t: 1347, Episode_t: 3, Action: 3, Reward: 5.60, Epsilon: 0.01
[INFO] model update: t: 1348, loss: 1224223.75
[INFO] Global_t: 1348, Episode_t: 4, Action: 24, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1349, loss: 175457.375
[INFO] Global_t: 1349, Episode_t: 5, Action: 16, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1350, loss: 528630.625
[INFO] Global_t: 1350, Episode_t: 6, Action: 8, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1351, loss: 1223944.25
[INFO] Global_t: 1351, Episode_t: 7, Action: 27, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1352, loss: 304221.125
[INFO] Global_t: 1352, Episode_t: 8, Action: 38, Reward: 2.05, Epsilon: 0.01
 68%|██████▊   | 1352/2000 [40:22<21:06,  1.95s/it]
[INFO] Global step: 1352, Cumulative rewards: 27.924000000000003, Runtime (s): 2422.49
------------------------------------------------------------
 
graph: 169, nodes: 215, edges: 635
[INFO] model update: t: 1353, loss: 193644.8125
[INFO] Global_t: 1353, Episode_t: 1, Action: 8, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 1354, loss: 481679.4375
[INFO] Global_t: 1354, Episode_t: 2, Action: 13, Reward: 4.77, Epsilon: 0.01
[INFO] model update: t: 1355, loss: 28253.125
[INFO] Global_t: 1355, Episode_t: 3, Action: 6, Reward: 4.18, Epsilon: 0.01
[INFO] model update: t: 1356, loss: 266049.0625
[INFO] Global_t: 1356, Episode_t: 4, Action: 9, Reward: 4.26, Epsilon: 0.01
[INFO] model update: t: 1357, loss: 197943.5625
[INFO] Global_t: 1357, Episode_t: 5, Action: 5, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1358, loss: 48744.87890625
[INFO] Global_t: 1358, Episode_t: 6, Action: 10, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1359, loss: 385367.15625
[INFO] Global_t: 1359, Episode_t: 7, Action: 28, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1360, loss: 123486.1875
[INFO] Global_t: 1360, Episode_t: 8, Action: 21, Reward: 1.38, Epsilon: 0.01

[INFO] Global step: 1360, Cumulative rewards: 25.677239999999994, Runtime (s): 2428.54
------------------------------------------------------------
 
 68%|██████▊   | 1360/2000 [40:28<17:00,  1.59s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5574262142181396
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9328811168670654
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.666256904602051
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5879831314086914
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6369001865386963
average cummulative reward vector is:  [0.12890026 0.11566273 0.13788497 0.11375023 0.12749516]
average cummulative reward is:  0.12473867245043084
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 170, nodes: 206, edges: 609
[INFO] model update: t: 1361, loss: 178086.96875
[INFO] Global_t: 1361, Episode_t: 1, Action: 7, Reward: 5.15, Epsilon: 0.01
[INFO] model update: t: 1362, loss: 486708.84375
[INFO] Global_t: 1362, Episode_t: 2, Action: 6, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1363, loss: 99507.1953125
[INFO] Global_t: 1363, Episode_t: 3, Action: 3, Reward: 5.66, Epsilon: 0.01
[INFO] model update: t: 1364, loss: 184293.25
[INFO] Global_t: 1364, Episode_t: 4, Action: 8, Reward: 3.74, Epsilon: 0.01
[INFO] model update: t: 1365, loss: 424862.03125
[INFO] Global_t: 1365, Episode_t: 5, Action: 4, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1366, loss: 9765.421875
[INFO] Global_t: 1366, Episode_t: 6, Action: 14, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 1367, loss: 403500.4375
[INFO] Global_t: 1367, Episode_t: 7, Action: 123, Reward: 1.12, Epsilon: 0.01
[INFO] model update: t: 1368, loss: 200860.0
[INFO] Global_t: 1368, Episode_t: 8, Action: 16, Reward: 2.27, Epsilon: 0.01
 68%|██████▊   | 1368/2000 [40:52<21:11,  2.01s/it]
[INFO] Global step: 1368, Cumulative rewards: 27.226080000000003, Runtime (s): 2452.42
------------------------------------------------------------
 
graph: 171, nodes: 202, edges: 597
[INFO] model update: t: 1369, loss: 20400.3515625
[INFO] Global_t: 1369, Episode_t: 1, Action: 12, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1370, loss: 178777.34375
[INFO] Global_t: 1370, Episode_t: 2, Action: 9, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1371, loss: 108500.2578125
[INFO] Global_t: 1371, Episode_t: 3, Action: 30, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1372, loss: 44156.625
[INFO] Global_t: 1372, Episode_t: 4, Action: 14, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 1373, loss: 271431.4375
[INFO] Global_t: 1373, Episode_t: 5, Action: 2, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1374, loss: 48596.1796875
[INFO] Global_t: 1374, Episode_t: 6, Action: 17, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 1375, loss: 122847.640625
[INFO] Global_t: 1375, Episode_t: 7, Action: 16, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1376, loss: 165038.671875
[INFO] Global_t: 1376, Episode_t: 8, Action: 31, Reward: 1.53, Epsilon: 0.01
 69%|██████▉   | 1376/2000 [40:58<17:00,  1.63s/it]
[INFO] Global step: 1376, Cumulative rewards: 23.34252, Runtime (s): 2458.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.676579475402832
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8951938152313232
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2068397998809814
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6357035636901855
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6294403076171875
average cummulative reward vector is:  [0.13204158 0.11699051 0.12044399 0.11592967 0.127275  ]
average cummulative reward is:  0.12253615003497242
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 172, nodes: 206, edges: 609
[INFO] model update: t: 1377, loss: 6237.1279296875
[INFO] Global_t: 1377, Episode_t: 1, Action: 1, Reward: 5.85, Epsilon: 0.01
[INFO] model update: t: 1378, loss: 119938.7265625
[INFO] Global_t: 1378, Episode_t: 2, Action: 19, Reward: 3.52, Epsilon: 0.01
[INFO] model update: t: 1379, loss: 30528.984375
[INFO] Global_t: 1379, Episode_t: 3, Action: 4, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1380, loss: 73701.0
[INFO] Global_t: 1380, Episode_t: 4, Action: 11, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1381, loss: 241124.0625
[INFO] Global_t: 1381, Episode_t: 5, Action: 36, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1382, loss: 49288.9609375
[INFO] Global_t: 1382, Episode_t: 6, Action: 8, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1383, loss: 47232.953125
[INFO] Global_t: 1383, Episode_t: 7, Action: 24, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 1384, loss: 37112.29296875
[INFO] Global_t: 1384, Episode_t: 8, Action: 21, Reward: 2.68, Epsilon: 0.01
 69%|██████▉   | 1384/2000 [41:20<20:19,  1.98s/it]
[INFO] Global step: 1384, Cumulative rewards: 27.219719999999995, Runtime (s): 2480.72
------------------------------------------------------------
 
graph: 173, nodes: 217, edges: 641
[INFO] model update: t: 1385, loss: 13794.380859375
[INFO] Global_t: 1385, Episode_t: 1, Action: 9, Reward: 5.29, Epsilon: 0.01
[INFO] model update: t: 1386, loss: 45110.44921875
[INFO] Global_t: 1386, Episode_t: 2, Action: 14, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1387, loss: 27067.50390625
[INFO] Global_t: 1387, Episode_t: 3, Action: 17, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 1388, loss: 20164.4921875
[INFO] Global_t: 1388, Episode_t: 4, Action: 23, Reward: 3.48, Epsilon: 0.01
[INFO] model update: t: 1389, loss: 13971.3857421875
[INFO] Global_t: 1389, Episode_t: 5, Action: 20, Reward: 3.20, Epsilon: 0.01
[INFO] model update: t: 1390, loss: 11389.986328125
[INFO] Global_t: 1390, Episode_t: 6, Action: 8, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 1391, loss: 8536.3828125
[INFO] Global_t: 1391, Episode_t: 7, Action: 13, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1392, loss: 14104.2265625
[INFO] Global_t: 1392, Episode_t: 8, Action: 18, Reward: 2.50, Epsilon: 0.01
 70%|██████▉   | 1392/2000 [41:25<16:02,  1.58s/it]
[INFO] Global step: 1392, Cumulative rewards: 28.592639999999996, Runtime (s): 2485.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7361202239990234
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.588451862335205
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.061381816864014
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8336639404296875
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.697089195251465
average cummulative reward vector is:  [0.13304395 0.11388079 0.14272432 0.12352383 0.13765887]
average cummulative reward is:  0.13016635081775832
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 174, nodes: 217, edges: 640
[INFO] model update: t: 1393, loss: 10071.708984375
[INFO] Global_t: 1393, Episode_t: 1, Action: 10, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 1394, loss: 7556.4619140625
[INFO] Global_t: 1394, Episode_t: 2, Action: 28, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1395, loss: 5583.54443359375
[INFO] Global_t: 1395, Episode_t: 3, Action: 0, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 1396, loss: 10450.666015625
[INFO] Global_t: 1396, Episode_t: 4, Action: 5, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1397, loss: 17704.87890625
[INFO] Global_t: 1397, Episode_t: 5, Action: 1, Reward: 3.48, Epsilon: 0.01
[INFO] model update: t: 1398, loss: 8439.3857421875
[INFO] Global_t: 1398, Episode_t: 6, Action: 15, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 1399, loss: 37273.1640625
[INFO] Global_t: 1399, Episode_t: 7, Action: 16, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 1400, loss: 59368.4140625
[INFO] Global_t: 1400, Episode_t: 8, Action: 11, Reward: 2.46, Epsilon: 0.01
 70%|███████   | 1400/2000 [41:50<20:19,  2.03s/it]
[INFO] Global step: 1400, Cumulative rewards: 27.174, Runtime (s): 2510.65
------------------------------------------------------------
 
graph: 175, nodes: 200, edges: 591
[INFO] model update: t: 1401, loss: 31702.78125
[INFO] Global_t: 1401, Episode_t: 1, Action: 6, Reward: 5.21, Epsilon: 0.01
[INFO] model update: t: 1402, loss: 22665.75390625
[INFO] Global_t: 1402, Episode_t: 2, Action: 0, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1403, loss: 35858.7734375
[INFO] Global_t: 1403, Episode_t: 3, Action: 9, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1404, loss: 13995.623046875
[INFO] Global_t: 1404, Episode_t: 4, Action: 58, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1405, loss: 18889.21875
[INFO] Global_t: 1405, Episode_t: 5, Action: 21, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 1406, loss: 34480.9765625
[INFO] Global_t: 1406, Episode_t: 6, Action: 14, Reward: 3.74, Epsilon: 0.01
[INFO] model update: t: 1407, loss: 5914.9677734375
[INFO] Global_t: 1407, Episode_t: 7, Action: 1, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 1408, loss: 12239.2109375
[INFO] Global_t: 1408, Episode_t: 8, Action: 32, Reward: 2.39, Epsilon: 0.01
 70%|███████   | 1408/2000 [41:55<15:39,  1.59s/it]
[INFO] Global step: 1408, Cumulative rewards: 26.460720000000002, Runtime (s): 2515.02
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.731736660003662
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5008790493011475
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5122592449188232
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.817139148712158
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6606898307800293
average cummulative reward vector is:  [0.12871421 0.11084444 0.13423251 0.11508061 0.13608737]
average cummulative reward is:  0.12499182833999915
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 176, nodes: 180, edges: 531
[INFO] model update: t: 1409, loss: 13287.9130859375
[INFO] Global_t: 1409, Episode_t: 1, Action: 1, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1410, loss: 36649.9375
[INFO] Global_t: 1410, Episode_t: 2, Action: 9, Reward: 4.41, Epsilon: 0.01
[INFO] model update: t: 1411, loss: 15297.419921875
[INFO] Global_t: 1411, Episode_t: 3, Action: 22, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 1412, loss: 13371.86328125
[INFO] Global_t: 1412, Episode_t: 4, Action: 5, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1413, loss: 52971.296875
[INFO] Global_t: 1413, Episode_t: 5, Action: 12, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1414, loss: 22418.28515625
[INFO] Global_t: 1414, Episode_t: 6, Action: 19, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 1415, loss: 22521.06640625
[INFO] Global_t: 1415, Episode_t: 7, Action: 10, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1416, loss: 35851.8984375
[INFO] Global_t: 1416, Episode_t: 8, Action: 13, Reward: 1.90, Epsilon: 0.01
 71%|███████   | 1416/2000 [42:17<18:58,  1.95s/it]
[INFO] Global step: 1416, Cumulative rewards: 25.27404, Runtime (s): 2537.39
------------------------------------------------------------
 
graph: 177, nodes: 192, edges: 567
[INFO] model update: t: 1417, loss: 6408.38818359375
[INFO] Global_t: 1417, Episode_t: 1, Action: 15, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 1418, loss: 57751.1015625
[INFO] Global_t: 1418, Episode_t: 2, Action: 7, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1419, loss: 46776.1171875
[INFO] Global_t: 1419, Episode_t: 3, Action: 17, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1420, loss: 13438.6484375
[INFO] Global_t: 1420, Episode_t: 4, Action: 8, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1421, loss: 7653.30078125
[INFO] Global_t: 1421, Episode_t: 5, Action: 13, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 1422, loss: 7953.79443359375
[INFO] Global_t: 1422, Episode_t: 6, Action: 12, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1423, loss: 9014.5869140625
[INFO] Global_t: 1423, Episode_t: 7, Action: 9, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 1424, loss: 19123.7265625
[INFO] Global_t: 1424, Episode_t: 8, Action: 2, Reward: 2.95, Epsilon: 0.01

[INFO] Global step: 1424, Cumulative rewards: 27.6792, Runtime (s): 2542.16
------------------------------------------------------------
 
 71%|███████   | 1424/2000 [42:22<14:49,  1.54s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5855002403259277
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.322355508804321
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.628466844558716
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7589457035064697
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6071715354919434
average cummulative reward vector is:  [0.12988868 0.12225833 0.13632213 0.11891379 0.12732876]
average cummulative reward is:  0.12694233943579797
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 178, nodes: 209, edges: 618
[INFO] model update: t: 1425, loss: 8976.580078125
[INFO] Global_t: 1425, Episode_t: 1, Action: 19, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1426, loss: 4843.306640625
[INFO] Global_t: 1426, Episode_t: 2, Action: 11, Reward: 5.57, Epsilon: 0.01
[INFO] model update: t: 1427, loss: 14594.576171875
[INFO] Global_t: 1427, Episode_t: 3, Action: 16, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1428, loss: 31703.33984375
[INFO] Global_t: 1428, Episode_t: 4, Action: 22, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 1429, loss: 11954.5810546875
[INFO] Global_t: 1429, Episode_t: 5, Action: 12, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1430, loss: 19045.728515625
[INFO] Global_t: 1430, Episode_t: 6, Action: 6, Reward: 3.52, Epsilon: 0.01
[INFO] model update: t: 1431, loss: 25539.39453125
[INFO] Global_t: 1431, Episode_t: 7, Action: 21, Reward: 4.43, Epsilon: 0.01
[INFO] model update: t: 1432, loss: 17872.640625
[INFO] Global_t: 1432, Episode_t: 8, Action: 24, Reward: 2.88, Epsilon: 0.01
 72%|███████▏  | 1432/2000 [42:44<18:03,  1.91s/it]
[INFO] Global step: 1432, Cumulative rewards: 30.82956, Runtime (s): 2564.21
------------------------------------------------------------
 
graph: 179, nodes: 205, edges: 606
[INFO] model update: t: 1433, loss: 17883.921875
[INFO] Global_t: 1433, Episode_t: 1, Action: 4, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1434, loss: 17376.3828125
[INFO] Global_t: 1434, Episode_t: 2, Action: 13, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1435, loss: 20278.232421875
[INFO] Global_t: 1435, Episode_t: 3, Action: 15, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 1436, loss: 18116.7109375
[INFO] Global_t: 1436, Episode_t: 4, Action: 9, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1437, loss: 15854.0947265625
[INFO] Global_t: 1437, Episode_t: 5, Action: 29, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 1438, loss: 8667.3173828125
[INFO] Global_t: 1438, Episode_t: 6, Action: 1, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1439, loss: 17285.552734375
[INFO] Global_t: 1439, Episode_t: 7, Action: 5, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1440, loss: 50301.5
[INFO] Global_t: 1440, Episode_t: 8, Action: 10, Reward: 3.45, Epsilon: 0.01
 72%|███████▏  | 1440/2000 [42:48<14:03,  1.51s/it]
[INFO] Global step: 1440, Cumulative rewards: 28.22064, Runtime (s): 2568.75
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.294512987136841
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9932100772857666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.905360221862793
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.553955554962158
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6927366256713867
average cummulative reward vector is:  [0.13475184 0.12554375 0.12925956 0.11282804 0.13640457]
average cummulative reward is:  0.12775755244448878
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 180, nodes: 202, edges: 596
[INFO] model update: t: 1441, loss: 18131.2109375
[INFO] Global_t: 1441, Episode_t: 1, Action: 6, Reward: 4.98, Epsilon: 0.01
[INFO] model update: t: 1442, loss: 9958.8251953125
[INFO] Global_t: 1442, Episode_t: 2, Action: 12, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1443, loss: 46001.8671875
[INFO] Global_t: 1443, Episode_t: 3, Action: 21, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1444, loss: 42231.84375
[INFO] Global_t: 1444, Episode_t: 4, Action: 8, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 1445, loss: 7886.60546875
[INFO] Global_t: 1445, Episode_t: 5, Action: 9, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1446, loss: 84611.1875
[INFO] Global_t: 1446, Episode_t: 6, Action: 58, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1447, loss: 134099.09375
[INFO] Global_t: 1447, Episode_t: 7, Action: 40, Reward: 2.56, Epsilon: 0.01
[INFO] model update: t: 1448, loss: 17717.771484375
[INFO] Global_t: 1448, Episode_t: 8, Action: 27, Reward: 2.27, Epsilon: 0.01
 72%|███████▏  | 1448/2000 [43:13<18:04,  1.96s/it]
[INFO] Global step: 1448, Cumulative rewards: 25.999799999999997, Runtime (s): 2593.03
------------------------------------------------------------
 
graph: 181, nodes: 205, edges: 606
[INFO] model update: t: 1449, loss: 273780.6875
[INFO] Global_t: 1449, Episode_t: 1, Action: 6, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1450, loss: 184593.359375
[INFO] Global_t: 1450, Episode_t: 2, Action: 14, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1451, loss: 17455.21875
[INFO] Global_t: 1451, Episode_t: 3, Action: 9, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1452, loss: 87033.9453125
[INFO] Global_t: 1452, Episode_t: 4, Action: 16, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1453, loss: 47041.546875
[INFO] Global_t: 1453, Episode_t: 5, Action: 8, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 1454, loss: 72601.3203125
[INFO] Global_t: 1454, Episode_t: 6, Action: 29, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1455, loss: 215224.71875
[INFO] Global_t: 1455, Episode_t: 7, Action: 12, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1456, loss: 9249.923828125
[INFO] Global_t: 1456, Episode_t: 8, Action: 0, Reward: 3.87, Epsilon: 0.01
 73%|███████▎  | 1456/2000 [43:17<14:01,  1.55s/it]
[INFO] Global step: 1456, Cumulative rewards: 28.836239999999997, Runtime (s): 2597.59
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5645499229431152
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.004032373428345
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.280604839324951
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7794156074523926
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9323549270629883
average cummulative reward vector is:  [0.12114763 0.12686713 0.12378169 0.11354603 0.1443664 ]
average cummulative reward is:  0.1259417762168987
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 182, nodes: 205, edges: 606
[INFO] model update: t: 1457, loss: 134539.328125
[INFO] Global_t: 1457, Episode_t: 1, Action: 8, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1458, loss: 124628.9921875
[INFO] Global_t: 1458, Episode_t: 2, Action: 33, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 1459, loss: 11263.697265625
[INFO] Global_t: 1459, Episode_t: 3, Action: 23, Reward: 4.92, Epsilon: 0.01
[INFO] model update: t: 1460, loss: 118326.703125
[INFO] Global_t: 1460, Episode_t: 4, Action: 10, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1461, loss: 93919.03125
[INFO] Global_t: 1461, Episode_t: 5, Action: 24, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 1462, loss: 7042.04296875
[INFO] Global_t: 1462, Episode_t: 6, Action: 17, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1463, loss: 67892.765625
[INFO] Global_t: 1463, Episode_t: 7, Action: 22, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1464, loss: 7225.56298828125
[INFO] Global_t: 1464, Episode_t: 8, Action: 45, Reward: 2.34, Epsilon: 0.01
 73%|███████▎  | 1464/2000 [43:41<17:46,  1.99s/it]
[INFO] Global step: 1464, Cumulative rewards: 25.967399999999998, Runtime (s): 2621.77
------------------------------------------------------------
 
graph: 183, nodes: 217, edges: 642
[INFO] model update: t: 1465, loss: 80646.28125
[INFO] Global_t: 1465, Episode_t: 1, Action: 6, Reward: 5.80, Epsilon: 0.01
[INFO] model update: t: 1466, loss: 52549.17578125
[INFO] Global_t: 1466, Episode_t: 2, Action: 33, Reward: 4.40, Epsilon: 0.01
[INFO] model update: t: 1467, loss: 24750.609375
[INFO] Global_t: 1467, Episode_t: 3, Action: 9, Reward: 5.27, Epsilon: 0.01
[INFO] model update: t: 1468, loss: 116119.0625
[INFO] Global_t: 1468, Episode_t: 4, Action: 8, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 1469, loss: 23137.099609375
[INFO] Global_t: 1469, Episode_t: 5, Action: 14, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1470, loss: 29395.052734375
[INFO] Global_t: 1470, Episode_t: 6, Action: 12, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 1471, loss: 42646.265625
[INFO] Global_t: 1471, Episode_t: 7, Action: 42, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 1472, loss: 26168.25
[INFO] Global_t: 1472, Episode_t: 8, Action: 7, Reward: 3.61, Epsilon: 0.01
 74%|███████▎  | 1472/2000 [43:45<13:38,  1.55s/it]
[INFO] Global step: 1472, Cumulative rewards: 32.98164, Runtime (s): 2625.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5654492378234863
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.313425779342651
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.448601722717285
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.672032117843628
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.336214065551758
average cummulative reward vector is:  [0.13002816 0.11838333 0.13011311 0.11748341 0.14176344]
average cummulative reward is:  0.12755429161146736
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 184, nodes: 196, edges: 579
[INFO] model update: t: 1473, loss: 122394.9453125
[INFO] Global_t: 1473, Episode_t: 1, Action: 5, Reward: 5.64, Epsilon: 0.01
[INFO] model update: t: 1474, loss: 101049.734375
[INFO] Global_t: 1474, Episode_t: 2, Action: 10, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1475, loss: 8567.9814453125
[INFO] Global_t: 1475, Episode_t: 3, Action: 19, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 1476, loss: 23409.00390625
[INFO] Global_t: 1476, Episode_t: 4, Action: 9, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1477, loss: 7765.7353515625
[INFO] Global_t: 1477, Episode_t: 5, Action: 8, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 1478, loss: 20918.740234375
[INFO] Global_t: 1478, Episode_t: 6, Action: 4, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1479, loss: 37093.421875
[INFO] Global_t: 1479, Episode_t: 7, Action: 16, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1480, loss: 2506.947265625
[INFO] Global_t: 1480, Episode_t: 8, Action: 21, Reward: 1.63, Epsilon: 0.01
 74%|███████▍  | 1480/2000 [44:10<17:23,  2.01s/it]
[INFO] Global step: 1480, Cumulative rewards: 25.78835999999999, Runtime (s): 2650.53
------------------------------------------------------------
 
graph: 185, nodes: 180, edges: 530
[INFO] model update: t: 1481, loss: 67086.875
[INFO] Global_t: 1481, Episode_t: 1, Action: 30, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1482, loss: 50243.58203125
[INFO] Global_t: 1482, Episode_t: 2, Action: 1, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1483, loss: 7135.20166015625
[INFO] Global_t: 1483, Episode_t: 3, Action: 5, Reward: 4.75, Epsilon: 0.01
[INFO] model update: t: 1484, loss: 39649.73046875
[INFO] Global_t: 1484, Episode_t: 4, Action: 17, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 1485, loss: 16447.4375
[INFO] Global_t: 1485, Episode_t: 5, Action: 26, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 1486, loss: 7315.77734375
[INFO] Global_t: 1486, Episode_t: 6, Action: 18, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1487, loss: 14543.767578125
[INFO] Global_t: 1487, Episode_t: 7, Action: 3, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1488, loss: 5795.841796875
[INFO] Global_t: 1488, Episode_t: 8, Action: 6, Reward: 2.45, Epsilon: 0.01
 74%|███████▍  | 1488/2000 [44:14<13:19,  1.56s/it]
[INFO] Global step: 1488, Cumulative rewards: 26.796959999999995, Runtime (s): 2654.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.712526559829712
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.743758201599121
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7555882930755615
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.565577745437622
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5664451122283936
average cummulative reward vector is:  [0.13442079 0.1185787  0.13344508 0.11314252 0.13036263]
average cummulative reward is:  0.12598994658353782
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 186, nodes: 210, edges: 621
[INFO] model update: t: 1489, loss: 24205.876953125
[INFO] Global_t: 1489, Episode_t: 1, Action: 8, Reward: 4.84, Epsilon: 0.01
[INFO] model update: t: 1490, loss: 11753.5302734375
[INFO] Global_t: 1490, Episode_t: 2, Action: 26, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1491, loss: 31892.390625
[INFO] Global_t: 1491, Episode_t: 3, Action: 12, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1492, loss: 120392.1484375
[INFO] Global_t: 1492, Episode_t: 4, Action: 45, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 1493, loss: 43418.890625
[INFO] Global_t: 1493, Episode_t: 5, Action: 13, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1494, loss: 24812.77734375
[INFO] Global_t: 1494, Episode_t: 6, Action: 37, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1495, loss: 170305.875
[INFO] Global_t: 1495, Episode_t: 7, Action: 22, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 1496, loss: 31725.8125
[INFO] Global_t: 1496, Episode_t: 8, Action: 19, Reward: 3.77, Epsilon: 0.01
 75%|███████▍  | 1496/2000 [44:37<16:19,  1.94s/it]
[INFO] Global step: 1496, Cumulative rewards: 29.202599999999997, Runtime (s): 2677.40
------------------------------------------------------------
 
graph: 187, nodes: 210, edges: 621
[INFO] model update: t: 1497, loss: 85225.0390625
[INFO] Global_t: 1497, Episode_t: 1, Action: 5, Reward: 6.36, Epsilon: 0.01
[INFO] model update: t: 1498, loss: 74340.625
[INFO] Global_t: 1498, Episode_t: 2, Action: 21, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1499, loss: 26151.93359375
[INFO] Global_t: 1499, Episode_t: 3, Action: 13, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1500, loss: 97079.640625
[INFO] Global_t: 1500, Episode_t: 4, Action: 22, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1501, loss: 27336.15625
[INFO] Global_t: 1501, Episode_t: 5, Action: 32, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1502, loss: 12304.4794921875
[INFO] Global_t: 1502, Episode_t: 6, Action: 19, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1503, loss: 32039.828125
[INFO] Global_t: 1503, Episode_t: 7, Action: 17, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1504, loss: 11476.376953125
[INFO] Global_t: 1504, Episode_t: 8, Action: 33, Reward: 2.28, Epsilon: 0.01
 75%|███████▌  | 1504/2000 [44:42<12:56,  1.56s/it]
[INFO] Global step: 1504, Cumulative rewards: 27.997920000000004, Runtime (s): 2682.85
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8934438228607178
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.943451404571533
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.512260675430298
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.338182687759399
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5955820083618164
average cummulative reward vector is:  [0.13326474 0.12474907 0.13247077 0.12017383 0.13308737]
average cummulative reward is:  0.1287491546621201
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 188, nodes: 198, edges: 585
[INFO] model update: t: 1505, loss: 16777.890625
[INFO] Global_t: 1505, Episode_t: 1, Action: 12, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1506, loss: 38676.8671875
[INFO] Global_t: 1506, Episode_t: 2, Action: 35, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 1507, loss: 6917.03564453125
[INFO] Global_t: 1507, Episode_t: 3, Action: 1, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1508, loss: 47366.91796875
[INFO] Global_t: 1508, Episode_t: 4, Action: 10, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 1509, loss: 8662.91015625
[INFO] Global_t: 1509, Episode_t: 5, Action: 21, Reward: 3.12, Epsilon: 0.01
[INFO] model update: t: 1510, loss: 37277.51953125
[INFO] Global_t: 1510, Episode_t: 6, Action: 6, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1511, loss: 75244.1953125
[INFO] Global_t: 1511, Episode_t: 7, Action: 0, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 1512, loss: 15440.1982421875
[INFO] Global_t: 1512, Episode_t: 8, Action: 50, Reward: 2.25, Epsilon: 0.01
 76%|███████▌  | 1512/2000 [45:07<16:25,  2.02s/it]
[INFO] Global step: 1512, Cumulative rewards: 27.362759999999998, Runtime (s): 2707.48
------------------------------------------------------------
 
graph: 189, nodes: 180, edges: 531
[INFO] model update: t: 1513, loss: 78311.78125
[INFO] Global_t: 1513, Episode_t: 1, Action: 7, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 1514, loss: 173812.84375
[INFO] Global_t: 1514, Episode_t: 2, Action: 5, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1515, loss: 9122.509765625
[INFO] Global_t: 1515, Episode_t: 3, Action: 8, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1516, loss: 141506.15625
[INFO] Global_t: 1516, Episode_t: 4, Action: 2, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1517, loss: 175420.75
[INFO] Global_t: 1517, Episode_t: 5, Action: 6, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1518, loss: 9696.5322265625
[INFO] Global_t: 1518, Episode_t: 6, Action: 11, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1519, loss: 325969.75
[INFO] Global_t: 1519, Episode_t: 7, Action: 9, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1520, loss: 832836.75
[INFO] Global_t: 1520, Episode_t: 8, Action: 15, Reward: 1.87, Epsilon: 0.01
 76%|███████▌  | 1520/2000 [45:12<12:43,  1.59s/it]
[INFO] Global step: 1520, Cumulative rewards: 25.251840000000005, Runtime (s): 2712.19
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.755967378616333
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.084171772003174
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3331925868988037
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5775341987609863
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.050757169723511
average cummulative reward vector is:  [0.13641868 0.12166944 0.12463743 0.11515818 0.13427446]
average cummulative reward is:  0.12643164005692892
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 190, nodes: 194, edges: 573
[INFO] model update: t: 1521, loss: 317106.125
[INFO] Global_t: 1521, Episode_t: 1, Action: 3, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1522, loss: 33579.15625
[INFO] Global_t: 1522, Episode_t: 2, Action: 13, Reward: 4.39, Epsilon: 0.01
[INFO] model update: t: 1523, loss: 395643.9375
[INFO] Global_t: 1523, Episode_t: 3, Action: 9, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 1524, loss: 155307.390625
[INFO] Global_t: 1524, Episode_t: 4, Action: 26, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 1525, loss: 152178.6875
[INFO] Global_t: 1525, Episode_t: 5, Action: 5, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1526, loss: 416405.21875
[INFO] Global_t: 1526, Episode_t: 6, Action: 7, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 1527, loss: 35498.1796875
[INFO] Global_t: 1527, Episode_t: 7, Action: 24, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1528, loss: 149815.859375
[INFO] Global_t: 1528, Episode_t: 8, Action: 8, Reward: 2.33, Epsilon: 0.01
 76%|███████▋  | 1528/2000 [45:35<15:36,  1.98s/it]
[INFO] Global step: 1528, Cumulative rewards: 26.11968, Runtime (s): 2735.42
------------------------------------------------------------
 
graph: 191, nodes: 183, edges: 539
[INFO] model update: t: 1529, loss: 113318.015625
[INFO] Global_t: 1529, Episode_t: 1, Action: 6, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1530, loss: 12402.95703125
[INFO] Global_t: 1530, Episode_t: 2, Action: 5, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1531, loss: 115816.90625
[INFO] Global_t: 1531, Episode_t: 3, Action: 12, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1532, loss: 68424.1875
[INFO] Global_t: 1532, Episode_t: 4, Action: 9, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 1533, loss: 17134.46484375
[INFO] Global_t: 1533, Episode_t: 5, Action: 7, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1534, loss: 44916.5859375
[INFO] Global_t: 1534, Episode_t: 6, Action: 17, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1535, loss: 42466.140625
[INFO] Global_t: 1535, Episode_t: 7, Action: 18, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1536, loss: 6107.4228515625
[INFO] Global_t: 1536, Episode_t: 8, Action: 15, Reward: 2.35, Epsilon: 0.01
 77%|███████▋  | 1536/2000 [45:39<12:01,  1.56s/it]
[INFO] Global step: 1536, Cumulative rewards: 27.33396, Runtime (s): 2739.86
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4622223377227783
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.664594888687134
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.929874897003174
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6236119270324707
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.821201801300049
average cummulative reward vector is:  [0.12471658 0.11711852 0.14154454 0.11651028 0.14034731]
average cummulative reward is:  0.12804744503736026
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 192, nodes: 214, edges: 633
[INFO] model update: t: 1537, loss: 36043.875
[INFO] Global_t: 1537, Episode_t: 1, Action: 2, Reward: 4.95, Epsilon: 0.01
[INFO] model update: t: 1538, loss: 26188.03125
[INFO] Global_t: 1538, Episode_t: 2, Action: 1, Reward: 4.30, Epsilon: 0.01
[INFO] model update: t: 1539, loss: 12102.21484375
[INFO] Global_t: 1539, Episode_t: 3, Action: 9, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1540, loss: 40390.3515625
[INFO] Global_t: 1540, Episode_t: 4, Action: 10, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1541, loss: 11864.861328125
[INFO] Global_t: 1541, Episode_t: 5, Action: 15, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1542, loss: 36118.06640625
[INFO] Global_t: 1542, Episode_t: 6, Action: 11, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1543, loss: 23930.81640625
[INFO] Global_t: 1543, Episode_t: 7, Action: 8, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1544, loss: 44880.3515625
[INFO] Global_t: 1544, Episode_t: 8, Action: 16, Reward: 2.31, Epsilon: 0.01

[INFO] Global step: 1544, Cumulative rewards: 28.707839999999994, Runtime (s): 2763.24
------------------------------------------------------------
 
 77%|███████▋  | 1544/2000 [46:03<14:56,  1.97s/it]graph: 193, nodes: 218, edges: 645
[INFO] model update: t: 1545, loss: 191700.5625
[INFO] Global_t: 1545, Episode_t: 1, Action: 6, Reward: 5.21, Epsilon: 0.01
[INFO] model update: t: 1546, loss: 45398.6484375
[INFO] Global_t: 1546, Episode_t: 2, Action: 9, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1547, loss: 42037.09765625
[INFO] Global_t: 1547, Episode_t: 3, Action: 11, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1548, loss: 121145.0
[INFO] Global_t: 1548, Episode_t: 4, Action: 18, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1549, loss: 42304.203125
[INFO] Global_t: 1549, Episode_t: 5, Action: 24, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 1550, loss: 7730.228515625
[INFO] Global_t: 1550, Episode_t: 6, Action: 7, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1551, loss: 31362.154296875
[INFO] Global_t: 1551, Episode_t: 7, Action: 19, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 1552, loss: 10214.85546875
[INFO] Global_t: 1552, Episode_t: 8, Action: 56, Reward: 2.25, Epsilon: 0.01
 78%|███████▊  | 1552/2000 [46:07<11:27,  1.53s/it]
[INFO] Global step: 1552, Cumulative rewards: 29.777160000000002, Runtime (s): 2767.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8673288822174072
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8582749366760254
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5410709381103516
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9928722381591797
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.50984525680542
average cummulative reward vector is:  [0.12548211 0.12168032 0.1332306  0.11414813 0.1294586 ]
average cummulative reward is:  0.12479995268435747
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 194, nodes: 213, edges: 630
[INFO] model update: t: 1553, loss: 6635.8271484375
[INFO] Global_t: 1553, Episode_t: 1, Action: 3, Reward: 5.44, Epsilon: 0.01
[INFO] model update: t: 1554, loss: 13867.9736328125
[INFO] Global_t: 1554, Episode_t: 2, Action: 12, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1555, loss: 10342.89453125
[INFO] Global_t: 1555, Episode_t: 3, Action: 10, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1556, loss: 10053.064453125
[INFO] Global_t: 1556, Episode_t: 4, Action: 11, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1557, loss: 5128.390625
[INFO] Global_t: 1557, Episode_t: 5, Action: 5, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 1558, loss: 21511.80078125
[INFO] Global_t: 1558, Episode_t: 6, Action: 18, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1559, loss: 23304.74609375
[INFO] Global_t: 1559, Episode_t: 7, Action: 24, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1560, loss: 11348.4775390625
[INFO] Global_t: 1560, Episode_t: 8, Action: 23, Reward: 1.90, Epsilon: 0.01
 78%|███████▊  | 1560/2000 [46:32<14:38,  2.00s/it]
[INFO] Global step: 1560, Cumulative rewards: 28.305599999999995, Runtime (s): 2792.08
------------------------------------------------------------
 
graph: 195, nodes: 189, edges: 558
[INFO] model update: t: 1561, loss: 19374.29296875
[INFO] Global_t: 1561, Episode_t: 1, Action: 7, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1562, loss: 29224.515625
[INFO] Global_t: 1562, Episode_t: 2, Action: 12, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1563, loss: 6307.26904296875
[INFO] Global_t: 1563, Episode_t: 3, Action: 13, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1564, loss: 16085.921875
[INFO] Global_t: 1564, Episode_t: 4, Action: 9, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1565, loss: 22050.26171875
[INFO] Global_t: 1565, Episode_t: 5, Action: 48, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 1566, loss: 5537.94677734375
[INFO] Global_t: 1566, Episode_t: 6, Action: 29, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1567, loss: 22411.65234375
[INFO] Global_t: 1567, Episode_t: 7, Action: 10, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 1568, loss: 25019.44921875
[INFO] Global_t: 1568, Episode_t: 8, Action: 25, Reward: 1.44, Epsilon: 0.01
 78%|███████▊  | 1568/2000 [46:36<11:11,  1.55s/it]
[INFO] Global step: 1568, Cumulative rewards: 24.05352, Runtime (s): 2796.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8397555351257324
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.083100318908691
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4566221237182617
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.598963975906372
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.212425231933594
average cummulative reward vector is:  [0.13949763 0.11652569 0.13022432 0.11598154 0.13687554]
average cummulative reward is:  0.12782094453075318
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 196, nodes: 208, edges: 615
[INFO] model update: t: 1569, loss: 13861.58203125
[INFO] Global_t: 1569, Episode_t: 1, Action: 5, Reward: 4.84, Epsilon: 0.01
[INFO] model update: t: 1570, loss: 20280.791015625
[INFO] Global_t: 1570, Episode_t: 2, Action: 9, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 1571, loss: 17130.8046875
[INFO] Global_t: 1571, Episode_t: 3, Action: 8, Reward: 5.01, Epsilon: 0.01
[INFO] model update: t: 1572, loss: 9117.9541015625
[INFO] Global_t: 1572, Episode_t: 4, Action: 55, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 1573, loss: 13148.6015625
[INFO] Global_t: 1573, Episode_t: 5, Action: 1, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1574, loss: 13296.724609375
[INFO] Global_t: 1574, Episode_t: 6, Action: 6, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1575, loss: 19760.97265625
[INFO] Global_t: 1575, Episode_t: 7, Action: 17, Reward: 2.59, Epsilon: 0.01
[INFO] model update: t: 1576, loss: 7981.64306640625
[INFO] Global_t: 1576, Episode_t: 8, Action: 4, Reward: 2.86, Epsilon: 0.01
 79%|███████▉  | 1576/2000 [46:59<13:56,  1.97s/it]
[INFO] Global step: 1576, Cumulative rewards: 28.769280000000002, Runtime (s): 2819.88
------------------------------------------------------------
 
graph: 197, nodes: 197, edges: 582
[INFO] model update: t: 1577, loss: 14562.423828125
[INFO] Global_t: 1577, Episode_t: 1, Action: 2, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1578, loss: 5238.083984375
[INFO] Global_t: 1578, Episode_t: 2, Action: 5, Reward: 4.81, Epsilon: 0.01
[INFO] model update: t: 1579, loss: 18771.7421875
[INFO] Global_t: 1579, Episode_t: 3, Action: 10, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1580, loss: 24133.359375
[INFO] Global_t: 1580, Episode_t: 4, Action: 1, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1581, loss: 7561.982421875
[INFO] Global_t: 1581, Episode_t: 5, Action: 11, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 1582, loss: 6397.94775390625
[INFO] Global_t: 1582, Episode_t: 6, Action: 6, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 1583, loss: 9400.44921875
[INFO] Global_t: 1583, Episode_t: 7, Action: 15, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1584, loss: 40730.6640625
[INFO] Global_t: 1584, Episode_t: 8, Action: 21, Reward: 2.30, Epsilon: 0.01
 79%|███████▉  | 1584/2000 [47:04<10:44,  1.55s/it]
[INFO] Global step: 1584, Cumulative rewards: 28.4394, Runtime (s): 2824.36
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.622891664505005
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8373615741729736
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7720792293548584
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7690927982330322
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6918182373046875
average cummulative reward vector is:  [0.13037184 0.12130648 0.13091858 0.12072477 0.13537124]
average cummulative reward is:  0.12773858114719946
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 198, nodes: 187, edges: 552
[INFO] model update: t: 1585, loss: 40491.984375
[INFO] Global_t: 1585, Episode_t: 1, Action: 5, Reward: 4.96, Epsilon: 0.01
[INFO] model update: t: 1586, loss: 7911.3056640625
[INFO] Global_t: 1586, Episode_t: 2, Action: 3, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1587, loss: 31954.041015625
[INFO] Global_t: 1587, Episode_t: 3, Action: 17, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1588, loss: 4250.0830078125
[INFO] Global_t: 1588, Episode_t: 4, Action: 11, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1589, loss: 40353.3515625
[INFO] Global_t: 1589, Episode_t: 5, Action: 13, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1590, loss: 5260.3349609375
[INFO] Global_t: 1590, Episode_t: 6, Action: 20, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1591, loss: 7531.244140625
[INFO] Global_t: 1591, Episode_t: 7, Action: 22, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1592, loss: 3493.130615234375
[INFO] Global_t: 1592, Episode_t: 8, Action: 7, Reward: 2.90, Epsilon: 0.01
 80%|███████▉  | 1592/2000 [47:27<13:23,  1.97s/it]
[INFO] Global step: 1592, Cumulative rewards: 26.41512, Runtime (s): 2847.92
------------------------------------------------------------
 
graph: 199, nodes: 216, edges: 638
[INFO] model update: t: 1593, loss: 16943.5234375
[INFO] Global_t: 1593, Episode_t: 1, Action: 8, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 1594, loss: 20327.02734375
[INFO] Global_t: 1594, Episode_t: 2, Action: 7, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 1595, loss: 7173.41064453125
[INFO] Global_t: 1595, Episode_t: 3, Action: 31, Reward: 3.39, Epsilon: 0.01
[INFO] model update: t: 1596, loss: 13322.998046875
[INFO] Global_t: 1596, Episode_t: 4, Action: 5, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1597, loss: 23908.640625
[INFO] Global_t: 1597, Episode_t: 5, Action: 14, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 1598, loss: 11035.91015625
[INFO] Global_t: 1598, Episode_t: 6, Action: 28, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 1599, loss: 20110.068359375
[INFO] Global_t: 1599, Episode_t: 7, Action: 20, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 1600, loss: 71013.96875
[INFO] Global_t: 1600, Episode_t: 8, Action: 11, Reward: 3.75, Epsilon: 0.01
 80%|████████  | 1600/2000 [47:31<10:09,  1.52s/it]
[INFO] Global step: 1600, Cumulative rewards: 28.866479999999996, Runtime (s): 2851.79
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.275476932525635
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.732163190841675
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4266529083251953
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.117399454116821
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6663730144500732
average cummulative reward vector is:  [0.13074395 0.11785671 0.12869153 0.12053037 0.13337661]
average cummulative reward is:  0.12623983542420608
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  1
graph: 0, nodes: 180, edges: 531
[INFO] model update: t: 1601, loss: 46158.953125
[INFO] Global_t: 1601, Episode_t: 1, Action: 4, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1602, loss: 7720.5625
[INFO] Global_t: 1602, Episode_t: 2, Action: 12, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1603, loss: 47339.3359375
[INFO] Global_t: 1603, Episode_t: 3, Action: 20, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 1604, loss: 21861.693359375
[INFO] Global_t: 1604, Episode_t: 4, Action: 8, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1605, loss: 17717.767578125
[INFO] Global_t: 1605, Episode_t: 5, Action: 3, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1606, loss: 40550.35546875
[INFO] Global_t: 1606, Episode_t: 6, Action: 2, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1607, loss: 16521.31640625
[INFO] Global_t: 1607, Episode_t: 7, Action: 28, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1608, loss: 8257.7978515625
[INFO] Global_t: 1608, Episode_t: 8, Action: 0, Reward: 2.53, Epsilon: 0.01
 80%|████████  | 1608/2000 [47:55<12:45,  1.95s/it]
[INFO] Global step: 1608, Cumulative rewards: 28.28508, Runtime (s): 2875.42
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] model update: t: 1609, loss: 25586.80078125
[INFO] Global_t: 1609, Episode_t: 1, Action: 7, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1610, loss: 10614.845703125
[INFO] Global_t: 1610, Episode_t: 2, Action: 6, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 1611, loss: 20068.9609375
[INFO] Global_t: 1611, Episode_t: 3, Action: 5, Reward: 5.03, Epsilon: 0.01
[INFO] model update: t: 1612, loss: 33657.921875
[INFO] Global_t: 1612, Episode_t: 4, Action: 27, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1613, loss: 20176.548828125
[INFO] Global_t: 1613, Episode_t: 5, Action: 12, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 1614, loss: 2263.6728515625
[INFO] Global_t: 1614, Episode_t: 6, Action: 20, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1615, loss: 10088.64453125
[INFO] Global_t: 1615, Episode_t: 7, Action: 4, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 1616, loss: 8401.46875
[INFO] Global_t: 1616, Episode_t: 8, Action: 8, Reward: 2.84, Epsilon: 0.01
 81%|████████  | 1616/2000 [48:00<09:57,  1.56s/it]
[INFO] Global step: 1616, Cumulative rewards: 30.365279999999995, Runtime (s): 2880.47
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9734585285186768
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.563686847686768
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.864011287689209
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7351295948028564
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.174920082092285
average cummulative reward vector is:  [0.13975921 0.12596528 0.13726038 0.11684229 0.13609758]
average cummulative reward is:  0.13118494823650845
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] model update: t: 1617, loss: 9167.212890625
[INFO] Global_t: 1617, Episode_t: 1, Action: 6, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1618, loss: 29749.537109375
[INFO] Global_t: 1618, Episode_t: 2, Action: 37, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1619, loss: 15511.8955078125
[INFO] Global_t: 1619, Episode_t: 3, Action: 18, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1620, loss: 11992.5576171875
[INFO] Global_t: 1620, Episode_t: 4, Action: 12, Reward: 4.18, Epsilon: 0.01
[INFO] model update: t: 1621, loss: 41015.01953125
[INFO] Global_t: 1621, Episode_t: 5, Action: 17, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1622, loss: 16756.732421875
[INFO] Global_t: 1622, Episode_t: 6, Action: 8, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1623, loss: 14235.291015625
[INFO] Global_t: 1623, Episode_t: 7, Action: 10, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1624, loss: 24620.78125
[INFO] Global_t: 1624, Episode_t: 8, Action: 20, Reward: 2.80, Epsilon: 0.01

[INFO] Global step: 1624, Cumulative rewards: 32.43204, Runtime (s): 2905.09
------------------------------------------------------------
 
 81%|████████  | 1624/2000 [48:25<12:36,  2.01s/it]graph: 3, nodes: 204, edges: 603
[INFO] model update: t: 1625, loss: 24176.587890625
[INFO] Global_t: 1625, Episode_t: 1, Action: 7, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1626, loss: 8695.8974609375
[INFO] Global_t: 1626, Episode_t: 2, Action: 9, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1627, loss: 21988.55859375
[INFO] Global_t: 1627, Episode_t: 3, Action: 1, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1628, loss: 11945.5908203125
[INFO] Global_t: 1628, Episode_t: 4, Action: 13, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1629, loss: 14758.4990234375
[INFO] Global_t: 1629, Episode_t: 5, Action: 5, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1630, loss: 13525.1728515625
[INFO] Global_t: 1630, Episode_t: 6, Action: 17, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 1631, loss: 5823.9453125
[INFO] Global_t: 1631, Episode_t: 7, Action: 29, Reward: 1.16, Epsilon: 0.01
[INFO] model update: t: 1632, loss: 37274.7109375
[INFO] Global_t: 1632, Episode_t: 8, Action: 16, Reward: 2.29, Epsilon: 0.01
 82%|████████▏ | 1632/2000 [48:30<09:53,  1.61s/it]
[INFO] Global step: 1632, Cumulative rewards: 25.20192, Runtime (s): 2910.54
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5186665058135986
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.645697832107544
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6245954036712646
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.973743438720703
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.484492063522339
average cummulative reward vector is:  [0.12809947 0.11490093 0.12178798 0.12404696 0.14456048]
average cummulative reward is:  0.12667916484800062
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] model update: t: 1633, loss: 103771.2421875
[INFO] Global_t: 1633, Episode_t: 1, Action: 5, Reward: 5.69, Epsilon: 0.01
[INFO] model update: t: 1634, loss: 72138.75
[INFO] Global_t: 1634, Episode_t: 2, Action: 9, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 1635, loss: 37748.48046875
[INFO] Global_t: 1635, Episode_t: 3, Action: 19, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 1636, loss: 334274.40625
[INFO] Global_t: 1636, Episode_t: 4, Action: 10, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1637, loss: 301656.5
[INFO] Global_t: 1637, Episode_t: 5, Action: 7, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1638, loss: 10065.0830078125
[INFO] Global_t: 1638, Episode_t: 6, Action: 11, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1639, loss: 296169.375
[INFO] Global_t: 1639, Episode_t: 7, Action: 36, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 1640, loss: 93488.5
[INFO] Global_t: 1640, Episode_t: 8, Action: 1, Reward: 2.34, Epsilon: 0.01
 82%|████████▏ | 1640/2000 [48:54<12:04,  2.01s/it]
[INFO] Global step: 1640, Cumulative rewards: 27.974159999999998, Runtime (s): 2934.11
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] model update: t: 1641, loss: 91165.8203125
[INFO] Global_t: 1641, Episode_t: 1, Action: 6, Reward: 5.52, Epsilon: 0.01
[INFO] model update: t: 1642, loss: 116466.59375
[INFO] Global_t: 1642, Episode_t: 2, Action: 2, Reward: 4.91, Epsilon: 0.01
[INFO] model update: t: 1643, loss: 46254.96875
[INFO] Global_t: 1643, Episode_t: 3, Action: 185, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1644, loss: 299375.8125
[INFO] Global_t: 1644, Episode_t: 4, Action: 10, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1645, loss: 62447.4296875
[INFO] Global_t: 1645, Episode_t: 5, Action: 5, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1646, loss: 97865.59375
[INFO] Global_t: 1646, Episode_t: 6, Action: 7, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1647, loss: 279271.0
[INFO] Global_t: 1647, Episode_t: 7, Action: 14, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 1648, loss: 171208.203125
[INFO] Global_t: 1648, Episode_t: 8, Action: 11, Reward: 2.81, Epsilon: 0.01
 82%|████████▏ | 1648/2000 [48:58<09:13,  1.57s/it]
[INFO] Global step: 1648, Cumulative rewards: 28.999079999999996, Runtime (s): 2938.47
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.433373928070068
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8226876258850098
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.85721755027771
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.524453639984131
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7661678791046143
average cummulative reward vector is:  [0.13398974 0.12033727 0.1336429  0.11038645 0.13401962]
average cummulative reward is:  0.12647519475790642
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 1649, loss: 25018.943359375
[INFO] Global_t: 1649, Episode_t: 1, Action: 11, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1650, loss: 331915.6875
[INFO] Global_t: 1650, Episode_t: 2, Action: 5, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 1651, loss: 508156.8125
[INFO] Global_t: 1651, Episode_t: 3, Action: 8, Reward: 3.73, Epsilon: 0.01
[INFO] model update: t: 1652, loss: 200826.171875
[INFO] Global_t: 1652, Episode_t: 4, Action: 7, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1653, loss: 47857.0390625
[INFO] Global_t: 1653, Episode_t: 5, Action: 0, Reward: 2.87, Epsilon: 0.01
[INFO] model update: t: 1654, loss: 373779.53125
[INFO] Global_t: 1654, Episode_t: 6, Action: 2, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 1655, loss: 293988.4375
[INFO] Global_t: 1655, Episode_t: 7, Action: 26, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1656, loss: 8694.3828125
[INFO] Global_t: 1656, Episode_t: 8, Action: 18, Reward: 2.28, Epsilon: 0.01
 83%|████████▎ | 1656/2000 [49:23<11:35,  2.02s/it]
[INFO] Global step: 1656, Cumulative rewards: 26.4264, Runtime (s): 2963.06
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 1657, loss: 321366.1875
[INFO] Global_t: 1657, Episode_t: 1, Action: 3, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1658, loss: 235913.9375
[INFO] Global_t: 1658, Episode_t: 2, Action: 6, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1659, loss: 124685.9140625
[INFO] Global_t: 1659, Episode_t: 3, Action: 14, Reward: 4.28, Epsilon: 0.01
[INFO] model update: t: 1660, loss: 662005.25
[INFO] Global_t: 1660, Episode_t: 4, Action: 10, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1661, loss: 25504.513671875
[INFO] Global_t: 1661, Episode_t: 5, Action: 35, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1662, loss: 517650.4375
[INFO] Global_t: 1662, Episode_t: 6, Action: 4, Reward: 3.26, Epsilon: 0.01
[INFO] model update: t: 1663, loss: 711554.0625
[INFO] Global_t: 1663, Episode_t: 7, Action: 13, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 1664, loss: 127278.3046875
[INFO] Global_t: 1664, Episode_t: 8, Action: 28, Reward: 2.30, Epsilon: 0.01
 83%|████████▎ | 1664/2000 [49:27<08:55,  1.59s/it]
[INFO] Global step: 1664, Cumulative rewards: 26.420279999999995, Runtime (s): 2967.79
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.0245044231414795
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5912632942199707
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.570943593978882
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.85323166847229
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.702472448348999
average cummulative reward vector is:  [0.12528289 0.11382894 0.13315055 0.11117336 0.13583011]
average cummulative reward is:  0.12385316967659557
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 1665, loss: 110027.1875
[INFO] Global_t: 1665, Episode_t: 1, Action: 3, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1666, loss: 136442.375
[INFO] Global_t: 1666, Episode_t: 2, Action: 8, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1667, loss: 25505.96484375
[INFO] Global_t: 1667, Episode_t: 3, Action: 10, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1668, loss: 354308.875
[INFO] Global_t: 1668, Episode_t: 4, Action: 16, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1669, loss: 356960.625
[INFO] Global_t: 1669, Episode_t: 5, Action: 2, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 1670, loss: 28352.138671875
[INFO] Global_t: 1670, Episode_t: 6, Action: 11, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 1671, loss: 490670.6875
[INFO] Global_t: 1671, Episode_t: 7, Action: 18, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1672, loss: 331373.3125
[INFO] Global_t: 1672, Episode_t: 8, Action: 21, Reward: 2.07, Epsilon: 0.01
 84%|████████▎ | 1672/2000 [49:50<10:45,  1.97s/it]
[INFO] Global step: 1672, Cumulative rewards: 26.567040000000002, Runtime (s): 2990.56
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 1673, loss: 9564.8876953125
[INFO] Global_t: 1673, Episode_t: 1, Action: 0, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1674, loss: 350846.5625
[INFO] Global_t: 1674, Episode_t: 2, Action: 36, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 1675, loss: 336581.21875
[INFO] Global_t: 1675, Episode_t: 3, Action: 14, Reward: 4.29, Epsilon: 0.01
[INFO] model update: t: 1676, loss: 10464.673828125
[INFO] Global_t: 1676, Episode_t: 4, Action: 32, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 1677, loss: 396380.75
[INFO] Global_t: 1677, Episode_t: 5, Action: 81, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 1678, loss: 316180.25
[INFO] Global_t: 1678, Episode_t: 6, Action: 13, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 1679, loss: 89031.8359375
[INFO] Global_t: 1679, Episode_t: 7, Action: 9, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 1680, loss: 457087.8125
[INFO] Global_t: 1680, Episode_t: 8, Action: 23, Reward: 1.46, Epsilon: 0.01
 84%|████████▍ | 1680/2000 [49:55<08:25,  1.58s/it]
[INFO] Global step: 1680, Cumulative rewards: 24.91704, Runtime (s): 2995.91
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9935946464538574
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.482480525970459
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8557121753692627
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.089693069458008
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.626417636871338
average cummulative reward vector is:  [0.13887632 0.12551528 0.13846639 0.11744042 0.12956559]
average cummulative reward is:  0.1299727997936943
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 1681, loss: 82652.1875
[INFO] Global_t: 1681, Episode_t: 1, Action: 8, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1682, loss: 938127.0625
[INFO] Global_t: 1682, Episode_t: 2, Action: 6, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 1683, loss: 299429.90625
[INFO] Global_t: 1683, Episode_t: 3, Action: 5, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 1684, loss: 168350.046875
[INFO] Global_t: 1684, Episode_t: 4, Action: 0, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1685, loss: 861868.625
[INFO] Global_t: 1685, Episode_t: 5, Action: 3, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1686, loss: 465917.0625
[INFO] Global_t: 1686, Episode_t: 6, Action: 21, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1687, loss: 79090.3515625
[INFO] Global_t: 1687, Episode_t: 7, Action: 4, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 1688, loss: 676795.6875
[INFO] Global_t: 1688, Episode_t: 8, Action: 15, Reward: 2.46, Epsilon: 0.01
 84%|████████▍ | 1688/2000 [50:20<10:27,  2.01s/it]
[INFO] Global step: 1688, Cumulative rewards: 25.637999999999998, Runtime (s): 3020.10
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 1689, loss: 28328.46484375
[INFO] Global_t: 1689, Episode_t: 1, Action: 9, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1690, loss: 511628.1875
[INFO] Global_t: 1690, Episode_t: 2, Action: 2, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 1691, loss: 761803.625
[INFO] Global_t: 1691, Episode_t: 3, Action: 6, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1692, loss: 28051.361328125
[INFO] Global_t: 1692, Episode_t: 4, Action: 33, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1693, loss: 418942.6875
[INFO] Global_t: 1693, Episode_t: 5, Action: 14, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1694, loss: 709772.5625
[INFO] Global_t: 1694, Episode_t: 6, Action: 7, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1695, loss: 49385.22265625
[INFO] Global_t: 1695, Episode_t: 7, Action: 17, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1696, loss: 387877.65625
[INFO] Global_t: 1696, Episode_t: 8, Action: 19, Reward: 1.80, Epsilon: 0.01
 85%|████████▍ | 1696/2000 [50:25<08:11,  1.62s/it]
[INFO] Global step: 1696, Cumulative rewards: 27.50676, Runtime (s): 3025.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.944056510925293
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.119473695755005
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5034403800964355
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9089133739471436
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9547080993652344
average cummulative reward vector is:  [0.13123053 0.11644097 0.12878197 0.11875911 0.13076398]
average cummulative reward is:  0.12519531127905656
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 1697, loss: 730806.0625
[INFO] Global_t: 1697, Episode_t: 1, Action: 4, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1698, loss: 7323.82666015625
[INFO] Global_t: 1698, Episode_t: 2, Action: 19, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1699, loss: 656606.0
[INFO] Global_t: 1699, Episode_t: 3, Action: 8, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1700, loss: 667730.9375
[INFO] Global_t: 1700, Episode_t: 4, Action: 17, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 1701, loss: 3441.521728515625
[INFO] Global_t: 1701, Episode_t: 5, Action: 13, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 1702, loss: 521878.3125
[INFO] Global_t: 1702, Episode_t: 6, Action: 33, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 1703, loss: 663354.9375
[INFO] Global_t: 1703, Episode_t: 7, Action: 1, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1704, loss: 57066.3359375
[INFO] Global_t: 1704, Episode_t: 8, Action: 31, Reward: 2.78, Epsilon: 0.01
 85%|████████▌ | 1704/2000 [50:48<09:52,  2.00s/it]
[INFO] Global step: 1704, Cumulative rewards: 28.496039999999997, Runtime (s): 3048.79
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 1705, loss: 200739.0625
[INFO] Global_t: 1705, Episode_t: 1, Action: 1, Reward: 5.16, Epsilon: 0.01
[INFO] model update: t: 1706, loss: 412201.0625
[INFO] Global_t: 1706, Episode_t: 2, Action: 6, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1707, loss: 38909.23046875
[INFO] Global_t: 1707, Episode_t: 3, Action: 20, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1708, loss: 99217.5625
[INFO] Global_t: 1708, Episode_t: 4, Action: 27, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1709, loss: 81484.859375
[INFO] Global_t: 1709, Episode_t: 5, Action: 9, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1710, loss: 7203.64599609375
[INFO] Global_t: 1710, Episode_t: 6, Action: 24, Reward: 1.90, Epsilon: 0.01
[INFO] model update: t: 1711, loss: 57690.453125
[INFO] Global_t: 1711, Episode_t: 7, Action: 79, Reward: 1.76, Epsilon: 0.01
[INFO] model update: t: 1712, loss: 75790.046875
[INFO] Global_t: 1712, Episode_t: 8, Action: 14, Reward: 1.92, Epsilon: 0.01
 86%|████████▌ | 1712/2000 [50:55<07:50,  1.63s/it]
[INFO] Global step: 1712, Cumulative rewards: 23.919240000000002, Runtime (s): 3055.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.134875535964966
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.131058931350708
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.342482328414917
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.971776008605957
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.639326572418213
average cummulative reward vector is:  [0.13962895 0.12459537 0.1416347  0.12177033 0.13036129]
average cummulative reward is:  0.13159812692354556
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 1713, loss: 13134.482421875
[INFO] Global_t: 1713, Episode_t: 1, Action: 11, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 1714, loss: 36246.12109375
[INFO] Global_t: 1714, Episode_t: 2, Action: 9, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1715, loss: 58437.1640625
[INFO] Global_t: 1715, Episode_t: 3, Action: 6, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1716, loss: 14053.931640625
[INFO] Global_t: 1716, Episode_t: 4, Action: 5, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 1717, loss: 7070.48291015625
[INFO] Global_t: 1717, Episode_t: 5, Action: 0, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1718, loss: 9646.19140625
[INFO] Global_t: 1718, Episode_t: 6, Action: 30, Reward: 3.02, Epsilon: 0.01
[INFO] model update: t: 1719, loss: 11487.177734375
[INFO] Global_t: 1719, Episode_t: 7, Action: 14, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 1720, loss: 6027.19970703125
[INFO] Global_t: 1720, Episode_t: 8, Action: 7, Reward: 3.74, Epsilon: 0.01
 86%|████████▌ | 1720/2000 [51:19<09:38,  2.07s/it]
[INFO] Global step: 1720, Cumulative rewards: 29.00724, Runtime (s): 3079.67
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 1721, loss: 20196.57421875
[INFO] Global_t: 1721, Episode_t: 1, Action: 12, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1722, loss: 5354.06298828125
[INFO] Global_t: 1722, Episode_t: 2, Action: 1, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1723, loss: 23270.734375
[INFO] Global_t: 1723, Episode_t: 3, Action: 8, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1724, loss: 20077.068359375
[INFO] Global_t: 1724, Episode_t: 4, Action: 17, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 1725, loss: 7450.0693359375
[INFO] Global_t: 1725, Episode_t: 5, Action: 16, Reward: 3.18, Epsilon: 0.01
[INFO] model update: t: 1726, loss: 17698.564453125
[INFO] Global_t: 1726, Episode_t: 6, Action: 0, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 1727, loss: 16211.474609375
[INFO] Global_t: 1727, Episode_t: 7, Action: 10, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 1728, loss: 35252.76171875
[INFO] Global_t: 1728, Episode_t: 8, Action: 24, Reward: 2.12, Epsilon: 0.01
 86%|████████▋ | 1728/2000 [51:24<07:18,  1.61s/it]
[INFO] Global step: 1728, Cumulative rewards: 25.342079999999996, Runtime (s): 3084.08
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.039942502975464
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.88549542427063
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.170281171798706
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.979782819747925
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8459861278533936
average cummulative reward vector is:  [0.13044684 0.11629236 0.1460276  0.11343271 0.13806747]
average cummulative reward is:  0.1288533964486886
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 1729, loss: 5505.51904296875
[INFO] Global_t: 1729, Episode_t: 1, Action: 3, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1730, loss: 27064.33203125
[INFO] Global_t: 1730, Episode_t: 2, Action: 7, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 1731, loss: 10668.333984375
[INFO] Global_t: 1731, Episode_t: 3, Action: 18, Reward: 3.48, Epsilon: 0.01
[INFO] model update: t: 1732, loss: 30346.884765625
[INFO] Global_t: 1732, Episode_t: 4, Action: 20, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1733, loss: 62625.6484375
[INFO] Global_t: 1733, Episode_t: 5, Action: 23, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1734, loss: 20254.998046875
[INFO] Global_t: 1734, Episode_t: 6, Action: 10, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1735, loss: 7630.71484375
[INFO] Global_t: 1735, Episode_t: 7, Action: 6, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 1736, loss: 13096.65625
[INFO] Global_t: 1736, Episode_t: 8, Action: 8, Reward: 3.04, Epsilon: 0.01
 87%|████████▋ | 1736/2000 [51:48<09:03,  2.06s/it]
[INFO] Global step: 1736, Cumulative rewards: 28.940879999999993, Runtime (s): 3108.84
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 1737, loss: 6735.7021484375
[INFO] Global_t: 1737, Episode_t: 1, Action: 4, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1738, loss: 15658.771484375
[INFO] Global_t: 1738, Episode_t: 2, Action: 15, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1739, loss: 2784.77978515625
[INFO] Global_t: 1739, Episode_t: 3, Action: 8, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1740, loss: 11702.275390625
[INFO] Global_t: 1740, Episode_t: 4, Action: 19, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1741, loss: 6990.6806640625
[INFO] Global_t: 1741, Episode_t: 5, Action: 12, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1742, loss: 14117.3291015625
[INFO] Global_t: 1742, Episode_t: 6, Action: 38, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 1743, loss: 47416.1484375
[INFO] Global_t: 1743, Episode_t: 7, Action: 1, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1744, loss: 122814.234375
[INFO] Global_t: 1744, Episode_t: 8, Action: 16, Reward: 2.67, Epsilon: 0.01
 87%|████████▋ | 1744/2000 [51:53<06:52,  1.61s/it]
[INFO] Global step: 1744, Cumulative rewards: 26.19276, Runtime (s): 3113.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7356038093566895
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.729145050048828
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8531551361083984
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.114089012145996
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8601841926574707
average cummulative reward vector is:  [0.13179316 0.12420324 0.13345546 0.11343201 0.1339543 ]
average cummulative reward is:  0.12736763470748302
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 1745, loss: 32754.75390625
[INFO] Global_t: 1745, Episode_t: 1, Action: 4, Reward: 5.14, Epsilon: 0.01
[INFO] model update: t: 1746, loss: 48869.32421875
[INFO] Global_t: 1746, Episode_t: 2, Action: 6, Reward: 5.15, Epsilon: 0.01
[INFO] model update: t: 1747, loss: 139117.828125
[INFO] Global_t: 1747, Episode_t: 3, Action: 10, Reward: 3.73, Epsilon: 0.01
[INFO] model update: t: 1748, loss: 21789.017578125
[INFO] Global_t: 1748, Episode_t: 4, Action: 13, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1749, loss: 38962.390625
[INFO] Global_t: 1749, Episode_t: 5, Action: 24, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1750, loss: 106124.0625
[INFO] Global_t: 1750, Episode_t: 6, Action: 1, Reward: 2.10, Epsilon: 0.01
[INFO] model update: t: 1751, loss: 31557.458984375
[INFO] Global_t: 1751, Episode_t: 7, Action: 20, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1752, loss: 8562.380859375
[INFO] Global_t: 1752, Episode_t: 8, Action: 8, Reward: 2.05, Epsilon: 0.01
 88%|████████▊ | 1752/2000 [52:19<08:46,  2.12s/it]
[INFO] Global step: 1752, Cumulative rewards: 26.42772, Runtime (s): 3139.93
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 1753, loss: 30070.09375
[INFO] Global_t: 1753, Episode_t: 1, Action: 4, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1754, loss: 9499.498046875
[INFO] Global_t: 1754, Episode_t: 2, Action: 13, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1755, loss: 9321.064453125
[INFO] Global_t: 1755, Episode_t: 3, Action: 8, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 1756, loss: 18170.697265625
[INFO] Global_t: 1756, Episode_t: 4, Action: 30, Reward: 3.39, Epsilon: 0.01
[INFO] model update: t: 1757, loss: 18790.51171875
[INFO] Global_t: 1757, Episode_t: 5, Action: 10, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 1758, loss: 8274.37890625
[INFO] Global_t: 1758, Episode_t: 6, Action: 11, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1759, loss: 5398.2158203125
[INFO] Global_t: 1759, Episode_t: 7, Action: 23, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 1760, loss: 10445.578125
[INFO] Global_t: 1760, Episode_t: 8, Action: 7, Reward: 3.00, Epsilon: 0.01
 88%|████████▊ | 1760/2000 [52:25<06:44,  1.69s/it]
[INFO] Global step: 1760, Cumulative rewards: 27.425159999999998, Runtime (s): 3145.24
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.713991165161133
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.178863048553467
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8207833766937256
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.496002674102783
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.704240322113037
average cummulative reward vector is:  [0.13086921 0.11842569 0.13436831 0.12506963 0.12856828]
average cummulative reward is:  0.12746022334396118
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 1761, loss: 5157.5
[INFO] Global_t: 1761, Episode_t: 1, Action: 13, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1762, loss: 8435.2158203125
[INFO] Global_t: 1762, Episode_t: 2, Action: 0, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1763, loss: 5451.3271484375
[INFO] Global_t: 1763, Episode_t: 3, Action: 3, Reward: 5.94, Epsilon: 0.01
[INFO] model update: t: 1764, loss: 9073.35546875
[INFO] Global_t: 1764, Episode_t: 4, Action: 11, Reward: 3.31, Epsilon: 0.01
[INFO] model update: t: 1765, loss: 3567.84326171875
[INFO] Global_t: 1765, Episode_t: 5, Action: 18, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 1766, loss: 10214.2578125
[INFO] Global_t: 1766, Episode_t: 6, Action: 16, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1767, loss: 2501.612548828125
[INFO] Global_t: 1767, Episode_t: 7, Action: 17, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1768, loss: 10698.2216796875
[INFO] Global_t: 1768, Episode_t: 8, Action: 7, Reward: 3.14, Epsilon: 0.01
 88%|████████▊ | 1768/2000 [52:49<08:05,  2.09s/it]
[INFO] Global step: 1768, Cumulative rewards: 33.02184, Runtime (s): 3169.59
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 1769, loss: 6885.36865234375
[INFO] Global_t: 1769, Episode_t: 1, Action: 8, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 1770, loss: 11916.970703125
[INFO] Global_t: 1770, Episode_t: 2, Action: 6, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 1771, loss: 5879.8056640625
[INFO] Global_t: 1771, Episode_t: 3, Action: 9, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 1772, loss: 16381.3974609375
[INFO] Global_t: 1772, Episode_t: 4, Action: 7, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1773, loss: 22744.69140625
[INFO] Global_t: 1773, Episode_t: 5, Action: 40, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1774, loss: 4977.16064453125
[INFO] Global_t: 1774, Episode_t: 6, Action: 18, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1775, loss: 16758.96875
[INFO] Global_t: 1775, Episode_t: 7, Action: 13, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1776, loss: 15568.853515625
[INFO] Global_t: 1776, Episode_t: 8, Action: 0, Reward: 2.52, Epsilon: 0.01
 89%|████████▉ | 1776/2000 [52:53<06:04,  1.63s/it]
[INFO] Global step: 1776, Cumulative rewards: 25.22004, Runtime (s): 3173.88
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.705404281616211
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.3242506980896
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7659504413604736
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.738020896911621
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.585602045059204
average cummulative reward vector is:  [0.13058289 0.11513171 0.1297694  0.11219603 0.14874651]
average cummulative reward is:  0.12728530800412724
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 1777, loss: 15286.900390625
[INFO] Global_t: 1777, Episode_t: 1, Action: 4, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1778, loss: 27630.78125
[INFO] Global_t: 1778, Episode_t: 2, Action: 5, Reward: 4.95, Epsilon: 0.01
[INFO] model update: t: 1779, loss: 20021.8671875
[INFO] Global_t: 1779, Episode_t: 3, Action: 13, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1780, loss: 4905.3984375
[INFO] Global_t: 1780, Episode_t: 4, Action: 1, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1781, loss: 16446.9140625
[INFO] Global_t: 1781, Episode_t: 5, Action: 18, Reward: 2.08, Epsilon: 0.01
[INFO] model update: t: 1782, loss: 11226.458984375
[INFO] Global_t: 1782, Episode_t: 6, Action: 15, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1783, loss: 35245.46484375
[INFO] Global_t: 1783, Episode_t: 7, Action: 2, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 1784, loss: 28490.86328125
[INFO] Global_t: 1784, Episode_t: 8, Action: 8, Reward: 2.28, Epsilon: 0.01
 89%|████████▉ | 1784/2000 [53:19<07:29,  2.08s/it]
[INFO] Global step: 1784, Cumulative rewards: 26.769119999999997, Runtime (s): 3199.02
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 1785, loss: 14782.6494140625
[INFO] Global_t: 1785, Episode_t: 1, Action: 14, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1786, loss: 58809.59375
[INFO] Global_t: 1786, Episode_t: 2, Action: 18, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1787, loss: 11537.490234375
[INFO] Global_t: 1787, Episode_t: 3, Action: 13, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1788, loss: 23727.091796875
[INFO] Global_t: 1788, Episode_t: 4, Action: 9, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 1789, loss: 49494.9140625
[INFO] Global_t: 1789, Episode_t: 5, Action: 6, Reward: 3.13, Epsilon: 0.01
[INFO] model update: t: 1790, loss: 39302.421875
[INFO] Global_t: 1790, Episode_t: 6, Action: 21, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 1791, loss: 1996.6544189453125
[INFO] Global_t: 1791, Episode_t: 7, Action: 12, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1792, loss: 31645.169921875
[INFO] Global_t: 1792, Episode_t: 8, Action: 35, Reward: 2.19, Epsilon: 0.01
 90%|████████▉ | 1792/2000 [53:23<05:40,  1.64s/it]
[INFO] Global step: 1792, Cumulative rewards: 26.608079999999998, Runtime (s): 3203.78
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5361828804016113
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7740864753723145
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.305905818939209
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.209189176559448
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.940302848815918
average cummulative reward vector is:  [0.12721947 0.11356574 0.13456366 0.12427126 0.12997419]
average cummulative reward is:  0.12591886617155343
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 1793, loss: 8286.203125
[INFO] Global_t: 1793, Episode_t: 1, Action: 13, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1794, loss: 29863.388671875
[INFO] Global_t: 1794, Episode_t: 2, Action: 1, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1795, loss: 20436.22265625
[INFO] Global_t: 1795, Episode_t: 3, Action: 0, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1796, loss: 7198.2109375
[INFO] Global_t: 1796, Episode_t: 4, Action: 8, Reward: 3.48, Epsilon: 0.01
[INFO] model update: t: 1797, loss: 40557.984375
[INFO] Global_t: 1797, Episode_t: 5, Action: 14, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 1798, loss: 20970.81640625
[INFO] Global_t: 1798, Episode_t: 6, Action: 11, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1799, loss: 4674.4296875
[INFO] Global_t: 1799, Episode_t: 7, Action: 21, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 1800, loss: 11144.7568359375
[INFO] Global_t: 1800, Episode_t: 8, Action: 9, Reward: 2.96, Epsilon: 0.01
 90%|█████████ | 1800/2000 [53:48<06:53,  2.07s/it]
[INFO] Global step: 1800, Cumulative rewards: 26.10456, Runtime (s): 3228.34
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 1801, loss: 11317.6708984375
[INFO] Global_t: 1801, Episode_t: 1, Action: 14, Reward: 4.28, Epsilon: 0.01
[INFO] model update: t: 1802, loss: 21269.701171875
[INFO] Global_t: 1802, Episode_t: 2, Action: 25, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1803, loss: 11775.9638671875
[INFO] Global_t: 1803, Episode_t: 3, Action: 0, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1804, loss: 8868.1015625
[INFO] Global_t: 1804, Episode_t: 4, Action: 17, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1805, loss: 24144.763671875
[INFO] Global_t: 1805, Episode_t: 5, Action: 7, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 1806, loss: 20871.306640625
[INFO] Global_t: 1806, Episode_t: 6, Action: 13, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1807, loss: 4509.3857421875
[INFO] Global_t: 1807, Episode_t: 7, Action: 8, Reward: 3.15, Epsilon: 0.01
[INFO] model update: t: 1808, loss: 21809.833984375
[INFO] Global_t: 1808, Episode_t: 8, Action: 15, Reward: 1.91, Epsilon: 0.01
 90%|█████████ | 1808/2000 [53:54<05:20,  1.67s/it]
[INFO] Global step: 1808, Cumulative rewards: 25.76364, Runtime (s): 3234.33
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.733154773712158
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.919283628463745
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.289666652679443
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7872555255889893
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.700531482696533
average cummulative reward vector is:  [0.13251579 0.11759676 0.13757131 0.1171986  0.13241075]
average cummulative reward is:  0.1274586422054733
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 1809, loss: 15110.291015625
[INFO] Global_t: 1809, Episode_t: 1, Action: 0, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1810, loss: 10255.173828125
[INFO] Global_t: 1810, Episode_t: 2, Action: 2, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1811, loss: 5076.267578125
[INFO] Global_t: 1811, Episode_t: 3, Action: 24, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1812, loss: 6872.80712890625
[INFO] Global_t: 1812, Episode_t: 4, Action: 1, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1813, loss: 4383.63671875
[INFO] Global_t: 1813, Episode_t: 5, Action: 8, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 1814, loss: 6944.6650390625
[INFO] Global_t: 1814, Episode_t: 6, Action: 19, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1815, loss: 6906.77734375
[INFO] Global_t: 1815, Episode_t: 7, Action: 6, Reward: 2.67, Epsilon: 0.01
[INFO] model update: t: 1816, loss: 9723.2373046875
[INFO] Global_t: 1816, Episode_t: 8, Action: 11, Reward: 2.49, Epsilon: 0.01
 91%|█████████ | 1816/2000 [54:19<06:27,  2.10s/it]
[INFO] Global step: 1816, Cumulative rewards: 27.028679999999998, Runtime (s): 3259.26
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 1817, loss: 21179.783203125
[INFO] Global_t: 1817, Episode_t: 1, Action: 1, Reward: 4.82, Epsilon: 0.01
[INFO] model update: t: 1818, loss: 13364.326171875
[INFO] Global_t: 1818, Episode_t: 2, Action: 5, Reward: 5.01, Epsilon: 0.01
[INFO] model update: t: 1819, loss: 15760.5888671875
[INFO] Global_t: 1819, Episode_t: 3, Action: 6, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1820, loss: 36079.7734375
[INFO] Global_t: 1820, Episode_t: 4, Action: 9, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 1821, loss: 18884.2421875
[INFO] Global_t: 1821, Episode_t: 5, Action: 22, Reward: 3.18, Epsilon: 0.01
[INFO] model update: t: 1822, loss: 11167.197265625
[INFO] Global_t: 1822, Episode_t: 6, Action: 3, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 1823, loss: 28244.9453125
[INFO] Global_t: 1823, Episode_t: 7, Action: 18, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 1824, loss: 12840.7177734375
[INFO] Global_t: 1824, Episode_t: 8, Action: 41, Reward: 1.83, Epsilon: 0.01
 91%|█████████ | 1824/2000 [54:24<04:51,  1.65s/it]
[INFO] Global step: 1824, Cumulative rewards: 28.23348, Runtime (s): 3264.07
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.083170652389526
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.730332136154175
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.076878309249878
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.142855167388916
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.960211753845215
average cummulative reward vector is:  [0.13524158 0.11291065 0.13788634 0.11488855 0.14157446]
average cummulative reward is:  0.12850031593215827
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 1825, loss: 12111.44140625
[INFO] Global_t: 1825, Episode_t: 1, Action: 7, Reward: 3.69, Epsilon: 0.01
[INFO] model update: t: 1826, loss: 54839.46875
[INFO] Global_t: 1826, Episode_t: 2, Action: 1, Reward: 4.54, Epsilon: 0.01
[INFO] model update: t: 1827, loss: 37148.0703125
[INFO] Global_t: 1827, Episode_t: 3, Action: 8, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 1828, loss: 6138.84521484375
[INFO] Global_t: 1828, Episode_t: 4, Action: 13, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1829, loss: 14115.771484375
[INFO] Global_t: 1829, Episode_t: 5, Action: 21, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1830, loss: 12042.0166015625
[INFO] Global_t: 1830, Episode_t: 6, Action: 11, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1831, loss: 18331.37109375
[INFO] Global_t: 1831, Episode_t: 7, Action: 0, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1832, loss: 13898.61328125
[INFO] Global_t: 1832, Episode_t: 8, Action: 12, Reward: 1.81, Epsilon: 0.01
 92%|█████████▏| 1832/2000 [54:49<05:55,  2.11s/it]
[INFO] Global step: 1832, Cumulative rewards: 23.896319999999996, Runtime (s): 3289.57
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 1833, loss: 15972.0009765625
[INFO] Global_t: 1833, Episode_t: 1, Action: 8, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1834, loss: 69068.15625
[INFO] Global_t: 1834, Episode_t: 2, Action: 7, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1835, loss: 4376.501953125
[INFO] Global_t: 1835, Episode_t: 3, Action: 6, Reward: 5.21, Epsilon: 0.01
[INFO] model update: t: 1836, loss: 46988.21875
[INFO] Global_t: 1836, Episode_t: 4, Action: 57, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 1837, loss: 19318.564453125
[INFO] Global_t: 1837, Episode_t: 5, Action: 15, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1838, loss: 9620.0068359375
[INFO] Global_t: 1838, Episode_t: 6, Action: 21, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 1839, loss: 20495.638671875
[INFO] Global_t: 1839, Episode_t: 7, Action: 9, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1840, loss: 7437.17431640625
[INFO] Global_t: 1840, Episode_t: 8, Action: 10, Reward: 1.90, Epsilon: 0.01
 92%|█████████▏| 1840/2000 [54:54<04:25,  1.66s/it]
[INFO] Global step: 1840, Cumulative rewards: 27.077399999999997, Runtime (s): 3294.40
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.336223602294922
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.02776026725769
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5911779403686523
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.491257905960083
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5585196018218994
average cummulative reward vector is:  [0.13894316 0.12034977 0.12888169 0.12025537 0.12871237]
average cummulative reward is:  0.1274284719651
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 1841, loss: 4524.64208984375
[INFO] Global_t: 1841, Episode_t: 1, Action: 6, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1842, loss: 6740.9921875
[INFO] Global_t: 1842, Episode_t: 2, Action: 17, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1843, loss: 13256.203125
[INFO] Global_t: 1843, Episode_t: 3, Action: 2, Reward: 4.64, Epsilon: 0.01
[INFO] model update: t: 1844, loss: 48429.0546875
[INFO] Global_t: 1844, Episode_t: 4, Action: 38, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1845, loss: 15090.115234375
[INFO] Global_t: 1845, Episode_t: 5, Action: 10, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 1846, loss: 18908.021484375
[INFO] Global_t: 1846, Episode_t: 6, Action: 11, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 1847, loss: 51588.5234375
[INFO] Global_t: 1847, Episode_t: 7, Action: 14, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1848, loss: 26197.900390625
[INFO] Global_t: 1848, Episode_t: 8, Action: 31, Reward: 2.35, Epsilon: 0.01
 92%|█████████▏| 1848/2000 [55:19<05:20,  2.11s/it]
[INFO] Global step: 1848, Cumulative rewards: 27.110279999999996, Runtime (s): 3319.54
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 1849, loss: 17550.59765625
[INFO] Global_t: 1849, Episode_t: 1, Action: 6, Reward: 5.59, Epsilon: 0.01
[INFO] model update: t: 1850, loss: 114399.328125
[INFO] Global_t: 1850, Episode_t: 2, Action: 3, Reward: 4.72, Epsilon: 0.01
[INFO] model update: t: 1851, loss: 167539.03125
[INFO] Global_t: 1851, Episode_t: 3, Action: 35, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 1852, loss: 5546.96923828125
[INFO] Global_t: 1852, Episode_t: 4, Action: 32, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 1853, loss: 110704.9296875
[INFO] Global_t: 1853, Episode_t: 5, Action: 16, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 1854, loss: 13420.587890625
[INFO] Global_t: 1854, Episode_t: 6, Action: 5, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1855, loss: 74743.2890625
[INFO] Global_t: 1855, Episode_t: 7, Action: 8, Reward: 3.15, Epsilon: 0.01
[INFO] model update: t: 1856, loss: 91365.90625
[INFO] Global_t: 1856, Episode_t: 8, Action: 20, Reward: 3.35, Epsilon: 0.01
 93%|█████████▎| 1856/2000 [55:24<03:56,  1.64s/it]
[INFO] Global step: 1856, Cumulative rewards: 30.199559999999998, Runtime (s): 3324.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.171799182891846
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.5351622104644775
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8446943759918213
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.775771856307983
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.2081193923950195
average cummulative reward vector is:  [0.14273632 0.11443565 0.1228377  0.11719883 0.1498586 ]
average cummulative reward is:  0.12941342055637864
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 1857, loss: 19881.3984375
[INFO] Global_t: 1857, Episode_t: 1, Action: 5, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1858, loss: 23228.453125
[INFO] Global_t: 1858, Episode_t: 2, Action: 7, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1859, loss: 64190.0703125
[INFO] Global_t: 1859, Episode_t: 3, Action: 18, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1860, loss: 9257.458984375
[INFO] Global_t: 1860, Episode_t: 4, Action: 59, Reward: 3.54, Epsilon: 0.01
[INFO] model update: t: 1861, loss: 37284.05859375
[INFO] Global_t: 1861, Episode_t: 5, Action: 9, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 1862, loss: 73118.078125
[INFO] Global_t: 1862, Episode_t: 6, Action: 26, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 1863, loss: 40796.875
[INFO] Global_t: 1863, Episode_t: 7, Action: 12, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1864, loss: 5785.1689453125
[INFO] Global_t: 1864, Episode_t: 8, Action: 22, Reward: 1.92, Epsilon: 0.01
 93%|█████████▎| 1864/2000 [55:51<04:56,  2.18s/it]
[INFO] Global step: 1864, Cumulative rewards: 25.36848, Runtime (s): 3351.60
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 1865, loss: 13577.39453125
[INFO] Global_t: 1865, Episode_t: 1, Action: 14, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 1866, loss: 14425.115234375
[INFO] Global_t: 1866, Episode_t: 2, Action: 7, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1867, loss: 2719.895751953125
[INFO] Global_t: 1867, Episode_t: 3, Action: 18, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1868, loss: 15735.25390625
[INFO] Global_t: 1868, Episode_t: 4, Action: 16, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 1869, loss: 21458.384765625
[INFO] Global_t: 1869, Episode_t: 5, Action: 23, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1870, loss: 7864.76123046875
[INFO] Global_t: 1870, Episode_t: 6, Action: 1, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1871, loss: 10652.75390625
[INFO] Global_t: 1871, Episode_t: 7, Action: 26, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1872, loss: 12855.361328125
[INFO] Global_t: 1872, Episode_t: 8, Action: 11, Reward: 3.06, Epsilon: 0.01
 94%|█████████▎| 1872/2000 [55:55<03:35,  1.69s/it]
[INFO] Global step: 1872, Cumulative rewards: 30.112799999999996, Runtime (s): 3355.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.723750114440918
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.927877187728882
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.3361780643463135
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.74219274520874
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.379171371459961
average cummulative reward vector is:  [0.13147526 0.12574838 0.14300164 0.11282477 0.13393468]
average cummulative reward is:  0.12939694518125636
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 1873, loss: 5011.205078125
[INFO] Global_t: 1873, Episode_t: 1, Action: 1, Reward: 5.30, Epsilon: 0.01
[INFO] model update: t: 1874, loss: 4789.095703125
[INFO] Global_t: 1874, Episode_t: 2, Action: 26, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1875, loss: 17291.32421875
[INFO] Global_t: 1875, Episode_t: 3, Action: 4, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1876, loss: 24543.17578125
[INFO] Global_t: 1876, Episode_t: 4, Action: 18, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1877, loss: 11642.591796875
[INFO] Global_t: 1877, Episode_t: 5, Action: 25, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 1878, loss: 8848.1865234375
[INFO] Global_t: 1878, Episode_t: 6, Action: 21, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 1879, loss: 4857.77197265625
[INFO] Global_t: 1879, Episode_t: 7, Action: 2, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 1880, loss: 9986.2138671875
[INFO] Global_t: 1880, Episode_t: 8, Action: 29, Reward: 2.70, Epsilon: 0.01
 94%|█████████▍| 1880/2000 [56:32<05:05,  2.54s/it]
[INFO] Global step: 1880, Cumulative rewards: 29.23608, Runtime (s): 3392.12
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 1881, loss: 3283.533203125
[INFO] Global_t: 1881, Episode_t: 1, Action: 14, Reward: 3.97, Epsilon: 0.01
[INFO] model update: t: 1882, loss: 5136.5029296875
[INFO] Global_t: 1882, Episode_t: 2, Action: 3, Reward: 5.07, Epsilon: 0.01
[INFO] model update: t: 1883, loss: 7216.93408203125
[INFO] Global_t: 1883, Episode_t: 3, Action: 17, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1884, loss: 8344.390625
[INFO] Global_t: 1884, Episode_t: 4, Action: 8, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 1885, loss: 15572.685546875
[INFO] Global_t: 1885, Episode_t: 5, Action: 37, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1886, loss: 6565.572265625
[INFO] Global_t: 1886, Episode_t: 6, Action: 32, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 1887, loss: 7450.57958984375
[INFO] Global_t: 1887, Episode_t: 7, Action: 11, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 1888, loss: 16812.4609375
[INFO] Global_t: 1888, Episode_t: 8, Action: 4, Reward: 3.25, Epsilon: 0.01
 94%|█████████▍| 1888/2000 [56:36<03:38,  1.95s/it]
[INFO] Global step: 1888, Cumulative rewards: 27.304199999999998, Runtime (s): 3396.73
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6587588787078857
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.4440553188323975
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.839245319366455
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.40663743019104
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.985630989074707
average cummulative reward vector is:  [0.12912263 0.12667269 0.13264044 0.12148458 0.13264731]
average cummulative reward is:  0.12851352903796237
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 1889, loss: 8779.2431640625
[INFO] Global_t: 1889, Episode_t: 1, Action: 5, Reward: 5.75, Epsilon: 0.01
[INFO] model update: t: 1890, loss: 3369.112060546875
[INFO] Global_t: 1890, Episode_t: 2, Action: 1, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1891, loss: 12319.82421875
[INFO] Global_t: 1891, Episode_t: 3, Action: 33, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 1892, loss: 3577.964111328125
[INFO] Global_t: 1892, Episode_t: 4, Action: 9, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 1893, loss: 7254.96435546875
[INFO] Global_t: 1893, Episode_t: 5, Action: 19, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 1894, loss: 5961.21630859375
[INFO] Global_t: 1894, Episode_t: 6, Action: 7, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 1895, loss: 6367.14111328125
[INFO] Global_t: 1895, Episode_t: 7, Action: 40, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1896, loss: 14874.630859375
[INFO] Global_t: 1896, Episode_t: 8, Action: 2, Reward: 4.01, Epsilon: 0.01
 95%|█████████▍| 1896/2000 [57:14<04:50,  2.79s/it]
[INFO] Global step: 1896, Cumulative rewards: 29.029799999999998, Runtime (s): 3434.78
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 1897, loss: 13543.4697265625
[INFO] Global_t: 1897, Episode_t: 1, Action: 12, Reward: 4.82, Epsilon: 0.01
[INFO] model update: t: 1898, loss: 4467.52880859375
[INFO] Global_t: 1898, Episode_t: 2, Action: 15, Reward: 4.18, Epsilon: 0.01
[INFO] model update: t: 1899, loss: 12856.650390625
[INFO] Global_t: 1899, Episode_t: 3, Action: 10, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1900, loss: 37299.08984375
[INFO] Global_t: 1900, Episode_t: 4, Action: 21, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1901, loss: 27545.69140625
[INFO] Global_t: 1901, Episode_t: 5, Action: 39, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1902, loss: 3046.36376953125
[INFO] Global_t: 1902, Episode_t: 6, Action: 27, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1903, loss: 10656.720703125
[INFO] Global_t: 1903, Episode_t: 7, Action: 0, Reward: 5.44, Epsilon: 0.01
[INFO] model update: t: 1904, loss: 9359.0625
[INFO] Global_t: 1904, Episode_t: 8, Action: 7, Reward: 4.94, Epsilon: 0.01
 95%|█████████▌| 1904/2000 [57:20<03:27,  2.16s/it]
[INFO] Global step: 1904, Cumulative rewards: 33.8892, Runtime (s): 3440.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7889115810394287
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.273591756820679
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7571260929107666
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.00096583366394
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.225099802017212
average cummulative reward vector is:  [0.12895921 0.11695139 0.13489098 0.12375724 0.13561102]
average cummulative reward is:  0.12803396950355853
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 1905, loss: 11798.99609375
[INFO] Global_t: 1905, Episode_t: 1, Action: 11, Reward: 5.49, Epsilon: 0.01
[INFO] model update: t: 1906, loss: 5820.626953125
[INFO] Global_t: 1906, Episode_t: 2, Action: 9, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1907, loss: 4927.3740234375
[INFO] Global_t: 1907, Episode_t: 3, Action: 1, Reward: 5.76, Epsilon: 0.01
[INFO] model update: t: 1908, loss: 9665.2421875
[INFO] Global_t: 1908, Episode_t: 4, Action: 16, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 1909, loss: 8256.5927734375
[INFO] Global_t: 1909, Episode_t: 5, Action: 19, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 1910, loss: 4254.6240234375
[INFO] Global_t: 1910, Episode_t: 6, Action: 22, Reward: 2.59, Epsilon: 0.01
[INFO] model update: t: 1911, loss: 6691.68505859375
[INFO] Global_t: 1911, Episode_t: 7, Action: 5, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 1912, loss: 6592.17919921875
[INFO] Global_t: 1912, Episode_t: 8, Action: 15, Reward: 2.27, Epsilon: 0.01
 96%|█████████▌| 1912/2000 [57:46<03:38,  2.49s/it]
[INFO] Global step: 1912, Cumulative rewards: 31.965959999999995, Runtime (s): 3466.17
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 1913, loss: 3047.62890625
[INFO] Global_t: 1913, Episode_t: 1, Action: 5, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1914, loss: 8184.01953125
[INFO] Global_t: 1914, Episode_t: 2, Action: 8, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1915, loss: 13701.998046875
[INFO] Global_t: 1915, Episode_t: 3, Action: 7, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1916, loss: 7743.232421875
[INFO] Global_t: 1916, Episode_t: 4, Action: 3, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1917, loss: 76404.75
[INFO] Global_t: 1917, Episode_t: 5, Action: 4, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1918, loss: 190546.671875
[INFO] Global_t: 1918, Episode_t: 6, Action: 6, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 1919, loss: 47808.171875
[INFO] Global_t: 1919, Episode_t: 7, Action: 32, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1920, loss: 71964.8515625
[INFO] Global_t: 1920, Episode_t: 8, Action: 11, Reward: 2.20, Epsilon: 0.01
 96%|█████████▌| 1920/2000 [57:50<02:33,  1.92s/it]
[INFO] Global step: 1920, Cumulative rewards: 27.93828, Runtime (s): 3470.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.858576774597168
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.298441648483276
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.521566152572632
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8354904651641846
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.780604362487793
average cummulative reward vector is:  [0.13488921 0.12205532 0.13018087 0.11802383 0.12657366]
average cummulative reward is:  0.12634457932140186
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 1921, loss: 167144.921875
[INFO] Global_t: 1921, Episode_t: 1, Action: 5, Reward: 5.46, Epsilon: 0.01
[INFO] model update: t: 1922, loss: 7057.31494140625
[INFO] Global_t: 1922, Episode_t: 2, Action: 22, Reward: 3.12, Epsilon: 0.01
[INFO] model update: t: 1923, loss: 127321.265625
[INFO] Global_t: 1923, Episode_t: 3, Action: 4, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 1924, loss: 169738.359375
[INFO] Global_t: 1924, Episode_t: 4, Action: 18, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 1925, loss: 35224.07421875
[INFO] Global_t: 1925, Episode_t: 5, Action: 10, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 1926, loss: 51376.27734375
[INFO] Global_t: 1926, Episode_t: 6, Action: 11, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1927, loss: 211027.640625
[INFO] Global_t: 1927, Episode_t: 7, Action: 17, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1928, loss: 164311.875
[INFO] Global_t: 1928, Episode_t: 8, Action: 25, Reward: 2.17, Epsilon: 0.01
 96%|█████████▋| 1928/2000 [58:14<02:41,  2.24s/it]
[INFO] Global step: 1928, Cumulative rewards: 25.084439999999997, Runtime (s): 3494.80
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 1929, loss: 37399.3203125
[INFO] Global_t: 1929, Episode_t: 1, Action: 4, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1930, loss: 9091.65234375
[INFO] Global_t: 1930, Episode_t: 2, Action: 7, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1931, loss: 46684.90234375
[INFO] Global_t: 1931, Episode_t: 3, Action: 8, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1932, loss: 32500.87109375
[INFO] Global_t: 1932, Episode_t: 4, Action: 6, Reward: 4.20, Epsilon: 0.01
[INFO] model update: t: 1933, loss: 3351.79638671875
[INFO] Global_t: 1933, Episode_t: 5, Action: 25, Reward: 1.88, Epsilon: 0.01
[INFO] model update: t: 1934, loss: 30798.875
[INFO] Global_t: 1934, Episode_t: 6, Action: 0, Reward: 2.10, Epsilon: 0.01
[INFO] model update: t: 1935, loss: 10534.365234375
[INFO] Global_t: 1935, Episode_t: 7, Action: 17, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1936, loss: 5013.013671875
[INFO] Global_t: 1936, Episode_t: 8, Action: 18, Reward: 1.00, Epsilon: 0.01

[INFO] Global step: 1936, Cumulative rewards: 22.454399999999993, Runtime (s): 3513.94
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
 97%|█████████▋| 1936/2000 [58:33<02:26,  2.28s/it]runtime for one graph is:  4.507185935974121
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.061522006988525
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.619727849960327
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9906153678894043
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.676340341567993
average cummulative reward vector is:  [0.13643447 0.11075486 0.13337268 0.11952453 0.12972634]
average cummulative reward is:  0.1259625778374504
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 1937, loss: 19130.46484375
[INFO] Global_t: 1937, Episode_t: 1, Action: 1, Reward: 5.58, Epsilon: 0.01
[INFO] model update: t: 1938, loss: 10183.6328125
[INFO] Global_t: 1938, Episode_t: 2, Action: 47, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1939, loss: 14117.7529296875
[INFO] Global_t: 1939, Episode_t: 3, Action: 12, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1940, loss: 50893.96484375
[INFO] Global_t: 1940, Episode_t: 4, Action: 20, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1941, loss: 85123.9921875
[INFO] Global_t: 1941, Episode_t: 5, Action: 13, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1942, loss: 1675.5557861328125
[INFO] Global_t: 1942, Episode_t: 6, Action: 56, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1943, loss: 68775.5625
[INFO] Global_t: 1943, Episode_t: 7, Action: 51, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 1944, loss: 15161.927734375
[INFO] Global_t: 1944, Episode_t: 8, Action: 0, Reward: 2.47, Epsilon: 0.01
 97%|█████████▋| 1944/2000 [59:00<02:25,  2.61s/it]
[INFO] Global step: 1944, Cumulative rewards: 27.687119999999997, Runtime (s): 3540.78
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 1945, loss: 40392.59375
[INFO] Global_t: 1945, Episode_t: 1, Action: 5, Reward: 4.98, Epsilon: 0.01
[INFO] model update: t: 1946, loss: 130657.0546875
[INFO] Global_t: 1946, Episode_t: 2, Action: 6, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1947, loss: 65075.8359375
[INFO] Global_t: 1947, Episode_t: 3, Action: 4, Reward: 4.57, Epsilon: 0.01
[INFO] model update: t: 1948, loss: 7316.3193359375
[INFO] Global_t: 1948, Episode_t: 4, Action: 8, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1949, loss: 27621.017578125
[INFO] Global_t: 1949, Episode_t: 5, Action: 13, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1950, loss: 54893.96484375
[INFO] Global_t: 1950, Episode_t: 6, Action: 12, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1951, loss: 55240.55078125
[INFO] Global_t: 1951, Episode_t: 7, Action: 22, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1952, loss: 19528.271484375
[INFO] Global_t: 1952, Episode_t: 8, Action: 10, Reward: 2.47, Epsilon: 0.01
 98%|█████████▊| 1952/2000 [59:08<01:42,  2.13s/it]
[INFO] Global step: 1952, Cumulative rewards: 26.150280000000006, Runtime (s): 3548.83
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.235753059387207
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.834045648574829
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.28034520149231
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.150239706039429
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8201303482055664
average cummulative reward vector is:  [0.12732053 0.11792292 0.1568306  0.12052944 0.13919946]
average cummulative reward is:  0.13236058913865603
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 1953, loss: 7432.51953125
[INFO] Global_t: 1953, Episode_t: 1, Action: 7, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1954, loss: 18457.37890625
[INFO] Global_t: 1954, Episode_t: 2, Action: 25, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1955, loss: 16358.0400390625
[INFO] Global_t: 1955, Episode_t: 3, Action: 6, Reward: 4.48, Epsilon: 0.01
[INFO] model update: t: 1956, loss: 4068.41064453125
[INFO] Global_t: 1956, Episode_t: 4, Action: 9, Reward: 4.37, Epsilon: 0.01
[INFO] model update: t: 1957, loss: 13731.794921875
[INFO] Global_t: 1957, Episode_t: 5, Action: 4, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1958, loss: 22155.73828125
[INFO] Global_t: 1958, Episode_t: 6, Action: 1, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1959, loss: 9548.2998046875
[INFO] Global_t: 1959, Episode_t: 7, Action: 13, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1960, loss: 3884.7568359375
[INFO] Global_t: 1960, Episode_t: 8, Action: 31, Reward: 1.96, Epsilon: 0.01
 98%|█████████▊| 1960/2000 [59:35<01:39,  2.50s/it]
[INFO] Global step: 1960, Cumulative rewards: 26.08404, Runtime (s): 3575.71
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 1961, loss: 12266.0458984375
[INFO] Global_t: 1961, Episode_t: 1, Action: 5, Reward: 5.03, Epsilon: 0.01
[INFO] model update: t: 1962, loss: 10429.859375
[INFO] Global_t: 1962, Episode_t: 2, Action: 4, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1963, loss: 2878.37890625
[INFO] Global_t: 1963, Episode_t: 3, Action: 2, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1964, loss: 8177.17041015625
[INFO] Global_t: 1964, Episode_t: 4, Action: 19, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1965, loss: 12622.9111328125
[INFO] Global_t: 1965, Episode_t: 5, Action: 6, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1966, loss: 6772.6455078125
[INFO] Global_t: 1966, Episode_t: 6, Action: 44, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1967, loss: 5241.44482421875
[INFO] Global_t: 1967, Episode_t: 7, Action: 24, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1968, loss: 9226.1591796875
[INFO] Global_t: 1968, Episode_t: 8, Action: 1, Reward: 1.89, Epsilon: 0.01
 98%|█████████▊| 1968/2000 [59:46<01:08,  2.15s/it]
[INFO] Global step: 1968, Cumulative rewards: 24.566279999999995, Runtime (s): 3586.37
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.587393283843994
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.268210411071777
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7011749744415283
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7878410816192627
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.211251497268677
average cummulative reward vector is:  [0.12466211 0.1221875  0.13592131 0.11850467 0.13940376]
average cummulative reward is:  0.12813587061532483
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 1969, loss: 9366.595703125
[INFO] Global_t: 1969, Episode_t: 1, Action: 9, Reward: 4.90, Epsilon: 0.01
[INFO] model update: t: 1970, loss: 28986.193359375
[INFO] Global_t: 1970, Episode_t: 2, Action: 21, Reward: 4.32, Epsilon: 0.01
[INFO] model update: t: 1971, loss: 64246.99609375
[INFO] Global_t: 1971, Episode_t: 3, Action: 8, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1972, loss: 14052.982421875
[INFO] Global_t: 1972, Episode_t: 4, Action: 5, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 1973, loss: 41054.390625
[INFO] Global_t: 1973, Episode_t: 5, Action: 20, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 1974, loss: 191823.65625
[INFO] Global_t: 1974, Episode_t: 6, Action: 6, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1975, loss: 50195.15625
[INFO] Global_t: 1975, Episode_t: 7, Action: 14, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 1976, loss: 65034.86328125
[INFO] Global_t: 1976, Episode_t: 8, Action: 35, Reward: 2.35, Epsilon: 0.01
 99%|█████████▉| 1976/2000 [1:00:10<00:57,  2.39s/it]
[INFO] Global step: 1976, Cumulative rewards: 27.3108, Runtime (s): 3610.14
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 1977, loss: 402725.5
[INFO] Global_t: 1977, Episode_t: 1, Action: 5, Reward: 4.83, Epsilon: 0.01
[INFO] model update: t: 1978, loss: 479200.03125
[INFO] Global_t: 1978, Episode_t: 2, Action: 17, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1979, loss: 151227.875
[INFO] Global_t: 1979, Episode_t: 3, Action: 10, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 1980, loss: 3416.599609375
[INFO] Global_t: 1980, Episode_t: 4, Action: 11, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1981, loss: 100900.9375
[INFO] Global_t: 1981, Episode_t: 5, Action: 4, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1982, loss: 37159.7734375
[INFO] Global_t: 1982, Episode_t: 6, Action: 28, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1983, loss: 62765.1640625
[INFO] Global_t: 1983, Episode_t: 7, Action: 1, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 1984, loss: 139477.9375
[INFO] Global_t: 1984, Episode_t: 8, Action: 16, Reward: 2.16, Epsilon: 0.01
 99%|█████████▉| 1984/2000 [1:00:21<00:33,  2.11s/it]
[INFO] Global step: 1984, Cumulative rewards: 24.240359999999995, Runtime (s): 3621.72
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.196845531463623
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.345607042312622
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7249858379364014
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.899858236312866
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7374351024627686
average cummulative reward vector is:  [0.124865   0.12696921 0.13191066 0.11354836 0.13599919]
average cummulative reward is:  0.12665848534700727
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 1985, loss: 29976.751953125
[INFO] Global_t: 1985, Episode_t: 1, Action: 16, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1986, loss: 18851.669921875
[INFO] Global_t: 1986, Episode_t: 2, Action: 11, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1987, loss: 109095.3125
[INFO] Global_t: 1987, Episode_t: 3, Action: 8, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1988, loss: 127463.46875
[INFO] Global_t: 1988, Episode_t: 4, Action: 5, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1989, loss: 14101.0390625
[INFO] Global_t: 1989, Episode_t: 5, Action: 4, Reward: 3.26, Epsilon: 0.01
[INFO] model update: t: 1990, loss: 20578.693359375
[INFO] Global_t: 1990, Episode_t: 6, Action: 17, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 1991, loss: 32078.2265625
[INFO] Global_t: 1991, Episode_t: 7, Action: 25, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1992, loss: 2646.60107421875
[INFO] Global_t: 1992, Episode_t: 8, Action: 14, Reward: 2.13, Epsilon: 0.01
100%|█████████▉| 1992/2000 [1:00:46<00:19,  2.41s/it]
[INFO] Global step: 1992, Cumulative rewards: 25.923000000000002, Runtime (s): 3646.55
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 1993, loss: 24583.453125
[INFO] Global_t: 1993, Episode_t: 1, Action: 5, Reward: 5.56, Epsilon: 0.01
[INFO] model update: t: 1994, loss: 22812.18359375
[INFO] Global_t: 1994, Episode_t: 2, Action: 18, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1995, loss: 3859.7158203125
[INFO] Global_t: 1995, Episode_t: 3, Action: 17, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1996, loss: 36584.27734375
[INFO] Global_t: 1996, Episode_t: 4, Action: 8, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1997, loss: 38644.23046875
[INFO] Global_t: 1997, Episode_t: 5, Action: 13, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 1998, loss: 4229.693359375
[INFO] Global_t: 1998, Episode_t: 6, Action: 6, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1999, loss: 18870.5546875
[INFO] Global_t: 1999, Episode_t: 7, Action: 16, Reward: 2.08, Epsilon: 0.01

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.830404043197632
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.190778732299805
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.733846426010132
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.776991128921509
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8634586334228516
average cummulative reward vector is:  [0.13081395 0.11691019 0.13182787 0.10506752 0.13969409]
average cummulative reward is:  0.12486272215841132
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  2
