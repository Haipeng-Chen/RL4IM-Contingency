[INFO 16:03:28] Experiments Running command 'my_main'
[INFO 16:03:28] Experiments Started run with ID "2"
[DEBUG 16:03:28] Experiments Starting Heartbeat
[DEBUG 16:03:28] my_main Started
Loading train graph:  powerlaw
train graphs in total:  200
Loading test graph:  powerlaw
merged graphs length:  205
/home/docker/app/src/agent/colge/utils/config.py:10: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  model_config = yaml.load(config_file)
  0%|          | 0/2000 [00:00<?, ?it/s]epoch:  0
graph: 0, nodes: 180, edges: 531
[INFO] Global_t: 1, Episode_t: 1, Action: 178, Reward: 1.22, Epsilon: 0.99
[INFO] Global_t: 2, Episode_t: 2, Action: 99, Reward: 2.21, Epsilon: 0.99
[INFO] Global_t: 3, Episode_t: 3, Action: 114, Reward: 1.86, Epsilon: 0.99
[INFO] Global_t: 4, Episode_t: 4, Action: 149, Reward: 1.54, Epsilon: 0.99
[INFO] Global_t: 5, Episode_t: 5, Action: 157, Reward: 1.54, Epsilon: 0.99
[INFO] Global_t: 6, Episode_t: 6, Action: 62, Reward: 1.90, Epsilon: 0.99
[INFO] Global_t: 7, Episode_t: 7, Action: 101, Reward: 1.17, Epsilon: 0.98
[INFO] Global_t: 8, Episode_t: 8, Action: 141, Reward: 1.02, Epsilon: 0.98

[INFO] Global step: 8, Cumulative rewards: 12.470639999999998, Runtime (s): 2.41
------------------------------------------------------------
 
  0%|          | 8/2000 [00:02<09:59,  3.32it/s]graph: 1, nodes: 217, edges: 642
[INFO] Global_t: 9, Episode_t: 1, Action: 76, Reward: 2.01, Epsilon: 0.98
[INFO] Global_t: 10, Episode_t: 2, Action: 106, Reward: 2.00, Epsilon: 0.98
[INFO] Global_t: 11, Episode_t: 3, Action: 47, Reward: 1.49, Epsilon: 0.98
[INFO] Global_t: 12, Episode_t: 4, Action: 55, Reward: 3.02, Epsilon: 0.98
[INFO] Global_t: 13, Episode_t: 5, Action: 185, Reward: 1.68, Epsilon: 0.98
[INFO] Global_t: 14, Episode_t: 6, Action: 8, Reward: 4.05, Epsilon: 0.98
[INFO] Global_t: 15, Episode_t: 7, Action: 103, Reward: 1.41, Epsilon: 0.98
[INFO] Global_t: 16, Episode_t: 8, Action: 49, Reward: 2.15, Epsilon: 0.98
  1%|          | 16/2000 [00:05<10:41,  3.09it/s]
[INFO] Global step: 16, Cumulative rewards: 17.80764, Runtime (s): 5.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.1793127059936523
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.1876742839813232
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1601924896240234
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.1594643592834473
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.1325862407684326
average cummulative reward vector is:  [0.04718868 0.04345162 0.05074645 0.04184042 0.04669677]
average cummulative reward is:  0.04598478948452489
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] Global_t: 17, Episode_t: 1, Action: 14, Reward: 2.68, Epsilon: 0.97
[INFO] Global_t: 18, Episode_t: 2, Action: 148, Reward: 2.57, Epsilon: 0.97
[INFO] Global_t: 19, Episode_t: 3, Action: 219, Reward: 1.49, Epsilon: 0.97
[INFO] Global_t: 20, Episode_t: 4, Action: 152, Reward: 1.74, Epsilon: 0.97
[INFO] Global_t: 21, Episode_t: 5, Action: 159, Reward: 2.42, Epsilon: 0.97
[INFO] Global_t: 22, Episode_t: 6, Action: 97, Reward: 1.64, Epsilon: 0.97
[INFO] Global_t: 23, Episode_t: 7, Action: 2, Reward: 6.74, Epsilon: 0.97
[INFO] Global_t: 24, Episode_t: 8, Action: 73, Reward: 2.29, Epsilon: 0.97
  1%|          | 24/2000 [00:14<18:28,  1.78it/s]
[INFO] Global step: 24, Cumulative rewards: 21.58416, Runtime (s): 14.34
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] Global_t: 25, Episode_t: 1, Action: 17, Reward: 4.02, Epsilon: 0.97
[INFO] Global_t: 26, Episode_t: 2, Action: 13, Reward: 4.17, Epsilon: 0.97
[INFO] Global_t: 27, Episode_t: 3, Action: 170, Reward: 0.83, Epsilon: 0.96
[INFO] Global_t: 28, Episode_t: 4, Action: 38, Reward: 1.48, Epsilon: 0.96
[INFO] Global_t: 29, Episode_t: 5, Action: 34, Reward: 1.15, Epsilon: 0.96
[INFO] Global_t: 30, Episode_t: 6, Action: 178, Reward: 1.02, Epsilon: 0.96
[INFO] Global_t: 31, Episode_t: 7, Action: 2, Reward: 3.60, Epsilon: 0.96
[INFO] Global_t: 32, Episode_t: 8, Action: 121, Reward: 1.29, Epsilon: 0.96
  2%|▏         | 32/2000 [00:19<19:48,  1.66it/s]
[INFO] Global step: 32, Cumulative rewards: 17.5716, Runtime (s): 19.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2363317012786865
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.1260201930999756
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.0587382316589355
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.1647748947143555
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.1474299430847168
average cummulative reward vector is:  [0.04864132 0.03945093 0.04408607 0.04200607 0.04780968]
average cummulative reward is:  0.044398811894976006
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] Global_t: 33, Episode_t: 1, Action: 76, Reward: 1.68, Epsilon: 0.96
[INFO] Global_t: 34, Episode_t: 2, Action: 66, Reward: 2.03, Epsilon: 0.96
[INFO] Global_t: 35, Episode_t: 3, Action: 179, Reward: 1.25, Epsilon: 0.96
[INFO] Global_t: 36, Episode_t: 4, Action: 172, Reward: 1.43, Epsilon: 0.96
[INFO] Global_t: 37, Episode_t: 5, Action: 136, Reward: 1.21, Epsilon: 0.95
[INFO] Global_t: 38, Episode_t: 6, Action: 133, Reward: 1.74, Epsilon: 0.95
[INFO] Global_t: 39, Episode_t: 7, Action: 132, Reward: 1.29, Epsilon: 0.95
[INFO] Global_t: 40, Episode_t: 8, Action: 53, Reward: 2.27, Epsilon: 0.95
  2%|▏         | 40/2000 [00:28<23:45,  1.38it/s]
[INFO] Global step: 40, Cumulative rewards: 12.908159999999999, Runtime (s): 28.09
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] Global_t: 41, Episode_t: 1, Action: 211, Reward: 1.27, Epsilon: 0.95
[INFO] Global_t: 42, Episode_t: 2, Action: 74, Reward: 1.87, Epsilon: 0.95
[INFO] Global_t: 43, Episode_t: 3, Action: 140, Reward: 2.18, Epsilon: 0.95
[INFO] Global_t: 44, Episode_t: 4, Action: 155, Reward: 1.59, Epsilon: 0.95
[INFO] Global_t: 45, Episode_t: 5, Action: 106, Reward: 1.89, Epsilon: 0.95
[INFO] Global_t: 46, Episode_t: 6, Action: 71, Reward: 1.32, Epsilon: 0.95
[INFO] Global_t: 47, Episode_t: 7, Action: 118, Reward: 1.82, Epsilon: 0.94
[INFO] Global_t: 48, Episode_t: 8, Action: 84, Reward: 1.43, Epsilon: 0.94
  2%|▏         | 48/2000 [00:30<19:54,  1.63it/s]
[INFO] Global step: 48, Cumulative rewards: 13.365960000000003, Runtime (s): 30.83
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2209746837615967
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.1450424194335938
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1704275608062744
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.1710224151611328
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.189028263092041
average cummulative reward vector is:  [0.04877211 0.04021829 0.04891066 0.04182009 0.04938737]
average cummulative reward is:  0.045821701417448325
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 49, loss: 861567680.0
[INFO] Global_t: 49, Episode_t: 1, Action: 187, Reward: 2.02, Epsilon: 0.94
[INFO] model update: t: 50, loss: 463405383680.0
[INFO] Global_t: 50, Episode_t: 2, Action: 79, Reward: 2.57, Epsilon: 0.94
[INFO] model update: t: 51, loss: 221843652608.0
[INFO] Global_t: 51, Episode_t: 3, Action: 126, Reward: 1.38, Epsilon: 0.94
[INFO] model update: t: 52, loss: 329909796864.0
[INFO] Global_t: 52, Episode_t: 4, Action: 125, Reward: 1.59, Epsilon: 0.94
[INFO] model update: t: 53, loss: 20090572800.0
[INFO] Global_t: 53, Episode_t: 5, Action: 18, Reward: 3.40, Epsilon: 0.94
[INFO] model update: t: 54, loss: 46700306432.0
[INFO] Global_t: 54, Episode_t: 6, Action: 113, Reward: 1.56, Epsilon: 0.94
[INFO] model update: t: 55, loss: 57825910784.0
[INFO] Global_t: 55, Episode_t: 7, Action: 71, Reward: 2.01, Epsilon: 0.94
[INFO] model update: t: 56, loss: 14309642240.0
[INFO] Global_t: 56, Episode_t: 8, Action: 68, Reward: 1.48, Epsilon: 0.94
  3%|▎         | 56/2000 [00:40<25:52,  1.25it/s]
[INFO] Global step: 56, Cumulative rewards: 16.0104, Runtime (s): 40.71
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 57, loss: 5005612032.0
[INFO] Global_t: 57, Episode_t: 1, Action: 179, Reward: 1.25, Epsilon: 0.94
[INFO] model update: t: 58, loss: 26605295616.0
[INFO] Global_t: 58, Episode_t: 2, Action: 130, Reward: 1.62, Epsilon: 0.93
[INFO] model update: t: 59, loss: 8580539904.0
[INFO] Global_t: 59, Episode_t: 3, Action: 93, Reward: 1.56, Epsilon: 0.93
[INFO] model update: t: 60, loss: 45925728.0
[INFO] Global_t: 60, Episode_t: 4, Action: 81, Reward: 1.37, Epsilon: 0.93
[INFO] model update: t: 61, loss: 6388068864.0
[INFO] Global_t: 61, Episode_t: 5, Action: 152, Reward: 1.11, Epsilon: 0.93
[INFO] model update: t: 62, loss: 9215281152.0
[INFO] Global_t: 62, Episode_t: 6, Action: 31, Reward: 2.53, Epsilon: 0.93
[INFO] model update: t: 63, loss: 1062496768.0
[INFO] Global_t: 63, Episode_t: 7, Action: 70, Reward: 1.59, Epsilon: 0.93
[INFO] model update: t: 64, loss: 1090910080.0
[INFO] Global_t: 64, Episode_t: 8, Action: 170, Reward: 1.05, Epsilon: 0.93
  3%|▎         | 64/2000 [00:43<21:23,  1.51it/s]
[INFO] Global step: 64, Cumulative rewards: 12.07056, Runtime (s): 43.47
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3944594860076904
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.575917959213257
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.482635974884033
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.0994784832000732
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.477848529815674
average cummulative reward vector is:  [0.12451105 0.11175023 0.13430082 0.09956846 0.12773978]
average cummulative reward is:  0.11957406933507068
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 65, loss: 3607759616.0
[INFO] Global_t: 65, Episode_t: 1, Action: 5, Reward: 4.08, Epsilon: 0.93
[INFO] model update: t: 66, loss: 650192896.0
[INFO] Global_t: 66, Episode_t: 2, Action: 107, Reward: 1.50, Epsilon: 0.93
[INFO] model update: t: 67, loss: 726525376.0
[INFO] Global_t: 67, Episode_t: 3, Action: 118, Reward: 1.23, Epsilon: 0.93
[INFO] model update: t: 68, loss: 2222169600.0
[INFO] Global_t: 68, Episode_t: 4, Action: 157, Reward: 1.18, Epsilon: 0.92
[INFO] model update: t: 69, loss: 356295552.0
[INFO] Global_t: 69, Episode_t: 5, Action: 113, Reward: 1.44, Epsilon: 0.92
[INFO] model update: t: 70, loss: 200672752.0
[INFO] Global_t: 70, Episode_t: 6, Action: 122, Reward: 1.37, Epsilon: 0.92
[INFO] model update: t: 71, loss: 1124099584.0
[INFO] Global_t: 71, Episode_t: 7, Action: 35, Reward: 2.42, Epsilon: 0.92
[INFO] model update: t: 72, loss: 722149888.0
[INFO] Global_t: 72, Episode_t: 8, Action: 31, Reward: 2.73, Epsilon: 0.92

[INFO] Global step: 72, Cumulative rewards: 15.948839999999997, Runtime (s): 63.56
------------------------------------------------------------
 
  4%|▎         | 72/2000 [01:03<39:06,  1.22s/it]graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 73, loss: 43870784.0
[INFO] Global_t: 73, Episode_t: 1, Action: 197, Reward: 1.81, Epsilon: 0.92
[INFO] model update: t: 74, loss: 403094720.0
[INFO] Global_t: 74, Episode_t: 2, Action: 155, Reward: 1.76, Epsilon: 0.92
[INFO] model update: t: 75, loss: 495129888.0
[INFO] Global_t: 75, Episode_t: 3, Action: 194, Reward: 1.21, Epsilon: 0.92
[INFO] model update: t: 76, loss: 15895992.0
[INFO] Global_t: 76, Episode_t: 4, Action: 12, Reward: 3.22, Epsilon: 0.92
[INFO] model update: t: 77, loss: 248284288.0
[INFO] Global_t: 77, Episode_t: 5, Action: 71, Reward: 1.15, Epsilon: 0.92
[INFO] model update: t: 78, loss: 323658848.0
[INFO] Global_t: 78, Episode_t: 6, Action: 11, Reward: 2.88, Epsilon: 0.91
[INFO] model update: t: 79, loss: 45072792.0
[INFO] Global_t: 79, Episode_t: 7, Action: 200, Reward: 1.11, Epsilon: 0.91
[INFO] model update: t: 80, loss: 67831072.0
[INFO] Global_t: 80, Episode_t: 8, Action: 113, Reward: 1.77, Epsilon: 0.91
  4%|▍         | 80/2000 [01:06<31:01,  1.03it/s]
[INFO] Global step: 80, Cumulative rewards: 14.8968, Runtime (s): 66.69
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.139400005340576
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8486862182617188
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1131393909454346
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4239230155944824
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6982016563415527
average cummulative reward vector is:  [0.11249421 0.12173565 0.11997158 0.10761145 0.13622419]
average cummulative reward is:  0.11960741710408707
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 81, loss: 255805360.0
[INFO] Global_t: 81, Episode_t: 1, Action: 62, Reward: 1.78, Epsilon: 0.91
[INFO] model update: t: 82, loss: 100295440.0
[INFO] Global_t: 82, Episode_t: 2, Action: 133, Reward: 1.73, Epsilon: 0.91
[INFO] model update: t: 83, loss: 12257204.0
[INFO] Global_t: 83, Episode_t: 3, Action: 83, Reward: 2.26, Epsilon: 0.91
[INFO] model update: t: 84, loss: 141386368.0
[INFO] Global_t: 84, Episode_t: 4, Action: 155, Reward: 1.11, Epsilon: 0.91
[INFO] model update: t: 85, loss: 140742816.0
[INFO] Global_t: 85, Episode_t: 5, Action: 5, Reward: 3.82, Epsilon: 0.91
[INFO] model update: t: 86, loss: 9896292.0
[INFO] Global_t: 86, Episode_t: 6, Action: 106, Reward: 1.32, Epsilon: 0.91
[INFO] model update: t: 87, loss: 54787896.0
[INFO] Global_t: 87, Episode_t: 7, Action: 178, Reward: 1.75, Epsilon: 0.91
[INFO] model update: t: 88, loss: 110117456.0
[INFO] Global_t: 88, Episode_t: 8, Action: 14, Reward: 2.77, Epsilon: 0.90
  4%|▍         | 88/2000 [01:26<45:35,  1.43s/it]
[INFO] Global step: 88, Cumulative rewards: 16.52508, Runtime (s): 86.75
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 89, loss: 53398520.0
[INFO] Global_t: 89, Episode_t: 1, Action: 20, Reward: 2.64, Epsilon: 0.90
[INFO] model update: t: 90, loss: 318274.25
[INFO] Global_t: 90, Episode_t: 2, Action: 65, Reward: 1.91, Epsilon: 0.90
[INFO] model update: t: 91, loss: 43769640.0
[INFO] Global_t: 91, Episode_t: 3, Action: 93, Reward: 1.45, Epsilon: 0.90
[INFO] model update: t: 92, loss: 83884520.0
[INFO] Global_t: 92, Episode_t: 4, Action: 162, Reward: 1.41, Epsilon: 0.90
[INFO] model update: t: 93, loss: 26585340.0
[INFO] Global_t: 93, Episode_t: 5, Action: 113, Reward: 1.72, Epsilon: 0.90
[INFO] model update: t: 94, loss: 3836590.75
[INFO] Global_t: 94, Episode_t: 6, Action: 203, Reward: 1.44, Epsilon: 0.90
[INFO] model update: t: 95, loss: 39340624.0
[INFO] Global_t: 95, Episode_t: 7, Action: 189, Reward: 1.10, Epsilon: 0.90
[INFO] model update: t: 96, loss: 52921976.0
[INFO] Global_t: 96, Episode_t: 8, Action: 33, Reward: 2.87, Epsilon: 0.90
  5%|▍         | 96/2000 [01:30<36:33,  1.15s/it]
[INFO] Global step: 96, Cumulative rewards: 14.544359999999998, Runtime (s): 90.76
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.1930017471313477
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7863030433654785
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5920114517211914
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5233213901519775
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6430885791778564
average cummulative reward vector is:  [0.11450158 0.11985532 0.13084809 0.11304556 0.13548602]
average cummulative reward is:  0.12274731454123529
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 97, loss: 7890730.0
[INFO] Global_t: 97, Episode_t: 1, Action: 10, Reward: 6.22, Epsilon: 0.90
[INFO] model update: t: 98, loss: 5942641.0
[INFO] Global_t: 98, Episode_t: 2, Action: 178, Reward: 1.59, Epsilon: 0.89
[INFO] model update: t: 99, loss: 44964584.0
[INFO] Global_t: 99, Episode_t: 3, Action: 39, Reward: 1.22, Epsilon: 0.89
[INFO] model update: t: 100, loss: 27818648.0
[INFO] Global_t: 100, Episode_t: 4, Action: 86, Reward: 1.60, Epsilon: 0.89
[INFO] model update: t: 101, loss: 82308.25
[INFO] Global_t: 101, Episode_t: 5, Action: 146, Reward: 1.29, Epsilon: 0.89
[INFO] model update: t: 102, loss: 17806132.0
[INFO] Global_t: 102, Episode_t: 6, Action: 84, Reward: 1.27, Epsilon: 0.89
[INFO] model update: t: 103, loss: 23109610.0
[INFO] Global_t: 103, Episode_t: 7, Action: 36, Reward: 1.30, Epsilon: 0.89
[INFO] model update: t: 104, loss: 11942268.0
[INFO] Global_t: 104, Episode_t: 8, Action: 45, Reward: 1.91, Epsilon: 0.89
  5%|▌         | 104/2000 [01:54<53:27,  1.69s/it]
[INFO] Global step: 104, Cumulative rewards: 16.386000000000003, Runtime (s): 114.37
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 105, loss: 919848.75
[INFO] Global_t: 105, Episode_t: 1, Action: 120, Reward: 1.78, Epsilon: 0.89
[INFO] model update: t: 106, loss: 16808252.0
[INFO] Global_t: 106, Episode_t: 2, Action: 25, Reward: 2.58, Epsilon: 0.89
[INFO] model update: t: 107, loss: 15020737.0
[INFO] Global_t: 107, Episode_t: 3, Action: 1, Reward: 4.90, Epsilon: 0.89
[INFO] model update: t: 108, loss: 892367.4375
[INFO] Global_t: 108, Episode_t: 4, Action: 77, Reward: 2.60, Epsilon: 0.89
[INFO] model update: t: 109, loss: 5067191.0
[INFO] Global_t: 109, Episode_t: 5, Action: 175, Reward: 0.88, Epsilon: 0.88
[INFO] model update: t: 110, loss: 11978360.0
[INFO] Global_t: 110, Episode_t: 6, Action: 6, Reward: 2.50, Epsilon: 0.88
[INFO] model update: t: 111, loss: 4588912.5
[INFO] Global_t: 111, Episode_t: 7, Action: 75, Reward: 1.32, Epsilon: 0.88
[INFO] model update: t: 112, loss: 215306.96875
[INFO] Global_t: 112, Episode_t: 8, Action: 122, Reward: 1.15, Epsilon: 0.88

  6%|▌         | 112/2000 [01:58<42:31,  1.35s/it]412, Runtime (s): 118.82
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.279881715774536
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6690964698791504
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3266677856445312
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.666520357131958
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.523314952850342
average cummulative reward vector is:  [0.11804711 0.11587315 0.12540027 0.11535327 0.13073683]
average cummulative reward is:  0.12108212512407528
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 113, loss: 7049785.0
[INFO] Global_t: 113, Episode_t: 1, Action: 30, Reward: 3.79, Epsilon: 0.88
[INFO] model update: t: 114, loss: 5535179.0
[INFO] Global_t: 114, Episode_t: 2, Action: 17, Reward: 3.63, Epsilon: 0.88
[INFO] model update: t: 115, loss: 246065.1875
[INFO] Global_t: 115, Episode_t: 3, Action: 21, Reward: 2.22, Epsilon: 0.88
[INFO] model update: t: 116, loss: 2619968.0
[INFO] Global_t: 116, Episode_t: 4, Action: 126, Reward: 1.64, Epsilon: 0.88
[INFO] model update: t: 117, loss: 5236332.0
[INFO] Global_t: 117, Episode_t: 5, Action: 12, Reward: 2.71, Epsilon: 0.88
[INFO] model update: t: 118, loss: 1120088.75
[INFO] Global_t: 118, Episode_t: 6, Action: 183, Reward: 1.31, Epsilon: 0.88
[INFO] model update: t: 119, loss: 583289.5
[INFO] Global_t: 119, Episode_t: 7, Action: 196, Reward: 0.93, Epsilon: 0.87
[INFO] model update: t: 120, loss: 4119519.5
[INFO] Global_t: 120, Episode_t: 8, Action: 9, Reward: 2.38, Epsilon: 0.87
  6%|▌         | 120/2000 [02:21<56:18,  1.80s/it]
[INFO] Global step: 120, Cumulative rewards: 18.606959999999997, Runtime (s): 141.52
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 121, loss: 1757370.125
[INFO] Global_t: 121, Episode_t: 1, Action: 18, Reward: 2.58, Epsilon: 0.87
[INFO] model update: t: 122, loss: 272419.5625
[INFO] Global_t: 122, Episode_t: 2, Action: 88, Reward: 1.84, Epsilon: 0.87
[INFO] model update: t: 123, loss: 2745059.5
[INFO] Global_t: 123, Episode_t: 3, Action: 35, Reward: 2.85, Epsilon: 0.87
[INFO] model update: t: 124, loss: 2001151.5
[INFO] Global_t: 124, Episode_t: 4, Action: 6, Reward: 3.43, Epsilon: 0.87
[INFO] model update: t: 125, loss: 351485.8125
[INFO] Global_t: 125, Episode_t: 5, Action: 28, Reward: 2.29, Epsilon: 0.87
[INFO] model update: t: 126, loss: 1019151.875
[INFO] Global_t: 126, Episode_t: 6, Action: 104, Reward: 1.61, Epsilon: 0.87
[INFO] model update: t: 127, loss: 2613857.75
[INFO] Global_t: 127, Episode_t: 7, Action: 8, Reward: 2.24, Epsilon: 0.87
[INFO] model update: t: 128, loss: 331853.9375
[INFO] Global_t: 128, Episode_t: 8, Action: 21, Reward: 1.51, Epsilon: 0.87
  6%|▋         | 128/2000 [02:26<45:10,  1.45s/it]
[INFO] Global step: 128, Cumulative rewards: 18.35172, Runtime (s): 146.59
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3930399417877197
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6600921154022217
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2127838134765625
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.492652177810669
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.658836841583252
average cummulative reward vector is:  [0.12212368 0.11358218 0.12114481 0.10770374 0.13597258]
average cummulative reward is:  0.12010539756850798
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 129, loss: 708276.875
[INFO] Global_t: 129, Episode_t: 1, Action: 100, Reward: 2.36, Epsilon: 0.86
[INFO] model update: t: 130, loss: 1736651.0
[INFO] Global_t: 130, Episode_t: 2, Action: 0, Reward: 8.29, Epsilon: 0.86
[INFO] model update: t: 131, loss: 262289.3125
[INFO] Global_t: 131, Episode_t: 3, Action: 136, Reward: 1.01, Epsilon: 0.86
[INFO] model update: t: 132, loss: 569157.8125
[INFO] Global_t: 132, Episode_t: 4, Action: 61, Reward: 1.36, Epsilon: 0.86
[INFO] model update: t: 133, loss: 1398789.125
[INFO] Global_t: 133, Episode_t: 5, Action: 153, Reward: 1.15, Epsilon: 0.86
[INFO] model update: t: 134, loss: 818749.8125
[INFO] Global_t: 134, Episode_t: 6, Action: 7, Reward: 2.52, Epsilon: 0.86
[INFO] model update: t: 135, loss: 541288.0
[INFO] Global_t: 135, Episode_t: 7, Action: 73, Reward: 1.56, Epsilon: 0.86
[INFO] model update: t: 136, loss: 1909740.875
[INFO] Global_t: 136, Episode_t: 8, Action: 128, Reward: 1.06, Epsilon: 0.86
  7%|▋         | 136/2000 [02:50<59:37,  1.92s/it]
[INFO] Global step: 136, Cumulative rewards: 19.31544, Runtime (s): 170.74
------------------------------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 137, loss: 743154.25
[INFO] Global_t: 137, Episode_t: 1, Action: 3, Reward: 3.61, Epsilon: 0.86
[INFO] model update: t: 138, loss: 751749.6875
[INFO] Global_t: 138, Episode_t: 2, Action: 115, Reward: 1.31, Epsilon: 0.86
[INFO] model update: t: 139, loss: 1349682.875
[INFO] Global_t: 139, Episode_t: 3, Action: 165, Reward: 1.31, Epsilon: 0.85
[INFO] model update: t: 140, loss: 950011.125
[INFO] Global_t: 140, Episode_t: 4, Action: 20, Reward: 1.49, Epsilon: 0.85
[INFO] model update: t: 141, loss: 583451.5
[INFO] Global_t: 141, Episode_t: 5, Action: 106, Reward: 1.51, Epsilon: 0.85
[INFO] model update: t: 142, loss: 1200798.25
[INFO] Global_t: 142, Episode_t: 6, Action: 169, Reward: 1.30, Epsilon: 0.85
[INFO] model update: t: 143, loss: 703657.375
[INFO] Global_t: 143, Episode_t: 7, Action: 26, Reward: 2.00, Epsilon: 0.85
[INFO] model update: t: 144, loss: 450120.3125
[INFO] Global_t: 144, Episode_t: 8, Action: 36, Reward: 1.62, Epsilon: 0.85
  7%|▋         | 144/2000 [02:54<46:23,  1.50s/it]
[INFO] Global step: 144, Cumulative rewards: 14.15052, Runtime (s): 174.91
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.524970769882202
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8081398010253906
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6803157329559326
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.508028507232666
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6124377250671387
average cummulative reward vector is:  [0.1278     0.11772431 0.13786749 0.10867547 0.13235027]
average cummulative reward is:  0.12488350560025543
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 145, loss: 1094802.75
[INFO] Global_t: 145, Episode_t: 1, Action: 145, Reward: 1.34, Epsilon: 0.85
[INFO] model update: t: 146, loss: 417878.125
[INFO] Global_t: 146, Episode_t: 2, Action: 175, Reward: 1.93, Epsilon: 0.85
[INFO] model update: t: 147, loss: 351717.6875
[INFO] Global_t: 147, Episode_t: 3, Action: 129, Reward: 1.73, Epsilon: 0.85
[INFO] model update: t: 148, loss: 1092544.375
[INFO] Global_t: 148, Episode_t: 4, Action: 0, Reward: 2.33, Epsilon: 0.85
[INFO] model update: t: 149, loss: 466907.5
[INFO] Global_t: 149, Episode_t: 5, Action: 50, Reward: 1.94, Epsilon: 0.84
[INFO] model update: t: 150, loss: 236362.6875
[INFO] Global_t: 150, Episode_t: 6, Action: 141, Reward: 1.21, Epsilon: 0.84
[INFO] model update: t: 151, loss: 336644.5
[INFO] Global_t: 151, Episode_t: 7, Action: 131, Reward: 1.46, Epsilon: 0.84
[INFO] model update: t: 152, loss: 564894.625
[INFO] Global_t: 152, Episode_t: 8, Action: 24, Reward: 3.18, Epsilon: 0.84
  8%|▊         | 152/2000 [03:15<56:28,  1.83s/it]
[INFO] Global step: 152, Cumulative rewards: 15.11892, Runtime (s): 195.81
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 153, loss: 218848.75
[INFO] Global_t: 153, Episode_t: 1, Action: 8, Reward: 5.25, Epsilon: 0.84
[INFO] model update: t: 154, loss: 478462.75
[INFO] Global_t: 154, Episode_t: 2, Action: 123, Reward: 0.99, Epsilon: 0.84
[INFO] model update: t: 155, loss: 666528.5
[INFO] Global_t: 155, Episode_t: 3, Action: 5, Reward: 1.56, Epsilon: 0.84
[INFO] model update: t: 156, loss: 283445.875
[INFO] Global_t: 156, Episode_t: 4, Action: 119, Reward: 1.58, Epsilon: 0.84
[INFO] model update: t: 157, loss: 125961.765625
[INFO] Global_t: 157, Episode_t: 5, Action: 116, Reward: 1.37, Epsilon: 0.84
[INFO] model update: t: 158, loss: 332653.25
[INFO] Global_t: 158, Episode_t: 6, Action: 10, Reward: 3.41, Epsilon: 0.84
[INFO] model update: t: 159, loss: 175046.78125
[INFO] Global_t: 159, Episode_t: 7, Action: 23, Reward: 3.22, Epsilon: 0.84
[INFO] model update: t: 160, loss: 199430.15625
[INFO] Global_t: 160, Episode_t: 8, Action: 41, Reward: 1.36, Epsilon: 0.83
  8%|▊         | 160/2000 [03:22<46:47,  1.53s/it]
[INFO] Global step: 160, Cumulative rewards: 18.754199999999997, Runtime (s): 202.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4628801345825195
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5057079792022705
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.721344470977783
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4230620861053467
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6069586277008057
average cummulative reward vector is:  [0.12439368 0.11130602 0.13679399 0.10966963 0.13292796]
average cummulative reward is:  0.12301825499151094
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 161, loss: 396121.1875
[INFO] Global_t: 161, Episode_t: 1, Action: 11, Reward: 4.11, Epsilon: 0.83
[INFO] model update: t: 162, loss: 192934.78125
[INFO] Global_t: 162, Episode_t: 2, Action: 132, Reward: 1.78, Epsilon: 0.83
[INFO] model update: t: 163, loss: 150558.03125
[INFO] Global_t: 163, Episode_t: 3, Action: 7, Reward: 3.41, Epsilon: 0.83
[INFO] model update: t: 164, loss: 210974.171875
[INFO] Global_t: 164, Episode_t: 4, Action: 77, Reward: 1.72, Epsilon: 0.83
[INFO] model update: t: 165, loss: 111317.21875
[INFO] Global_t: 165, Episode_t: 5, Action: 39, Reward: 1.57, Epsilon: 0.83
[INFO] model update: t: 166, loss: 84168.65625
[INFO] Global_t: 166, Episode_t: 6, Action: 84, Reward: 1.20, Epsilon: 0.83
[INFO] model update: t: 167, loss: 219348.21875
[INFO] Global_t: 167, Episode_t: 7, Action: 26, Reward: 1.32, Epsilon: 0.83
[INFO] model update: t: 168, loss: 98022.6328125
[INFO] Global_t: 168, Episode_t: 8, Action: 111, Reward: 1.73, Epsilon: 0.83
  8%|▊         | 168/2000 [03:46<59:49,  1.96s/it]
[INFO] Global step: 168, Cumulative rewards: 16.8402, Runtime (s): 226.04
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 169, loss: 157122.453125
[INFO] Global_t: 169, Episode_t: 1, Action: 13, Reward: 3.65, Epsilon: 0.83
[INFO] model update: t: 170, loss: 85066.5625
[INFO] Global_t: 170, Episode_t: 2, Action: 6, Reward: 3.64, Epsilon: 0.82
[INFO] model update: t: 171, loss: 66672.5625
[INFO] Global_t: 171, Episode_t: 3, Action: 156, Reward: 1.84, Epsilon: 0.82
[INFO] model update: t: 172, loss: 87646.53125
[INFO] Global_t: 172, Episode_t: 4, Action: 173, Reward: 1.49, Epsilon: 0.82
[INFO] model update: t: 173, loss: 168058.609375
[INFO] Global_t: 173, Episode_t: 5, Action: 0, Reward: 3.09, Epsilon: 0.82
[INFO] model update: t: 174, loss: 83288.7578125
[INFO] Global_t: 174, Episode_t: 6, Action: 9, Reward: 2.78, Epsilon: 0.82
[INFO] model update: t: 175, loss: 32481.412109375
[INFO] Global_t: 175, Episode_t: 7, Action: 152, Reward: 1.00, Epsilon: 0.82
[INFO] model update: t: 176, loss: 160816.53125
[INFO] Global_t: 176, Episode_t: 8, Action: 58, Reward: 1.49, Epsilon: 0.82
  9%|▉         | 176/2000 [03:50<47:03,  1.55s/it]
[INFO] Global step: 176, Cumulative rewards: 18.994559999999996, Runtime (s): 230.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.251523494720459
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4953842163085938
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4034199714660645
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.2695202827453613
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4715569019317627
average cummulative reward vector is:  [0.11945737 0.11016458 0.12514317 0.10363621 0.12482957]
average cummulative reward is:  0.11664618119980744
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 177, loss: 92654.65625
[INFO] Global_t: 177, Episode_t: 1, Action: 128, Reward: 1.63, Epsilon: 0.82
[INFO] model update: t: 178, loss: 94163.21875
[INFO] Global_t: 178, Episode_t: 2, Action: 1, Reward: 4.17, Epsilon: 0.82
[INFO] model update: t: 179, loss: 114456.9609375
[INFO] Global_t: 179, Episode_t: 3, Action: 99, Reward: 1.66, Epsilon: 0.82
[INFO] model update: t: 180, loss: 61954.8125
[INFO] Global_t: 180, Episode_t: 4, Action: 26, Reward: 2.71, Epsilon: 0.81
[INFO] model update: t: 181, loss: 32372.14453125
[INFO] Global_t: 181, Episode_t: 5, Action: 119, Reward: 1.80, Epsilon: 0.81
[INFO] model update: t: 182, loss: 84677.0703125
[INFO] Global_t: 182, Episode_t: 6, Action: 57, Reward: 1.78, Epsilon: 0.81
[INFO] model update: t: 183, loss: 75379.4296875
[INFO] Global_t: 183, Episode_t: 7, Action: 84, Reward: 2.13, Epsilon: 0.81
[INFO] model update: t: 184, loss: 65514.5078125
[INFO] Global_t: 184, Episode_t: 8, Action: 139, Reward: 0.97, Epsilon: 0.81
  9%|▉         | 184/2000 [04:11<56:38,  1.87s/it]
[INFO] Global step: 184, Cumulative rewards: 16.86228, Runtime (s): 251.75
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 185, loss: 58365.40625
[INFO] Global_t: 185, Episode_t: 1, Action: 76, Reward: 2.49, Epsilon: 0.81
[INFO] model update: t: 186, loss: 31272.29296875
[INFO] Global_t: 186, Episode_t: 2, Action: 78, Reward: 2.97, Epsilon: 0.81
[INFO] model update: t: 187, loss: 108007.8203125
[INFO] Global_t: 187, Episode_t: 3, Action: 36, Reward: 2.44, Epsilon: 0.81
[INFO] model update: t: 188, loss: 76997.7109375
[INFO] Global_t: 188, Episode_t: 4, Action: 73, Reward: 1.53, Epsilon: 0.81
[INFO] model update: t: 189, loss: 94622.203125
[INFO] Global_t: 189, Episode_t: 5, Action: 26, Reward: 2.01, Epsilon: 0.81
[INFO] model update: t: 190, loss: 63144.2265625
[INFO] Global_t: 190, Episode_t: 6, Action: 95, Reward: 1.58, Epsilon: 0.80
[INFO] model update: t: 191, loss: 33737.9296875
[INFO] Global_t: 191, Episode_t: 7, Action: 12, Reward: 2.43, Epsilon: 0.80
[INFO] model update: t: 192, loss: 84533.6328125
[INFO] Global_t: 192, Episode_t: 8, Action: 116, Reward: 1.51, Epsilon: 0.80
 10%|▉         | 192/2000 [04:16<44:54,  1.49s/it]
[INFO] Global step: 192, Cumulative rewards: 16.975920000000002, Runtime (s): 256.55
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5338449478149414
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8326737880706787
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.303379774093628
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.430704355239868
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7145237922668457
average cummulative reward vector is:  [0.12713263 0.11540764 0.12299426 0.1107007  0.13474274]
average cummulative reward is:  0.12219559512659631
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 193, loss: 144122.375
[INFO] Global_t: 193, Episode_t: 1, Action: 70, Reward: 2.16, Epsilon: 0.80
[INFO] model update: t: 194, loss: 64158.82421875
[INFO] Global_t: 194, Episode_t: 2, Action: 209, Reward: 1.58, Epsilon: 0.80
[INFO] model update: t: 195, loss: 132283.59375
[INFO] Global_t: 195, Episode_t: 3, Action: 66, Reward: 2.16, Epsilon: 0.80
[INFO] model update: t: 196, loss: 48610.1953125
[INFO] Global_t: 196, Episode_t: 4, Action: 0, Reward: 4.35, Epsilon: 0.80
[INFO] model update: t: 197, loss: 95027.546875
[INFO] Global_t: 197, Episode_t: 5, Action: 5, Reward: 6.11, Epsilon: 0.80
[INFO] model update: t: 198, loss: 81068.1171875
[INFO] Global_t: 198, Episode_t: 6, Action: 126, Reward: 1.56, Epsilon: 0.80
[INFO] model update: t: 199, loss: 62495.7109375
[INFO] Global_t: 199, Episode_t: 7, Action: 174, Reward: 0.80, Epsilon: 0.80
[INFO] model update: t: 200, loss: 67852.46875
[INFO] Global_t: 200, Episode_t: 8, Action: 8, Reward: 1.84, Epsilon: 0.79
 10%|█         | 200/2000 [04:42<1:00:40,  2.02s/it]
[INFO] Global step: 200, Cumulative rewards: 20.55924, Runtime (s): 282.67
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 201, loss: 62911.33984375
[INFO] Global_t: 201, Episode_t: 1, Action: 8, Reward: 5.09, Epsilon: 0.79
[INFO] model update: t: 202, loss: 87876.765625
[INFO] Global_t: 202, Episode_t: 2, Action: 132, Reward: 1.34, Epsilon: 0.79
[INFO] model update: t: 203, loss: 89794.7890625
[INFO] Global_t: 203, Episode_t: 3, Action: 18, Reward: 1.88, Epsilon: 0.79
[INFO] model update: t: 204, loss: 42434.1484375
[INFO] Global_t: 204, Episode_t: 4, Action: 2, Reward: 5.41, Epsilon: 0.79
[INFO] model update: t: 205, loss: 78238.2109375
[INFO] Global_t: 205, Episode_t: 5, Action: 85, Reward: 2.45, Epsilon: 0.79
[INFO] model update: t: 206, loss: 57109.359375
[INFO] Global_t: 206, Episode_t: 6, Action: 182, Reward: 1.11, Epsilon: 0.79
[INFO] model update: t: 207, loss: 88246.125
[INFO] Global_t: 207, Episode_t: 7, Action: 25, Reward: 3.37, Epsilon: 0.79
[INFO] model update: t: 208, loss: 64494.49609375
[INFO] Global_t: 208, Episode_t: 8, Action: 127, Reward: 1.07, Epsilon: 0.79
 10%|█         | 208/2000 [04:47<47:18,  1.58s/it]  
[INFO] Global step: 208, Cumulative rewards: 21.71916, Runtime (s): 287.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.378657817840576
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.0702786445617676
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5639090538024902
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.60762095451355
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6438775062561035
average cummulative reward vector is:  [0.12238763 0.0953956  0.13422978 0.11495514 0.13016935]
average cummulative reward is:  0.11942750197543797
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 209, loss: 54671.6484375
[INFO] Global_t: 209, Episode_t: 1, Action: 155, Reward: 1.35, Epsilon: 0.79
[INFO] model update: t: 210, loss: 67890.5625
[INFO] Global_t: 210, Episode_t: 2, Action: 172, Reward: 1.08, Epsilon: 0.79
[INFO] model update: t: 211, loss: 44598.859375
[INFO] Global_t: 211, Episode_t: 3, Action: 84, Reward: 1.40, Epsilon: 0.78
[INFO] model update: t: 212, loss: 37934.8125
[INFO] Global_t: 212, Episode_t: 4, Action: 55, Reward: 2.61, Epsilon: 0.78
[INFO] model update: t: 213, loss: 90878.515625
[INFO] Global_t: 213, Episode_t: 5, Action: 0, Reward: 3.96, Epsilon: 0.78
[INFO] model update: t: 214, loss: 103128.1484375
[INFO] Global_t: 214, Episode_t: 6, Action: 158, Reward: 0.91, Epsilon: 0.78
[INFO] model update: t: 215, loss: 107439.265625
[INFO] Global_t: 215, Episode_t: 7, Action: 173, Reward: 0.94, Epsilon: 0.78
[INFO] model update: t: 216, loss: 55195.7734375
[INFO] Global_t: 216, Episode_t: 8, Action: 34, Reward: 2.01, Epsilon: 0.78
 11%|█         | 216/2000 [05:08<56:41,  1.91s/it]
[INFO] Global step: 216, Cumulative rewards: 14.26848, Runtime (s): 308.43
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 217, loss: 27715.8984375
[INFO] Global_t: 217, Episode_t: 1, Action: 170, Reward: 1.58, Epsilon: 0.78
[INFO] model update: t: 218, loss: 43106.109375
[INFO] Global_t: 218, Episode_t: 2, Action: 11, Reward: 3.50, Epsilon: 0.78
[INFO] model update: t: 219, loss: 48652.80859375
[INFO] Global_t: 219, Episode_t: 3, Action: 189, Reward: 1.27, Epsilon: 0.78
[INFO] model update: t: 220, loss: 28526.73046875
[INFO] Global_t: 220, Episode_t: 4, Action: 6, Reward: 4.43, Epsilon: 0.78
[INFO] model update: t: 221, loss: 114005.796875
[INFO] Global_t: 221, Episode_t: 5, Action: 188, Reward: 1.67, Epsilon: 0.77
[INFO] model update: t: 222, loss: 40808.5
[INFO] Global_t: 222, Episode_t: 6, Action: 130, Reward: 1.38, Epsilon: 0.77
[INFO] model update: t: 223, loss: 93922.3359375
[INFO] Global_t: 223, Episode_t: 7, Action: 110, Reward: 1.87, Epsilon: 0.77
[INFO] model update: t: 224, loss: 44301.609375
[INFO] Global_t: 224, Episode_t: 8, Action: 107, Reward: 1.20, Epsilon: 0.77
 11%|█         | 224/2000 [05:12<43:49,  1.48s/it]
[INFO] Global step: 224, Cumulative rewards: 16.89408, Runtime (s): 312.33
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.140273094177246
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.3667681217193604
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.393028736114502
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.280205726623535
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.3972268104553223
average cummulative reward vector is:  [0.11000053 0.10511273 0.12426366 0.10441589 0.12536559]
average cummulative reward is:  0.11383167964955469
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 225, loss: 32874.9609375
[INFO] Global_t: 225, Episode_t: 1, Action: 46, Reward: 2.21, Epsilon: 0.77
[INFO] model update: t: 226, loss: 127441.3671875
[INFO] Global_t: 226, Episode_t: 2, Action: 7, Reward: 4.17, Epsilon: 0.77
[INFO] model update: t: 227, loss: 50418.7265625
[INFO] Global_t: 227, Episode_t: 3, Action: 147, Reward: 1.84, Epsilon: 0.77
[INFO] model update: t: 228, loss: 101330.234375
[INFO] Global_t: 228, Episode_t: 4, Action: 157, Reward: 1.82, Epsilon: 0.77
[INFO] model update: t: 229, loss: 68046.59375
[INFO] Global_t: 229, Episode_t: 5, Action: 12, Reward: 3.46, Epsilon: 0.77
[INFO] model update: t: 230, loss: 57950.7421875
[INFO] Global_t: 230, Episode_t: 6, Action: 20, Reward: 1.79, Epsilon: 0.77
[INFO] model update: t: 231, loss: 113161.2890625
[INFO] Global_t: 231, Episode_t: 7, Action: 97, Reward: 1.57, Epsilon: 0.76
[INFO] model update: t: 232, loss: 44627.15625
[INFO] Global_t: 232, Episode_t: 8, Action: 22, Reward: 1.69, Epsilon: 0.76
 12%|█▏        | 232/2000 [05:32<53:11,  1.81s/it]
[INFO] Global step: 232, Cumulative rewards: 18.540839999999996, Runtime (s): 332.83
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 233, loss: 162274.84375
[INFO] Global_t: 233, Episode_t: 1, Action: 119, Reward: 2.26, Epsilon: 0.76
[INFO] model update: t: 234, loss: 47133.4609375
[INFO] Global_t: 234, Episode_t: 2, Action: 97, Reward: 1.32, Epsilon: 0.76
[INFO] model update: t: 235, loss: 70268.1875
[INFO] Global_t: 235, Episode_t: 3, Action: 134, Reward: 1.23, Epsilon: 0.76
[INFO] model update: t: 236, loss: 115019.96875
[INFO] Global_t: 236, Episode_t: 4, Action: 62, Reward: 2.90, Epsilon: 0.76
[INFO] model update: t: 237, loss: 37051.8671875
[INFO] Global_t: 237, Episode_t: 5, Action: 51, Reward: 2.12, Epsilon: 0.76
[INFO] model update: t: 238, loss: 109479.40625
[INFO] Global_t: 238, Episode_t: 6, Action: 83, Reward: 1.60, Epsilon: 0.76
[INFO] model update: t: 239, loss: 48525.53515625
[INFO] Global_t: 239, Episode_t: 7, Action: 12, Reward: 1.84, Epsilon: 0.76
[INFO] model update: t: 240, loss: 70208.828125
[INFO] Global_t: 240, Episode_t: 8, Action: 98, Reward: 1.92, Epsilon: 0.76
 12%|█▏        | 240/2000 [05:37<42:19,  1.44s/it]
[INFO] Global step: 240, Cumulative rewards: 15.197999999999997, Runtime (s): 337.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4619596004486084
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.575737476348877
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6134939193725586
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.415186643600464
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.639045238494873
average cummulative reward vector is:  [0.12306553 0.10871921 0.1359612  0.11218341 0.13303414]
average cummulative reward is:  0.12259269849288887
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 241, loss: 41426.7265625
[INFO] Global_t: 241, Episode_t: 1, Action: 97, Reward: 1.65, Epsilon: 0.75
[INFO] model update: t: 242, loss: 44857.4609375
[INFO] Global_t: 242, Episode_t: 2, Action: 65, Reward: 2.27, Epsilon: 0.75
[INFO] model update: t: 243, loss: 75268.2734375
[INFO] Global_t: 243, Episode_t: 3, Action: 18, Reward: 2.54, Epsilon: 0.75
[INFO] model update: t: 244, loss: 57619.58984375
[INFO] Global_t: 244, Episode_t: 4, Action: 6, Reward: 3.25, Epsilon: 0.75
[INFO] model update: t: 245, loss: 47366.28515625
[INFO] Global_t: 245, Episode_t: 5, Action: 166, Reward: 1.66, Epsilon: 0.75
[INFO] model update: t: 246, loss: 52126.6875
[INFO] Global_t: 246, Episode_t: 6, Action: 17, Reward: 3.67, Epsilon: 0.75
[INFO] model update: t: 247, loss: 49533.3671875
[INFO] Global_t: 247, Episode_t: 7, Action: 142, Reward: 1.49, Epsilon: 0.75
[INFO] model update: t: 248, loss: 104719.203125
[INFO] Global_t: 248, Episode_t: 8, Action: 66, Reward: 1.93, Epsilon: 0.75
 12%|█▏        | 248/2000 [05:58<52:45,  1.81s/it]
[INFO] Global step: 248, Cumulative rewards: 18.461159999999996, Runtime (s): 358.85
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 249, loss: 41890.50390625
[INFO] Global_t: 249, Episode_t: 1, Action: 120, Reward: 1.44, Epsilon: 0.75
[INFO] model update: t: 250, loss: 71739.375
[INFO] Global_t: 250, Episode_t: 2, Action: 3, Reward: 5.34, Epsilon: 0.75
[INFO] model update: t: 251, loss: 73994.3046875
[INFO] Global_t: 251, Episode_t: 3, Action: 20, Reward: 5.10, Epsilon: 0.74
[INFO] model update: t: 252, loss: 32437.0859375
[INFO] Global_t: 252, Episode_t: 4, Action: 110, Reward: 1.82, Epsilon: 0.74
[INFO] model update: t: 253, loss: 68511.6953125
[INFO] Global_t: 253, Episode_t: 5, Action: 89, Reward: 1.09, Epsilon: 0.74
[INFO] model update: t: 254, loss: 26996.67578125
[INFO] Global_t: 254, Episode_t: 6, Action: 12, Reward: 2.73, Epsilon: 0.74
[INFO] model update: t: 255, loss: 100683.84375
[INFO] Global_t: 255, Episode_t: 7, Action: 118, Reward: 1.79, Epsilon: 0.74
[INFO] model update: t: 256, loss: 47957.3828125
[INFO] Global_t: 256, Episode_t: 8, Action: 11, Reward: 2.42, Epsilon: 0.74
 13%|█▎        | 256/2000 [06:02<40:59,  1.41s/it]
[INFO] Global step: 256, Cumulative rewards: 21.715439999999997, Runtime (s): 362.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.169658899307251
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.746321201324463
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.587595224380493
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.523236036300659
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.2213261127471924
average cummulative reward vector is:  [0.11382237 0.1167213  0.12460683 0.11403598 0.1213379 ]
average cummulative reward is:  0.1181048759705319
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 257, loss: 27161.40625
[INFO] Global_t: 257, Episode_t: 1, Action: 101, Reward: 2.19, Epsilon: 0.74
[INFO] model update: t: 258, loss: 115435.6953125
[INFO] Global_t: 258, Episode_t: 2, Action: 189, Reward: 1.51, Epsilon: 0.74
[INFO] model update: t: 259, loss: 24863.0546875
[INFO] Global_t: 259, Episode_t: 3, Action: 128, Reward: 1.53, Epsilon: 0.74
[INFO] model update: t: 260, loss: 106640.828125
[INFO] Global_t: 260, Episode_t: 4, Action: 59, Reward: 3.23, Epsilon: 0.74
[INFO] model update: t: 261, loss: 56539.5
[INFO] Global_t: 261, Episode_t: 5, Action: 8, Reward: 2.98, Epsilon: 0.74
[INFO] model update: t: 262, loss: 63824.98828125
[INFO] Global_t: 262, Episode_t: 6, Action: 29, Reward: 3.00, Epsilon: 0.73
[INFO] model update: t: 263, loss: 119409.0625
[INFO] Global_t: 263, Episode_t: 7, Action: 154, Reward: 1.20, Epsilon: 0.73
[INFO] model update: t: 264, loss: 29841.703125
[INFO] Global_t: 264, Episode_t: 8, Action: 146, Reward: 1.25, Epsilon: 0.73
 13%|█▎        | 264/2000 [06:24<51:44,  1.79s/it]
[INFO] Global step: 264, Cumulative rewards: 16.89072, Runtime (s): 384.10
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 265, loss: 97904.8671875
[INFO] Global_t: 265, Episode_t: 1, Action: 43, Reward: 1.62, Epsilon: 0.73
[INFO] model update: t: 266, loss: 29776540.0
[INFO] Global_t: 266, Episode_t: 2, Action: 92, Reward: 1.71, Epsilon: 0.73
[INFO] model update: t: 267, loss: 51466416.0
[INFO] Global_t: 267, Episode_t: 3, Action: 10, Reward: 3.24, Epsilon: 0.73
[INFO] model update: t: 268, loss: 29792356.0
[INFO] Global_t: 268, Episode_t: 4, Action: 12, Reward: 3.02, Epsilon: 0.73
[INFO] model update: t: 269, loss: 25926244.0
[INFO] Global_t: 269, Episode_t: 5, Action: 180, Reward: 1.38, Epsilon: 0.73
[INFO] model update: t: 270, loss: 65452328.0
[INFO] Global_t: 270, Episode_t: 6, Action: 81, Reward: 1.48, Epsilon: 0.73
[INFO] model update: t: 271, loss: 1659527.25
[INFO] Global_t: 271, Episode_t: 7, Action: 18, Reward: 3.10, Epsilon: 0.73
[INFO] model update: t: 272, loss: 80174320.0
[INFO] Global_t: 272, Episode_t: 8, Action: 27, Reward: 1.25, Epsilon: 0.72
 14%|█▎        | 272/2000 [06:28<40:52,  1.42s/it]
[INFO] Global step: 272, Cumulative rewards: 16.803240000000002, Runtime (s): 388.56
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.9028477668762207
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6550793647766113
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.437540292739868
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.195300817489624
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.1446542739868164
average cummulative reward vector is:  [0.10311711 0.11091366 0.12818279 0.10195444 0.1152879 ]
average cummulative reward is:  0.11189117840679082
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 273, loss: 532698.75
[INFO] Global_t: 273, Episode_t: 1, Action: 1, Reward: 5.40, Epsilon: 0.72
[INFO] model update: t: 274, loss: 54736732.0
[INFO] Global_t: 274, Episode_t: 2, Action: 4, Reward: 4.73, Epsilon: 0.72
[INFO] model update: t: 275, loss: 10753072.0
[INFO] Global_t: 275, Episode_t: 3, Action: 34, Reward: 2.60, Epsilon: 0.72
[INFO] model update: t: 276, loss: 18905416.0
[INFO] Global_t: 276, Episode_t: 4, Action: 160, Reward: 1.38, Epsilon: 0.72
[INFO] model update: t: 277, loss: 26929864.0
[INFO] Global_t: 277, Episode_t: 5, Action: 20, Reward: 2.33, Epsilon: 0.72
[INFO] model update: t: 278, loss: 143667.4375
[INFO] Global_t: 278, Episode_t: 6, Action: 15, Reward: 2.35, Epsilon: 0.72
[INFO] model update: t: 279, loss: 22481148.0
[INFO] Global_t: 279, Episode_t: 7, Action: 191, Reward: 1.26, Epsilon: 0.72
[INFO] model update: t: 280, loss: 10999096.0
[INFO] Global_t: 280, Episode_t: 8, Action: 201, Reward: 1.65, Epsilon: 0.72
 14%|█▍        | 280/2000 [06:50<52:08,  1.82s/it]
[INFO] Global step: 280, Cumulative rewards: 21.692879999999995, Runtime (s): 410.57
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 281, loss: 5409305.0
[INFO] Global_t: 281, Episode_t: 1, Action: 145, Reward: 1.46, Epsilon: 0.72
[INFO] model update: t: 282, loss: 28272124.0
[INFO] Global_t: 282, Episode_t: 2, Action: 6, Reward: 3.31, Epsilon: 0.71
[INFO] model update: t: 283, loss: 1373394.5
[INFO] Global_t: 283, Episode_t: 3, Action: 185, Reward: 1.49, Epsilon: 0.71
[INFO] model update: t: 284, loss: 18301922.0
[INFO] Global_t: 284, Episode_t: 4, Action: 161, Reward: 1.25, Epsilon: 0.71
[INFO] model update: t: 285, loss: 21181592.0
[INFO] Global_t: 285, Episode_t: 5, Action: 118, Reward: 1.68, Epsilon: 0.71
[INFO] model update: t: 286, loss: 532491.4375
[INFO] Global_t: 286, Episode_t: 6, Action: 38, Reward: 1.65, Epsilon: 0.71
[INFO] model update: t: 287, loss: 25431916.0
[INFO] Global_t: 287, Episode_t: 7, Action: 8, Reward: 3.15, Epsilon: 0.71
[INFO] model update: t: 288, loss: 3841578.5
[INFO] Global_t: 288, Episode_t: 8, Action: 170, Reward: 0.95, Epsilon: 0.71
 14%|█▍        | 288/2000 [06:54<40:23,  1.42s/it]
[INFO] Global step: 288, Cumulative rewards: 14.94168, Runtime (s): 414.37
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.9723846912384033
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7776618003845215
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3074564933776855
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.405236005783081
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.568714141845703
average cummulative reward vector is:  [0.10875711 0.11782755 0.12193798 0.10391425 0.13014005]
average cummulative reward is:  0.11651538716028402
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 289, loss: 12022357.0
[INFO] Global_t: 289, Episode_t: 1, Action: 125, Reward: 1.18, Epsilon: 0.71
[INFO] model update: t: 290, loss: 8713622.0
[INFO] Global_t: 290, Episode_t: 2, Action: 60, Reward: 2.16, Epsilon: 0.71
[INFO] model update: t: 291, loss: 356043.5625
[INFO] Global_t: 291, Episode_t: 3, Action: 43, Reward: 2.02, Epsilon: 0.71
[INFO] model update: t: 292, loss: 12627528.0
[INFO] Global_t: 292, Episode_t: 4, Action: 145, Reward: 1.26, Epsilon: 0.70
[INFO] model update: t: 293, loss: 116238.296875
[INFO] Global_t: 293, Episode_t: 5, Action: 56, Reward: 1.88, Epsilon: 0.70
[INFO] model update: t: 294, loss: 7276012.0
[INFO] Global_t: 294, Episode_t: 6, Action: 70, Reward: 1.70, Epsilon: 0.70
[INFO] model update: t: 295, loss: 2464606.0
[INFO] Global_t: 295, Episode_t: 7, Action: 3, Reward: 4.64, Epsilon: 0.70
[INFO] model update: t: 296, loss: 1787310.5
[INFO] Global_t: 296, Episode_t: 8, Action: 7, Reward: 2.64, Epsilon: 0.70
 15%|█▍        | 296/2000 [07:15<51:05,  1.80s/it]
[INFO] Global step: 296, Cumulative rewards: 17.482799999999997, Runtime (s): 435.92
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 297, loss: 4789812.5
[INFO] Global_t: 297, Episode_t: 1, Action: 192, Reward: 2.33, Epsilon: 0.70
[INFO] model update: t: 298, loss: 146205.765625
[INFO] Global_t: 298, Episode_t: 2, Action: 123, Reward: 2.31, Epsilon: 0.70
[INFO] model update: t: 299, loss: 4729355.0
[INFO] Global_t: 299, Episode_t: 3, Action: 172, Reward: 1.77, Epsilon: 0.70
[INFO] model update: t: 300, loss: 220144.75
[INFO] Global_t: 300, Episode_t: 4, Action: 162, Reward: 1.40, Epsilon: 0.70
[INFO] model update: t: 301, loss: 2337679.0
[INFO] Global_t: 301, Episode_t: 5, Action: 23, Reward: 2.91, Epsilon: 0.70
[INFO] model update: t: 302, loss: 1143727.125
[INFO] Global_t: 302, Episode_t: 6, Action: 27, Reward: 3.37, Epsilon: 0.70
[INFO] model update: t: 303, loss: 249435.5625
[INFO] Global_t: 303, Episode_t: 7, Action: 128, Reward: 1.61, Epsilon: 0.69
[INFO] model update: t: 304, loss: 1840296.5
[INFO] Global_t: 304, Episode_t: 8, Action: 10, Reward: 2.50, Epsilon: 0.69
 15%|█▌        | 304/2000 [07:20<40:32,  1.43s/it]
[INFO] Global step: 304, Cumulative rewards: 18.19284, Runtime (s): 440.58
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4294047355651855
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6198623180389404
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.157198190689087
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6290793418884277
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.173340320587158
average cummulative reward vector is:  [0.12215632 0.11574699 0.11821366 0.11041145 0.11763253]
average cummulative reward is:  0.11683218864245029
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 305, loss: 70148.1015625
[INFO] Global_t: 305, Episode_t: 1, Action: 203, Reward: 1.39, Epsilon: 0.69
[INFO] model update: t: 306, loss: 1319199.375
[INFO] Global_t: 306, Episode_t: 2, Action: 200, Reward: 1.76, Epsilon: 0.69
[INFO] model update: t: 307, loss: 302509.75
[INFO] Global_t: 307, Episode_t: 3, Action: 178, Reward: 1.67, Epsilon: 0.69
[INFO] model update: t: 308, loss: 772624.375
[INFO] Global_t: 308, Episode_t: 4, Action: 42, Reward: 2.73, Epsilon: 0.69
[INFO] model update: t: 309, loss: 1080838.5
[INFO] Global_t: 309, Episode_t: 5, Action: 64, Reward: 2.24, Epsilon: 0.69
[INFO] model update: t: 310, loss: 198091.125
[INFO] Global_t: 310, Episode_t: 6, Action: 121, Reward: 1.22, Epsilon: 0.69
[INFO] model update: t: 311, loss: 1577763.5
[INFO] Global_t: 311, Episode_t: 7, Action: 11, Reward: 4.77, Epsilon: 0.69
[INFO] model update: t: 312, loss: 13666.9814453125
[INFO] Global_t: 312, Episode_t: 8, Action: 58, Reward: 2.66, Epsilon: 0.69
 16%|█▌        | 312/2000 [07:42<51:49,  1.84s/it]
[INFO] Global step: 312, Cumulative rewards: 18.44976, Runtime (s): 462.94
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 313, loss: 994473.0
[INFO] Global_t: 313, Episode_t: 1, Action: 3, Reward: 3.61, Epsilon: 0.68
[INFO] model update: t: 314, loss: 408522.21875
[INFO] Global_t: 314, Episode_t: 2, Action: 90, Reward: 1.10, Epsilon: 0.68
[INFO] model update: t: 315, loss: 358086.0625
[INFO] Global_t: 315, Episode_t: 3, Action: 60, Reward: 1.92, Epsilon: 0.68
[INFO] model update: t: 316, loss: 1022823.875
[INFO] Global_t: 316, Episode_t: 4, Action: 14, Reward: 3.06, Epsilon: 0.68
[INFO] model update: t: 317, loss: 32570.630859375
[INFO] Global_t: 317, Episode_t: 5, Action: 173, Reward: 1.06, Epsilon: 0.68
[INFO] model update: t: 318, loss: 816117.375
[INFO] Global_t: 318, Episode_t: 6, Action: 103, Reward: 1.31, Epsilon: 0.68
[INFO] model update: t: 319, loss: 344591.375
[INFO] Global_t: 319, Episode_t: 7, Action: 0, Reward: 4.03, Epsilon: 0.68
[INFO] model update: t: 320, loss: 450733.8125
[INFO] Global_t: 320, Episode_t: 8, Action: 6, Reward: 3.23, Epsilon: 0.68
 16%|█▌        | 320/2000 [07:50<44:28,  1.59s/it]
[INFO] Global step: 320, Cumulative rewards: 19.319159999999997, Runtime (s): 470.90
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4759950637817383
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.561237096786499
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.399203300476074
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.45807147026062
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6678435802459717
average cummulative reward vector is:  [0.12231342 0.11325833 0.12908361 0.107575   0.1364672 ]
average cummulative reward is:  0.12173951304888345
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 321, loss: 617239.4375
[INFO] Global_t: 321, Episode_t: 1, Action: 5, Reward: 5.04, Epsilon: 0.68
[INFO] model update: t: 322, loss: 414321.4375
[INFO] Global_t: 322, Episode_t: 2, Action: 54, Reward: 1.98, Epsilon: 0.68
[INFO] model update: t: 323, loss: 509610.125
[INFO] Global_t: 323, Episode_t: 3, Action: 131, Reward: 1.97, Epsilon: 0.67
[INFO] model update: t: 324, loss: 71528.2421875
[INFO] Global_t: 324, Episode_t: 4, Action: 156, Reward: 0.84, Epsilon: 0.67
[INFO] model update: t: 325, loss: 463125.84375
[INFO] Global_t: 325, Episode_t: 5, Action: 67, Reward: 1.65, Epsilon: 0.67
[INFO] model update: t: 326, loss: 64694.76953125
[INFO] Global_t: 326, Episode_t: 6, Action: 9, Reward: 2.62, Epsilon: 0.67
[INFO] model update: t: 327, loss: 282533.25
[INFO] Global_t: 327, Episode_t: 7, Action: 15, Reward: 1.96, Epsilon: 0.67
[INFO] model update: t: 328, loss: 247605.09375
[INFO] Global_t: 328, Episode_t: 8, Action: 4, Reward: 3.06, Epsilon: 0.67
 16%|█▋        | 328/2000 [08:12<53:07,  1.91s/it]
[INFO] Global step: 328, Cumulative rewards: 19.12104, Runtime (s): 492.09
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 329, loss: 29933.029296875
[INFO] Global_t: 329, Episode_t: 1, Action: 0, Reward: 4.92, Epsilon: 0.67
[INFO] model update: t: 330, loss: 247817.453125
[INFO] Global_t: 330, Episode_t: 2, Action: 97, Reward: 1.82, Epsilon: 0.67
[INFO] model update: t: 331, loss: 104330.984375
[INFO] Global_t: 331, Episode_t: 3, Action: 148, Reward: 1.32, Epsilon: 0.67
[INFO] model update: t: 332, loss: 143774.703125
[INFO] Global_t: 332, Episode_t: 4, Action: 169, Reward: 1.52, Epsilon: 0.67
[INFO] model update: t: 333, loss: 191629.765625
[INFO] Global_t: 333, Episode_t: 5, Action: 158, Reward: 1.06, Epsilon: 0.66
[INFO] model update: t: 334, loss: 44834.54296875
[INFO] Global_t: 334, Episode_t: 6, Action: 176, Reward: 1.27, Epsilon: 0.66
[INFO] model update: t: 335, loss: 117015.984375
[INFO] Global_t: 335, Episode_t: 7, Action: 95, Reward: 1.80, Epsilon: 0.66
[INFO] model update: t: 336, loss: 38212.1328125
[INFO] Global_t: 336, Episode_t: 8, Action: 109, Reward: 1.83, Epsilon: 0.66
 17%|█▋        | 336/2000 [08:15<40:43,  1.47s/it]
[INFO] Global step: 336, Cumulative rewards: 15.53808, Runtime (s): 495.67
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3915064334869385
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6369290351867676
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6908445358276367
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4828431606292725
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.1757800579071045
average cummulative reward vector is:  [0.12119474 0.11293866 0.13468798 0.11043201 0.11779731]
average cummulative reward is:  0.11941013871306812
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 337, loss: 41964.3203125
[INFO] Global_t: 337, Episode_t: 1, Action: 169, Reward: 1.67, Epsilon: 0.66
[INFO] model update: t: 338, loss: 167179.078125
[INFO] Global_t: 338, Episode_t: 2, Action: 8, Reward: 4.30, Epsilon: 0.66
[INFO] model update: t: 339, loss: 12481.314453125
[INFO] Global_t: 339, Episode_t: 3, Action: 10, Reward: 3.35, Epsilon: 0.66
[INFO] model update: t: 340, loss: 98789.0234375
[INFO] Global_t: 340, Episode_t: 4, Action: 79, Reward: 2.20, Epsilon: 0.66
[INFO] model update: t: 341, loss: 89005.1328125
[INFO] Global_t: 341, Episode_t: 5, Action: 0, Reward: 2.75, Epsilon: 0.66
[INFO] model update: t: 342, loss: 39486.80859375
[INFO] Global_t: 342, Episode_t: 6, Action: 22, Reward: 2.06, Epsilon: 0.66
[INFO] model update: t: 343, loss: 154295.78125
[INFO] Global_t: 343, Episode_t: 7, Action: 193, Reward: 0.67, Epsilon: 0.65
[INFO] model update: t: 344, loss: 23044.78125
[INFO] Global_t: 344, Episode_t: 8, Action: 201, Reward: 1.22, Epsilon: 0.65
 17%|█▋        | 344/2000 [08:38<52:17,  1.89s/it]
[INFO] Global step: 344, Cumulative rewards: 18.225599999999996, Runtime (s): 518.77
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 345, loss: 186603.140625
[INFO] Global_t: 345, Episode_t: 1, Action: 26, Reward: 2.68, Epsilon: 0.65
[INFO] model update: t: 346, loss: 87598.3984375
[INFO] Global_t: 346, Episode_t: 2, Action: 175, Reward: 1.79, Epsilon: 0.65
[INFO] model update: t: 347, loss: 247961.9375
[INFO] Global_t: 347, Episode_t: 3, Action: 37, Reward: 1.81, Epsilon: 0.65
[INFO] model update: t: 348, loss: 70979.7421875
[INFO] Global_t: 348, Episode_t: 4, Action: 170, Reward: 1.08, Epsilon: 0.65
[INFO] model update: t: 349, loss: 98955.0078125
[INFO] Global_t: 349, Episode_t: 5, Action: 5, Reward: 4.27, Epsilon: 0.65
[INFO] model update: t: 350, loss: 173044.8125
[INFO] Global_t: 350, Episode_t: 6, Action: 9, Reward: 3.09, Epsilon: 0.65
[INFO] model update: t: 351, loss: 41602.5
[INFO] Global_t: 351, Episode_t: 7, Action: 13, Reward: 2.95, Epsilon: 0.65
[INFO] model update: t: 352, loss: 244368.84375
[INFO] Global_t: 352, Episode_t: 8, Action: 176, Reward: 1.34, Epsilon: 0.65
 18%|█▊        | 352/2000 [08:42<39:56,  1.45s/it]
[INFO] Global step: 352, Cumulative rewards: 19.01436, Runtime (s): 522.19
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.495450496673584
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6263458728790283
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.291987895965576
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.246711492538452
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.469975709915161
average cummulative reward vector is:  [0.12074474 0.11277546 0.12422869 0.10180304 0.12646398]
average cummulative reward is:  0.11720318084149191
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 353, loss: 42553.6640625
[INFO] Global_t: 353, Episode_t: 1, Action: 7, Reward: 4.70, Epsilon: 0.65
[INFO] model update: t: 354, loss: 88203.8125
[INFO] Global_t: 354, Episode_t: 2, Action: 4, Reward: 4.20, Epsilon: 0.64
[INFO] model update: t: 355, loss: 10404.0888671875
[INFO] Global_t: 355, Episode_t: 3, Action: 8, Reward: 2.55, Epsilon: 0.64
[INFO] model update: t: 356, loss: 36857.9375
[INFO] Global_t: 356, Episode_t: 4, Action: 3, Reward: 3.82, Epsilon: 0.64
[INFO] model update: t: 357, loss: 66603.015625
[INFO] Global_t: 357, Episode_t: 5, Action: 29, Reward: 1.02, Epsilon: 0.64
[INFO] model update: t: 358, loss: 28324.603515625
[INFO] Global_t: 358, Episode_t: 6, Action: 27, Reward: 2.23, Epsilon: 0.64
[INFO] model update: t: 359, loss: 81610.15625
[INFO] Global_t: 359, Episode_t: 7, Action: 9, Reward: 1.97, Epsilon: 0.64
[INFO] model update: t: 360, loss: 55291.28125
[INFO] Global_t: 360, Episode_t: 8, Action: 114, Reward: 0.83, Epsilon: 0.64
 18%|█▊        | 360/2000 [09:05<52:11,  1.91s/it]
[INFO] Global step: 360, Cumulative rewards: 21.325319999999994, Runtime (s): 545.97
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 361, loss: 108124.8125
[INFO] Global_t: 361, Episode_t: 1, Action: 33, Reward: 2.08, Epsilon: 0.64
[INFO] model update: t: 362, loss: 57851.81640625
[INFO] Global_t: 362, Episode_t: 2, Action: 11, Reward: 3.84, Epsilon: 0.64
[INFO] model update: t: 363, loss: 95061.84375
[INFO] Global_t: 363, Episode_t: 3, Action: 23, Reward: 2.28, Epsilon: 0.64
[INFO] model update: t: 364, loss: 49536.609375
[INFO] Global_t: 364, Episode_t: 4, Action: 88, Reward: 1.32, Epsilon: 0.63
[INFO] model update: t: 365, loss: 77147.3359375
[INFO] Global_t: 365, Episode_t: 5, Action: 92, Reward: 1.21, Epsilon: 0.63
[INFO] model update: t: 366, loss: 74732.515625
[INFO] Global_t: 366, Episode_t: 6, Action: 17, Reward: 2.10, Epsilon: 0.63
[INFO] model update: t: 367, loss: 62814.71484375
[INFO] Global_t: 367, Episode_t: 7, Action: 4, Reward: 3.13, Epsilon: 0.63
[INFO] model update: t: 368, loss: 42171.390625
[INFO] Global_t: 368, Episode_t: 8, Action: 178, Reward: 1.17, Epsilon: 0.63
 18%|█▊        | 368/2000 [09:10<41:08,  1.51s/it]
[INFO] Global step: 368, Cumulative rewards: 17.13612, Runtime (s): 550.66
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.183732271194458
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4442965984344482
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.423989772796631
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.616422414779663
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5265514850616455
average cummulative reward vector is:  [0.11596474 0.10509375 0.12717787 0.11222477 0.12835833]
average cummulative reward is:  0.11776389107660756
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 369, loss: 36659.22265625
[INFO] Global_t: 369, Episode_t: 1, Action: 32, Reward: 3.09, Epsilon: 0.63
[INFO] model update: t: 370, loss: 47991.76171875
[INFO] Global_t: 370, Episode_t: 2, Action: 8, Reward: 4.25, Epsilon: 0.63
[INFO] model update: t: 371, loss: 55204.1640625
[INFO] Global_t: 371, Episode_t: 3, Action: 6, Reward: 2.93, Epsilon: 0.63
[INFO] model update: t: 372, loss: 44711.2109375
[INFO] Global_t: 372, Episode_t: 4, Action: 22, Reward: 1.82, Epsilon: 0.63
[INFO] model update: t: 373, loss: 41980.40625
[INFO] Global_t: 373, Episode_t: 5, Action: 5, Reward: 2.91, Epsilon: 0.63
[INFO] model update: t: 374, loss: 22356.10546875
[INFO] Global_t: 374, Episode_t: 6, Action: 14, Reward: 2.92, Epsilon: 0.62
[INFO] model update: t: 375, loss: 18805.3515625
[INFO] Global_t: 375, Episode_t: 7, Action: 23, Reward: 1.99, Epsilon: 0.62
[INFO] model update: t: 376, loss: 16697.30078125
[INFO] Global_t: 376, Episode_t: 8, Action: 21, Reward: 1.84, Epsilon: 0.62

[INFO] Global step: 376, Cumulative rewards: 21.74364, Runtime (s): 572.45
 19%|█▉        | 376/2000 [09:32<50:46,  1.88s/it]------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 377, loss: 55822.24609375
[INFO] Global_t: 377, Episode_t: 1, Action: 119, Reward: 1.20, Epsilon: 0.62
[INFO] model update: t: 378, loss: 58088.16015625
[INFO] Global_t: 378, Episode_t: 2, Action: 5, Reward: 4.82, Epsilon: 0.62
[INFO] model update: t: 379, loss: 21914.35546875
[INFO] Global_t: 379, Episode_t: 3, Action: 4, Reward: 4.12, Epsilon: 0.62
[INFO] model update: t: 380, loss: 35163.23828125
[INFO] Global_t: 380, Episode_t: 4, Action: 3, Reward: 3.32, Epsilon: 0.62
[INFO] model update: t: 381, loss: 16931.611328125
[INFO] Global_t: 381, Episode_t: 5, Action: 84, Reward: 1.68, Epsilon: 0.62
[INFO] model update: t: 382, loss: 31359.96875
[INFO] Global_t: 382, Episode_t: 6, Action: 74, Reward: 1.50, Epsilon: 0.62
[INFO] model update: t: 383, loss: 40545.44140625
[INFO] Global_t: 383, Episode_t: 7, Action: 111, Reward: 1.45, Epsilon: 0.62
[INFO] model update: t: 384, loss: 62732.0078125
[INFO] Global_t: 384, Episode_t: 8, Action: 108, Reward: 1.47, Epsilon: 0.61
 19%|█▉        | 384/2000 [09:35<38:52,  1.44s/it]
[INFO] Global step: 384, Cumulative rewards: 19.538759999999996, Runtime (s): 575.93
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.342212200164795
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5068652629852295
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4266247749328613
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.45473313331604
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.337798833847046
average cummulative reward vector is:  [0.11902053 0.11151157 0.12477787 0.10958318 0.12116882]
average cummulative reward is:  0.11721239280334342
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 385, loss: 34339.1015625
[INFO] Global_t: 385, Episode_t: 1, Action: 5, Reward: 3.54, Epsilon: 0.61
[INFO] model update: t: 386, loss: 46979.69140625
[INFO] Global_t: 386, Episode_t: 2, Action: 167, Reward: 1.15, Epsilon: 0.61
[INFO] model update: t: 387, loss: 65628.5
[INFO] Global_t: 387, Episode_t: 3, Action: 133, Reward: 1.75, Epsilon: 0.61
[INFO] model update: t: 388, loss: 38620.04296875
[INFO] Global_t: 388, Episode_t: 4, Action: 168, Reward: 1.44, Epsilon: 0.61
[INFO] model update: t: 389, loss: 85708.046875
[INFO] Global_t: 389, Episode_t: 5, Action: 28, Reward: 2.93, Epsilon: 0.61
[INFO] model update: t: 390, loss: 40936.66796875
[INFO] Global_t: 390, Episode_t: 6, Action: 7, Reward: 2.33, Epsilon: 0.61
[INFO] model update: t: 391, loss: 24939.6171875
[INFO] Global_t: 391, Episode_t: 7, Action: 0, Reward: 1.65, Epsilon: 0.61
[INFO] model update: t: 392, loss: 16680.568359375
[INFO] Global_t: 392, Episode_t: 8, Action: 9, Reward: 1.35, Epsilon: 0.61
 20%|█▉        | 392/2000 [10:02<53:18,  1.99s/it]
[INFO] Global step: 392, Cumulative rewards: 16.1358, Runtime (s): 602.01
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 393, loss: 65244.0078125
[INFO] Global_t: 393, Episode_t: 1, Action: 50, Reward: 2.55, Epsilon: 0.61
[INFO] model update: t: 394, loss: 23502.64453125
[INFO] Global_t: 394, Episode_t: 2, Action: 5, Reward: 5.32, Epsilon: 0.60
[INFO] model update: t: 395, loss: 51941.92578125
[INFO] Global_t: 395, Episode_t: 3, Action: 6, Reward: 3.46, Epsilon: 0.60
[INFO] model update: t: 396, loss: 32806.87109375
[INFO] Global_t: 396, Episode_t: 4, Action: 15, Reward: 2.74, Epsilon: 0.60
[INFO] model update: t: 397, loss: 76742.75
[INFO] Global_t: 397, Episode_t: 5, Action: 69, Reward: 1.55, Epsilon: 0.60
[INFO] model update: t: 398, loss: 18129.13671875
[INFO] Global_t: 398, Episode_t: 6, Action: 13, Reward: 2.26, Epsilon: 0.60
[INFO] model update: t: 399, loss: 62618.5546875
[INFO] Global_t: 399, Episode_t: 7, Action: 17, Reward: 2.31, Epsilon: 0.60
[INFO] model update: t: 400, loss: 29189.833984375
[INFO] Global_t: 400, Episode_t: 8, Action: 173, Reward: 0.65, Epsilon: 0.60
 20%|██        | 400/2000 [10:07<42:49,  1.61s/it]
[INFO] Global step: 400, Cumulative rewards: 20.828039999999998, Runtime (s): 607.71
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3016340732574463
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4364912509918213
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.573162317276001
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3454675674438477
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.285722017288208
average cummulative reward vector is:  [0.12031158 0.10916181 0.12661585 0.1067236  0.12089919]
average cummulative reward is:  0.11674240463533754
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 401, loss: 48953.640625
[INFO] Global_t: 401, Episode_t: 1, Action: 9, Reward: 4.80, Epsilon: 0.60
[INFO] model update: t: 402, loss: 17252.4375
[INFO] Global_t: 402, Episode_t: 2, Action: 115, Reward: 1.59, Epsilon: 0.60
[INFO] model update: t: 403, loss: 43454.7578125
[INFO] Global_t: 403, Episode_t: 3, Action: 7, Reward: 3.38, Epsilon: 0.60
[INFO] model update: t: 404, loss: 43099.9296875
[INFO] Global_t: 404, Episode_t: 4, Action: 49, Reward: 1.98, Epsilon: 0.60
[INFO] model update: t: 405, loss: 23681.34375
[INFO] Global_t: 405, Episode_t: 5, Action: 100, Reward: 1.01, Epsilon: 0.59
[INFO] model update: t: 406, loss: 36976.62890625
[INFO] Global_t: 406, Episode_t: 6, Action: 8, Reward: 3.16, Epsilon: 0.59
[INFO] model update: t: 407, loss: 6849.533203125
[INFO] Global_t: 407, Episode_t: 7, Action: 101, Reward: 1.04, Epsilon: 0.59
[INFO] model update: t: 408, loss: 48760.7109375
[INFO] Global_t: 408, Episode_t: 8, Action: 211, Reward: 0.99, Epsilon: 0.59
 20%|██        | 408/2000 [10:30<52:48,  1.99s/it]
[INFO] Global step: 408, Cumulative rewards: 17.95848, Runtime (s): 630.81
------------------------------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 409, loss: 22788.51171875
[INFO] Global_t: 409, Episode_t: 1, Action: 112, Reward: 1.38, Epsilon: 0.59
[INFO] model update: t: 410, loss: 46224.13671875
[INFO] Global_t: 410, Episode_t: 2, Action: 66, Reward: 1.77, Epsilon: 0.59
[INFO] model update: t: 411, loss: 18336.076171875
[INFO] Global_t: 411, Episode_t: 3, Action: 0, Reward: 4.17, Epsilon: 0.59
[INFO] model update: t: 412, loss: 56199.40625
[INFO] Global_t: 412, Episode_t: 4, Action: 216, Reward: 1.49, Epsilon: 0.59
[INFO] model update: t: 413, loss: 26804.625
[INFO] Global_t: 413, Episode_t: 5, Action: 6, Reward: 4.02, Epsilon: 0.59
[INFO] model update: t: 414, loss: 19117.671875
[INFO] Global_t: 414, Episode_t: 6, Action: 83, Reward: 1.32, Epsilon: 0.59
[INFO] model update: t: 415, loss: 36786.7421875
[INFO] Global_t: 415, Episode_t: 7, Action: 104, Reward: 1.94, Epsilon: 0.58
[INFO] model update: t: 416, loss: 23541.3046875
[INFO] Global_t: 416, Episode_t: 8, Action: 115, Reward: 0.92, Epsilon: 0.58
 21%|██        | 416/2000 [10:34<40:44,  1.54s/it]
[INFO] Global step: 416, Cumulative rewards: 17.025720000000003, Runtime (s): 634.81
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.578815460205078
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4141218662261963
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3296403884887695
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.225919723510742
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4408299922943115
average cummulative reward vector is:  [0.12468132 0.10733287 0.12692077 0.09956355 0.12775403]
average cummulative reward is:  0.11725050696942003
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 417, loss: 33374.58203125
[INFO] Global_t: 417, Episode_t: 1, Action: 98, Reward: 2.00, Epsilon: 0.58
[INFO] model update: t: 418, loss: 26646.302734375
[INFO] Global_t: 418, Episode_t: 2, Action: 174, Reward: 1.66, Epsilon: 0.58
[INFO] model update: t: 419, loss: 60664.16796875
[INFO] Global_t: 419, Episode_t: 3, Action: 16, Reward: 4.12, Epsilon: 0.58
[INFO] model update: t: 420, loss: 23141.11328125
[INFO] Global_t: 420, Episode_t: 4, Action: 21, Reward: 3.61, Epsilon: 0.58
[INFO] model update: t: 421, loss: 42730.0390625
[INFO] Global_t: 421, Episode_t: 5, Action: 191, Reward: 1.52, Epsilon: 0.58
[INFO] model update: t: 422, loss: 30566.0625
[INFO] Global_t: 422, Episode_t: 6, Action: 120, Reward: 1.36, Epsilon: 0.58
[INFO] model update: t: 423, loss: 24547.1015625
[INFO] Global_t: 423, Episode_t: 7, Action: 79, Reward: 1.75, Epsilon: 0.58
 21%|██        | 424/2000 [11:01<54:27,  2.07s/it][INFO] model update: t: 424, loss: 28453.451171875
[INFO] Global_t: 424, Episode_t: 8, Action: 30, Reward: 2.94, Epsilon: 0.58

[INFO] Global step: 424, Cumulative rewards: 18.963119999999996, Runtime (s): 661.30
------------------------------------------------------------
 
graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 425, loss: 45879.65625
[INFO] Global_t: 425, Episode_t: 1, Action: 9, Reward: 4.53, Epsilon: 0.57
[INFO] model update: t: 426, loss: 58383.3515625
[INFO] Global_t: 426, Episode_t: 2, Action: 93, Reward: 1.77, Epsilon: 0.57
[INFO] model update: t: 427, loss: 46672.1328125
[INFO] Global_t: 427, Episode_t: 3, Action: 110, Reward: 1.86, Epsilon: 0.57
[INFO] model update: t: 428, loss: 28580.83203125
[INFO] Global_t: 428, Episode_t: 4, Action: 8, Reward: 3.21, Epsilon: 0.57
[INFO] model update: t: 429, loss: 38480.203125
[INFO] Global_t: 429, Episode_t: 5, Action: 98, Reward: 1.34, Epsilon: 0.57
[INFO] model update: t: 430, loss: 25419.30859375
[INFO] Global_t: 430, Episode_t: 6, Action: 102, Reward: 2.17, Epsilon: 0.57
[INFO] model update: t: 431, loss: 31915.234375
[INFO] Global_t: 431, Episode_t: 7, Action: 172, Reward: 1.52, Epsilon: 0.57
[INFO] model update: t: 432, loss: 28319.40234375
[INFO] Global_t: 432, Episode_t: 8, Action: 20, Reward: 1.39, Epsilon: 0.57
 22%|██▏       | 432/2000 [11:10<46:44,  1.79s/it]
[INFO] Global step: 432, Cumulative rewards: 17.806680000000004, Runtime (s): 670.29
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6572704315185547
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8168129920959473
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5705597400665283
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3315255641937256
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.343458414077759
average cummulative reward vector is:  [0.13331526 0.12059213 0.12910246 0.10378178 0.12350699]
average cummulative reward is:  0.12205972335043284
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 433, loss: 45421.0703125
[INFO] Global_t: 433, Episode_t: 1, Action: 1, Reward: 4.13, Epsilon: 0.57
[INFO] model update: t: 434, loss: 35682.7109375
[INFO] Global_t: 434, Episode_t: 2, Action: 5, Reward: 3.48, Epsilon: 0.57
[INFO] model update: t: 435, loss: 11296.681640625
[INFO] Global_t: 435, Episode_t: 3, Action: 111, Reward: 1.55, Epsilon: 0.56
[INFO] model update: t: 436, loss: 27736.521484375
[INFO] Global_t: 436, Episode_t: 4, Action: 49, Reward: 1.64, Epsilon: 0.56
[INFO] model update: t: 437, loss: 38609.60546875
[INFO] Global_t: 437, Episode_t: 5, Action: 98, Reward: 1.43, Epsilon: 0.56
[INFO] model update: t: 438, loss: 38667.8359375
[INFO] Global_t: 438, Episode_t: 6, Action: 2, Reward: 3.49, Epsilon: 0.56
[INFO] model update: t: 439, loss: 45680.8046875
[INFO] Global_t: 439, Episode_t: 7, Action: 53, Reward: 1.84, Epsilon: 0.56
[INFO] model update: t: 440, loss: 41163.5859375
[INFO] Global_t: 440, Episode_t: 8, Action: 153, Reward: 1.51, Epsilon: 0.56
 22%|██▏       | 440/2000 [11:35<56:43,  2.18s/it]
[INFO] Global step: 440, Cumulative rewards: 19.066799999999997, Runtime (s): 695.07
------------------------------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 441, loss: 34714.54296875
[INFO] Global_t: 441, Episode_t: 1, Action: 6, Reward: 4.82, Epsilon: 0.56
[INFO] model update: t: 442, loss: 40839.5859375
[INFO] Global_t: 442, Episode_t: 2, Action: 12, Reward: 4.02, Epsilon: 0.56
[INFO] model update: t: 443, loss: 32649.302734375
[INFO] Global_t: 443, Episode_t: 3, Action: 122, Reward: 1.08, Epsilon: 0.56
[INFO] model update: t: 444, loss: 77775.046875
[INFO] Global_t: 444, Episode_t: 4, Action: 7, Reward: 2.61, Epsilon: 0.56
[INFO] model update: t: 445, loss: 42145.5625
[INFO] Global_t: 445, Episode_t: 5, Action: 169, Reward: 1.07, Epsilon: 0.55
[INFO] model update: t: 446, loss: 62835.9375
[INFO] Global_t: 446, Episode_t: 6, Action: 106, Reward: 0.96, Epsilon: 0.55
[INFO] model update: t: 447, loss: 34453.18359375
[INFO] Global_t: 447, Episode_t: 7, Action: 10, Reward: 2.13, Epsilon: 0.55
[INFO] model update: t: 448, loss: 25854.974609375
[INFO] Global_t: 448, Episode_t: 8, Action: 89, Reward: 1.97, Epsilon: 0.55
 22%|██▏       | 448/2000 [11:42<46:57,  1.82s/it]
[INFO] Global step: 448, Cumulative rewards: 18.66408, Runtime (s): 702.76
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.213411808013916
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5573770999908447
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.559769630432129
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.1803460121154785
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.842839002609253
average cummulative reward vector is:  [0.11766105 0.11131366 0.13541749 0.10288575 0.13619301]
average cummulative reward is:  0.12069419095880476
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 449, loss: 48750.09765625
[INFO] Global_t: 449, Episode_t: 1, Action: 69, Reward: 2.44, Epsilon: 0.55
[INFO] model update: t: 450, loss: 20712.7265625
[INFO] Global_t: 450, Episode_t: 2, Action: 7, Reward: 3.61, Epsilon: 0.55
[INFO] model update: t: 451, loss: 22427.3515625
[INFO] Global_t: 451, Episode_t: 3, Action: 49, Reward: 2.34, Epsilon: 0.55
[INFO] model update: t: 452, loss: 18903.345703125
[INFO] Global_t: 452, Episode_t: 4, Action: 162, Reward: 1.14, Epsilon: 0.55
[INFO] model update: t: 453, loss: 23741.236328125
[INFO] Global_t: 453, Episode_t: 5, Action: 16, Reward: 2.54, Epsilon: 0.55
[INFO] model update: t: 454, loss: 36933.2421875
[INFO] Global_t: 454, Episode_t: 6, Action: 133, Reward: 1.04, Epsilon: 0.55
[INFO] model update: t: 455, loss: 57981.3515625
[INFO] Global_t: 455, Episode_t: 7, Action: 9, Reward: 2.01, Epsilon: 0.55
[INFO] model update: t: 456, loss: 37603.04296875
[INFO] Global_t: 456, Episode_t: 8, Action: 109, Reward: 1.65, Epsilon: 0.54
 23%|██▎       | 456/2000 [12:04<54:05,  2.10s/it]
[INFO] Global step: 456, Cumulative rewards: 16.776719999999997, Runtime (s): 724.93
------------------------------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 457, loss: 32285.00390625
[INFO] Global_t: 457, Episode_t: 1, Action: 178, Reward: 1.48, Epsilon: 0.54
[INFO] model update: t: 458, loss: 29684.8671875
[INFO] Global_t: 458, Episode_t: 2, Action: 4, Reward: 4.71, Epsilon: 0.54
[INFO] model update: t: 459, loss: 51873.12109375
[INFO] Global_t: 459, Episode_t: 3, Action: 51, Reward: 2.70, Epsilon: 0.54
[INFO] model update: t: 460, loss: 25635.806640625
[INFO] Global_t: 460, Episode_t: 4, Action: 37, Reward: 1.79, Epsilon: 0.54
[INFO] model update: t: 461, loss: 23517.9375
[INFO] Global_t: 461, Episode_t: 5, Action: 184, Reward: 0.83, Epsilon: 0.54
[INFO] model update: t: 462, loss: 33117.8203125
[INFO] Global_t: 462, Episode_t: 6, Action: 38, Reward: 1.57, Epsilon: 0.54
[INFO] model update: t: 463, loss: 19805.919921875
[INFO] Global_t: 463, Episode_t: 7, Action: 8, Reward: 2.42, Epsilon: 0.54
[INFO] model update: t: 464, loss: 16132.81640625
[INFO] Global_t: 464, Episode_t: 8, Action: 46, Reward: 1.47, Epsilon: 0.54
 23%|██▎       | 464/2000 [12:10<42:52,  1.67s/it]
[INFO] Global step: 464, Cumulative rewards: 16.972199999999997, Runtime (s): 730.34
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.119551181793213
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5403850078582764
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.589226722717285
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4308083057403564
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7582013607025146
average cummulative reward vector is:  [0.11158289 0.11280556 0.12768443 0.11116519 0.13778925]
average cummulative reward is:  0.12020546214992434
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 465, loss: 24842.583984375
[INFO] Global_t: 465, Episode_t: 1, Action: 4, Reward: 4.37, Epsilon: 0.54
[INFO] model update: t: 466, loss: 41214.203125
[INFO] Global_t: 466, Episode_t: 2, Action: 17, Reward: 3.96, Epsilon: 0.53
[INFO] model update: t: 467, loss: 18862.3515625
[INFO] Global_t: 467, Episode_t: 3, Action: 74, Reward: 2.57, Epsilon: 0.53
[INFO] model update: t: 468, loss: 11689.71875
[INFO] Global_t: 468, Episode_t: 4, Action: 8, Reward: 2.66, Epsilon: 0.53
[INFO] model update: t: 469, loss: 36077.76953125
[INFO] Global_t: 469, Episode_t: 5, Action: 23, Reward: 2.70, Epsilon: 0.53
[INFO] model update: t: 470, loss: 51834.1015625
[INFO] Global_t: 470, Episode_t: 6, Action: 155, Reward: 1.58, Epsilon: 0.53
[INFO] model update: t: 471, loss: 68092.828125
[INFO] Global_t: 471, Episode_t: 7, Action: 7, Reward: 2.77, Epsilon: 0.53
[INFO] model update: t: 472, loss: 42745.1484375
[INFO] Global_t: 472, Episode_t: 8, Action: 19, Reward: 1.83, Epsilon: 0.53
 24%|██▎       | 472/2000 [12:32<51:28,  2.02s/it]
[INFO] Global step: 472, Cumulative rewards: 22.44648, Runtime (s): 752.99
------------------------------------------------------------
 
graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 473, loss: 69214.1328125
[INFO] Global_t: 473, Episode_t: 1, Action: 3, Reward: 4.90, Epsilon: 0.53
[INFO] model update: t: 474, loss: 24780.546875
[INFO] Global_t: 474, Episode_t: 2, Action: 19, Reward: 3.32, Epsilon: 0.53
[INFO] model update: t: 475, loss: 66672.21875
[INFO] Global_t: 475, Episode_t: 3, Action: 11, Reward: 2.33, Epsilon: 0.53
[INFO] model update: t: 476, loss: 42132.3125
[INFO] Global_t: 476, Episode_t: 4, Action: 103, Reward: 1.33, Epsilon: 0.52
[INFO] model update: t: 477, loss: 28219.109375
[INFO] Global_t: 477, Episode_t: 5, Action: 4, Reward: 3.01, Epsilon: 0.52
[INFO] model update: t: 478, loss: 20366.880859375
[INFO] Global_t: 478, Episode_t: 6, Action: 12, Reward: 2.46, Epsilon: 0.52
[INFO] model update: t: 479, loss: 29057.16796875
[INFO] Global_t: 479, Episode_t: 7, Action: 43, Reward: 1.41, Epsilon: 0.52
[INFO] model update: t: 480, loss: 41556.0390625
[INFO] Global_t: 480, Episode_t: 8, Action: 7, Reward: 1.53, Epsilon: 0.52
 24%|██▍       | 480/2000 [12:38<40:40,  1.61s/it]
[INFO] Global step: 480, Cumulative rewards: 20.282280000000004, Runtime (s): 758.07
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8429994583129883
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4114527702331543
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3003554344177246
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3399317264556885
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.58671236038208
average cummulative reward vector is:  [0.13488711 0.10849352 0.12559945 0.10106963 0.13140188]
average cummulative reward is:  0.12029031704444866
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 481, loss: 39982.2109375
[INFO] Global_t: 481, Episode_t: 1, Action: 2, Reward: 4.06, Epsilon: 0.52
[INFO] model update: t: 482, loss: 22187.181640625
[INFO] Global_t: 482, Episode_t: 2, Action: 4, Reward: 3.64, Epsilon: 0.52
[INFO] model update: t: 483, loss: 45521.3515625
[INFO] Global_t: 483, Episode_t: 3, Action: 8, Reward: 2.20, Epsilon: 0.52
[INFO] model update: t: 484, loss: 23585.787109375
[INFO] Global_t: 484, Episode_t: 4, Action: 111, Reward: 1.36, Epsilon: 0.52
[INFO] model update: t: 485, loss: 22181.099609375
[INFO] Global_t: 485, Episode_t: 5, Action: 7, Reward: 3.05, Epsilon: 0.52
[INFO] model update: t: 486, loss: 11112.822265625
[INFO] Global_t: 486, Episode_t: 6, Action: 19, Reward: 2.33, Epsilon: 0.51
[INFO] model update: t: 487, loss: 27099.734375
[INFO] Global_t: 487, Episode_t: 7, Action: 79, Reward: 1.24, Epsilon: 0.51
[INFO] model update: t: 488, loss: 19727.5859375
[INFO] Global_t: 488, Episode_t: 8, Action: 173, Reward: 0.91, Epsilon: 0.51
 24%|██▍       | 488/2000 [12:59<48:55,  1.94s/it]
[INFO] Global step: 488, Cumulative rewards: 18.7962, Runtime (s): 779.87
------------------------------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 489, loss: 31621.689453125
[INFO] Global_t: 489, Episode_t: 1, Action: 1, Reward: 5.16, Epsilon: 0.51
[INFO] model update: t: 490, loss: 23867.646484375
[INFO] Global_t: 490, Episode_t: 2, Action: 19, Reward: 3.16, Epsilon: 0.51
[INFO] model update: t: 491, loss: 42669.0078125
[INFO] Global_t: 491, Episode_t: 3, Action: 8, Reward: 3.40, Epsilon: 0.51
[INFO] model update: t: 492, loss: 16907.79296875
[INFO] Global_t: 492, Episode_t: 4, Action: 36, Reward: 1.86, Epsilon: 0.51
[INFO] model update: t: 493, loss: 34108.828125
[INFO] Global_t: 493, Episode_t: 5, Action: 7, Reward: 2.75, Epsilon: 0.51
[INFO] model update: t: 494, loss: 13938.2255859375
[INFO] Global_t: 494, Episode_t: 6, Action: 149, Reward: 0.96, Epsilon: 0.51
[INFO] model update: t: 495, loss: 33119.62109375
[INFO] Global_t: 495, Episode_t: 7, Action: 45, Reward: 1.17, Epsilon: 0.51
[INFO] model update: t: 496, loss: 8547.47265625
[INFO] Global_t: 496, Episode_t: 8, Action: 24, Reward: 1.51, Epsilon: 0.50
 25%|██▍       | 496/2000 [13:05<39:20,  1.57s/it]
[INFO] Global step: 496, Cumulative rewards: 19.97124, Runtime (s): 785.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.232909679412842
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.046817064285278
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2214982509613037
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5828006267547607
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.752032518386841
average cummulative reward vector is:  [0.11266158 0.1189912  0.1207877  0.11566308 0.13737419]
average cummulative reward is:  0.1210955530459283
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 497, loss: 61447.6328125
[INFO] Global_t: 497, Episode_t: 1, Action: 3, Reward: 4.59, Epsilon: 0.50
[INFO] model update: t: 498, loss: 48733.52734375
[INFO] Global_t: 498, Episode_t: 2, Action: 0, Reward: 4.36, Epsilon: 0.50
[INFO] model update: t: 499, loss: 16823.74609375
[INFO] Global_t: 499, Episode_t: 3, Action: 111, Reward: 1.66, Epsilon: 0.50
[INFO] model update: t: 500, loss: 19834.529296875
[INFO] Global_t: 500, Episode_t: 4, Action: 8, Reward: 2.77, Epsilon: 0.50
[INFO] model update: t: 501, loss: 13099.8583984375
[INFO] Global_t: 501, Episode_t: 5, Action: 64, Reward: 2.03, Epsilon: 0.50
[INFO] model update: t: 502, loss: 26707.34765625
[INFO] Global_t: 502, Episode_t: 6, Action: 6, Reward: 2.57, Epsilon: 0.50
[INFO] model update: t: 503, loss: 29250.6875
[INFO] Global_t: 503, Episode_t: 7, Action: 140, Reward: 1.03, Epsilon: 0.50
[INFO] model update: t: 504, loss: 14443.80859375
[INFO] Global_t: 504, Episode_t: 8, Action: 11, Reward: 2.31, Epsilon: 0.50
 25%|██▌       | 504/2000 [13:28<48:33,  1.95s/it]
[INFO] Global step: 504, Cumulative rewards: 21.31272, Runtime (s): 808.12
------------------------------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 505, loss: 28884.791015625
[INFO] Global_t: 505, Episode_t: 1, Action: 71, Reward: 1.94, Epsilon: 0.50
[INFO] model update: t: 506, loss: 55153.33984375
[INFO] Global_t: 506, Episode_t: 2, Action: 86, Reward: 2.32, Epsilon: 0.50
[INFO] model update: t: 507, loss: 40146.234375
[INFO] Global_t: 507, Episode_t: 3, Action: 82, Reward: 1.88, Epsilon: 0.49
[INFO] model update: t: 508, loss: 80305.9921875
[INFO] Global_t: 508, Episode_t: 4, Action: 190, Reward: 1.02, Epsilon: 0.49
[INFO] model update: t: 509, loss: 40575.22265625
[INFO] Global_t: 509, Episode_t: 5, Action: 18, Reward: 3.58, Epsilon: 0.49
[INFO] model update: t: 510, loss: 48491.484375
[INFO] Global_t: 510, Episode_t: 6, Action: 24, Reward: 2.09, Epsilon: 0.49
[INFO] model update: t: 511, loss: 33126.1796875
[INFO] Global_t: 511, Episode_t: 7, Action: 23, Reward: 0.99, Epsilon: 0.49
[INFO] model update: t: 512, loss: 115883.5234375
[INFO] Global_t: 512, Episode_t: 8, Action: 134, Reward: 1.47, Epsilon: 0.49
 26%|██▌       | 512/2000 [13:32<37:44,  1.52s/it]
[INFO] Global step: 512, Cumulative rewards: 15.288599999999999, Runtime (s): 812.34
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3166191577911377
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5856361389160156
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.16262149810791
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.270237922668457
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.1752705574035645
average cummulative reward vector is:  [0.11868711 0.11406875 0.11150328 0.10384603 0.11512688]
average cummulative reward is:  0.11264640874189916
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 513, loss: 17044.736328125
[INFO] Global_t: 513, Episode_t: 1, Action: 1, Reward: 4.88, Epsilon: 0.49
[INFO] model update: t: 514, loss: 85567.671875
[INFO] Global_t: 514, Episode_t: 2, Action: 101, Reward: 1.54, Epsilon: 0.49
[INFO] model update: t: 515, loss: 34737.19921875
[INFO] Global_t: 515, Episode_t: 3, Action: 93, Reward: 1.68, Epsilon: 0.49
[INFO] model update: t: 516, loss: 41024.6875
[INFO] Global_t: 516, Episode_t: 4, Action: 58, Reward: 1.18, Epsilon: 0.49
[INFO] model update: t: 517, loss: 38762.5
[INFO] Global_t: 517, Episode_t: 5, Action: 151, Reward: 1.07, Epsilon: 0.48
[INFO] model update: t: 518, loss: 20253.6171875
[INFO] Global_t: 518, Episode_t: 6, Action: 8, Reward: 2.42, Epsilon: 0.48
[INFO] model update: t: 519, loss: 18531.609375
[INFO] Global_t: 519, Episode_t: 7, Action: 10, Reward: 1.85, Epsilon: 0.48
[INFO] model update: t: 520, loss: 18019.0234375
[INFO] Global_t: 520, Episode_t: 8, Action: 156, Reward: 1.12, Epsilon: 0.48
 26%|██▌       | 520/2000 [13:53<46:13,  1.87s/it]
[INFO] Global step: 520, Cumulative rewards: 15.73992, Runtime (s): 833.92
------------------------------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 521, loss: 44978.8359375
[INFO] Global_t: 521, Episode_t: 1, Action: 35, Reward: 2.63, Epsilon: 0.48
[INFO] model update: t: 522, loss: 40559.30078125
[INFO] Global_t: 522, Episode_t: 2, Action: 90, Reward: 1.67, Epsilon: 0.48
[INFO] model update: t: 523, loss: 34368.9140625
[INFO] Global_t: 523, Episode_t: 3, Action: 119, Reward: 1.37, Epsilon: 0.48
[INFO] model update: t: 524, loss: 14184.5869140625
[INFO] Global_t: 524, Episode_t: 4, Action: 10, Reward: 3.91, Epsilon: 0.48
[INFO] model update: t: 525, loss: 13033.0810546875
[INFO] Global_t: 525, Episode_t: 5, Action: 9, Reward: 2.61, Epsilon: 0.48
[INFO] model update: t: 526, loss: 17886.85546875
[INFO] Global_t: 526, Episode_t: 6, Action: 157, Reward: 1.75, Epsilon: 0.48
[INFO] model update: t: 527, loss: 12351.427734375
[INFO] Global_t: 527, Episode_t: 7, Action: 13, Reward: 3.22, Epsilon: 0.47
[INFO] model update: t: 528, loss: 31751.529296875
[INFO] Global_t: 528, Episode_t: 8, Action: 116, Reward: 1.18, Epsilon: 0.47
 26%|██▋       | 528/2000 [13:58<36:12,  1.48s/it]
[INFO] Global step: 528, Cumulative rewards: 18.352559999999997, Runtime (s): 838.29
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.365118980407715
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7562203407287598
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5853662490844727
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5827972888946533
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.454608678817749
average cummulative reward vector is:  [0.12127368 0.1168287  0.13614973 0.10570514 0.12820349]
average cummulative reward is:  0.12163214990015161
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 529, loss: 24722.978515625
[INFO] Global_t: 529, Episode_t: 1, Action: 109, Reward: 2.03, Epsilon: 0.47
[INFO] model update: t: 530, loss: 19022.51171875
[INFO] Global_t: 530, Episode_t: 2, Action: 187, Reward: 1.35, Epsilon: 0.47
[INFO] model update: t: 531, loss: 15689.228515625
[INFO] Global_t: 531, Episode_t: 3, Action: 82, Reward: 2.20, Epsilon: 0.47
[INFO] model update: t: 532, loss: 28168.625
[INFO] Global_t: 532, Episode_t: 4, Action: 18, Reward: 3.33, Epsilon: 0.47
[INFO] model update: t: 533, loss: 19675.6953125
[INFO] Global_t: 533, Episode_t: 5, Action: 9, Reward: 2.76, Epsilon: 0.47
[INFO] model update: t: 534, loss: 34378.0625
[INFO] Global_t: 534, Episode_t: 6, Action: 35, Reward: 2.00, Epsilon: 0.47
[INFO] model update: t: 535, loss: 19630.109375
[INFO] Global_t: 535, Episode_t: 7, Action: 12, Reward: 2.13, Epsilon: 0.47
[INFO] model update: t: 536, loss: 44154.02734375
[INFO] Global_t: 536, Episode_t: 8, Action: 8, Reward: 3.20, Epsilon: 0.47
 27%|██▋       | 536/2000 [14:20<45:11,  1.85s/it]
[INFO] Global step: 536, Cumulative rewards: 19.00404, Runtime (s): 860.12
------------------------------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 537, loss: 17007.943359375
[INFO] Global_t: 537, Episode_t: 1, Action: 6, Reward: 4.08, Epsilon: 0.46
[INFO] model update: t: 538, loss: 31659.359375
[INFO] Global_t: 538, Episode_t: 2, Action: 5, Reward: 3.85, Epsilon: 0.46
[INFO] model update: t: 539, loss: 27494.86328125
[INFO] Global_t: 539, Episode_t: 3, Action: 10, Reward: 2.01, Epsilon: 0.46
[INFO] model update: t: 540, loss: 18735.9296875
[INFO] Global_t: 540, Episode_t: 4, Action: 51, Reward: 1.42, Epsilon: 0.46
[INFO] model update: t: 541, loss: 24661.845703125
[INFO] Global_t: 541, Episode_t: 5, Action: 22, Reward: 2.58, Epsilon: 0.46
[INFO] model update: t: 542, loss: 26362.708984375
[INFO] Global_t: 542, Episode_t: 6, Action: 7, Reward: 2.07, Epsilon: 0.46
[INFO] model update: t: 543, loss: 43161.890625
[INFO] Global_t: 543, Episode_t: 7, Action: 17, Reward: 2.19, Epsilon: 0.46
[INFO] model update: t: 544, loss: 9095.40625
[INFO] Global_t: 544, Episode_t: 8, Action: 9, Reward: 1.57, Epsilon: 0.46
 27%|██▋       | 544/2000 [14:24<35:42,  1.47s/it]
[INFO] Global step: 544, Cumulative rewards: 19.769399999999997, Runtime (s): 864.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.246654987335205
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.481553316116333
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4407241344451904
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.367605447769165
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.430351495742798
average cummulative reward vector is:  [0.11702105 0.10767338 0.12439508 0.10799276 0.12608925]
average cummulative reward is:  0.11663430370991908
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 545, loss: 29995.9765625
[INFO] Global_t: 545, Episode_t: 1, Action: 137, Reward: 1.78, Epsilon: 0.46
[INFO] model update: t: 546, loss: 32739.80859375
[INFO] Global_t: 546, Episode_t: 2, Action: 12, Reward: 4.45, Epsilon: 0.46
[INFO] model update: t: 547, loss: 12585.66796875
[INFO] Global_t: 547, Episode_t: 3, Action: 46, Reward: 1.16, Epsilon: 0.45
[INFO] model update: t: 548, loss: 61986.0390625
[INFO] Global_t: 548, Episode_t: 4, Action: 23, Reward: 2.63, Epsilon: 0.45
[INFO] model update: t: 549, loss: 33494.87109375
[INFO] Global_t: 549, Episode_t: 5, Action: 3, Reward: 2.87, Epsilon: 0.45
[INFO] model update: t: 550, loss: 45164.015625
[INFO] Global_t: 550, Episode_t: 6, Action: 10, Reward: 2.98, Epsilon: 0.45
[INFO] model update: t: 551, loss: 47410.7421875
[INFO] Global_t: 551, Episode_t: 7, Action: 9, Reward: 2.86, Epsilon: 0.45
[INFO] model update: t: 552, loss: 20766.49609375
[INFO] Global_t: 552, Episode_t: 8, Action: 36, Reward: 2.07, Epsilon: 0.45
 28%|██▊       | 552/2000 [14:47<45:16,  1.88s/it]
[INFO] Global step: 552, Cumulative rewards: 20.79636, Runtime (s): 887.36
------------------------------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 553, loss: 40998.8125
[INFO] Global_t: 553, Episode_t: 1, Action: 9, Reward: 4.06, Epsilon: 0.45
[INFO] model update: t: 554, loss: 6105.31396484375
[INFO] Global_t: 554, Episode_t: 2, Action: 8, Reward: 3.28, Epsilon: 0.45
[INFO] model update: t: 555, loss: 27677.099609375
[INFO] Global_t: 555, Episode_t: 3, Action: 5, Reward: 2.95, Epsilon: 0.45
[INFO] model update: t: 556, loss: 10567.1689453125
[INFO] Global_t: 556, Episode_t: 4, Action: 110, Reward: 1.21, Epsilon: 0.45
[INFO] model update: t: 557, loss: 46145.453125
[INFO] Global_t: 557, Episode_t: 5, Action: 41, Reward: 2.43, Epsilon: 0.45
[INFO] model update: t: 558, loss: 28457.82421875
[INFO] Global_t: 558, Episode_t: 6, Action: 11, Reward: 3.60, Epsilon: 0.44
[INFO] model update: t: 559, loss: 58395.4765625
[INFO] Global_t: 559, Episode_t: 7, Action: 15, Reward: 1.82, Epsilon: 0.44
[INFO] model update: t: 560, loss: 115265.109375
[INFO] Global_t: 560, Episode_t: 8, Action: 14, Reward: 2.35, Epsilon: 0.44
 28%|██▊       | 560/2000 [14:51<35:13,  1.47s/it]
[INFO] Global step: 560, Cumulative rewards: 21.695639999999997, Runtime (s): 891.48
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.585111141204834
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.419893741607666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2336843013763428
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.560978651046753
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.3395779132843018
average cummulative reward vector is:  [0.12432421 0.10803958 0.12128579 0.10450187 0.12536075]
average cummulative reward is:  0.11670244161128529
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 561, loss: 34584.35546875
[INFO] Global_t: 561, Episode_t: 1, Action: 52, Reward: 1.82, Epsilon: 0.44
[INFO] model update: t: 562, loss: 89245.78125
[INFO] Global_t: 562, Episode_t: 2, Action: 6, Reward: 3.82, Epsilon: 0.44
[INFO] model update: t: 563, loss: 32056.736328125
[INFO] Global_t: 563, Episode_t: 3, Action: 30, Reward: 3.13, Epsilon: 0.44
[INFO] model update: t: 564, loss: 51829.8671875
[INFO] Global_t: 564, Episode_t: 4, Action: 21, Reward: 3.19, Epsilon: 0.44
[INFO] model update: t: 565, loss: 88228.03125
[INFO] Global_t: 565, Episode_t: 5, Action: 11, Reward: 2.08, Epsilon: 0.44
[INFO] model update: t: 566, loss: 18799.0234375
[INFO] Global_t: 566, Episode_t: 6, Action: 142, Reward: 1.49, Epsilon: 0.44
[INFO] model update: t: 567, loss: 42941.20703125
[INFO] Global_t: 567, Episode_t: 7, Action: 136, Reward: 1.35, Epsilon: 0.44
[INFO] model update: t: 568, loss: 21726.6640625
[INFO] Global_t: 568, Episode_t: 8, Action: 12, Reward: 2.84, Epsilon: 0.43
 28%|██▊       | 568/2000 [15:14<44:52,  1.88s/it]
[INFO] Global step: 568, Cumulative rewards: 19.72272, Runtime (s): 914.23
------------------------------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 569, loss: 65766.2890625
[INFO] Global_t: 569, Episode_t: 1, Action: 8, Reward: 5.07, Epsilon: 0.43
[INFO] model update: t: 570, loss: 102433.15625
[INFO] Global_t: 570, Episode_t: 2, Action: 7, Reward: 3.62, Epsilon: 0.43
[INFO] model update: t: 571, loss: 13801.3857421875
[INFO] Global_t: 571, Episode_t: 3, Action: 13, Reward: 2.88, Epsilon: 0.43
[INFO] model update: t: 572, loss: 60425.0
[INFO] Global_t: 572, Episode_t: 4, Action: 15, Reward: 2.84, Epsilon: 0.43
[INFO] model update: t: 573, loss: 25949.486328125
[INFO] Global_t: 573, Episode_t: 5, Action: 164, Reward: 1.19, Epsilon: 0.43
[INFO] model update: t: 574, loss: 77770.328125
[INFO] Global_t: 574, Episode_t: 6, Action: 9, Reward: 2.15, Epsilon: 0.43
[INFO] model update: t: 575, loss: 12638.69921875
[INFO] Global_t: 575, Episode_t: 7, Action: 16, Reward: 1.71, Epsilon: 0.43
[INFO] model update: t: 576, loss: 150447.5625
[INFO] Global_t: 576, Episode_t: 8, Action: 94, Reward: 1.18, Epsilon: 0.43
 29%|██▉       | 576/2000 [15:19<35:58,  1.52s/it]
[INFO] Global step: 576, Cumulative rewards: 20.65716, Runtime (s): 919.54
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.421184778213501
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.733811140060425
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2791011333465576
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.527269124984741
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.527867555618286
average cummulative reward vector is:  [0.12152395 0.11474144 0.12008989 0.1137285  0.1234172 ]
average cummulative reward is:  0.11870019644759225
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 577, loss: 114273.171875
[INFO] Global_t: 577, Episode_t: 1, Action: 3, Reward: 6.30, Epsilon: 0.43
[INFO] model update: t: 578, loss: 29647.77734375
[INFO] Global_t: 578, Episode_t: 2, Action: 5, Reward: 3.67, Epsilon: 0.42
[INFO] model update: t: 579, loss: 67874.6640625
[INFO] Global_t: 579, Episode_t: 3, Action: 9, Reward: 3.42, Epsilon: 0.42
[INFO] model update: t: 580, loss: 16048.0419921875
[INFO] Global_t: 580, Episode_t: 4, Action: 31, Reward: 2.53, Epsilon: 0.42
[INFO] model update: t: 581, loss: 44973.1328125
[INFO] Global_t: 581, Episode_t: 5, Action: 163, Reward: 1.20, Epsilon: 0.42
[INFO] model update: t: 582, loss: 29373.6640625
[INFO] Global_t: 582, Episode_t: 6, Action: 74, Reward: 1.06, Epsilon: 0.42
[INFO] model update: t: 583, loss: 83910.9296875
[INFO] Global_t: 583, Episode_t: 7, Action: 130, Reward: 1.51, Epsilon: 0.42
[INFO] model update: t: 584, loss: 18871.375
[INFO] Global_t: 584, Episode_t: 8, Action: 81, Reward: 1.48, Epsilon: 0.42
 29%|██▉       | 584/2000 [15:42<45:09,  1.91s/it]
[INFO] Global step: 584, Cumulative rewards: 21.16728, Runtime (s): 942.27
------------------------------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 585, loss: 36888.2578125
[INFO] Global_t: 585, Episode_t: 1, Action: 1, Reward: 4.75, Epsilon: 0.42
[INFO] model update: t: 586, loss: 29917.70703125
[INFO] Global_t: 586, Episode_t: 2, Action: 158, Reward: 2.09, Epsilon: 0.42
[INFO] model update: t: 587, loss: 40918.48046875
[INFO] Global_t: 587, Episode_t: 3, Action: 5, Reward: 2.89, Epsilon: 0.42
[INFO] model update: t: 588, loss: 5569.8564453125
[INFO] Global_t: 588, Episode_t: 4, Action: 162, Reward: 0.90, Epsilon: 0.41
[INFO] model update: t: 589, loss: 39841.49609375
[INFO] Global_t: 589, Episode_t: 5, Action: 9, Reward: 2.67, Epsilon: 0.41
[INFO] model update: t: 590, loss: 30493.86328125
[INFO] Global_t: 590, Episode_t: 6, Action: 2, Reward: 3.45, Epsilon: 0.41
[INFO] model update: t: 591, loss: 59614.6484375
[INFO] Global_t: 591, Episode_t: 7, Action: 15, Reward: 1.38, Epsilon: 0.41
[INFO] model update: t: 592, loss: 9723.4580078125
[INFO] Global_t: 592, Episode_t: 8, Action: 71, Reward: 1.77, Epsilon: 0.41
 30%|██▉       | 592/2000 [15:47<36:11,  1.54s/it]
[INFO] Global step: 592, Cumulative rewards: 19.90536, Runtime (s): 947.68
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.329510450363159
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9670400619506836
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.545405387878418
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.547560214996338
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5569803714752197
average cummulative reward vector is:  [0.11929868 0.11511389 0.12988279 0.11390864 0.12776962]
average cummulative reward is:  0.12119472570007764
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 593, loss: 29721.0859375
[INFO] Global_t: 593, Episode_t: 1, Action: 135, Reward: 1.44, Epsilon: 0.41
[INFO] model update: t: 594, loss: 6373.76220703125
[INFO] Global_t: 594, Episode_t: 2, Action: 193, Reward: 1.52, Epsilon: 0.41
[INFO] model update: t: 595, loss: 22964.546875
[INFO] Global_t: 595, Episode_t: 3, Action: 5, Reward: 4.04, Epsilon: 0.41
[INFO] model update: t: 596, loss: 17572.51953125
[INFO] Global_t: 596, Episode_t: 4, Action: 10, Reward: 3.91, Epsilon: 0.41
[INFO] model update: t: 597, loss: 23531.380859375
[INFO] Global_t: 597, Episode_t: 5, Action: 22, Reward: 2.95, Epsilon: 0.41
[INFO] model update: t: 598, loss: 18854.640625
[INFO] Global_t: 598, Episode_t: 6, Action: 68, Reward: 2.05, Epsilon: 0.40
[INFO] model update: t: 599, loss: 7808.93505859375
[INFO] Global_t: 599, Episode_t: 7, Action: 205, Reward: 1.62, Epsilon: 0.40
[INFO] model update: t: 600, loss: 33880.390625
[INFO] Global_t: 600, Episode_t: 8, Action: 4, Reward: 3.65, Epsilon: 0.40
 30%|███       | 600/2000 [16:09<44:35,  1.91s/it]
[INFO] Global step: 600, Cumulative rewards: 21.182999999999996, Runtime (s): 969.86
------------------------------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 601, loss: 44192.0703125
[INFO] Global_t: 601, Episode_t: 1, Action: 6, Reward: 4.15, Epsilon: 0.40
[INFO] model update: t: 602, loss: 29371.1796875
[INFO] Global_t: 602, Episode_t: 2, Action: 8, Reward: 4.45, Epsilon: 0.40
[INFO] model update: t: 603, loss: 89888.484375
[INFO] Global_t: 603, Episode_t: 3, Action: 15, Reward: 2.18, Epsilon: 0.40
[INFO] model update: t: 604, loss: 14670.3818359375
[INFO] Global_t: 604, Episode_t: 4, Action: 24, Reward: 1.81, Epsilon: 0.40
[INFO] model update: t: 605, loss: 92854.7734375
[INFO] Global_t: 605, Episode_t: 5, Action: 10, Reward: 2.54, Epsilon: 0.40
[INFO] model update: t: 606, loss: 14785.548828125
[INFO] Global_t: 606, Episode_t: 6, Action: 38, Reward: 1.49, Epsilon: 0.40
[INFO] model update: t: 607, loss: 109024.21875
[INFO] Global_t: 607, Episode_t: 7, Action: 65, Reward: 2.00, Epsilon: 0.40
[INFO] model update: t: 608, loss: 39188.48046875
[INFO] Global_t: 608, Episode_t: 8, Action: 149, Reward: 0.52, Epsilon: 0.40

[INFO] Global step: 608, Cumulative rewards: 19.142039999999998, Runtime (s): 975.88
------------------------------------------------------------
 
 30%|███       | 608/2000 [16:15<36:16,  1.56s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3382761478424072
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6700921058654785
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.756537675857544
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.332970142364502
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.507427215576172
average cummulative reward vector is:  [0.11796211 0.11352014 0.13533689 0.10775958 0.12896425]
average cummulative reward is:  0.12070859122980575
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 609, loss: 89190.015625
[INFO] Global_t: 609, Episode_t: 1, Action: 27, Reward: 3.14, Epsilon: 0.39
[INFO] model update: t: 610, loss: 116868.078125
[INFO] Global_t: 610, Episode_t: 2, Action: 7, Reward: 4.38, Epsilon: 0.39
[INFO] model update: t: 611, loss: 13002.423828125
[INFO] Global_t: 611, Episode_t: 3, Action: 4, Reward: 3.87, Epsilon: 0.39
[INFO] model update: t: 612, loss: 164777.53125
[INFO] Global_t: 612, Episode_t: 4, Action: 172, Reward: 0.97, Epsilon: 0.39
[INFO] model update: t: 613, loss: 39906.265625
[INFO] Global_t: 613, Episode_t: 5, Action: 6, Reward: 4.09, Epsilon: 0.39
[INFO] model update: t: 614, loss: 43922.34375
[INFO] Global_t: 614, Episode_t: 6, Action: 23, Reward: 2.82, Epsilon: 0.39
[INFO] model update: t: 615, loss: 94709.6875
[INFO] Global_t: 615, Episode_t: 7, Action: 19, Reward: 2.69, Epsilon: 0.39
[INFO] model update: t: 616, loss: 19168.296875
[INFO] Global_t: 616, Episode_t: 8, Action: 15, Reward: 1.91, Epsilon: 0.39
 31%|███       | 616/2000 [16:37<44:09,  1.91s/it]
[INFO] Global step: 616, Cumulative rewards: 23.873160000000002, Runtime (s): 997.73
------------------------------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 617, loss: 98531.515625
[INFO] Global_t: 617, Episode_t: 1, Action: 75, Reward: 1.72, Epsilon: 0.39
[INFO] model update: t: 618, loss: 13637.3671875
[INFO] Global_t: 618, Episode_t: 2, Action: 10, Reward: 4.75, Epsilon: 0.39
[INFO] model update: t: 619, loss: 221133.484375
[INFO] Global_t: 619, Episode_t: 3, Action: 6, Reward: 2.91, Epsilon: 0.38
[INFO] model update: t: 620, loss: 235938.640625
[INFO] Global_t: 620, Episode_t: 4, Action: 9, Reward: 2.63, Epsilon: 0.38
[INFO] model update: t: 621, loss: 92574.8359375
[INFO] Global_t: 621, Episode_t: 5, Action: 8, Reward: 2.39, Epsilon: 0.38
[INFO] model update: t: 622, loss: 289696.875
[INFO] Global_t: 622, Episode_t: 6, Action: 7, Reward: 2.74, Epsilon: 0.38
[INFO] model update: t: 623, loss: 23209.107421875
[INFO] Global_t: 623, Episode_t: 7, Action: 16, Reward: 1.94, Epsilon: 0.38
[INFO] model update: t: 624, loss: 205293.78125
[INFO] Global_t: 624, Episode_t: 8, Action: 22, Reward: 2.03, Epsilon: 0.38

[INFO] Global step: 624, Cumulative rewards: 21.10464, Runtime (s): 1002.78
 31%|███       | 624/2000 [16:42<35:03,  1.53s/it]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3577747344970703
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.063535690307617
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6454060077667236
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.663447380065918
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.321038007736206
average cummulative reward vector is:  [0.12383947 0.11934537 0.13018279 0.11575981 0.12309704]
average cummulative reward is:  0.12244489740693834
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 625, loss: 16071.0791015625
[INFO] Global_t: 625, Episode_t: 1, Action: 9, Reward: 5.00, Epsilon: 0.38
[INFO] model update: t: 626, loss: 258100.109375
[INFO] Global_t: 626, Episode_t: 2, Action: 3, Reward: 3.97, Epsilon: 0.38
[INFO] model update: t: 627, loss: 241587.09375
[INFO] Global_t: 627, Episode_t: 3, Action: 5, Reward: 3.05, Epsilon: 0.38
[INFO] model update: t: 628, loss: 19400.21484375
[INFO] Global_t: 628, Episode_t: 4, Action: 24, Reward: 2.50, Epsilon: 0.38
[INFO] model update: t: 629, loss: 76538.9453125
[INFO] Global_t: 629, Episode_t: 5, Action: 11, Reward: 2.30, Epsilon: 0.37
[INFO] model update: t: 630, loss: 15368.7890625
[INFO] Global_t: 630, Episode_t: 6, Action: 150, Reward: 0.86, Epsilon: 0.37
[INFO] model update: t: 631, loss: 72128.4375
[INFO] Global_t: 631, Episode_t: 7, Action: 20, Reward: 1.95, Epsilon: 0.37
[INFO] model update: t: 632, loss: 35266.70703125
[INFO] Global_t: 632, Episode_t: 8, Action: 103, Reward: 1.07, Epsilon: 0.37
 32%|███▏      | 632/2000 [17:05<44:03,  1.93s/it]
[INFO] Global step: 632, Cumulative rewards: 20.70192, Runtime (s): 1025.76
------------------------------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 633, loss: 28840.685546875
[INFO] Global_t: 633, Episode_t: 1, Action: 5, Reward: 4.77, Epsilon: 0.37
[INFO] model update: t: 634, loss: 12654.4228515625
[INFO] Global_t: 634, Episode_t: 2, Action: 7, Reward: 3.16, Epsilon: 0.37
[INFO] model update: t: 635, loss: 53551.6484375
[INFO] Global_t: 635, Episode_t: 3, Action: 23, Reward: 1.70, Epsilon: 0.37
[INFO] model update: t: 636, loss: 54080.55078125
[INFO] Global_t: 636, Episode_t: 4, Action: 36, Reward: 2.19, Epsilon: 0.37
[INFO] model update: t: 637, loss: 25961.62109375
[INFO] Global_t: 637, Episode_t: 5, Action: 136, Reward: 1.09, Epsilon: 0.37
[INFO] model update: t: 638, loss: 35021.21484375
[INFO] Global_t: 638, Episode_t: 6, Action: 8, Reward: 2.52, Epsilon: 0.37
[INFO] model update: t: 639, loss: 55795.7265625
[INFO] Global_t: 639, Episode_t: 7, Action: 9, Reward: 2.04, Epsilon: 0.36
[INFO] model update: t: 640, loss: 72085.1640625
[INFO] Global_t: 640, Episode_t: 8, Action: 143, Reward: 1.40, Epsilon: 0.36
 32%|███▏      | 640/2000 [17:11<35:31,  1.57s/it]
[INFO] Global step: 640, Cumulative rewards: 18.87096, Runtime (s): 1031.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.9213762283325195
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7770071029663086
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4380877017974854
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.2864677906036377
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.83477783203125
average cummulative reward vector is:  [0.10625474 0.1156662  0.12401503 0.10313294 0.13065941]
average cummulative reward is:  0.1159456640791195
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 641, loss: 26410.0546875
[INFO] Global_t: 641, Episode_t: 1, Action: 4, Reward: 3.69, Epsilon: 0.36
[INFO] model update: t: 642, loss: 100440.78125
[INFO] Global_t: 642, Episode_t: 2, Action: 78, Reward: 2.05, Epsilon: 0.36
[INFO] model update: t: 643, loss: 20531.27734375
[INFO] Global_t: 643, Episode_t: 3, Action: 5, Reward: 3.99, Epsilon: 0.36
[INFO] model update: t: 644, loss: 30721.50390625
[INFO] Global_t: 644, Episode_t: 4, Action: 12, Reward: 2.65, Epsilon: 0.36
[INFO] model update: t: 645, loss: 14284.619140625
[INFO] Global_t: 645, Episode_t: 5, Action: 13, Reward: 1.98, Epsilon: 0.36
[INFO] model update: t: 646, loss: 60443.78125
[INFO] Global_t: 646, Episode_t: 6, Action: 31, Reward: 2.08, Epsilon: 0.36
[INFO] model update: t: 647, loss: 35626.0390625
[INFO] Global_t: 647, Episode_t: 7, Action: 11, Reward: 1.82, Epsilon: 0.36
[INFO] model update: t: 648, loss: 17591.759765625
[INFO] Global_t: 648, Episode_t: 8, Action: 41, Reward: 1.65, Epsilon: 0.36
 32%|███▏      | 648/2000 [17:34<44:15,  1.96s/it]
[INFO] Global step: 648, Cumulative rewards: 19.898159999999997, Runtime (s): 1054.60
------------------------------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 649, loss: 45290.2421875
[INFO] Global_t: 649, Episode_t: 1, Action: 5, Reward: 4.31, Epsilon: 0.35
[INFO] model update: t: 650, loss: 13798.716796875
[INFO] Global_t: 650, Episode_t: 2, Action: 91, Reward: 2.58, Epsilon: 0.35
[INFO] model update: t: 651, loss: 53090.6484375
[INFO] Global_t: 651, Episode_t: 3, Action: 13, Reward: 2.18, Epsilon: 0.35
[INFO] model update: t: 652, loss: 27729.5546875
[INFO] Global_t: 652, Episode_t: 4, Action: 92, Reward: 1.46, Epsilon: 0.35
[INFO] model update: t: 653, loss: 17328.97265625
[INFO] Global_t: 653, Episode_t: 5, Action: 85, Reward: 1.36, Epsilon: 0.35
[INFO] model update: t: 654, loss: 14416.291015625
[INFO] Global_t: 654, Episode_t: 6, Action: 143, Reward: 1.01, Epsilon: 0.35
[INFO] model update: t: 655, loss: 26974.791015625
[INFO] Global_t: 655, Episode_t: 7, Action: 0, Reward: 2.69, Epsilon: 0.35
[INFO] model update: t: 656, loss: 17073.478515625
[INFO] Global_t: 656, Episode_t: 8, Action: 7, Reward: 1.84, Epsilon: 0.35
 33%|███▎      | 656/2000 [17:39<34:41,  1.55s/it]
[INFO] Global step: 656, Cumulative rewards: 17.42124, Runtime (s): 1059.24
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3127737045288086
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.523531913757324
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.263202428817749
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.527487277984619
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5852270126342773
average cummulative reward vector is:  [0.11885579 0.11102569 0.11662268 0.11235164 0.13204113]
average cummulative reward is:  0.11817938521200677
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
[INFO] model update: t: 657, loss: 27268.23046875
[INFO] Global_t: 657, Episode_t: 1, Action: 77, Reward: 1.92, Epsilon: 0.35
[INFO] model update: t: 658, loss: 13848.3779296875
[INFO] Global_t: 658, Episode_t: 2, Action: 59, Reward: 1.76, Epsilon: 0.35
[INFO] model update: t: 659, loss: 14268.330078125
[INFO] Global_t: 659, Episode_t: 3, Action: 6, Reward: 4.26, Epsilon: 0.35
[INFO] model update: t: 660, loss: 9680.4609375
[INFO] Global_t: 660, Episode_t: 4, Action: 103, Reward: 1.72, Epsilon: 0.34
[INFO] model update: t: 661, loss: 12677.6982421875
[INFO] Global_t: 661, Episode_t: 5, Action: 7, Reward: 2.43, Epsilon: 0.34
[INFO] model update: t: 662, loss: 9494.08984375
[INFO] Global_t: 662, Episode_t: 6, Action: 11, Reward: 3.44, Epsilon: 0.34
[INFO] model update: t: 663, loss: 17049.63671875
[INFO] Global_t: 663, Episode_t: 7, Action: 10, Reward: 3.12, Epsilon: 0.34
[INFO] model update: t: 664, loss: 14595.41015625
[INFO] Global_t: 664, Episode_t: 8, Action: 26, Reward: 2.13, Epsilon: 0.34
 33%|███▎      | 664/2000 [17:59<41:09,  1.85s/it]
[INFO] Global step: 664, Cumulative rewards: 20.78076, Runtime (s): 1079.62
------------------------------------------------------------
 
graph: 83, nodes: 198, edges: 584
[INFO] model update: t: 665, loss: 4330.08984375
[INFO] Global_t: 665, Episode_t: 1, Action: 13, Reward: 4.14, Epsilon: 0.34
[INFO] model update: t: 666, loss: 11606.44140625
[INFO] Global_t: 666, Episode_t: 2, Action: 97, Reward: 1.57, Epsilon: 0.34
[INFO] model update: t: 667, loss: 12203.078125
[INFO] Global_t: 667, Episode_t: 3, Action: 12, Reward: 3.00, Epsilon: 0.34
[INFO] model update: t: 668, loss: 13764.85546875
[INFO] Global_t: 668, Episode_t: 4, Action: 0, Reward: 2.72, Epsilon: 0.34
[INFO] model update: t: 669, loss: 11093.6572265625
[INFO] Global_t: 669, Episode_t: 5, Action: 17, Reward: 2.15, Epsilon: 0.34
[INFO] model update: t: 670, loss: 5785.96728515625
[INFO] Global_t: 670, Episode_t: 6, Action: 9, Reward: 3.19, Epsilon: 0.33
[INFO] model update: t: 671, loss: 30079.19921875
[INFO] Global_t: 671, Episode_t: 7, Action: 139, Reward: 0.99, Epsilon: 0.33
[INFO] model update: t: 672, loss: 5461.16943359375
[INFO] Global_t: 672, Episode_t: 8, Action: 15, Reward: 2.22, Epsilon: 0.33
 34%|███▎      | 672/2000 [18:04<32:48,  1.48s/it]
[INFO] Global step: 672, Cumulative rewards: 19.96548, Runtime (s): 1084.66
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.443694829940796
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.541475296020508
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4261646270751953
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.899362802505493
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.785295248031616
average cummulative reward vector is:  [0.12435395 0.10770764 0.12984426 0.11953925 0.1354129 ]
average cummulative reward is:  0.12337160082292939
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 84, nodes: 205, edges: 606
[INFO] model update: t: 673, loss: 14589.708984375
[INFO] Global_t: 673, Episode_t: 1, Action: 88, Reward: 2.26, Epsilon: 0.33
[INFO] model update: t: 674, loss: 5516.24609375
[INFO] Global_t: 674, Episode_t: 2, Action: 9, Reward: 4.10, Epsilon: 0.33
[INFO] model update: t: 675, loss: 6843.39697265625
[INFO] Global_t: 675, Episode_t: 3, Action: 15, Reward: 3.18, Epsilon: 0.33
[INFO] model update: t: 676, loss: 7774.8671875
[INFO] Global_t: 676, Episode_t: 4, Action: 11, Reward: 2.69, Epsilon: 0.33
[INFO] model update: t: 677, loss: 12093.205078125
[INFO] Global_t: 677, Episode_t: 5, Action: 13, Reward: 2.12, Epsilon: 0.33
[INFO] model update: t: 678, loss: 14175.2587890625
[INFO] Global_t: 678, Episode_t: 6, Action: 20, Reward: 2.27, Epsilon: 0.33
[INFO] model update: t: 679, loss: 14678.48046875
[INFO] Global_t: 679, Episode_t: 7, Action: 8, Reward: 1.40, Epsilon: 0.33
[INFO] model update: t: 680, loss: 3321.3740234375
[INFO] Global_t: 680, Episode_t: 8, Action: 78, Reward: 1.03, Epsilon: 0.32
 34%|███▍      | 680/2000 [18:28<42:29,  1.93s/it]
[INFO] Global step: 680, Cumulative rewards: 19.04316, Runtime (s): 1108.48
------------------------------------------------------------
 
graph: 85, nodes: 212, edges: 627
[INFO] model update: t: 681, loss: 2915.02734375
[INFO] Global_t: 681, Episode_t: 1, Action: 6, Reward: 4.70, Epsilon: 0.32
[INFO] model update: t: 682, loss: 8346.53125
[INFO] Global_t: 682, Episode_t: 2, Action: 16, Reward: 3.29, Epsilon: 0.32
[INFO] model update: t: 683, loss: 9878.0234375
[INFO] Global_t: 683, Episode_t: 3, Action: 17, Reward: 2.90, Epsilon: 0.32
[INFO] model update: t: 684, loss: 11828.4287109375
[INFO] Global_t: 684, Episode_t: 4, Action: 28, Reward: 1.70, Epsilon: 0.32
[INFO] model update: t: 685, loss: 9290.431640625
[INFO] Global_t: 685, Episode_t: 5, Action: 18, Reward: 2.09, Epsilon: 0.32
[INFO] model update: t: 686, loss: 26223.517578125
[INFO] Global_t: 686, Episode_t: 6, Action: 7, Reward: 2.10, Epsilon: 0.32
[INFO] model update: t: 687, loss: 36406.7890625
[INFO] Global_t: 687, Episode_t: 7, Action: 144, Reward: 1.29, Epsilon: 0.32
[INFO] model update: t: 688, loss: 18329.00390625
[INFO] Global_t: 688, Episode_t: 8, Action: 156, Reward: 1.32, Epsilon: 0.32
 34%|███▍      | 688/2000 [18:34<34:36,  1.58s/it]
[INFO] Global step: 688, Cumulative rewards: 19.387439999999998, Runtime (s): 1114.64
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.366628885269165
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8337807655334473
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.230825662612915
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4655370712280273
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.841564178466797
average cummulative reward vector is:  [0.12216211 0.11425139 0.12028033 0.11182313 0.13375538]
average cummulative reward is:  0.12045446584122135
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 86, nodes: 200, edges: 591
[INFO] model update: t: 689, loss: 24504.0234375
[INFO] Global_t: 689, Episode_t: 1, Action: 0, Reward: 4.70, Epsilon: 0.32
[INFO] model update: t: 690, loss: 27227.21875
[INFO] Global_t: 690, Episode_t: 2, Action: 133, Reward: 1.79, Epsilon: 0.31
[INFO] model update: t: 691, loss: 13999.0263671875
[INFO] Global_t: 691, Episode_t: 3, Action: 3, Reward: 3.49, Epsilon: 0.31
[INFO] model update: t: 692, loss: 18127.23828125
[INFO] Global_t: 692, Episode_t: 4, Action: 12, Reward: 2.62, Epsilon: 0.31
[INFO] model update: t: 693, loss: 27027.935546875
[INFO] Global_t: 693, Episode_t: 5, Action: 1, Reward: 2.37, Epsilon: 0.31
[INFO] model update: t: 694, loss: 26187.921875
[INFO] Global_t: 694, Episode_t: 6, Action: 33, Reward: 1.82, Epsilon: 0.31
[INFO] model update: t: 695, loss: 36534.484375
[INFO] Global_t: 695, Episode_t: 7, Action: 5, Reward: 1.93, Epsilon: 0.31
[INFO] model update: t: 696, loss: 14146.10546875
[INFO] Global_t: 696, Episode_t: 8, Action: 14, Reward: 1.73, Epsilon: 0.31
 35%|███▍      | 696/2000 [18:57<43:05,  1.98s/it]
[INFO] Global step: 696, Cumulative rewards: 20.449439999999996, Runtime (s): 1137.96
------------------------------------------------------------
 
graph: 87, nodes: 218, edges: 645
[INFO] model update: t: 697, loss: 56143.734375
[INFO] Global_t: 697, Episode_t: 1, Action: 121, Reward: 1.95, Epsilon: 0.31
[INFO] model update: t: 698, loss: 22754.990234375
[INFO] Global_t: 698, Episode_t: 2, Action: 8, Reward: 5.32, Epsilon: 0.31
[INFO] model update: t: 699, loss: 29199.0234375
[INFO] Global_t: 699, Episode_t: 3, Action: 27, Reward: 1.92, Epsilon: 0.31
[INFO] model update: t: 700, loss: 42310.078125
[INFO] Global_t: 700, Episode_t: 4, Action: 6, Reward: 3.17, Epsilon: 0.30
[INFO] model update: t: 701, loss: 8818.3076171875
[INFO] Global_t: 701, Episode_t: 5, Action: 7, Reward: 3.50, Epsilon: 0.30
[INFO] model update: t: 702, loss: 61529.734375
[INFO] Global_t: 702, Episode_t: 6, Action: 0, Reward: 3.23, Epsilon: 0.30
[INFO] model update: t: 703, loss: 20335.48828125
[INFO] Global_t: 703, Episode_t: 7, Action: 2, Reward: 2.88, Epsilon: 0.30
[INFO] model update: t: 704, loss: 32614.234375
[INFO] Global_t: 704, Episode_t: 8, Action: 10, Reward: 2.22, Epsilon: 0.30
 35%|███▌      | 704/2000 [19:02<34:01,  1.58s/it]
[INFO] Global step: 704, Cumulative rewards: 24.18036, Runtime (s): 1142.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4204275608062744
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.2588632106781006
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2360496520996094
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5919668674468994
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6302037239074707
average cummulative reward vector is:  [0.12462421 0.1033294  0.11357486 0.11420794 0.13503737]
average cummulative reward is:  0.11815475631581471
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 88, nodes: 204, edges: 603
[INFO] model update: t: 705, loss: 16744.7265625
[INFO] Global_t: 705, Episode_t: 1, Action: 89, Reward: 1.75, Epsilon: 0.30
[INFO] model update: t: 706, loss: 21942.662109375
[INFO] Global_t: 706, Episode_t: 2, Action: 9, Reward: 4.74, Epsilon: 0.30
[INFO] model update: t: 707, loss: 22575.7734375
[INFO] Global_t: 707, Episode_t: 3, Action: 14, Reward: 3.13, Epsilon: 0.30
[INFO] model update: t: 708, loss: 33955.4765625
[INFO] Global_t: 708, Episode_t: 4, Action: 3, Reward: 4.26, Epsilon: 0.30
[INFO] model update: t: 709, loss: 28454.46875
[INFO] Global_t: 709, Episode_t: 5, Action: 12, Reward: 2.02, Epsilon: 0.30
[INFO] model update: t: 710, loss: 4836.33154296875
[INFO] Global_t: 710, Episode_t: 6, Action: 7, Reward: 2.15, Epsilon: 0.30
[INFO] model update: t: 711, loss: 39441.27734375
[INFO] Global_t: 711, Episode_t: 7, Action: 11, Reward: 1.35, Epsilon: 0.29
[INFO] model update: t: 712, loss: 93265.328125
[INFO] Global_t: 712, Episode_t: 8, Action: 5, Reward: 1.62, Epsilon: 0.29
 36%|███▌      | 712/2000 [19:25<41:27,  1.93s/it]
[INFO] Global step: 712, Cumulative rewards: 21.012960000000007, Runtime (s): 1165.05
------------------------------------------------------------
 
graph: 89, nodes: 199, edges: 588
[INFO] model update: t: 713, loss: 55923.95703125
[INFO] Global_t: 713, Episode_t: 1, Action: 108, Reward: 1.13, Epsilon: 0.29
[INFO] model update: t: 714, loss: 16310.62109375
[INFO] Global_t: 714, Episode_t: 2, Action: 7, Reward: 4.67, Epsilon: 0.29
[INFO] model update: t: 715, loss: 35344.99609375
[INFO] Global_t: 715, Episode_t: 3, Action: 3, Reward: 4.45, Epsilon: 0.29
[INFO] model update: t: 716, loss: 22841.08984375
[INFO] Global_t: 716, Episode_t: 4, Action: 5, Reward: 4.83, Epsilon: 0.29
[INFO] model update: t: 717, loss: 10603.275390625
[INFO] Global_t: 717, Episode_t: 5, Action: 16, Reward: 1.99, Epsilon: 0.29
[INFO] model update: t: 718, loss: 24866.650390625
[INFO] Global_t: 718, Episode_t: 6, Action: 70, Reward: 1.27, Epsilon: 0.29
[INFO] model update: t: 719, loss: 9781.7177734375
[INFO] Global_t: 719, Episode_t: 7, Action: 102, Reward: 1.24, Epsilon: 0.29
[INFO] model update: t: 720, loss: 21760.3046875
[INFO] Global_t: 720, Episode_t: 8, Action: 20, Reward: 2.58, Epsilon: 0.29
 36%|███▌      | 720/2000 [19:29<32:01,  1.50s/it]
[INFO] Global step: 720, Cumulative rewards: 22.14792, Runtime (s): 1169.03
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9314913749694824
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.790499687194824
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1297430992126465
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.655841112136841
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.620728015899658
average cummulative reward vector is:  [0.13094737 0.11927199 0.11754235 0.10572056 0.13166102]
average cummulative reward is:  0.12102865822832184
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 90, nodes: 207, edges: 612
[INFO] model update: t: 721, loss: 18625.2734375
[INFO] Global_t: 721, Episode_t: 1, Action: 3, Reward: 5.40, Epsilon: 0.28
[INFO] model update: t: 722, loss: 19413.505859375
[INFO] Global_t: 722, Episode_t: 2, Action: 6, Reward: 3.57, Epsilon: 0.28
[INFO] model update: t: 723, loss: 42457.09375
[INFO] Global_t: 723, Episode_t: 3, Action: 9, Reward: 2.51, Epsilon: 0.28
[INFO] model update: t: 724, loss: 6553.671875
[INFO] Global_t: 724, Episode_t: 4, Action: 11, Reward: 2.02, Epsilon: 0.28
[INFO] model update: t: 725, loss: 23820.03125
[INFO] Global_t: 725, Episode_t: 5, Action: 0, Reward: 1.13, Epsilon: 0.28
[INFO] model update: t: 726, loss: 27154.84765625
[INFO] Global_t: 726, Episode_t: 6, Action: 10, Reward: 1.85, Epsilon: 0.28
[INFO] model update: t: 727, loss: 29834.056640625
[INFO] Global_t: 727, Episode_t: 7, Action: 31, Reward: 1.58, Epsilon: 0.28
[INFO] model update: t: 728, loss: 7513.59912109375
[INFO] Global_t: 728, Episode_t: 8, Action: 45, Reward: 0.68, Epsilon: 0.28
 36%|███▋      | 728/2000 [19:53<41:21,  1.95s/it]
[INFO] Global step: 728, Cumulative rewards: 18.73884, Runtime (s): 1193.04
------------------------------------------------------------
 
graph: 91, nodes: 198, edges: 585
[INFO] model update: t: 729, loss: 8160.4912109375
[INFO] Global_t: 729, Episode_t: 1, Action: 46, Reward: 2.26, Epsilon: 0.28
[INFO] model update: t: 730, loss: 13841.671875
[INFO] Global_t: 730, Episode_t: 2, Action: 16, Reward: 2.56, Epsilon: 0.28
[INFO] model update: t: 731, loss: 13109.046875
[INFO] Global_t: 731, Episode_t: 3, Action: 13, Reward: 3.74, Epsilon: 0.27
[INFO] model update: t: 732, loss: 11649.8125
[INFO] Global_t: 732, Episode_t: 4, Action: 0, Reward: 3.67, Epsilon: 0.27
[INFO] model update: t: 733, loss: 32394.455078125
[INFO] Global_t: 733, Episode_t: 5, Action: 15, Reward: 2.89, Epsilon: 0.27
[INFO] model update: t: 734, loss: 19210.990234375
[INFO] Global_t: 734, Episode_t: 6, Action: 26, Reward: 2.58, Epsilon: 0.27
[INFO] model update: t: 735, loss: 21760.16796875
[INFO] Global_t: 735, Episode_t: 7, Action: 7, Reward: 2.44, Epsilon: 0.27
[INFO] model update: t: 736, loss: 51604.6484375
[INFO] Global_t: 736, Episode_t: 8, Action: 27, Reward: 1.74, Epsilon: 0.27
 37%|███▋      | 736/2000 [19:57<31:55,  1.52s/it]
[INFO] Global step: 736, Cumulative rewards: 21.888479999999994, Runtime (s): 1197.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.279675245285034
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.569430351257324
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.542874813079834
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3611490726470947
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.472975730895996
average cummulative reward vector is:  [0.11689132 0.10771505 0.12908388 0.10560257 0.11921048]
average cummulative reward is:  0.11570065916632329
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 92, nodes: 183, edges: 539
[INFO] model update: t: 737, loss: 49280.96484375
[INFO] Global_t: 737, Episode_t: 1, Action: 3, Reward: 4.91, Epsilon: 0.27
[INFO] model update: t: 738, loss: 9992.7314453125
[INFO] Global_t: 738, Episode_t: 2, Action: 129, Reward: 1.68, Epsilon: 0.27
[INFO] model update: t: 739, loss: 45194.6328125
[INFO] Global_t: 739, Episode_t: 3, Action: 41, Reward: 3.74, Epsilon: 0.27
[INFO] model update: t: 740, loss: 23152.482421875
[INFO] Global_t: 740, Episode_t: 4, Action: 12, Reward: 4.00, Epsilon: 0.27
[INFO] model update: t: 741, loss: 45828.15234375
[INFO] Global_t: 741, Episode_t: 5, Action: 2, Reward: 3.03, Epsilon: 0.26
[INFO] model update: t: 742, loss: 91422.34375
[INFO] Global_t: 742, Episode_t: 6, Action: 13, Reward: 3.26, Epsilon: 0.26
[INFO] model update: t: 743, loss: 8411.765625
[INFO] Global_t: 743, Episode_t: 7, Action: 22, Reward: 3.24, Epsilon: 0.26
[INFO] model update: t: 744, loss: 89262.2109375
[INFO] Global_t: 744, Episode_t: 8, Action: 20, Reward: 2.91, Epsilon: 0.26
 37%|███▋      | 744/2000 [20:17<38:28,  1.84s/it]
[INFO] Global step: 744, Cumulative rewards: 26.76732, Runtime (s): 1217.75
------------------------------------------------------------
 
graph: 93, nodes: 217, edges: 642
[INFO] model update: t: 745, loss: 60464.55859375
[INFO] Global_t: 745, Episode_t: 1, Action: 3, Reward: 4.57, Epsilon: 0.26
[INFO] model update: t: 746, loss: 6726.28369140625
[INFO] Global_t: 746, Episode_t: 2, Action: 136, Reward: 2.07, Epsilon: 0.26
[INFO] model update: t: 747, loss: 38713.00390625
[INFO] Global_t: 747, Episode_t: 3, Action: 6, Reward: 3.99, Epsilon: 0.26
[INFO] model update: t: 748, loss: 13691.7412109375
[INFO] Global_t: 748, Episode_t: 4, Action: 30, Reward: 2.21, Epsilon: 0.26
[INFO] model update: t: 749, loss: 8838.64453125
[INFO] Global_t: 749, Episode_t: 5, Action: 13, Reward: 4.17, Epsilon: 0.26
[INFO] model update: t: 750, loss: 10507.015625
[INFO] Global_t: 750, Episode_t: 6, Action: 12, Reward: 3.00, Epsilon: 0.26
[INFO] model update: t: 751, loss: 8452.2587890625
[INFO] Global_t: 751, Episode_t: 7, Action: 144, Reward: 0.91, Epsilon: 0.26
[INFO] model update: t: 752, loss: 10017.3115234375
[INFO] Global_t: 752, Episode_t: 8, Action: 104, Reward: 1.53, Epsilon: 0.25
 38%|███▊      | 752/2000 [20:21<29:31,  1.42s/it]
[INFO] Global step: 752, Cumulative rewards: 22.45176, Runtime (s): 1221.31
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3727283477783203
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.618190288543701
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4544708728790283
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.334679365158081
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5587639808654785
average cummulative reward vector is:  [0.11778553 0.11066134 0.12709836 0.1020507  0.13043952]
average cummulative reward is:  0.11760708932554631
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 94, nodes: 198, edges: 585
[INFO] model update: t: 753, loss: 13433.806640625
[INFO] Global_t: 753, Episode_t: 1, Action: 121, Reward: 1.47, Epsilon: 0.25
[INFO] model update: t: 754, loss: 13148.4228515625
[INFO] Global_t: 754, Episode_t: 2, Action: 4, Reward: 4.88, Epsilon: 0.25
[INFO] model update: t: 755, loss: 13927.421875
[INFO] Global_t: 755, Episode_t: 3, Action: 7, Reward: 3.68, Epsilon: 0.25
[INFO] model update: t: 756, loss: 19039.18359375
[INFO] Global_t: 756, Episode_t: 4, Action: 16, Reward: 3.20, Epsilon: 0.25
[INFO] model update: t: 757, loss: 6437.4375
[INFO] Global_t: 757, Episode_t: 5, Action: 30, Reward: 2.84, Epsilon: 0.25
[INFO] model update: t: 758, loss: 26915.68359375
[INFO] Global_t: 758, Episode_t: 6, Action: 154, Reward: 1.56, Epsilon: 0.25
[INFO] model update: t: 759, loss: 12504.3037109375
[INFO] Global_t: 759, Episode_t: 7, Action: 166, Reward: 1.53, Epsilon: 0.25
[INFO] model update: t: 760, loss: 46658.1796875
[INFO] Global_t: 760, Episode_t: 8, Action: 28, Reward: 2.68, Epsilon: 0.25
 38%|███▊      | 760/2000 [20:43<37:24,  1.81s/it]
[INFO] Global step: 760, Cumulative rewards: 21.83928, Runtime (s): 1243.07
------------------------------------------------------------
 
graph: 95, nodes: 202, edges: 597
[INFO] model update: t: 761, loss: 156475.875
[INFO] Global_t: 761, Episode_t: 1, Action: 159, Reward: 1.73, Epsilon: 0.25
[INFO] model update: t: 762, loss: 72450.7890625
[INFO] Global_t: 762, Episode_t: 2, Action: 13, Reward: 3.98, Epsilon: 0.24
[INFO] model update: t: 763, loss: 11115.8173828125
[INFO] Global_t: 763, Episode_t: 3, Action: 118, Reward: 1.46, Epsilon: 0.24
[INFO] model update: t: 764, loss: 101970.84375
[INFO] Global_t: 764, Episode_t: 4, Action: 29, Reward: 2.74, Epsilon: 0.24
[INFO] model update: t: 765, loss: 71487.109375
[INFO] Global_t: 765, Episode_t: 5, Action: 36, Reward: 2.98, Epsilon: 0.24
[INFO] model update: t: 766, loss: 28610.81640625
[INFO] Global_t: 766, Episode_t: 6, Action: 23, Reward: 2.71, Epsilon: 0.24
[INFO] model update: t: 767, loss: 79798.3515625
[INFO] Global_t: 767, Episode_t: 7, Action: 34, Reward: 2.54, Epsilon: 0.24
[INFO] model update: t: 768, loss: 104300.78125
[INFO] Global_t: 768, Episode_t: 8, Action: 11, Reward: 2.57, Epsilon: 0.24
 38%|███▊      | 768/2000 [20:47<29:09,  1.42s/it]
[INFO] Global step: 768, Cumulative rewards: 20.700599999999998, Runtime (s): 1247.16
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.423109531402588
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.076719760894775
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2161481380462646
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8253700733184814
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4316070079803467
average cummulative reward vector is:  [0.12476132 0.12321991 0.12191803 0.11901846 0.12022903]
average cummulative reward is:  0.12182934923715123
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 96, nodes: 200, edges: 591
[INFO] model update: t: 769, loss: 9236.001953125
[INFO] Global_t: 769, Episode_t: 1, Action: 36, Reward: 1.68, Epsilon: 0.24
[INFO] model update: t: 770, loss: 183870.34375
[INFO] Global_t: 770, Episode_t: 2, Action: 4, Reward: 4.35, Epsilon: 0.24
[INFO] model update: t: 771, loss: 134520.53125
[INFO] Global_t: 771, Episode_t: 3, Action: 198, Reward: 1.00, Epsilon: 0.24
[INFO] model update: t: 772, loss: 11463.0546875
[INFO] Global_t: 772, Episode_t: 4, Action: 7, Reward: 3.36, Epsilon: 0.23
[INFO] model update: t: 773, loss: 146764.375
[INFO] Global_t: 773, Episode_t: 5, Action: 8, Reward: 2.30, Epsilon: 0.23
[INFO] model update: t: 774, loss: 144744.546875
[INFO] Global_t: 774, Episode_t: 6, Action: 9, Reward: 2.27, Epsilon: 0.23
[INFO] model update: t: 775, loss: 6948.8095703125
[INFO] Global_t: 775, Episode_t: 7, Action: 16, Reward: 2.02, Epsilon: 0.23
[INFO] model update: t: 776, loss: 110983.328125
[INFO] Global_t: 776, Episode_t: 8, Action: 6, Reward: 2.16, Epsilon: 0.23
 39%|███▉      | 776/2000 [21:09<37:42,  1.85s/it]
[INFO] Global step: 776, Cumulative rewards: 19.12824, Runtime (s): 1269.93
------------------------------------------------------------
 
graph: 97, nodes: 206, edges: 609
[INFO] model update: t: 777, loss: 95893.4765625
[INFO] Global_t: 777, Episode_t: 1, Action: 7, Reward: 4.47, Epsilon: 0.23
[INFO] model update: t: 778, loss: 18639.36328125
[INFO] Global_t: 778, Episode_t: 2, Action: 9, Reward: 3.99, Epsilon: 0.23
[INFO] model update: t: 779, loss: 125715.8828125
[INFO] Global_t: 779, Episode_t: 3, Action: 71, Reward: 1.91, Epsilon: 0.23
[INFO] model update: t: 780, loss: 38325.04296875
[INFO] Global_t: 780, Episode_t: 4, Action: 56, Reward: 2.69, Epsilon: 0.23
[INFO] model update: t: 781, loss: 17599.908203125
[INFO] Global_t: 781, Episode_t: 5, Action: 35, Reward: 2.21, Epsilon: 0.23
[INFO] model update: t: 782, loss: 41750.83203125
[INFO] Global_t: 782, Episode_t: 6, Action: 58, Reward: 1.31, Epsilon: 0.22
[INFO] model update: t: 783, loss: 4201.84033203125
[INFO] Global_t: 783, Episode_t: 7, Action: 5, Reward: 2.31, Epsilon: 0.22
[INFO] model update: t: 784, loss: 20539.16015625
[INFO] Global_t: 784, Episode_t: 8, Action: 3, Reward: 3.22, Epsilon: 0.22

[INFO] Global step: 784, Cumulative rewards: 22.1142, Runtime (s): 1274.93
 39%|███▉      | 784/2000 [21:14<30:01,  1.48s/it]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.968754768371582
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6207432746887207
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4146039485931396
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6657731533050537
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.489877462387085
average cummulative reward vector is:  [0.10751237 0.11298472 0.12134481 0.11778972 0.12961129]
average cummulative reward is:  0.11784858186703862
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 98, nodes: 206, edges: 607
[INFO] model update: t: 785, loss: 8420.3662109375
[INFO] Global_t: 785, Episode_t: 1, Action: 1, Reward: 4.17, Epsilon: 0.22
[INFO] model update: t: 786, loss: 13468.7783203125
[INFO] Global_t: 786, Episode_t: 2, Action: 0, Reward: 3.36, Epsilon: 0.22
[INFO] model update: t: 787, loss: 29900.677734375
[INFO] Global_t: 787, Episode_t: 3, Action: 167, Reward: 1.60, Epsilon: 0.22
[INFO] model update: t: 788, loss: 8343.15234375
[INFO] Global_t: 788, Episode_t: 4, Action: 2, Reward: 3.75, Epsilon: 0.22
[INFO] model update: t: 789, loss: 14269.8388671875
[INFO] Global_t: 789, Episode_t: 5, Action: 8, Reward: 2.25, Epsilon: 0.22
[INFO] model update: t: 790, loss: 10900.7607421875
[INFO] Global_t: 790, Episode_t: 6, Action: 9, Reward: 1.90, Epsilon: 0.22
[INFO] model update: t: 791, loss: 5915.1298828125
[INFO] Global_t: 791, Episode_t: 7, Action: 42, Reward: 2.20, Epsilon: 0.22
[INFO] model update: t: 792, loss: 2066.13916015625
[INFO] Global_t: 792, Episode_t: 8, Action: 10, Reward: 2.50, Epsilon: 0.21
 40%|███▉      | 792/2000 [21:40<40:26,  2.01s/it]
[INFO] Global step: 792, Cumulative rewards: 21.71604, Runtime (s): 1300.86
------------------------------------------------------------
 
graph: 99, nodes: 181, edges: 533
[INFO] model update: t: 793, loss: 6141.3935546875
[INFO] Global_t: 793, Episode_t: 1, Action: 6, Reward: 3.32, Epsilon: 0.21
[INFO] model update: t: 794, loss: 32582.67578125
[INFO] Global_t: 794, Episode_t: 2, Action: 9, Reward: 4.70, Epsilon: 0.21
[INFO] model update: t: 795, loss: 39496.72265625
[INFO] Global_t: 795, Episode_t: 3, Action: 43, Reward: 3.54, Epsilon: 0.21
[INFO] model update: t: 796, loss: 12004.634765625
[INFO] Global_t: 796, Episode_t: 4, Action: 22, Reward: 3.14, Epsilon: 0.21
[INFO] model update: t: 797, loss: 26285.802734375
[INFO] Global_t: 797, Episode_t: 5, Action: 28, Reward: 1.97, Epsilon: 0.21
[INFO] model update: t: 798, loss: 22248.75
[INFO] Global_t: 798, Episode_t: 6, Action: 34, Reward: 2.68, Epsilon: 0.21
[INFO] model update: t: 799, loss: 15962.1064453125
[INFO] Global_t: 799, Episode_t: 7, Action: 16, Reward: 2.47, Epsilon: 0.21
[INFO] model update: t: 800, loss: 107286.359375
[INFO] Global_t: 800, Episode_t: 8, Action: 93, Reward: 1.14, Epsilon: 0.21
 40%|████      | 800/2000 [21:48<34:05,  1.70s/it]
[INFO] Global step: 800, Cumulative rewards: 22.957319999999996, Runtime (s): 1308.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.403904676437378
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.782608985900879
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.447308301925659
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6156511306762695
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5840067863464355
average cummulative reward vector is:  [0.12230105 0.11516898 0.12879071 0.11420164 0.12705645]
average cummulative reward is:  0.12150376632449919
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 100, nodes: 188, edges: 555
[INFO] model update: t: 801, loss: 79661.453125
[INFO] Global_t: 801, Episode_t: 1, Action: 4, Reward: 5.23, Epsilon: 0.21
[INFO] model update: t: 802, loss: 5707.23583984375
[INFO] Global_t: 802, Episode_t: 2, Action: 124, Reward: 1.80, Epsilon: 0.21
[INFO] model update: t: 803, loss: 44055.875
[INFO] Global_t: 803, Episode_t: 3, Action: 12, Reward: 3.55, Epsilon: 0.20
[INFO] model update: t: 804, loss: 23394.896484375
[INFO] Global_t: 804, Episode_t: 4, Action: 16, Reward: 3.02, Epsilon: 0.20
[INFO] model update: t: 805, loss: 56875.21484375
[INFO] Global_t: 805, Episode_t: 5, Action: 7, Reward: 3.10, Epsilon: 0.20
[INFO] model update: t: 806, loss: 78256.9921875
[INFO] Global_t: 806, Episode_t: 6, Action: 6, Reward: 4.64, Epsilon: 0.20
[INFO] model update: t: 807, loss: 4836.115234375
[INFO] Global_t: 807, Episode_t: 7, Action: 170, Reward: 0.97, Epsilon: 0.20
[INFO] model update: t: 808, loss: 79262.8125
[INFO] Global_t: 808, Episode_t: 8, Action: 14, Reward: 2.37, Epsilon: 0.20
 40%|████      | 808/2000 [22:10<39:55,  2.01s/it]
[INFO] Global step: 808, Cumulative rewards: 24.685200000000002, Runtime (s): 1330.58
------------------------------------------------------------
 
graph: 101, nodes: 211, edges: 624
[INFO] model update: t: 809, loss: 37695.65625
[INFO] Global_t: 809, Episode_t: 1, Action: 10, Reward: 4.56, Epsilon: 0.20
[INFO] model update: t: 810, loss: 45252.25
[INFO] Global_t: 810, Episode_t: 2, Action: 14, Reward: 3.78, Epsilon: 0.20
[INFO] model update: t: 811, loss: 154205.234375
[INFO] Global_t: 811, Episode_t: 3, Action: 6, Reward: 4.48, Epsilon: 0.20
[INFO] model update: t: 812, loss: 45910.75
[INFO] Global_t: 812, Episode_t: 4, Action: 105, Reward: 1.76, Epsilon: 0.20
[INFO] model update: t: 813, loss: 67416.171875
[INFO] Global_t: 813, Episode_t: 5, Action: 5, Reward: 2.77, Epsilon: 0.19
[INFO] model update: t: 814, loss: 148278.203125
[INFO] Global_t: 814, Episode_t: 6, Action: 12, Reward: 3.26, Epsilon: 0.19
[INFO] model update: t: 815, loss: 48575.79296875
[INFO] Global_t: 815, Episode_t: 7, Action: 97, Reward: 0.88, Epsilon: 0.19
[INFO] model update: t: 816, loss: 33755.0546875
[INFO] Global_t: 816, Episode_t: 8, Action: 173, Reward: 1.21, Epsilon: 0.19
 41%|████      | 816/2000 [22:15<31:33,  1.60s/it]
[INFO] Global step: 816, Cumulative rewards: 22.694640000000003, Runtime (s): 1335.72
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7004220485687256
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7447478771209717
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.452737331390381
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3832995891571045
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.2233312129974365
average cummulative reward vector is:  [0.12236263 0.1137412  0.12362705 0.1098965  0.12120618]
average cummulative reward is:  0.11816671251715613
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 102, nodes: 180, edges: 531
[INFO] model update: t: 817, loss: 120942.9765625
[INFO] Global_t: 817, Episode_t: 1, Action: 22, Reward: 3.96, Epsilon: 0.19
[INFO] model update: t: 818, loss: 39736.4375
[INFO] Global_t: 818, Episode_t: 2, Action: 7, Reward: 4.94, Epsilon: 0.19
[INFO] model update: t: 819, loss: 38489.625
[INFO] Global_t: 819, Episode_t: 3, Action: 36, Reward: 2.01, Epsilon: 0.19
[INFO] model update: t: 820, loss: 190550.8125
[INFO] Global_t: 820, Episode_t: 4, Action: 17, Reward: 2.57, Epsilon: 0.19
[INFO] model update: t: 821, loss: 115765.59375
[INFO] Global_t: 821, Episode_t: 5, Action: 2, Reward: 2.17, Epsilon: 0.19
[INFO] model update: t: 822, loss: 30832.1484375
[INFO] Global_t: 822, Episode_t: 6, Action: 5, Reward: 2.75, Epsilon: 0.19
[INFO] model update: t: 823, loss: 168424.40625
[INFO] Global_t: 823, Episode_t: 7, Action: 18, Reward: 1.16, Epsilon: 0.18
[INFO] model update: t: 824, loss: 35509.41015625
[INFO] Global_t: 824, Episode_t: 8, Action: 30, Reward: 1.84, Epsilon: 0.18
 41%|████      | 824/2000 [22:38<38:55,  1.99s/it]
[INFO] Global step: 824, Cumulative rewards: 21.394560000000002, Runtime (s): 1358.81
------------------------------------------------------------
 
graph: 103, nodes: 187, edges: 551
[INFO] model update: t: 825, loss: 71547.640625
[INFO] Global_t: 825, Episode_t: 1, Action: 14, Reward: 4.34, Epsilon: 0.18
[INFO] model update: t: 826, loss: 136088.109375
[INFO] Global_t: 826, Episode_t: 2, Action: 151, Reward: 1.58, Epsilon: 0.18
[INFO] model update: t: 827, loss: 8574.466796875
[INFO] Global_t: 827, Episode_t: 3, Action: 1, Reward: 3.69, Epsilon: 0.18
[INFO] model update: t: 828, loss: 129768.5625
[INFO] Global_t: 828, Episode_t: 4, Action: 11, Reward: 2.66, Epsilon: 0.18
[INFO] model update: t: 829, loss: 137283.40625
[INFO] Global_t: 829, Episode_t: 5, Action: 22, Reward: 1.80, Epsilon: 0.18
[INFO] model update: t: 830, loss: 15451.2998046875
[INFO] Global_t: 830, Episode_t: 6, Action: 25, Reward: 2.40, Epsilon: 0.18
[INFO] model update: t: 831, loss: 59293.7109375
[INFO] Global_t: 831, Episode_t: 7, Action: 9, Reward: 1.63, Epsilon: 0.18
[INFO] model update: t: 832, loss: 52095.73046875
[INFO] Global_t: 832, Episode_t: 8, Action: 12, Reward: 2.10, Epsilon: 0.18
 42%|████▏     | 832/2000 [22:42<30:06,  1.55s/it]
[INFO] Global step: 832, Cumulative rewards: 20.192639999999997, Runtime (s): 1362.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.815606117248535
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5242700576782227
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.230011463165283
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9721641540527344
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.3411192893981934
average cummulative reward vector is:  [0.12893579 0.10757523 0.1191735  0.11642126 0.12363844]
average cummulative reward is:  0.11914884415307665
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 104, nodes: 185, edges: 546
[INFO] model update: t: 833, loss: 11780.884765625
[INFO] Global_t: 833, Episode_t: 1, Action: 7, Reward: 3.88, Epsilon: 0.17
[INFO] model update: t: 834, loss: 62177.4140625
[INFO] Global_t: 834, Episode_t: 2, Action: 160, Reward: 1.46, Epsilon: 0.17
[INFO] model update: t: 835, loss: 15706.33984375
[INFO] Global_t: 835, Episode_t: 3, Action: 10, Reward: 2.85, Epsilon: 0.17
[INFO] model update: t: 836, loss: 77431.5625
[INFO] Global_t: 836, Episode_t: 4, Action: 60, Reward: 1.62, Epsilon: 0.17
[INFO] model update: t: 837, loss: 20741.861328125
[INFO] Global_t: 837, Episode_t: 5, Action: 31, Reward: 1.68, Epsilon: 0.17
[INFO] model update: t: 838, loss: 194771.453125
[INFO] Global_t: 838, Episode_t: 6, Action: 1, Reward: 2.34, Epsilon: 0.17
[INFO] model update: t: 839, loss: 133083.890625
[INFO] Global_t: 839, Episode_t: 7, Action: 13, Reward: 2.18, Epsilon: 0.17
[INFO] model update: t: 840, loss: 11977.01953125
[INFO] Global_t: 840, Episode_t: 8, Action: 65, Reward: 0.81, Epsilon: 0.17
 42%|████▏     | 840/2000 [23:05<37:28,  1.94s/it]
[INFO] Global step: 840, Cumulative rewards: 16.825200000000002, Runtime (s): 1385.80
------------------------------------------------------------
 
graph: 105, nodes: 180, edges: 531
[INFO] model update: t: 841, loss: 179266.1875
[INFO] Global_t: 841, Episode_t: 1, Action: 4, Reward: 4.12, Epsilon: 0.17
[INFO] model update: t: 842, loss: 291383.625
[INFO] Global_t: 842, Episode_t: 2, Action: 7, Reward: 3.74, Epsilon: 0.17
[INFO] model update: t: 843, loss: 84527.9921875
[INFO] Global_t: 843, Episode_t: 3, Action: 6, Reward: 3.09, Epsilon: 0.16
[INFO] model update: t: 844, loss: 75530.125
[INFO] Global_t: 844, Episode_t: 4, Action: 5, Reward: 3.18, Epsilon: 0.16
[INFO] model update: t: 845, loss: 329754.875
[INFO] Global_t: 845, Episode_t: 5, Action: 12, Reward: 3.02, Epsilon: 0.16
[INFO] model update: t: 846, loss: 127153.03125
[INFO] Global_t: 846, Episode_t: 6, Action: 2, Reward: 3.60, Epsilon: 0.16
[INFO] model update: t: 847, loss: 61907.390625
[INFO] Global_t: 847, Episode_t: 7, Action: 46, Reward: 1.89, Epsilon: 0.16
[INFO] model update: t: 848, loss: 321701.5625
[INFO] Global_t: 848, Episode_t: 8, Action: 36, Reward: 1.72, Epsilon: 0.16
 42%|████▏     | 848/2000 [23:09<28:53,  1.50s/it]
[INFO] Global step: 848, Cumulative rewards: 24.36144, Runtime (s): 1389.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.320702075958252
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.905641794204712
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.406235694885254
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3899612426757812
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6087024211883545
average cummulative reward vector is:  [0.11753974 0.10833009 0.12612158 0.10782453 0.12799059]
average cummulative reward is:  0.11756130764845625
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 106, nodes: 206, edges: 608
[INFO] model update: t: 849, loss: 34490.58984375
[INFO] Global_t: 849, Episode_t: 1, Action: 120, Reward: 1.77, Epsilon: 0.16
[INFO] model update: t: 850, loss: 215583.84375
[INFO] Global_t: 850, Episode_t: 2, Action: 76, Reward: 1.92, Epsilon: 0.16
[INFO] model update: t: 851, loss: 401962.625
[INFO] Global_t: 851, Episode_t: 3, Action: 22, Reward: 2.12, Epsilon: 0.16
[INFO] model update: t: 852, loss: 110073.6015625
[INFO] Global_t: 852, Episode_t: 4, Action: 198, Reward: 1.73, Epsilon: 0.16
[INFO] model update: t: 853, loss: 78301.1796875
[INFO] Global_t: 853, Episode_t: 5, Action: 10, Reward: 3.82, Epsilon: 0.16
[INFO] model update: t: 854, loss: 423751.6875
[INFO] Global_t: 854, Episode_t: 6, Action: 17, Reward: 3.43, Epsilon: 0.15
[INFO] model update: t: 855, loss: 345905.90625
[INFO] Global_t: 855, Episode_t: 7, Action: 39, Reward: 2.16, Epsilon: 0.15
[INFO] model update: t: 856, loss: 22767.78515625
[INFO] Global_t: 856, Episode_t: 8, Action: 28, Reward: 2.54, Epsilon: 0.15
 43%|████▎     | 856/2000 [23:30<35:10,  1.85s/it]
[INFO] Global step: 856, Cumulative rewards: 19.47852, Runtime (s): 1410.86
------------------------------------------------------------
 
graph: 107, nodes: 205, edges: 606
[INFO] model update: t: 857, loss: 110415.1640625
[INFO] Global_t: 857, Episode_t: 1, Action: 6, Reward: 3.91, Epsilon: 0.15
[INFO] model update: t: 858, loss: 102838.1484375
[INFO] Global_t: 858, Episode_t: 2, Action: 103, Reward: 1.72, Epsilon: 0.15
[INFO] model update: t: 859, loss: 5204.2255859375
[INFO] Global_t: 859, Episode_t: 3, Action: 4, Reward: 3.06, Epsilon: 0.15
[INFO] model update: t: 860, loss: 89539.7734375
[INFO] Global_t: 860, Episode_t: 4, Action: 9, Reward: 3.08, Epsilon: 0.15
[INFO] model update: t: 861, loss: 52274.375
[INFO] Global_t: 861, Episode_t: 5, Action: 11, Reward: 3.01, Epsilon: 0.15
[INFO] model update: t: 862, loss: 25573.30859375
[INFO] Global_t: 862, Episode_t: 6, Action: 48, Reward: 1.32, Epsilon: 0.15
[INFO] model update: t: 863, loss: 123198.328125
[INFO] Global_t: 863, Episode_t: 7, Action: 21, Reward: 2.89, Epsilon: 0.15
[INFO] model update: t: 864, loss: 15154.1298828125
[INFO] Global_t: 864, Episode_t: 8, Action: 13, Reward: 2.52, Epsilon: 0.14
 43%|████▎     | 864/2000 [23:34<27:08,  1.43s/it]
[INFO] Global step: 864, Cumulative rewards: 21.512399999999996, Runtime (s): 1414.65
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.320406913757324
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.873251438140869
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.265064001083374
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.822613000869751
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.898045301437378
average cummulative reward vector is:  [0.11719447 0.12264213 0.12191393 0.10880234 0.1357922 ]
average cummulative reward is:  0.12126901569794861
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 108, nodes: 215, edges: 636
[INFO] model update: t: 865, loss: 141077.078125
[INFO] Global_t: 865, Episode_t: 1, Action: 7, Reward: 4.61, Epsilon: 0.14
[INFO] model update: t: 866, loss: 398441.75
[INFO] Global_t: 866, Episode_t: 2, Action: 6, Reward: 3.92, Epsilon: 0.14
[INFO] model update: t: 867, loss: 41316.0625
[INFO] Global_t: 867, Episode_t: 3, Action: 21, Reward: 3.55, Epsilon: 0.14
[INFO] model update: t: 868, loss: 265883.78125
[INFO] Global_t: 868, Episode_t: 4, Action: 20, Reward: 2.47, Epsilon: 0.14
[INFO] model update: t: 869, loss: 520159.875
[INFO] Global_t: 869, Episode_t: 5, Action: 8, Reward: 3.07, Epsilon: 0.14
[INFO] model update: t: 870, loss: 84456.390625
[INFO] Global_t: 870, Episode_t: 6, Action: 9, Reward: 4.09, Epsilon: 0.14
[INFO] model update: t: 871, loss: 1199614.5
[INFO] Global_t: 871, Episode_t: 7, Action: 3, Reward: 2.50, Epsilon: 0.14
[INFO] model update: t: 872, loss: 1132710.625
[INFO] Global_t: 872, Episode_t: 8, Action: 13, Reward: 2.16, Epsilon: 0.14
 44%|████▎     | 872/2000 [23:57<35:11,  1.87s/it]
[INFO] Global step: 872, Cumulative rewards: 26.36124, Runtime (s): 1437.82
------------------------------------------------------------
 
graph: 109, nodes: 186, edges: 549
[INFO] model update: t: 873, loss: 3127.135009765625
[INFO] Global_t: 873, Episode_t: 1, Action: 14, Reward: 3.95, Epsilon: 0.14
[INFO] model update: t: 874, loss: 867538.25
[INFO] Global_t: 874, Episode_t: 2, Action: 5, Reward: 3.48, Epsilon: 0.13
[INFO] model update: t: 875, loss: 486612.78125
[INFO] Global_t: 875, Episode_t: 3, Action: 8, Reward: 4.00, Epsilon: 0.13
[INFO] model update: t: 876, loss: 23557.544921875
[INFO] Global_t: 876, Episode_t: 4, Action: 9, Reward: 3.91, Epsilon: 0.13
[INFO] model update: t: 877, loss: 579413.125
[INFO] Global_t: 877, Episode_t: 5, Action: 7, Reward: 3.45, Epsilon: 0.13
[INFO] model update: t: 878, loss: 197909.5625
[INFO] Global_t: 878, Episode_t: 6, Action: 24, Reward: 2.38, Epsilon: 0.13
[INFO] model update: t: 879, loss: 27950.57421875
[INFO] Global_t: 879, Episode_t: 7, Action: 49, Reward: 1.68, Epsilon: 0.13
[INFO] model update: t: 880, loss: 396015.625
[INFO] Global_t: 880, Episode_t: 8, Action: 0, Reward: 1.78, Epsilon: 0.13
 44%|████▍     | 880/2000 [24:02<27:25,  1.47s/it]
[INFO] Global step: 880, Cumulative rewards: 24.63, Runtime (s): 1442.04
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5233473777770996
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.042806148529053
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.235538959503174
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5874524116516113
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.783135175704956
average cummulative reward vector is:  [0.12662711 0.11974306 0.1209959  0.11558458 0.12895188]
average cummulative reward is:  0.12238050472354804
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 110, nodes: 180, edges: 531
[INFO] model update: t: 881, loss: 282561.78125
[INFO] Global_t: 881, Episode_t: 1, Action: 5, Reward: 4.36, Epsilon: 0.13
[INFO] model update: t: 882, loss: 17513.19921875
[INFO] Global_t: 882, Episode_t: 2, Action: 10, Reward: 3.40, Epsilon: 0.13
[INFO] model update: t: 883, loss: 101232.640625
[INFO] Global_t: 883, Episode_t: 3, Action: 8, Reward: 3.88, Epsilon: 0.13
[INFO] model update: t: 884, loss: 37842.03125
[INFO] Global_t: 884, Episode_t: 4, Action: 6, Reward: 4.21, Epsilon: 0.12
[INFO] model update: t: 885, loss: 74133.46875
[INFO] Global_t: 885, Episode_t: 5, Action: 1, Reward: 3.19, Epsilon: 0.12
[INFO] model update: t: 886, loss: 77381.46875
[INFO] Global_t: 886, Episode_t: 6, Action: 12, Reward: 3.06, Epsilon: 0.12
[INFO] model update: t: 887, loss: 16681.92578125
[INFO] Global_t: 887, Episode_t: 7, Action: 38, Reward: 1.60, Epsilon: 0.12
[INFO] model update: t: 888, loss: 5958.90771484375
[INFO] Global_t: 888, Episode_t: 8, Action: 2, Reward: 2.32, Epsilon: 0.12
 44%|████▍     | 888/2000 [24:26<36:05,  1.95s/it]
[INFO] Global step: 888, Cumulative rewards: 26.030279999999998, Runtime (s): 1466.56
------------------------------------------------------------
 
graph: 111, nodes: 200, edges: 591
[INFO] model update: t: 889, loss: 5759.416015625
[INFO] Global_t: 889, Episode_t: 1, Action: 6, Reward: 3.78, Epsilon: 0.12
[INFO] model update: t: 890, loss: 5633.39501953125
[INFO] Global_t: 890, Episode_t: 2, Action: 33, Reward: 2.72, Epsilon: 0.12
[INFO] model update: t: 891, loss: 10709.93359375
[INFO] Global_t: 891, Episode_t: 3, Action: 4, Reward: 4.06, Epsilon: 0.12
[INFO] model update: t: 892, loss: 5913.408203125
[INFO] Global_t: 892, Episode_t: 4, Action: 11, Reward: 3.25, Epsilon: 0.12
[INFO] model update: t: 893, loss: 4809.31640625
[INFO] Global_t: 893, Episode_t: 5, Action: 2, Reward: 2.40, Epsilon: 0.12
[INFO] model update: t: 894, loss: 4148.78173828125
[INFO] Global_t: 894, Episode_t: 6, Action: 9, Reward: 1.96, Epsilon: 0.11
[INFO] model update: t: 895, loss: 12772.06640625
[INFO] Global_t: 895, Episode_t: 7, Action: 8, Reward: 2.17, Epsilon: 0.11
[INFO] model update: t: 896, loss: 4156.9541015625
[INFO] Global_t: 896, Episode_t: 8, Action: 12, Reward: 2.85, Epsilon: 0.11

[INFO] Global step: 896, Cumulative rewards: 23.18688, Runtime (s): 1471.73
------------------------------------------------------------
 
 45%|████▍     | 896/2000 [24:31<28:39,  1.56s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2293620109558105
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.778979778289795
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4483799934387207
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.281888961791992
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.3841116428375244
average cummulative reward vector is:  [0.11811474 0.11419977 0.12940984 0.10256659 0.11993737]
average cummulative reward is:  0.11684565916052843
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 112, nodes: 216, edges: 639
[INFO] model update: t: 897, loss: 58648.9609375
[INFO] Global_t: 897, Episode_t: 1, Action: 28, Reward: 3.01, Epsilon: 0.11
[INFO] model update: t: 898, loss: 152863.1875
[INFO] Global_t: 898, Episode_t: 2, Action: 213, Reward: 1.29, Epsilon: 0.11
[INFO] model update: t: 899, loss: 46643.9140625
[INFO] Global_t: 899, Episode_t: 3, Action: 8, Reward: 4.12, Epsilon: 0.11
[INFO] model update: t: 900, loss: 49706.0546875
[INFO] Global_t: 900, Episode_t: 4, Action: 11, Reward: 3.70, Epsilon: 0.11
[INFO] model update: t: 901, loss: 132805.03125
[INFO] Global_t: 901, Episode_t: 5, Action: 129, Reward: 1.40, Epsilon: 0.11
[INFO] model update: t: 902, loss: 22417.033203125
[INFO] Global_t: 902, Episode_t: 6, Action: 18, Reward: 2.91, Epsilon: 0.11
[INFO] model update: t: 903, loss: 22011.365234375
[INFO] Global_t: 903, Episode_t: 7, Action: 10, Reward: 3.25, Epsilon: 0.11
[INFO] model update: t: 904, loss: 45481.8984375
[INFO] Global_t: 904, Episode_t: 8, Action: 27, Reward: 2.64, Epsilon: 0.11
 45%|████▌     | 904/2000 [24:52<33:58,  1.86s/it]
[INFO] Global step: 904, Cumulative rewards: 22.309079999999994, Runtime (s): 1492.26
------------------------------------------------------------
 
graph: 113, nodes: 217, edges: 642
[INFO] model update: t: 905, loss: 20202.1796875
[INFO] Global_t: 905, Episode_t: 1, Action: 4, Reward: 4.66, Epsilon: 0.10
[INFO] model update: t: 906, loss: 16870.15625
[INFO] Global_t: 906, Episode_t: 2, Action: 17, Reward: 3.79, Epsilon: 0.10
[INFO] model update: t: 907, loss: 38360.44140625
[INFO] Global_t: 907, Episode_t: 3, Action: 13, Reward: 2.84, Epsilon: 0.10
[INFO] model update: t: 908, loss: 13067.11328125
[INFO] Global_t: 908, Episode_t: 4, Action: 6, Reward: 4.59, Epsilon: 0.10
[INFO] model update: t: 909, loss: 10181.2900390625
[INFO] Global_t: 909, Episode_t: 5, Action: 172, Reward: 1.16, Epsilon: 0.10
[INFO] model update: t: 910, loss: 22010.7578125
[INFO] Global_t: 910, Episode_t: 6, Action: 19, Reward: 2.40, Epsilon: 0.10
[INFO] model update: t: 911, loss: 12451.3349609375
[INFO] Global_t: 911, Episode_t: 7, Action: 11, Reward: 2.28, Epsilon: 0.10
[INFO] model update: t: 912, loss: 56819.7109375
[INFO] Global_t: 912, Episode_t: 8, Action: 7, Reward: 1.97, Epsilon: 0.10
 46%|████▌     | 912/2000 [24:57<27:10,  1.50s/it]
[INFO] Global step: 912, Cumulative rewards: 23.704559999999997, Runtime (s): 1497.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.56486439704895
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4801950454711914
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.413951873779297
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.8356330394744873
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4810988903045654
average cummulative reward vector is:  [0.12225026 0.10865903 0.13025519 0.11035911 0.12916048]
average cummulative reward is:  0.12013681564260073
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 114, nodes: 190, edges: 561
[INFO] model update: t: 913, loss: 30726.36328125
[INFO] Global_t: 913, Episode_t: 1, Action: 12, Reward: 3.84, Epsilon: 0.10
[INFO] model update: t: 914, loss: 5478.44140625
[INFO] Global_t: 914, Episode_t: 2, Action: 13, Reward: 3.81, Epsilon: 0.10
[INFO] model update: t: 915, loss: 35667.8984375
[INFO] Global_t: 915, Episode_t: 3, Action: 6, Reward: 2.31, Epsilon: 0.09
[INFO] model update: t: 916, loss: 6592.3447265625
[INFO] Global_t: 916, Episode_t: 4, Action: 146, Reward: 1.25, Epsilon: 0.09
[INFO] model update: t: 917, loss: 11612.6572265625
[INFO] Global_t: 917, Episode_t: 5, Action: 138, Reward: 1.43, Epsilon: 0.09
[INFO] model update: t: 918, loss: 9274.1162109375
[INFO] Global_t: 918, Episode_t: 6, Action: 16, Reward: 1.97, Epsilon: 0.09
[INFO] model update: t: 919, loss: 36288.9765625
[INFO] Global_t: 919, Episode_t: 7, Action: 21, Reward: 2.03, Epsilon: 0.09
[INFO] model update: t: 920, loss: 63524.9296875
[INFO] Global_t: 920, Episode_t: 8, Action: 9, Reward: 1.94, Epsilon: 0.09
 46%|████▌     | 920/2000 [25:21<34:52,  1.94s/it]
[INFO] Global step: 920, Cumulative rewards: 18.57936, Runtime (s): 1521.19
------------------------------------------------------------
 
graph: 115, nodes: 198, edges: 585
[INFO] model update: t: 921, loss: 11238.490234375
[INFO] Global_t: 921, Episode_t: 1, Action: 9, Reward: 4.05, Epsilon: 0.09
[INFO] model update: t: 922, loss: 54795.625
[INFO] Global_t: 922, Episode_t: 2, Action: 88, Reward: 1.64, Epsilon: 0.09
[INFO] model update: t: 923, loss: 114675.6640625
[INFO] Global_t: 923, Episode_t: 3, Action: 15, Reward: 3.13, Epsilon: 0.09
[INFO] model update: t: 924, loss: 42537.109375
[INFO] Global_t: 924, Episode_t: 4, Action: 51, Reward: 1.28, Epsilon: 0.09
[INFO] model update: t: 925, loss: 8930.5849609375
[INFO] Global_t: 925, Episode_t: 5, Action: 12, Reward: 2.98, Epsilon: 0.08
[INFO] model update: t: 926, loss: 66023.9296875
[INFO] Global_t: 926, Episode_t: 6, Action: 18, Reward: 2.73, Epsilon: 0.08
[INFO] model update: t: 927, loss: 17698.80859375
[INFO] Global_t: 927, Episode_t: 7, Action: 20, Reward: 2.27, Epsilon: 0.08
[INFO] model update: t: 928, loss: 17133.587890625
[INFO] Global_t: 928, Episode_t: 8, Action: 7, Reward: 2.95, Epsilon: 0.08
 46%|████▋     | 928/2000 [25:24<26:41,  1.49s/it]
[INFO] Global step: 928, Cumulative rewards: 21.03888, Runtime (s): 1524.87
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3747878074645996
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6235525608062744
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2459170818328857
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.502980947494507
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9190750122070312
average cummulative reward vector is:  [0.12273263 0.10838519 0.12279481 0.1129472  0.1305293 ]
average cummulative reward is:  0.11947782456885062
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 116, nodes: 182, edges: 537
[INFO] model update: t: 929, loss: 74397.59375
[INFO] Global_t: 929, Episode_t: 1, Action: 0, Reward: 4.94, Epsilon: 0.08
[INFO] model update: t: 930, loss: 41545.36328125
[INFO] Global_t: 930, Episode_t: 2, Action: 5, Reward: 4.07, Epsilon: 0.08
[INFO] model update: t: 931, loss: 21151.08984375
[INFO] Global_t: 931, Episode_t: 3, Action: 10, Reward: 3.55, Epsilon: 0.08
[INFO] model update: t: 932, loss: 56007.65625
[INFO] Global_t: 932, Episode_t: 4, Action: 13, Reward: 2.66, Epsilon: 0.08
[INFO] model update: t: 933, loss: 5668.81982421875
[INFO] Global_t: 933, Episode_t: 5, Action: 15, Reward: 2.49, Epsilon: 0.08
[INFO] model update: t: 934, loss: 25230.95703125
[INFO] Global_t: 934, Episode_t: 6, Action: 18, Reward: 3.04, Epsilon: 0.08
[INFO] model update: t: 935, loss: 16177.9296875
[INFO] Global_t: 935, Episode_t: 7, Action: 21, Reward: 1.79, Epsilon: 0.07
[INFO] model update: t: 936, loss: 9981.8681640625
[INFO] Global_t: 936, Episode_t: 8, Action: 28, Reward: 1.91, Epsilon: 0.07
 47%|████▋     | 936/2000 [25:46<32:58,  1.86s/it]
[INFO] Global step: 936, Cumulative rewards: 24.447840000000003, Runtime (s): 1546.56
------------------------------------------------------------
 
graph: 117, nodes: 196, edges: 579
[INFO] model update: t: 937, loss: 27631.6640625
[INFO] Global_t: 937, Episode_t: 1, Action: 5, Reward: 4.64, Epsilon: 0.07
[INFO] model update: t: 938, loss: 15349.056640625
[INFO] Global_t: 938, Episode_t: 2, Action: 7, Reward: 4.18, Epsilon: 0.07
[INFO] model update: t: 939, loss: 2881.67431640625
[INFO] Global_t: 939, Episode_t: 3, Action: 6, Reward: 2.93, Epsilon: 0.07
[INFO] model update: t: 940, loss: 31949.955078125
[INFO] Global_t: 940, Episode_t: 4, Action: 13, Reward: 2.96, Epsilon: 0.07
[INFO] model update: t: 941, loss: 37220.171875
[INFO] Global_t: 941, Episode_t: 5, Action: 14, Reward: 2.36, Epsilon: 0.07
[INFO] model update: t: 942, loss: 6945.4033203125
[INFO] Global_t: 942, Episode_t: 6, Action: 8, Reward: 3.37, Epsilon: 0.07
[INFO] model update: t: 943, loss: 28413.158203125
[INFO] Global_t: 943, Episode_t: 7, Action: 10, Reward: 1.68, Epsilon: 0.07
[INFO] model update: t: 944, loss: 17328.43359375
[INFO] Global_t: 944, Episode_t: 8, Action: 46, Reward: 2.21, Epsilon: 0.07
 47%|████▋     | 944/2000 [25:52<26:31,  1.51s/it]
[INFO] Global step: 944, Cumulative rewards: 24.32604, Runtime (s): 1552.05
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3851044178009033
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4605090618133545
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6270201206207275
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3963143825531006
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5165679454803467
average cummulative reward vector is:  [0.12092316 0.10729306 0.13155273 0.10692523 0.13129731]
average cummulative reward is:  0.11959829823270929
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 118, nodes: 180, edges: 531
[INFO] model update: t: 945, loss: 24152.08203125
[INFO] Global_t: 945, Episode_t: 1, Action: 5, Reward: 4.50, Epsilon: 0.06
[INFO] model update: t: 946, loss: 42339.84375
[INFO] Global_t: 946, Episode_t: 2, Action: 29, Reward: 3.16, Epsilon: 0.06
[INFO] model update: t: 947, loss: 36534.546875
[INFO] Global_t: 947, Episode_t: 3, Action: 4, Reward: 3.74, Epsilon: 0.06
[INFO] model update: t: 948, loss: 23270.5234375
[INFO] Global_t: 948, Episode_t: 4, Action: 3, Reward: 5.05, Epsilon: 0.06
[INFO] model update: t: 949, loss: 4219.46826171875
[INFO] Global_t: 949, Episode_t: 5, Action: 8, Reward: 2.16, Epsilon: 0.06
[INFO] model update: t: 950, loss: 13046.11328125
[INFO] Global_t: 950, Episode_t: 6, Action: 16, Reward: 2.53, Epsilon: 0.06
[INFO] model update: t: 951, loss: 18719.048828125
[INFO] Global_t: 951, Episode_t: 7, Action: 7, Reward: 2.11, Epsilon: 0.06
[INFO] model update: t: 952, loss: 4582.55224609375
[INFO] Global_t: 952, Episode_t: 8, Action: 13, Reward: 1.99, Epsilon: 0.06
 48%|████▊     | 952/2000 [26:13<32:25,  1.86s/it]
[INFO] Global step: 952, Cumulative rewards: 25.234799999999993, Runtime (s): 1573.42
------------------------------------------------------------
 
graph: 119, nodes: 182, edges: 537
[INFO] model update: t: 953, loss: 25399.662109375
[INFO] Global_t: 953, Episode_t: 1, Action: 3, Reward: 4.57, Epsilon: 0.06
[INFO] model update: t: 954, loss: 21400.66796875
[INFO] Global_t: 954, Episode_t: 2, Action: 5, Reward: 2.99, Epsilon: 0.06
[INFO] model update: t: 955, loss: 11878.9853515625
[INFO] Global_t: 955, Episode_t: 3, Action: 8, Reward: 3.08, Epsilon: 0.06
[INFO] model update: t: 956, loss: 6390.5458984375
[INFO] Global_t: 956, Episode_t: 4, Action: 12, Reward: 2.25, Epsilon: 0.05
[INFO] model update: t: 957, loss: 10875.822265625
[INFO] Global_t: 957, Episode_t: 5, Action: 13, Reward: 2.20, Epsilon: 0.05
[INFO] model update: t: 958, loss: 10341.18359375
[INFO] Global_t: 958, Episode_t: 6, Action: 6, Reward: 1.39, Epsilon: 0.05
[INFO] model update: t: 959, loss: 15088.541015625
[INFO] Global_t: 959, Episode_t: 7, Action: 14, Reward: 2.39, Epsilon: 0.05
[INFO] model update: t: 960, loss: 13597.955078125
[INFO] Global_t: 960, Episode_t: 8, Action: 70, Reward: 1.30, Epsilon: 0.05
 48%|████▊     | 960/2000 [26:19<26:12,  1.51s/it]
[INFO] Global step: 960, Cumulative rewards: 20.15796, Runtime (s): 1579.08
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2888236045837402
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6918065547943115
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4831066131591797
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.0126793384552
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4343912601470947
average cummulative reward vector is:  [0.11309947 0.11663935 0.13083279 0.11741916 0.12718656]
average cummulative reward is:  0.12103546608791957
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 120, nodes: 219, edges: 648
[INFO] model update: t: 961, loss: 7218.546875
[INFO] Global_t: 961, Episode_t: 1, Action: 0, Reward: 4.93, Epsilon: 0.05
[INFO] model update: t: 962, loss: 50106.2734375
[INFO] Global_t: 962, Episode_t: 2, Action: 25, Reward: 3.97, Epsilon: 0.05
[INFO] model update: t: 963, loss: 104410.4375
[INFO] Global_t: 963, Episode_t: 3, Action: 43, Reward: 3.52, Epsilon: 0.05
[INFO] model update: t: 964, loss: 120413.4921875
[INFO] Global_t: 964, Episode_t: 4, Action: 4, Reward: 4.22, Epsilon: 0.05
[INFO] model update: t: 965, loss: 32651.259765625
[INFO] Global_t: 965, Episode_t: 5, Action: 17, Reward: 2.08, Epsilon: 0.05
[INFO] model update: t: 966, loss: 30329.78515625
[INFO] Global_t: 966, Episode_t: 6, Action: 24, Reward: 2.21, Epsilon: 0.04
[INFO] model update: t: 967, loss: 205052.421875
[INFO] Global_t: 967, Episode_t: 7, Action: 15, Reward: 1.46, Epsilon: 0.04
[INFO] model update: t: 968, loss: 289549.46875
[INFO] Global_t: 968, Episode_t: 8, Action: 34, Reward: 1.91, Epsilon: 0.04
 48%|████▊     | 968/2000 [26:43<33:41,  1.96s/it]
[INFO] Global step: 968, Cumulative rewards: 24.292559999999998, Runtime (s): 1603.10
------------------------------------------------------------
 
graph: 121, nodes: 182, edges: 536
[INFO] model update: t: 969, loss: 187195.625
[INFO] Global_t: 969, Episode_t: 1, Action: 16, Reward: 3.86, Epsilon: 0.04
[INFO] model update: t: 970, loss: 51419.640625
[INFO] Global_t: 970, Episode_t: 2, Action: 5, Reward: 4.08, Epsilon: 0.04
[INFO] model update: t: 971, loss: 13219.0791015625
[INFO] Global_t: 971, Episode_t: 3, Action: 19, Reward: 2.86, Epsilon: 0.04
[INFO] model update: t: 972, loss: 35729.796875
[INFO] Global_t: 972, Episode_t: 4, Action: 68, Reward: 2.61, Epsilon: 0.04
[INFO] model update: t: 973, loss: 22935.130859375
[INFO] Global_t: 973, Episode_t: 5, Action: 11, Reward: 2.52, Epsilon: 0.04
[INFO] model update: t: 974, loss: 4570.60205078125
[INFO] Global_t: 974, Episode_t: 6, Action: 6, Reward: 2.74, Epsilon: 0.04
[INFO] model update: t: 975, loss: 33489.67578125
[INFO] Global_t: 975, Episode_t: 7, Action: 13, Reward: 2.12, Epsilon: 0.04
[INFO] model update: t: 976, loss: 27011.615234375
[INFO] Global_t: 976, Episode_t: 8, Action: 7, Reward: 2.39, Epsilon: 0.03
 49%|████▉     | 976/2000 [26:46<25:53,  1.52s/it]
[INFO] Global step: 976, Cumulative rewards: 23.164679999999997, Runtime (s): 1607.00
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5731663703918457
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8373496532440186
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.469019889831543
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.302182912826538
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.811309814453125
average cummulative reward vector is:  [0.12928158 0.11510139 0.13140546 0.10450631 0.12762339]
average cummulative reward is:  0.12158362556502415
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 122, nodes: 206, edges: 609
[INFO] model update: t: 977, loss: 14536.724609375
[INFO] Global_t: 977, Episode_t: 1, Action: 10, Reward: 4.16, Epsilon: 0.03
[INFO] model update: t: 978, loss: 36916.80078125
[INFO] Global_t: 978, Episode_t: 2, Action: 100, Reward: 1.85, Epsilon: 0.03
[INFO] model update: t: 979, loss: 18844.58203125
[INFO] Global_t: 979, Episode_t: 3, Action: 193, Reward: 1.50, Epsilon: 0.03
[INFO] model update: t: 980, loss: 137081.203125
[INFO] Global_t: 980, Episode_t: 4, Action: 9, Reward: 3.99, Epsilon: 0.03
[INFO] model update: t: 981, loss: 208159.296875
[INFO] Global_t: 981, Episode_t: 5, Action: 12, Reward: 3.54, Epsilon: 0.03
[INFO] model update: t: 982, loss: 8193.640625
[INFO] Global_t: 982, Episode_t: 6, Action: 0, Reward: 3.41, Epsilon: 0.03
[INFO] model update: t: 983, loss: 310200.34375
[INFO] Global_t: 983, Episode_t: 7, Action: 14, Reward: 3.31, Epsilon: 0.03
[INFO] model update: t: 984, loss: 316591.6875
[INFO] Global_t: 984, Episode_t: 8, Action: 32, Reward: 2.81, Epsilon: 0.03
 49%|████▉     | 984/2000 [27:08<31:30,  1.86s/it]
[INFO] Global step: 984, Cumulative rewards: 24.55956, Runtime (s): 1628.28
------------------------------------------------------------
 
graph: 123, nodes: 182, edges: 537
[INFO] model update: t: 985, loss: 125598.109375
[INFO] Global_t: 985, Episode_t: 1, Action: 8, Reward: 4.29, Epsilon: 0.03
[INFO] model update: t: 986, loss: 21068.048828125
[INFO] Global_t: 986, Episode_t: 2, Action: 3, Reward: 4.23, Epsilon: 0.02
[INFO] model update: t: 987, loss: 161322.75
[INFO] Global_t: 987, Episode_t: 3, Action: 4, Reward: 4.54, Epsilon: 0.02
[INFO] model update: t: 988, loss: 127606.859375
[INFO] Global_t: 988, Episode_t: 4, Action: 7, Reward: 3.56, Epsilon: 0.02
[INFO] model update: t: 989, loss: 22270.306640625
[INFO] Global_t: 989, Episode_t: 5, Action: 13, Reward: 2.56, Epsilon: 0.02
[INFO] model update: t: 990, loss: 20869.92578125
[INFO] Global_t: 990, Episode_t: 6, Action: 11, Reward: 2.47, Epsilon: 0.02
[INFO] model update: t: 991, loss: 42411.16796875
[INFO] Global_t: 991, Episode_t: 7, Action: 31, Reward: 2.11, Epsilon: 0.02
[INFO] model update: t: 992, loss: 8258.58203125
[INFO] Global_t: 992, Episode_t: 8, Action: 17, Reward: 2.18, Epsilon: 0.02
 50%|████▉     | 992/2000 [27:12<24:41,  1.47s/it]
[INFO] Global step: 992, Cumulative rewards: 25.941119999999998, Runtime (s): 1632.74
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8077938556671143
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4923179149627686
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2394089698791504
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7434444427490234
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.552149534225464
average cummulative reward vector is:  [0.13189263 0.10965949 0.12275164 0.11228107 0.13033495]
average cummulative reward is:  0.12138395653337293
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 124, nodes: 194, edges: 573
[INFO] model update: t: 993, loss: 41656.484375
[INFO] Global_t: 993, Episode_t: 1, Action: 2, Reward: 4.13, Epsilon: 0.02
[INFO] model update: t: 994, loss: 53669.3984375
[INFO] Global_t: 994, Episode_t: 2, Action: 7, Reward: 3.89, Epsilon: 0.02
[INFO] model update: t: 995, loss: 7869.70751953125
[INFO] Global_t: 995, Episode_t: 3, Action: 6, Reward: 3.14, Epsilon: 0.02
[INFO] model update: t: 996, loss: 55841.1640625
[INFO] Global_t: 996, Episode_t: 4, Action: 10, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 997, loss: 116154.7578125
[INFO] Global_t: 997, Episode_t: 5, Action: 8, Reward: 1.63, Epsilon: 0.01
[INFO] model update: t: 998, loss: 36559.47265625
[INFO] Global_t: 998, Episode_t: 6, Action: 65, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 999, loss: 14631.619140625
[INFO] Global_t: 999, Episode_t: 7, Action: 35, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 1000, loss: 78064.4765625
[INFO] Global_t: 1000, Episode_t: 8, Action: 38, Reward: 1.60, Epsilon: 0.01
 50%|█████     | 1000/2000 [27:36<32:11,  1.93s/it]
[INFO] Global step: 1000, Cumulative rewards: 19.70184, Runtime (s): 1656.82
------------------------------------------------------------
 
graph: 125, nodes: 209, edges: 617
[INFO] model update: t: 1001, loss: 52455.734375
[INFO] Global_t: 1001, Episode_t: 1, Action: 8, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1002, loss: 21544.14453125
[INFO] Global_t: 1002, Episode_t: 2, Action: 39, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1003, loss: 89238.84375
[INFO] Global_t: 1003, Episode_t: 3, Action: 2, Reward: 4.89, Epsilon: 0.01
[INFO] model update: t: 1004, loss: 230450.8125
[INFO] Global_t: 1004, Episode_t: 4, Action: 4, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1005, loss: 478473.71875
[INFO] Global_t: 1005, Episode_t: 5, Action: 5, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1006, loss: 511650.75
[INFO] Global_t: 1006, Episode_t: 6, Action: 25, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1007, loss: 116302.2890625
[INFO] Global_t: 1007, Episode_t: 7, Action: 15, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1008, loss: 37706.9140625
[INFO] Global_t: 1008, Episode_t: 8, Action: 54, Reward: 1.34, Epsilon: 0.01
 50%|█████     | 1008/2000 [27:42<25:53,  1.57s/it]
[INFO] Global step: 1008, Cumulative rewards: 26.002079999999996, Runtime (s): 1662.52
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8512485027313232
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5478010177612305
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2667102813720703
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.661792516708374
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.213142156600952
average cummulative reward vector is:  [0.12907211 0.10982917 0.12307268 0.11231636 0.11575161]
average cummulative reward is:  0.11800838351377314
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 126, nodes: 218, edges: 645
[INFO] model update: t: 1009, loss: 260862.25
[INFO] Global_t: 1009, Episode_t: 1, Action: 6, Reward: 5.17, Epsilon: 0.01
[INFO] model update: t: 1010, loss: 513139.28125
[INFO] Global_t: 1010, Episode_t: 2, Action: 5, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1011, loss: 185402.5
[INFO] Global_t: 1011, Episode_t: 3, Action: 11, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1012, loss: 31264.25
[INFO] Global_t: 1012, Episode_t: 4, Action: 8, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 1013, loss: 227176.125
[INFO] Global_t: 1013, Episode_t: 5, Action: 9, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1014, loss: 231240.75
[INFO] Global_t: 1014, Episode_t: 6, Action: 16, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 1015, loss: 45628.41015625
[INFO] Global_t: 1015, Episode_t: 7, Action: 27, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 1016, loss: 95613.7265625
[INFO] Global_t: 1016, Episode_t: 8, Action: 37, Reward: 1.68, Epsilon: 0.01
 51%|█████     | 1016/2000 [28:06<32:39,  1.99s/it]
[INFO] Global step: 1016, Cumulative rewards: 20.817239999999998, Runtime (s): 1686.39
------------------------------------------------------------
 
graph: 127, nodes: 189, edges: 558
[INFO] model update: t: 1017, loss: 428217.4375
[INFO] Global_t: 1017, Episode_t: 1, Action: 7, Reward: 3.74, Epsilon: 0.01
[INFO] model update: t: 1018, loss: 290122.84375
[INFO] Global_t: 1018, Episode_t: 2, Action: 4, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1019, loss: 5567.0087890625
[INFO] Global_t: 1019, Episode_t: 3, Action: 12, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 1020, loss: 127331.3828125
[INFO] Global_t: 1020, Episode_t: 4, Action: 15, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1021, loss: 149779.75
[INFO] Global_t: 1021, Episode_t: 5, Action: 32, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1022, loss: 30218.58203125
[INFO] Global_t: 1022, Episode_t: 6, Action: 21, Reward: 1.67, Epsilon: 0.01
[INFO] model update: t: 1023, loss: 39222.93359375
[INFO] Global_t: 1023, Episode_t: 7, Action: 5, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1024, loss: 133743.1875
[INFO] Global_t: 1024, Episode_t: 8, Action: 18, Reward: 1.44, Epsilon: 0.01
 51%|█████     | 1024/2000 [28:11<25:41,  1.58s/it]
[INFO] Global step: 1024, Cumulative rewards: 21.7152, Runtime (s): 1691.35
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.356921672821045
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6240737438201904
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2379186153411865
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3494086265563965
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.722663640975952
average cummulative reward vector is:  [0.12169211 0.1075162  0.1195612  0.10708645 0.12331882]
average cummulative reward is:  0.11583495539101718
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 128, nodes: 198, edges: 585
[INFO] model update: t: 1025, loss: 206587.25
[INFO] Global_t: 1025, Episode_t: 1, Action: 4, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1026, loss: 240470.03125
[INFO] Global_t: 1026, Episode_t: 2, Action: 5, Reward: 4.07, Epsilon: 0.01
[INFO] model update: t: 1027, loss: 130412.390625
[INFO] Global_t: 1027, Episode_t: 3, Action: 8, Reward: 3.23, Epsilon: 0.01
[INFO] model update: t: 1028, loss: 10117.6689453125
[INFO] Global_t: 1028, Episode_t: 4, Action: 6, Reward: 2.63, Epsilon: 0.01
[INFO] model update: t: 1029, loss: 136867.875
[INFO] Global_t: 1029, Episode_t: 5, Action: 36, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 1030, loss: 311996.875
[INFO] Global_t: 1030, Episode_t: 6, Action: 13, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1031, loss: 10088.9599609375
[INFO] Global_t: 1031, Episode_t: 7, Action: 39, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1032, loss: 232556.765625
[INFO] Global_t: 1032, Episode_t: 8, Action: 21, Reward: 2.55, Epsilon: 0.01
 52%|█████▏    | 1032/2000 [28:32<30:36,  1.90s/it]
[INFO] Global step: 1032, Cumulative rewards: 24.398159999999997, Runtime (s): 1712.46
------------------------------------------------------------
 
graph: 129, nodes: 211, edges: 624
[INFO] model update: t: 1033, loss: 381179.5625
[INFO] Global_t: 1033, Episode_t: 1, Action: 7, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1034, loss: 240992.296875
[INFO] Global_t: 1034, Episode_t: 2, Action: 4, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 1035, loss: 32485.234375
[INFO] Global_t: 1035, Episode_t: 3, Action: 5, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1036, loss: 79400.0546875
[INFO] Global_t: 1036, Episode_t: 4, Action: 11, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1037, loss: 325472.875
[INFO] Global_t: 1037, Episode_t: 5, Action: 26, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1038, loss: 703545.0
[INFO] Global_t: 1038, Episode_t: 6, Action: 50, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1039, loss: 123708.40625
[INFO] Global_t: 1039, Episode_t: 7, Action: 13, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1040, loss: 191626.46875
[INFO] Global_t: 1040, Episode_t: 8, Action: 52, Reward: 1.30, Epsilon: 0.01
 52%|█████▏    | 1040/2000 [28:40<26:04,  1.63s/it]
[INFO] Global step: 1040, Cumulative rewards: 21.38484, Runtime (s): 1720.51
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.844674587249756
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9871695041656494
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1392126083374023
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.1562225818634033
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8399596214294434
average cummulative reward vector is:  [0.1272     0.11580347 0.11751803 0.09954696 0.12675887]
average cummulative reward is:  0.11736546771873435
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 130, nodes: 205, edges: 606
[INFO] model update: t: 1041, loss: 523897.71875
[INFO] Global_t: 1041, Episode_t: 1, Action: 13, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1042, loss: 21078.345703125
[INFO] Global_t: 1042, Episode_t: 2, Action: 10, Reward: 4.26, Epsilon: 0.01
[INFO] model update: t: 1043, loss: 430983.21875
[INFO] Global_t: 1043, Episode_t: 3, Action: 18, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 1044, loss: 881164.0
[INFO] Global_t: 1044, Episode_t: 4, Action: 11, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1045, loss: 1237636.0
[INFO] Global_t: 1045, Episode_t: 5, Action: 12, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 1046, loss: 246134.9375
[INFO] Global_t: 1046, Episode_t: 6, Action: 7, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1047, loss: 55230.61328125
[INFO] Global_t: 1047, Episode_t: 7, Action: 26, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1048, loss: 498325.34375
[INFO] Global_t: 1048, Episode_t: 8, Action: 32, Reward: 1.82, Epsilon: 0.01
 52%|█████▏    | 1048/2000 [29:03<31:44,  2.00s/it]
[INFO] Global step: 1048, Cumulative rewards: 22.605359999999997, Runtime (s): 1743.42
------------------------------------------------------------
 
graph: 131, nodes: 210, edges: 620
[INFO] model update: t: 1049, loss: 409030.0
[INFO] Global_t: 1049, Episode_t: 1, Action: 0, Reward: 5.13, Epsilon: 0.01
[INFO] model update: t: 1050, loss: 21826.7734375
[INFO] Global_t: 1050, Episode_t: 2, Action: 16, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1051, loss: 126252.328125
[INFO] Global_t: 1051, Episode_t: 3, Action: 7, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1052, loss: 292892.09375
[INFO] Global_t: 1052, Episode_t: 4, Action: 39, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1053, loss: 82501.578125
[INFO] Global_t: 1053, Episode_t: 5, Action: 11, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1054, loss: 14264.150390625
[INFO] Global_t: 1054, Episode_t: 6, Action: 1, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1055, loss: 104800.234375
[INFO] Global_t: 1055, Episode_t: 7, Action: 10, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 1056, loss: 174632.96875
[INFO] Global_t: 1056, Episode_t: 8, Action: 19, Reward: 1.69, Epsilon: 0.01
 53%|█████▎    | 1056/2000 [29:09<25:23,  1.61s/it]
[INFO] Global step: 1056, Cumulative rewards: 23.11056, Runtime (s): 1749.11
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.32732892036438
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.044874429702759
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6396894454956055
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.434425115585327
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.449561357498169
average cummulative reward vector is:  [0.11382632 0.12536968 0.13122978 0.1099778  0.12277285]
average cummulative reward is:  0.1206352852673696
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 132, nodes: 213, edges: 630
[INFO] model update: t: 1057, loss: 349883.8125
[INFO] Global_t: 1057, Episode_t: 1, Action: 1, Reward: 4.93, Epsilon: 0.01
[INFO] model update: t: 1058, loss: 275636.25
[INFO] Global_t: 1058, Episode_t: 2, Action: 7, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1059, loss: 177402.5625
[INFO] Global_t: 1059, Episode_t: 3, Action: 8, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1060, loss: 11650.44140625
[INFO] Global_t: 1060, Episode_t: 4, Action: 6, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1061, loss: 125134.9765625
[INFO] Global_t: 1061, Episode_t: 5, Action: 13, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 1062, loss: 214964.59375
[INFO] Global_t: 1062, Episode_t: 6, Action: 10, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 1063, loss: 48453.2734375
[INFO] Global_t: 1063, Episode_t: 7, Action: 18, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 1064, loss: 78925.9296875
[INFO] Global_t: 1064, Episode_t: 8, Action: 20, Reward: 2.02, Epsilon: 0.01

[INFO] Global step: 1064, Cumulative rewards: 25.34304, Runtime (s): 1771.81
------------------------------------------------------------
 
 53%|█████▎    | 1064/2000 [29:31<30:53,  1.98s/it]graph: 133, nodes: 213, edges: 630
[INFO] model update: t: 1065, loss: 187411.078125
[INFO] Global_t: 1065, Episode_t: 1, Action: 4, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1066, loss: 8064.0966796875
[INFO] Global_t: 1066, Episode_t: 2, Action: 13, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1067, loss: 134484.625
[INFO] Global_t: 1067, Episode_t: 3, Action: 9, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1068, loss: 119310.3828125
[INFO] Global_t: 1068, Episode_t: 4, Action: 7, Reward: 3.57, Epsilon: 0.01
[INFO] model update: t: 1069, loss: 12154.1337890625
[INFO] Global_t: 1069, Episode_t: 5, Action: 2, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1070, loss: 60437.4296875
[INFO] Global_t: 1070, Episode_t: 6, Action: 20, Reward: 2.67, Epsilon: 0.01
[INFO] model update: t: 1071, loss: 67032.65625
[INFO] Global_t: 1071, Episode_t: 7, Action: 36, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1072, loss: 7168.15087890625
[INFO] Global_t: 1072, Episode_t: 8, Action: 27, Reward: 2.21, Epsilon: 0.01
 54%|█████▎    | 1072/2000 [29:35<23:51,  1.54s/it]
[INFO] Global step: 1072, Cumulative rewards: 27.66936, Runtime (s): 1775.97
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.739872694015503
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8361384868621826
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1396427154541016
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4151554107666016
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7077465057373047
average cummulative reward vector is:  [0.12237    0.11583704 0.11775929 0.09873715 0.13409274]
average cummulative reward is:  0.11775924362454351
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 134, nodes: 215, edges: 635
[INFO] model update: t: 1073, loss: 39388.359375
[INFO] Global_t: 1073, Episode_t: 1, Action: 3, Reward: 5.04, Epsilon: 0.01
[INFO] model update: t: 1074, loss: 57464.3671875
[INFO] Global_t: 1074, Episode_t: 2, Action: 1, Reward: 4.62, Epsilon: 0.01
[INFO] model update: t: 1075, loss: 11990.408203125
[INFO] Global_t: 1075, Episode_t: 3, Action: 10, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 1076, loss: 1799.222900390625
[INFO] Global_t: 1076, Episode_t: 4, Action: 17, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1077, loss: 4456.88427734375
[INFO] Global_t: 1077, Episode_t: 5, Action: 29, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1078, loss: 23328.25
[INFO] Global_t: 1078, Episode_t: 6, Action: 15, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1079, loss: 71257.2890625
[INFO] Global_t: 1079, Episode_t: 7, Action: 11, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1080, loss: 60078.9921875
[INFO] Global_t: 1080, Episode_t: 8, Action: 66, Reward: 1.40, Epsilon: 0.01
 54%|█████▍    | 1080/2000 [29:58<29:39,  1.93s/it]
[INFO] Global step: 1080, Cumulative rewards: 22.578599999999998, Runtime (s): 1798.75
------------------------------------------------------------
 
graph: 135, nodes: 211, edges: 624
[INFO] model update: t: 1081, loss: 5490.498046875
[INFO] Global_t: 1081, Episode_t: 1, Action: 54, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1082, loss: 44748.58203125
[INFO] Global_t: 1082, Episode_t: 2, Action: 5, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1083, loss: 219001.75
[INFO] Global_t: 1083, Episode_t: 3, Action: 7, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1084, loss: 564798.5625
[INFO] Global_t: 1084, Episode_t: 4, Action: 11, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1085, loss: 284046.03125
[INFO] Global_t: 1085, Episode_t: 5, Action: 19, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1086, loss: 72090.8125
[INFO] Global_t: 1086, Episode_t: 6, Action: 25, Reward: 1.45, Epsilon: 0.01
[INFO] model update: t: 1087, loss: 22914.599609375
[INFO] Global_t: 1087, Episode_t: 7, Action: 8, Reward: 1.63, Epsilon: 0.01
[INFO] model update: t: 1088, loss: 167065.34375
[INFO] Global_t: 1088, Episode_t: 8, Action: 20, Reward: 2.06, Epsilon: 0.01
 54%|█████▍    | 1088/2000 [30:04<23:50,  1.57s/it]
[INFO] Global step: 1088, Cumulative rewards: 21.08016, Runtime (s): 1804.49
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4194421768188477
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5736734867095947
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2084543704986572
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3091704845428467
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.678481340408325
average cummulative reward vector is:  [0.11817605 0.10595347 0.11796639 0.10573481 0.12712581]
average cummulative reward is:  0.11499130756642986
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 136, nodes: 211, edges: 624
[INFO] model update: t: 1089, loss: 41486.13671875
[INFO] Global_t: 1089, Episode_t: 1, Action: 4, Reward: 4.86, Epsilon: 0.01
[INFO] model update: t: 1090, loss: 66736.25
[INFO] Global_t: 1090, Episode_t: 2, Action: 11, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1091, loss: 347855.3125
[INFO] Global_t: 1091, Episode_t: 3, Action: 8, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 1092, loss: 719509.75
[INFO] Global_t: 1092, Episode_t: 4, Action: 25, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1093, loss: 1156715.0
[INFO] Global_t: 1093, Episode_t: 5, Action: 16, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 1094, loss: 467743.34375
[INFO] Global_t: 1094, Episode_t: 6, Action: 21, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1095, loss: 11950.111328125
[INFO] Global_t: 1095, Episode_t: 7, Action: 44, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1096, loss: 374016.4375
[INFO] Global_t: 1096, Episode_t: 8, Action: 12, Reward: 2.17, Epsilon: 0.01
 55%|█████▍    | 1096/2000 [30:26<28:59,  1.92s/it]
[INFO] Global step: 1096, Cumulative rewards: 22.706400000000002, Runtime (s): 1826.50
------------------------------------------------------------
 
graph: 137, nodes: 210, edges: 621
[INFO] model update: t: 1097, loss: 782119.0625
[INFO] Global_t: 1097, Episode_t: 1, Action: 9, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1098, loss: 384424.875
[INFO] Global_t: 1098, Episode_t: 2, Action: 13, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1099, loss: 20745.6328125
[INFO] Global_t: 1099, Episode_t: 3, Action: 25, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1100, loss: 253533.34375
[INFO] Global_t: 1100, Episode_t: 4, Action: 5, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1101, loss: 607224.5625
[INFO] Global_t: 1101, Episode_t: 5, Action: 8, Reward: 4.50, Epsilon: 0.01
[INFO] model update: t: 1102, loss: 227374.265625
[INFO] Global_t: 1102, Episode_t: 6, Action: 0, Reward: 3.01, Epsilon: 0.01
[INFO] model update: t: 1103, loss: 143580.375
[INFO] Global_t: 1103, Episode_t: 7, Action: 7, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1104, loss: 856334.125
[INFO] Global_t: 1104, Episode_t: 8, Action: 6, Reward: 2.52, Epsilon: 0.01
 55%|█████▌    | 1104/2000 [30:31<22:40,  1.52s/it]
[INFO] Global step: 1104, Cumulative rewards: 29.07023999999999, Runtime (s): 1831.07
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4589860439300537
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.949706792831421
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6567277908325195
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.451627731323242
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.386141061782837
average cummulative reward vector is:  [0.12341684 0.12216551 0.1275918  0.10956308 0.12481559]
average cummulative reward is:  0.12151056603064199
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 138, nodes: 185, edges: 545
[INFO] model update: t: 1105, loss: 426518.0
[INFO] Global_t: 1105, Episode_t: 1, Action: 19, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1106, loss: 41022.7578125
[INFO] Global_t: 1106, Episode_t: 2, Action: 7, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1107, loss: 472840.75
[INFO] Global_t: 1107, Episode_t: 3, Action: 15, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1108, loss: 214301.109375
[INFO] Global_t: 1108, Episode_t: 4, Action: 17, Reward: 2.77, Epsilon: 0.01
[INFO] model update: t: 1109, loss: 57714.0390625
[INFO] Global_t: 1109, Episode_t: 5, Action: 20, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1110, loss: 342246.0
[INFO] Global_t: 1110, Episode_t: 6, Action: 29, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1111, loss: 111523.484375
[INFO] Global_t: 1111, Episode_t: 7, Action: 13, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 1112, loss: 191504.0
[INFO] Global_t: 1112, Episode_t: 8, Action: 12, Reward: 1.60, Epsilon: 0.01
 56%|█████▌    | 1112/2000 [30:54<28:55,  1.95s/it]
[INFO] Global step: 1112, Cumulative rewards: 22.478520000000003, Runtime (s): 1854.85
------------------------------------------------------------
 
graph: 139, nodes: 184, edges: 543
[INFO] model update: t: 1113, loss: 879231.5
[INFO] Global_t: 1113, Episode_t: 1, Action: 5, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 1114, loss: 470042.875
[INFO] Global_t: 1114, Episode_t: 2, Action: 10, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1115, loss: 50989.89453125
[INFO] Global_t: 1115, Episode_t: 3, Action: 9, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1116, loss: 89465.078125
[INFO] Global_t: 1116, Episode_t: 4, Action: 3, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1117, loss: 145662.765625
[INFO] Global_t: 1117, Episode_t: 5, Action: 19, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1118, loss: 25224.36328125
[INFO] Global_t: 1118, Episode_t: 6, Action: 7, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1119, loss: 35166.6796875
[INFO] Global_t: 1119, Episode_t: 7, Action: 11, Reward: 1.83, Epsilon: 0.01
[INFO] model update: t: 1120, loss: 133445.96875
[INFO] Global_t: 1120, Episode_t: 8, Action: 21, Reward: 1.43, Epsilon: 0.01
 56%|█████▌    | 1120/2000 [30:59<22:23,  1.53s/it]
[INFO] Global step: 1120, Cumulative rewards: 22.679999999999996, Runtime (s): 1859.09
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.9190449714660645
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7391197681427
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8395607471466064
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.9632651805877686
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4887170791625977
average cummulative reward vector is:  [0.12574447 0.1158662  0.14191749 0.1150965  0.13026559]
average cummulative reward is:  0.12577805009033288
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 140, nodes: 220, edges: 651
[INFO] model update: t: 1121, loss: 258651.09375
[INFO] Global_t: 1121, Episode_t: 1, Action: 31, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1122, loss: 503520.78125
[INFO] Global_t: 1122, Episode_t: 2, Action: 18, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1123, loss: 464962.8125
[INFO] Global_t: 1123, Episode_t: 3, Action: 12, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1124, loss: 35667.8203125
[INFO] Global_t: 1124, Episode_t: 4, Action: 9, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1125, loss: 150908.625
[INFO] Global_t: 1125, Episode_t: 5, Action: 3, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1126, loss: 120107.359375
[INFO] Global_t: 1126, Episode_t: 6, Action: 22, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1127, loss: 10008.068359375
[INFO] Global_t: 1127, Episode_t: 7, Action: 17, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1128, loss: 71248.4453125
[INFO] Global_t: 1128, Episode_t: 8, Action: 19, Reward: 2.43, Epsilon: 0.01
 56%|█████▋    | 1128/2000 [31:22<28:05,  1.93s/it]
[INFO] Global step: 1128, Cumulative rewards: 25.886880000000005, Runtime (s): 1882.13
------------------------------------------------------------
 
graph: 141, nodes: 205, edges: 606
[INFO] model update: t: 1129, loss: 270038.375
[INFO] Global_t: 1129, Episode_t: 1, Action: 8, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1130, loss: 264342.59375
[INFO] Global_t: 1130, Episode_t: 2, Action: 32, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 1131, loss: 19828.3984375
[INFO] Global_t: 1131, Episode_t: 3, Action: 14, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1132, loss: 123570.5625
[INFO] Global_t: 1132, Episode_t: 4, Action: 24, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1133, loss: 246557.84375
[INFO] Global_t: 1133, Episode_t: 5, Action: 9, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 1134, loss: 121572.7265625
[INFO] Global_t: 1134, Episode_t: 6, Action: 5, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 1135, loss: 13730.62109375
[INFO] Global_t: 1135, Episode_t: 7, Action: 1, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 1136, loss: 16169.19140625
[INFO] Global_t: 1136, Episode_t: 8, Action: 37, Reward: 2.52, Epsilon: 0.01
 57%|█████▋    | 1136/2000 [31:26<21:48,  1.51s/it]
[INFO] Global step: 1136, Cumulative rewards: 28.315200000000004, Runtime (s): 1886.44
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.493514060974121
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.793120861053467
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4258697032928467
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4882001876831055
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7885899543762207
average cummulative reward vector is:  [0.12399    0.10860463 0.12782951 0.11140701 0.13058602]
average cummulative reward is:  0.12048343373550433
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 142, nodes: 201, edges: 593
[INFO] model update: t: 1137, loss: 64335.64453125
[INFO] Global_t: 1137, Episode_t: 1, Action: 24, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1138, loss: 44429.5859375
[INFO] Global_t: 1138, Episode_t: 2, Action: 8, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1139, loss: 12928.92578125
[INFO] Global_t: 1139, Episode_t: 3, Action: 0, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1140, loss: 23636.091796875
[INFO] Global_t: 1140, Episode_t: 4, Action: 9, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1141, loss: 19721.05078125
[INFO] Global_t: 1141, Episode_t: 5, Action: 17, Reward: 3.74, Epsilon: 0.01
[INFO] model update: t: 1142, loss: 7770.6748046875
[INFO] Global_t: 1142, Episode_t: 6, Action: 15, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1143, loss: 3035.686279296875
[INFO] Global_t: 1143, Episode_t: 7, Action: 11, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 1144, loss: 4230.49365234375
[INFO] Global_t: 1144, Episode_t: 8, Action: 16, Reward: 2.29, Epsilon: 0.01
 57%|█████▋    | 1144/2000 [31:47<26:33,  1.86s/it]
[INFO] Global step: 1144, Cumulative rewards: 30.177000000000003, Runtime (s): 1907.82
------------------------------------------------------------
 
graph: 143, nodes: 194, edges: 573
[INFO] model update: t: 1145, loss: 9750.669921875
[INFO] Global_t: 1145, Episode_t: 1, Action: 5, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1146, loss: 12974.5244140625
[INFO] Global_t: 1146, Episode_t: 2, Action: 20, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1147, loss: 6054.49853515625
[INFO] Global_t: 1147, Episode_t: 3, Action: 9, Reward: 3.01, Epsilon: 0.01
[INFO] model update: t: 1148, loss: 11671.564453125
[INFO] Global_t: 1148, Episode_t: 4, Action: 10, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1149, loss: 40002.76171875
[INFO] Global_t: 1149, Episode_t: 5, Action: 6, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1150, loss: 28061.458984375
[INFO] Global_t: 1150, Episode_t: 6, Action: 36, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1151, loss: 10224.4814453125
[INFO] Global_t: 1151, Episode_t: 7, Action: 24, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1152, loss: 11278.345703125
[INFO] Global_t: 1152, Episode_t: 8, Action: 30, Reward: 2.06, Epsilon: 0.01
 58%|█████▊    | 1152/2000 [31:52<20:48,  1.47s/it]
[INFO] Global step: 1152, Cumulative rewards: 21.97368, Runtime (s): 1912.34
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.41776180267334
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.000993967056274
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2420618534088135
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7257885932922363
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.67134690284729
average cummulative reward vector is:  [0.11150474 0.12541505 0.12081503 0.10936519 0.13302204]
average cummulative reward is:  0.12002440807748929
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 144, nodes: 219, edges: 648
[INFO] model update: t: 1153, loss: 23048.013671875
[INFO] Global_t: 1153, Episode_t: 1, Action: 5, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1154, loss: 7767.3447265625
[INFO] Global_t: 1154, Episode_t: 2, Action: 7, Reward: 4.73, Epsilon: 0.01
[INFO] model update: t: 1155, loss: 6035.6064453125
[INFO] Global_t: 1155, Episode_t: 3, Action: 9, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 1156, loss: 10668.6259765625
[INFO] Global_t: 1156, Episode_t: 4, Action: 13, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 1157, loss: 13153.267578125
[INFO] Global_t: 1157, Episode_t: 5, Action: 53, Reward: 2.85, Epsilon: 0.01
[INFO] model update: t: 1158, loss: 17911.412109375
[INFO] Global_t: 1158, Episode_t: 6, Action: 20, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1159, loss: 24988.0078125
[INFO] Global_t: 1159, Episode_t: 7, Action: 2, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 1160, loss: 13619.498046875
[INFO] Global_t: 1160, Episode_t: 8, Action: 21, Reward: 1.84, Epsilon: 0.01
 58%|█████▊    | 1160/2000 [32:15<26:40,  1.90s/it]
[INFO] Global step: 1160, Cumulative rewards: 24.780959999999997, Runtime (s): 1935.64
------------------------------------------------------------
 
graph: 145, nodes: 217, edges: 642
[INFO] model update: t: 1161, loss: 7219.673828125
[INFO] Global_t: 1161, Episode_t: 1, Action: 8, Reward: 5.39, Epsilon: 0.01
[INFO] model update: t: 1162, loss: 3405.398193359375
[INFO] Global_t: 1162, Episode_t: 2, Action: 7, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1163, loss: 11984.4560546875
[INFO] Global_t: 1163, Episode_t: 3, Action: 4, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1164, loss: 15404.5888671875
[INFO] Global_t: 1164, Episode_t: 4, Action: 20, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1165, loss: 16377.67578125
[INFO] Global_t: 1165, Episode_t: 5, Action: 28, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 1166, loss: 3807.0224609375
[INFO] Global_t: 1166, Episode_t: 6, Action: 12, Reward: 1.44, Epsilon: 0.01
[INFO] model update: t: 1167, loss: 6835.619140625
[INFO] Global_t: 1167, Episode_t: 7, Action: 19, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1168, loss: 12124.1943359375
[INFO] Global_t: 1168, Episode_t: 8, Action: 23, Reward: 1.74, Epsilon: 0.01
 58%|█████▊    | 1168/2000 [32:21<21:18,  1.54s/it]
[INFO] Global step: 1168, Cumulative rewards: 23.19635999999999, Runtime (s): 1941.06
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.259625196456909
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.121108055114746
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.203327178955078
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4015297889709473
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5958425998687744
average cummulative reward vector is:  [0.11461789 0.11935926 0.11875273 0.1080014  0.12007876]
average cummulative reward is:  0.11616201030931153
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 146, nodes: 207, edges: 612
[INFO] model update: t: 1169, loss: 5744.99169921875
[INFO] Global_t: 1169, Episode_t: 1, Action: 5, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1170, loss: 6100.869140625
[INFO] Global_t: 1170, Episode_t: 2, Action: 22, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1171, loss: 5904.8876953125
[INFO] Global_t: 1171, Episode_t: 3, Action: 7, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 1172, loss: 7023.39404296875
[INFO] Global_t: 1172, Episode_t: 4, Action: 0, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1173, loss: 4860.6708984375
[INFO] Global_t: 1173, Episode_t: 5, Action: 13, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1174, loss: 8087.8427734375
[INFO] Global_t: 1174, Episode_t: 6, Action: 9, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 1175, loss: 11795.2529296875
[INFO] Global_t: 1175, Episode_t: 7, Action: 45, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 1176, loss: 17881.05859375
[INFO] Global_t: 1176, Episode_t: 8, Action: 28, Reward: 2.25, Epsilon: 0.01

[INFO] Global step: 1176, Cumulative rewards: 23.876999999999995, Runtime (s): 1963.15
------------------------------------------------------------
 
 59%|█████▉    | 1176/2000 [32:43<26:08,  1.90s/it]graph: 147, nodes: 202, edges: 597
[INFO] model update: t: 1177, loss: 25373.130859375
[INFO] Global_t: 1177, Episode_t: 1, Action: 7, Reward: 4.23, Epsilon: 0.01
[INFO] model update: t: 1178, loss: 12669.0
[INFO] Global_t: 1178, Episode_t: 2, Action: 5, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1179, loss: 3254.75439453125
[INFO] Global_t: 1179, Episode_t: 3, Action: 18, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 1180, loss: 12888.201171875
[INFO] Global_t: 1180, Episode_t: 4, Action: 19, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1181, loss: 3980.905029296875
[INFO] Global_t: 1181, Episode_t: 5, Action: 13, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1182, loss: 5520.44677734375
[INFO] Global_t: 1182, Episode_t: 6, Action: 30, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 1183, loss: 7903.587890625
[INFO] Global_t: 1183, Episode_t: 7, Action: 10, Reward: 1.35, Epsilon: 0.01
[INFO] model update: t: 1184, loss: 22503.958984375
[INFO] Global_t: 1184, Episode_t: 8, Action: 53, Reward: 1.80, Epsilon: 0.01
 59%|█████▉    | 1184/2000 [32:48<21:04,  1.55s/it]
[INFO] Global step: 1184, Cumulative rewards: 20.337480000000003, Runtime (s): 1968.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3490803241729736
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.822237491607666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5316617488861084
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.1475412845611572
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.450002431869507
average cummulative reward vector is:  [0.11990868 0.11931968 0.12402486 0.09925023 0.12602177]
average cummulative reward is:  0.1177050462725677
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 148, nodes: 199, edges: 587
[INFO] model update: t: 1185, loss: 47384.25
[INFO] Global_t: 1185, Episode_t: 1, Action: 4, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1186, loss: 136949.46875
[INFO] Global_t: 1186, Episode_t: 2, Action: 33, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1187, loss: 463238.15625
[INFO] Global_t: 1187, Episode_t: 3, Action: 12, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1188, loss: 926533.375
[INFO] Global_t: 1188, Episode_t: 4, Action: 9, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1189, loss: 337602.5
[INFO] Global_t: 1189, Episode_t: 5, Action: 17, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 1190, loss: 16018.6259765625
[INFO] Global_t: 1190, Episode_t: 6, Action: 2, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1191, loss: 100215.765625
[INFO] Global_t: 1191, Episode_t: 7, Action: 5, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 1192, loss: 249298.265625
[INFO] Global_t: 1192, Episode_t: 8, Action: 14, Reward: 2.39, Epsilon: 0.01
 60%|█████▉    | 1192/2000 [33:09<24:55,  1.85s/it]
[INFO] Global step: 1192, Cumulative rewards: 26.727960000000003, Runtime (s): 1989.36
------------------------------------------------------------
 
graph: 149, nodes: 208, edges: 615
[INFO] model update: t: 1193, loss: 14348.4921875
[INFO] Global_t: 1193, Episode_t: 1, Action: 18, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1194, loss: 202272.625
[INFO] Global_t: 1194, Episode_t: 2, Action: 14, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1195, loss: 267238.625
[INFO] Global_t: 1195, Episode_t: 3, Action: 10, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 1196, loss: 118470.140625
[INFO] Global_t: 1196, Episode_t: 4, Action: 6, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1197, loss: 1727004.0
[INFO] Global_t: 1197, Episode_t: 5, Action: 50, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 1198, loss: 4077310.0
[INFO] Global_t: 1198, Episode_t: 6, Action: 27, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1199, loss: 3716039.0
[INFO] Global_t: 1199, Episode_t: 7, Action: 9, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 1200, loss: 1937587.5
[INFO] Global_t: 1200, Episode_t: 8, Action: 32, Reward: 2.50, Epsilon: 0.01
 60%|██████    | 1200/2000 [33:13<19:12,  1.44s/it]
[INFO] Global step: 1200, Cumulative rewards: 28.331039999999998, Runtime (s): 1993.22
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3925845623016357
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.029861688613892
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4294025897979736
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3383965492248535
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.8987531661987305
average cummulative reward vector is:  [0.12388289 0.11360301 0.12677568 0.10540491 0.12441935]
average cummulative reward is:  0.11881716968739527
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 150, nodes: 216, edges: 639
[INFO] model update: t: 1201, loss: 328100.9375
[INFO] Global_t: 1201, Episode_t: 1, Action: 9, Reward: 3.73, Epsilon: 0.01
[INFO] model update: t: 1202, loss: 249226.484375
[INFO] Global_t: 1202, Episode_t: 2, Action: 1, Reward: 4.13, Epsilon: 0.01
[INFO] model update: t: 1203, loss: 1534607.5
[INFO] Global_t: 1203, Episode_t: 3, Action: 6, Reward: 3.73, Epsilon: 0.01
[INFO] model update: t: 1204, loss: 1027590.75
[INFO] Global_t: 1204, Episode_t: 4, Action: 13, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 1205, loss: 39522.4453125
[INFO] Global_t: 1205, Episode_t: 5, Action: 12, Reward: 3.13, Epsilon: 0.01
[INFO] model update: t: 1206, loss: 466344.15625
[INFO] Global_t: 1206, Episode_t: 6, Action: 37, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 1207, loss: 1139955.5
[INFO] Global_t: 1207, Episode_t: 7, Action: 18, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 1208, loss: 44231.765625
[INFO] Global_t: 1208, Episode_t: 8, Action: 11, Reward: 2.53, Epsilon: 0.01
 60%|██████    | 1208/2000 [33:35<24:14,  1.84s/it]
[INFO] Global step: 1208, Cumulative rewards: 26.266920000000002, Runtime (s): 2015.30
------------------------------------------------------------
 
graph: 151, nodes: 204, edges: 601
[INFO] model update: t: 1209, loss: 665684.0
[INFO] Global_t: 1209, Episode_t: 1, Action: 3, Reward: 5.10, Epsilon: 0.01
[INFO] model update: t: 1210, loss: 1507325.5
[INFO] Global_t: 1210, Episode_t: 2, Action: 7, Reward: 4.41, Epsilon: 0.01
[INFO] model update: t: 1211, loss: 959781.5
[INFO] Global_t: 1211, Episode_t: 3, Action: 12, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1212, loss: 21031.25390625
[INFO] Global_t: 1212, Episode_t: 4, Action: 6, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1213, loss: 1274972.375
[INFO] Global_t: 1213, Episode_t: 5, Action: 13, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1214, loss: 1749431.75
[INFO] Global_t: 1214, Episode_t: 6, Action: 25, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1215, loss: 93320.296875
[INFO] Global_t: 1215, Episode_t: 7, Action: 16, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 1216, loss: 542816.25
[INFO] Global_t: 1216, Episode_t: 8, Action: 33, Reward: 1.77, Epsilon: 0.01
 61%|██████    | 1216/2000 [33:40<19:13,  1.47s/it]
[INFO] Global step: 1216, Cumulative rewards: 22.364999999999995, Runtime (s): 2020.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.143000602722168
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5962460041046143
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.941300630569458
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.172703742980957
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.561851978302002
average cummulative reward vector is:  [0.11279184 0.11225579 0.13378852 0.102175   0.1307586 ]
average cummulative reward is:  0.11835395117660034
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 152, nodes: 208, edges: 615
[INFO] model update: t: 1217, loss: 1502386.5
[INFO] Global_t: 1217, Episode_t: 1, Action: 2, Reward: 4.81, Epsilon: 0.01
[INFO] model update: t: 1218, loss: 3458410.0
[INFO] Global_t: 1218, Episode_t: 2, Action: 5, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1219, loss: 2392110.25
[INFO] Global_t: 1219, Episode_t: 3, Action: 9, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1220, loss: 92063.2734375
[INFO] Global_t: 1220, Episode_t: 4, Action: 4, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1221, loss: 1404479.5
[INFO] Global_t: 1221, Episode_t: 5, Action: 21, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1222, loss: 4675752.0
[INFO] Global_t: 1222, Episode_t: 6, Action: 12, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1223, loss: 1949208.625
[INFO] Global_t: 1223, Episode_t: 7, Action: 26, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 1224, loss: 141644.15625
[INFO] Global_t: 1224, Episode_t: 8, Action: 17, Reward: 1.82, Epsilon: 0.01
 61%|██████    | 1224/2000 [34:05<25:44,  1.99s/it]
[INFO] Global step: 1224, Cumulative rewards: 22.881720000000005, Runtime (s): 2045.86
------------------------------------------------------------
 
graph: 153, nodes: 211, edges: 623
[INFO] model update: t: 1225, loss: 756318.0
[INFO] Global_t: 1225, Episode_t: 1, Action: 8, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 1226, loss: 1812122.375
[INFO] Global_t: 1226, Episode_t: 2, Action: 46, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 1227, loss: 873237.8125
[INFO] Global_t: 1227, Episode_t: 3, Action: 2, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1228, loss: 80206.3984375
[INFO] Global_t: 1228, Episode_t: 4, Action: 11, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1229, loss: 289363.875
[INFO] Global_t: 1229, Episode_t: 5, Action: 10, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1230, loss: 946900.0
[INFO] Global_t: 1230, Episode_t: 6, Action: 48, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1231, loss: 242486.40625
[INFO] Global_t: 1231, Episode_t: 7, Action: 20, Reward: 2.04, Epsilon: 0.01
[INFO] model update: t: 1232, loss: 37802.28515625
[INFO] Global_t: 1232, Episode_t: 8, Action: 22, Reward: 1.73, Epsilon: 0.01
 62%|██████▏   | 1232/2000 [34:11<20:22,  1.59s/it]
[INFO] Global step: 1232, Cumulative rewards: 23.95992, Runtime (s): 2051.15
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3735849857330322
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.40972900390625
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3910295963287354
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5015175342559814
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.293721914291382
average cummulative reward vector is:  [0.12300605 0.10802454 0.12095601 0.11086986 0.12112634]
average cummulative reward is:  0.11679656089933665
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 154, nodes: 189, edges: 558
[INFO] model update: t: 1233, loss: 392912.375
[INFO] Global_t: 1233, Episode_t: 1, Action: 6, Reward: 4.68, Epsilon: 0.01
[INFO] model update: t: 1234, loss: 590555.375
[INFO] Global_t: 1234, Episode_t: 2, Action: 39, Reward: 3.12, Epsilon: 0.01
[INFO] model update: t: 1235, loss: 550731.3125
[INFO] Global_t: 1235, Episode_t: 3, Action: 52, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1236, loss: 555258.5
[INFO] Global_t: 1236, Episode_t: 4, Action: 10, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 1237, loss: 64974.875
[INFO] Global_t: 1237, Episode_t: 5, Action: 8, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1238, loss: 202326.484375
[INFO] Global_t: 1238, Episode_t: 6, Action: 19, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1239, loss: 632761.125
[INFO] Global_t: 1239, Episode_t: 7, Action: 18, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1240, loss: 560301.25
[INFO] Global_t: 1240, Episode_t: 8, Action: 9, Reward: 2.12, Epsilon: 0.01
 62%|██████▏   | 1240/2000 [34:34<25:16,  2.00s/it]
[INFO] Global step: 1240, Cumulative rewards: 20.932439999999996, Runtime (s): 2074.66
------------------------------------------------------------
 
graph: 155, nodes: 203, edges: 599
[INFO] model update: t: 1241, loss: 87270.78125
[INFO] Global_t: 1241, Episode_t: 1, Action: 5, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1242, loss: 113032.6796875
[INFO] Global_t: 1242, Episode_t: 2, Action: 4, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1243, loss: 865886.375
[INFO] Global_t: 1243, Episode_t: 3, Action: 12, Reward: 2.88, Epsilon: 0.01
[INFO] model update: t: 1244, loss: 3353164.5
[INFO] Global_t: 1244, Episode_t: 4, Action: 22, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1245, loss: 11053826.0
[INFO] Global_t: 1245, Episode_t: 5, Action: 32, Reward: 2.41, Epsilon: 0.01
[INFO] model update: t: 1246, loss: 29940864.0
[INFO] Global_t: 1246, Episode_t: 6, Action: 27, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 1247, loss: 59090912.0
[INFO] Global_t: 1247, Episode_t: 7, Action: 45, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1248, loss: 51452352.0
[INFO] Global_t: 1248, Episode_t: 8, Action: 14, Reward: 1.56, Epsilon: 0.01
 62%|██████▏   | 1248/2000 [34:40<20:05,  1.60s/it]
[INFO] Global step: 1248, Cumulative rewards: 21.63588, Runtime (s): 2080.17
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.529384136199951
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8475277423858643
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.404644012451172
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.785287380218506
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.3276617527008057
average cummulative reward vector is:  [0.11845842 0.11833426 0.12497596 0.11007523 0.12427688]
average cummulative reward is:  0.11922415039226675
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 156, nodes: 192, edges: 567
[INFO] model update: t: 1249, loss: 6859693.0
[INFO] Global_t: 1249, Episode_t: 1, Action: 8, Reward: 4.44, Epsilon: 0.01
[INFO] model update: t: 1250, loss: 7467177.5
[INFO] Global_t: 1250, Episode_t: 2, Action: 7, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1251, loss: 28519516.0
[INFO] Global_t: 1251, Episode_t: 3, Action: 5, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1252, loss: 6348261.0
[INFO] Global_t: 1252, Episode_t: 4, Action: 10, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 1253, loss: 11599204.0
[INFO] Global_t: 1253, Episode_t: 5, Action: 6, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1254, loss: 52550400.0
[INFO] Global_t: 1254, Episode_t: 6, Action: 37, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1255, loss: 37646056.0
[INFO] Global_t: 1255, Episode_t: 7, Action: 2, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 1256, loss: 3555884.75
[INFO] Global_t: 1256, Episode_t: 8, Action: 9, Reward: 2.65, Epsilon: 0.01

[INFO] Global step: 1256, Cumulative rewards: 22.79844, Runtime (s): 2105.74
------------------------------------------------------------
 
 63%|██████▎   | 1256/2000 [35:05<25:48,  2.08s/it]graph: 157, nodes: 220, edges: 651
[INFO] model update: t: 1257, loss: 8015470.0
[INFO] Global_t: 1257, Episode_t: 1, Action: 8, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1258, loss: 25289544.0
[INFO] Global_t: 1258, Episode_t: 2, Action: 16, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 1259, loss: 12756530.0
[INFO] Global_t: 1259, Episode_t: 3, Action: 15, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1260, loss: 79322.609375
[INFO] Global_t: 1260, Episode_t: 4, Action: 9, Reward: 3.19, Epsilon: 0.01
[INFO] model update: t: 1261, loss: 9678420.0
[INFO] Global_t: 1261, Episode_t: 5, Action: 1, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1262, loss: 5479213.0
[INFO] Global_t: 1262, Episode_t: 6, Action: 14, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1263, loss: 359490.625
[INFO] Global_t: 1263, Episode_t: 7, Action: 7, Reward: 1.71, Epsilon: 0.01
[INFO] model update: t: 1264, loss: 6727866.0
[INFO] Global_t: 1264, Episode_t: 8, Action: 17, Reward: 2.07, Epsilon: 0.01
 63%|██████▎   | 1264/2000 [35:13<21:37,  1.76s/it]
[INFO] Global step: 1264, Cumulative rewards: 24.30084, Runtime (s): 2113.88
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4860997200012207
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5789992809295654
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.529188871383667
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3054966926574707
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4814181327819824
average cummulative reward vector is:  [0.12425447 0.11426481 0.12688634 0.10656425 0.12806747]
average cummulative reward is:  0.12000747055031355
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 158, nodes: 209, edges: 618
[INFO] model update: t: 1265, loss: 6225493.0
[INFO] Global_t: 1265, Episode_t: 1, Action: 6, Reward: 5.04, Epsilon: 0.01
[INFO] model update: t: 1266, loss: 255022.515625
[INFO] Global_t: 1266, Episode_t: 2, Action: 7, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1267, loss: 3535537.5
[INFO] Global_t: 1267, Episode_t: 3, Action: 5, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1268, loss: 5192370.5
[INFO] Global_t: 1268, Episode_t: 4, Action: 27, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1269, loss: 152992.84375
[INFO] Global_t: 1269, Episode_t: 5, Action: 15, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 1270, loss: 5178557.0
[INFO] Global_t: 1270, Episode_t: 6, Action: 13, Reward: 1.53, Epsilon: 0.01
[INFO] model update: t: 1271, loss: 12492024.0
[INFO] Global_t: 1271, Episode_t: 7, Action: 8, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 1272, loss: 5106970.0
[INFO] Global_t: 1272, Episode_t: 8, Action: 11, Reward: 1.89, Epsilon: 0.01
 64%|██████▎   | 1272/2000 [35:37<25:29,  2.10s/it]
[INFO] Global step: 1272, Cumulative rewards: 24.753, Runtime (s): 2137.03
------------------------------------------------------------
 
graph: 159, nodes: 191, edges: 564
[INFO] model update: t: 1273, loss: 432354.5625
[INFO] Global_t: 1273, Episode_t: 1, Action: 8, Reward: 5.23, Epsilon: 0.01
[INFO] model update: t: 1274, loss: 6432287.5
[INFO] Global_t: 1274, Episode_t: 2, Action: 9, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1275, loss: 1615308.5
[INFO] Global_t: 1275, Episode_t: 3, Action: 26, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1276, loss: 1410320.0
[INFO] Global_t: 1276, Episode_t: 4, Action: 6, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 1277, loss: 5296791.5
[INFO] Global_t: 1277, Episode_t: 5, Action: 11, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1278, loss: 907029.5
[INFO] Global_t: 1278, Episode_t: 6, Action: 14, Reward: 1.78, Epsilon: 0.01
[INFO] model update: t: 1279, loss: 1589108.375
[INFO] Global_t: 1279, Episode_t: 7, Action: 10, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1280, loss: 1699502.375
[INFO] Global_t: 1280, Episode_t: 8, Action: 22, Reward: 1.96, Epsilon: 0.01
 64%|██████▍   | 1280/2000 [35:41<19:51,  1.65s/it]
[INFO] Global step: 1280, Cumulative rewards: 21.48492, Runtime (s): 2141.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4434900283813477
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8465147018432617
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.257507801055908
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5530736446380615
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5352301597595215
average cummulative reward vector is:  [0.11249632 0.12043611 0.12066366 0.10083762 0.13109086]
average cummulative reward is:  0.11710491302805084
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 160, nodes: 220, edges: 650
[INFO] model update: t: 1281, loss: 137769.78125
[INFO] Global_t: 1281, Episode_t: 1, Action: 2, Reward: 4.28, Epsilon: 0.01
[INFO] model update: t: 1282, loss: 2388296.5
[INFO] Global_t: 1282, Episode_t: 2, Action: 10, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1283, loss: 837712.375
[INFO] Global_t: 1283, Episode_t: 3, Action: 1, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1284, loss: 1076675.875
[INFO] Global_t: 1284, Episode_t: 4, Action: 14, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1285, loss: 3101632.0
[INFO] Global_t: 1285, Episode_t: 5, Action: 11, Reward: 3.54, Epsilon: 0.01
[INFO] model update: t: 1286, loss: 1040842.375
[INFO] Global_t: 1286, Episode_t: 6, Action: 21, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1287, loss: 340224.28125
[INFO] Global_t: 1287, Episode_t: 7, Action: 17, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1288, loss: 1196067.75
[INFO] Global_t: 1288, Episode_t: 8, Action: 19, Reward: 2.93, Epsilon: 0.01
 64%|██████▍   | 1288/2000 [36:03<23:21,  1.97s/it]
[INFO] Global step: 1288, Cumulative rewards: 27.08736, Runtime (s): 2163.51
------------------------------------------------------------
 
graph: 161, nodes: 194, edges: 573
[INFO] model update: t: 1289, loss: 308733.5
[INFO] Global_t: 1289, Episode_t: 1, Action: 8, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1290, loss: 103658.796875
[INFO] Global_t: 1290, Episode_t: 2, Action: 5, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1291, loss: 318543.6875
[INFO] Global_t: 1291, Episode_t: 3, Action: 3, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1292, loss: 42703.90625
[INFO] Global_t: 1292, Episode_t: 4, Action: 14, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 1293, loss: 145803.125
[INFO] Global_t: 1293, Episode_t: 5, Action: 6, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 1294, loss: 121415.328125
[INFO] Global_t: 1294, Episode_t: 6, Action: 47, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1295, loss: 20355.689453125
[INFO] Global_t: 1295, Episode_t: 7, Action: 11, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 1296, loss: 138269.375
[INFO] Global_t: 1296, Episode_t: 8, Action: 7, Reward: 1.96, Epsilon: 0.01
 65%|██████▍   | 1296/2000 [36:07<18:06,  1.54s/it]
[INFO] Global step: 1296, Cumulative rewards: 24.53208, Runtime (s): 2167.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.457329511642456
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.949436664581299
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1663341522216797
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3785488605499268
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5033397674560547
average cummulative reward vector is:  [0.12329421 0.12307431 0.11048142 0.10809579 0.13089274]
average cummulative reward is:  0.11916769463498118
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 162, nodes: 191, edges: 564
[INFO] model update: t: 1297, loss: 31556.12109375
[INFO] Global_t: 1297, Episode_t: 1, Action: 18, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1298, loss: 46879.68359375
[INFO] Global_t: 1298, Episode_t: 2, Action: 6, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 1299, loss: 16894.587890625
[INFO] Global_t: 1299, Episode_t: 3, Action: 16, Reward: 3.33, Epsilon: 0.01
[INFO] model update: t: 1300, loss: 29846.982421875
[INFO] Global_t: 1300, Episode_t: 4, Action: 4, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1301, loss: 72945.4296875
[INFO] Global_t: 1301, Episode_t: 5, Action: 12, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1302, loss: 12572.84765625
[INFO] Global_t: 1302, Episode_t: 6, Action: 9, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1303, loss: 39538.6015625
[INFO] Global_t: 1303, Episode_t: 7, Action: 17, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1304, loss: 63524.92578125
[INFO] Global_t: 1304, Episode_t: 8, Action: 70, Reward: 1.48, Epsilon: 0.01
 65%|██████▌   | 1304/2000 [36:30<22:20,  1.93s/it]
[INFO] Global step: 1304, Cumulative rewards: 22.93692, Runtime (s): 2190.48
------------------------------------------------------------
 
graph: 163, nodes: 213, edges: 629
[INFO] model update: t: 1305, loss: 17947.71484375
[INFO] Global_t: 1305, Episode_t: 1, Action: 38, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1306, loss: 19930.50390625
[INFO] Global_t: 1306, Episode_t: 2, Action: 6, Reward: 4.79, Epsilon: 0.01
[INFO] model update: t: 1307, loss: 80042.125
[INFO] Global_t: 1307, Episode_t: 3, Action: 59, Reward: 3.01, Epsilon: 0.01
[INFO] model update: t: 1308, loss: 12657.255859375
[INFO] Global_t: 1308, Episode_t: 4, Action: 4, Reward: 3.15, Epsilon: 0.01
[INFO] model update: t: 1309, loss: 37007.3203125
[INFO] Global_t: 1309, Episode_t: 5, Action: 70, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 1310, loss: 68333.484375
[INFO] Global_t: 1310, Episode_t: 6, Action: 17, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1311, loss: 21217.84375
[INFO] Global_t: 1311, Episode_t: 7, Action: 13, Reward: 1.63, Epsilon: 0.01
[INFO] model update: t: 1312, loss: 46403.015625
[INFO] Global_t: 1312, Episode_t: 8, Action: 26, Reward: 1.95, Epsilon: 0.01
 66%|██████▌   | 1312/2000 [36:35<17:40,  1.54s/it]
[INFO] Global step: 1312, Cumulative rewards: 22.20216, Runtime (s): 2195.63
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.8769187927246094
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7061920166015625
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7569081783294678
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5656332969665527
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.6294193267822266
average cummulative reward vector is:  [0.12237605 0.11647153 0.13230984 0.11264322 0.13311183]
average cummulative reward is:  0.12338249374619703
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 164, nodes: 182, edges: 537
[INFO] model update: t: 1313, loss: 95289.3984375
[INFO] Global_t: 1313, Episode_t: 1, Action: 5, Reward: 4.33, Epsilon: 0.01
[INFO] model update: t: 1314, loss: 4076.05615234375
[INFO] Global_t: 1314, Episode_t: 2, Action: 2, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 1315, loss: 175006.671875
[INFO] Global_t: 1315, Episode_t: 3, Action: 9, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1316, loss: 253556.265625
[INFO] Global_t: 1316, Episode_t: 4, Action: 11, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1317, loss: 5850.7001953125
[INFO] Global_t: 1317, Episode_t: 5, Action: 10, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 1318, loss: 258841.15625
[INFO] Global_t: 1318, Episode_t: 6, Action: 25, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1319, loss: 159710.03125
[INFO] Global_t: 1319, Episode_t: 7, Action: 15, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1320, loss: 9556.0380859375
[INFO] Global_t: 1320, Episode_t: 8, Action: 13, Reward: 2.04, Epsilon: 0.01
 66%|██████▌   | 1320/2000 [36:59<22:20,  1.97s/it]
[INFO] Global step: 1320, Cumulative rewards: 21.048720000000003, Runtime (s): 2219.42
------------------------------------------------------------
 
graph: 165, nodes: 180, edges: 531
[INFO] model update: t: 1321, loss: 257526.140625
[INFO] Global_t: 1321, Episode_t: 1, Action: 5, Reward: 4.69, Epsilon: 0.01
[INFO] model update: t: 1322, loss: 461473.5625
[INFO] Global_t: 1322, Episode_t: 2, Action: 3, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1323, loss: 252272.734375
[INFO] Global_t: 1323, Episode_t: 3, Action: 6, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1324, loss: 18041.62109375
[INFO] Global_t: 1324, Episode_t: 4, Action: 25, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 1325, loss: 314347.4375
[INFO] Global_t: 1325, Episode_t: 5, Action: 18, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 1326, loss: 143077.5625
[INFO] Global_t: 1326, Episode_t: 6, Action: 10, Reward: 2.67, Epsilon: 0.01
[INFO] model update: t: 1327, loss: 138016.125
[INFO] Global_t: 1327, Episode_t: 7, Action: 21, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1328, loss: 171397.40625
[INFO] Global_t: 1328, Episode_t: 8, Action: 15, Reward: 2.29, Epsilon: 0.01
 66%|██████▋   | 1328/2000 [37:03<17:03,  1.52s/it]
[INFO] Global step: 1328, Cumulative rewards: 26.907479999999996, Runtime (s): 2223.25
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2437047958374023
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.164785623550415
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1040637493133545
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3313465118408203
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9142489433288574
average cummulative reward vector is:  [0.118155   0.12164977 0.11560902 0.1067271  0.12817876]
average cummulative reward is:  0.11806393023131194
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 166, nodes: 185, edges: 544
[INFO] model update: t: 1329, loss: 62646.49609375
[INFO] Global_t: 1329, Episode_t: 1, Action: 7, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1330, loss: 249754.8125
[INFO] Global_t: 1330, Episode_t: 2, Action: 4, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 1331, loss: 16563.43359375
[INFO] Global_t: 1331, Episode_t: 3, Action: 10, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1332, loss: 299182.75
[INFO] Global_t: 1332, Episode_t: 4, Action: 6, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1333, loss: 132463.453125
[INFO] Global_t: 1333, Episode_t: 5, Action: 8, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1334, loss: 84330.5703125
[INFO] Global_t: 1334, Episode_t: 6, Action: 11, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1335, loss: 228091.78125
[INFO] Global_t: 1335, Episode_t: 7, Action: 5, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1336, loss: 11620.5234375
[INFO] Global_t: 1336, Episode_t: 8, Action: 16, Reward: 1.64, Epsilon: 0.01
 67%|██████▋   | 1336/2000 [37:26<21:20,  1.93s/it]
[INFO] Global step: 1336, Cumulative rewards: 21.549, Runtime (s): 2246.23
------------------------------------------------------------
 
graph: 167, nodes: 181, edges: 533
[INFO] model update: t: 1337, loss: 138928.15625
[INFO] Global_t: 1337, Episode_t: 1, Action: 5, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1338, loss: 104067.625
[INFO] Global_t: 1338, Episode_t: 2, Action: 4, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1339, loss: 11774.1826171875
[INFO] Global_t: 1339, Episode_t: 3, Action: 37, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 1340, loss: 78293.046875
[INFO] Global_t: 1340, Episode_t: 4, Action: 14, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1341, loss: 32027.68359375
[INFO] Global_t: 1341, Episode_t: 5, Action: 17, Reward: 2.11, Epsilon: 0.01
[INFO] model update: t: 1342, loss: 5249.82275390625
[INFO] Global_t: 1342, Episode_t: 6, Action: 9, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1343, loss: 9957.1875
[INFO] Global_t: 1343, Episode_t: 7, Action: 43, Reward: 2.08, Epsilon: 0.01
[INFO] model update: t: 1344, loss: 8377.89453125
[INFO] Global_t: 1344, Episode_t: 8, Action: 2, Reward: 1.97, Epsilon: 0.01

[INFO] Global step: 1344, Cumulative rewards: 19.915679999999995, Runtime (s): 2251.06
------------------------------------------------------------
 
 67%|██████▋   | 1344/2000 [37:31<16:44,  1.53s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.0395660400390625
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.756542205810547
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.608018398284912
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4355411529541016
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.481346607208252
average cummulative reward vector is:  [0.10947526 0.11767569 0.12858579 0.10994252 0.12772204]
average cummulative reward is:  0.11868026326546093
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 168, nodes: 201, edges: 594
[INFO] model update: t: 1345, loss: 10227.3125
[INFO] Global_t: 1345, Episode_t: 1, Action: 7, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1346, loss: 34427.21484375
[INFO] Global_t: 1346, Episode_t: 2, Action: 10, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1347, loss: 32033.640625
[INFO] Global_t: 1347, Episode_t: 3, Action: 56, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1348, loss: 6595.79150390625
[INFO] Global_t: 1348, Episode_t: 4, Action: 27, Reward: 3.14, Epsilon: 0.01
[INFO] model update: t: 1349, loss: 35951.7109375
[INFO] Global_t: 1349, Episode_t: 5, Action: 22, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 1350, loss: 95881.9296875
[INFO] Global_t: 1350, Episode_t: 6, Action: 38, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 1351, loss: 51243.765625
[INFO] Global_t: 1351, Episode_t: 7, Action: 13, Reward: 3.24, Epsilon: 0.01
[INFO] model update: t: 1352, loss: 21255.36328125
[INFO] Global_t: 1352, Episode_t: 8, Action: 15, Reward: 2.15, Epsilon: 0.01
 68%|██████▊   | 1352/2000 [37:52<20:16,  1.88s/it]
[INFO] Global step: 1352, Cumulative rewards: 25.75668, Runtime (s): 2272.54
------------------------------------------------------------
 
graph: 169, nodes: 215, edges: 635
[INFO] model update: t: 1353, loss: 86670.1171875
[INFO] Global_t: 1353, Episode_t: 1, Action: 8, Reward: 4.59, Epsilon: 0.01
[INFO] model update: t: 1354, loss: 45893.0
[INFO] Global_t: 1354, Episode_t: 2, Action: 5, Reward: 4.35, Epsilon: 0.01
[INFO] model update: t: 1355, loss: 2875.20068359375
[INFO] Global_t: 1355, Episode_t: 3, Action: 9, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 1356, loss: 26747.81640625
[INFO] Global_t: 1356, Episode_t: 4, Action: 31, Reward: 3.01, Epsilon: 0.01
[INFO] model update: t: 1357, loss: 23458.44140625
[INFO] Global_t: 1357, Episode_t: 5, Action: 13, Reward: 4.55, Epsilon: 0.01
[INFO] model update: t: 1358, loss: 1774.8995361328125
[INFO] Global_t: 1358, Episode_t: 6, Action: 21, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 1359, loss: 36405.953125
[INFO] Global_t: 1359, Episode_t: 7, Action: 26, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 1360, loss: 47776.3515625
[INFO] Global_t: 1360, Episode_t: 8, Action: 43, Reward: 1.99, Epsilon: 0.01

[INFO] Global step: 1360, Cumulative rewards: 26.22168, Runtime (s): 2277.05
------------------------------------------------------------
 
 68%|██████▊   | 1360/2000 [37:57<15:49,  1.48s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6655702590942383
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6942760944366455
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5467405319213867
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.793196439743042
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7838902473449707
average cummulative reward vector is:  [0.12149421 0.11440463 0.13178306 0.11176776 0.14011505]
average cummulative reward is:  0.12391294220760433
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 170, nodes: 206, edges: 609
[INFO] model update: t: 1361, loss: 13951.2265625
[INFO] Global_t: 1361, Episode_t: 1, Action: 5, Reward: 3.92, Epsilon: 0.01
[INFO] model update: t: 1362, loss: 150960.28125
[INFO] Global_t: 1362, Episode_t: 2, Action: 9, Reward: 4.74, Epsilon: 0.01
[INFO] model update: t: 1363, loss: 155793.625
[INFO] Global_t: 1363, Episode_t: 3, Action: 13, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 1364, loss: 25818.2265625
[INFO] Global_t: 1364, Episode_t: 4, Action: 8, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1365, loss: 271261.1875
[INFO] Global_t: 1365, Episode_t: 5, Action: 14, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1366, loss: 164464.9375
[INFO] Global_t: 1366, Episode_t: 6, Action: 12, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1367, loss: 18622.12109375
[INFO] Global_t: 1367, Episode_t: 7, Action: 32, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 1368, loss: 67494.09375
[INFO] Global_t: 1368, Episode_t: 8, Action: 7, Reward: 2.93, Epsilon: 0.01
 68%|██████▊   | 1368/2000 [38:20<20:03,  1.90s/it]
[INFO] Global step: 1368, Cumulative rewards: 26.614919999999998, Runtime (s): 2300.13
------------------------------------------------------------
 
graph: 171, nodes: 202, edges: 597
[INFO] model update: t: 1369, loss: 144033.28125
[INFO] Global_t: 1369, Episode_t: 1, Action: 12, Reward: 4.45, Epsilon: 0.01
[INFO] model update: t: 1370, loss: 14447.0673828125
[INFO] Global_t: 1370, Episode_t: 2, Action: 2, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1371, loss: 71550.6875
[INFO] Global_t: 1371, Episode_t: 3, Action: 7, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1372, loss: 58091.6171875
[INFO] Global_t: 1372, Episode_t: 4, Action: 1, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 1373, loss: 5571.5791015625
[INFO] Global_t: 1373, Episode_t: 5, Action: 30, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1374, loss: 21959.595703125
[INFO] Global_t: 1374, Episode_t: 6, Action: 22, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 1375, loss: 15710.6640625
[INFO] Global_t: 1375, Episode_t: 7, Action: 6, Reward: 1.74, Epsilon: 0.01
[INFO] model update: t: 1376, loss: 5478.1171875
[INFO] Global_t: 1376, Episode_t: 8, Action: 9, Reward: 2.78, Epsilon: 0.01
 69%|██████▉   | 1376/2000 [38:26<16:30,  1.59s/it]
[INFO] Global step: 1376, Cumulative rewards: 21.785040000000002, Runtime (s): 2306.92
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.471285104751587
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.811249017715454
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6159555912017822
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.2113704681396484
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.649325132369995
average cummulative reward vector is:  [0.12296895 0.10640602 0.13503361 0.10179556 0.1270129 ]
average cummulative reward is:  0.11864340728355734
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 172, nodes: 206, edges: 609
[INFO] model update: t: 1377, loss: 24554.791015625
[INFO] Global_t: 1377, Episode_t: 1, Action: 11, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1378, loss: 4133.42431640625
[INFO] Global_t: 1378, Episode_t: 2, Action: 14, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 1379, loss: 29164.4453125
[INFO] Global_t: 1379, Episode_t: 3, Action: 36, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1380, loss: 34786.6953125
[INFO] Global_t: 1380, Episode_t: 4, Action: 8, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 1381, loss: 2467.9365234375
[INFO] Global_t: 1381, Episode_t: 5, Action: 23, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1382, loss: 47496.23828125
[INFO] Global_t: 1382, Episode_t: 6, Action: 32, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1383, loss: 91130.7734375
[INFO] Global_t: 1383, Episode_t: 7, Action: 19, Reward: 3.48, Epsilon: 0.01
[INFO] model update: t: 1384, loss: 18870.076171875
[INFO] Global_t: 1384, Episode_t: 8, Action: 58, Reward: 3.07, Epsilon: 0.01
 69%|██████▉   | 1384/2000 [38:47<19:20,  1.88s/it]
[INFO] Global step: 1384, Cumulative rewards: 29.12532, Runtime (s): 2327.53
------------------------------------------------------------
 
graph: 173, nodes: 217, edges: 641
[INFO] model update: t: 1385, loss: 48303.6875
[INFO] Global_t: 1385, Episode_t: 1, Action: 20, Reward: 4.31, Epsilon: 0.01
[INFO] model update: t: 1386, loss: 129268.296875
[INFO] Global_t: 1386, Episode_t: 2, Action: 9, Reward: 4.92, Epsilon: 0.01
[INFO] model update: t: 1387, loss: 2495.326171875
[INFO] Global_t: 1387, Episode_t: 3, Action: 14, Reward: 3.06, Epsilon: 0.01
[INFO] model update: t: 1388, loss: 105368.796875
[INFO] Global_t: 1388, Episode_t: 4, Action: 8, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1389, loss: 56878.9609375
[INFO] Global_t: 1389, Episode_t: 5, Action: 18, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1390, loss: 17439.185546875
[INFO] Global_t: 1390, Episode_t: 6, Action: 23, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1391, loss: 115355.6796875
[INFO] Global_t: 1391, Episode_t: 7, Action: 13, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1392, loss: 28300.86328125
[INFO] Global_t: 1392, Episode_t: 8, Action: 44, Reward: 1.83, Epsilon: 0.01
 70%|██████▉   | 1392/2000 [38:53<15:39,  1.54s/it]
[INFO] Global step: 1392, Cumulative rewards: 23.778599999999997, Runtime (s): 2333.55
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3667802810668945
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.8614513874053955
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.010310173034668
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.389744281768799
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.924290657043457
average cummulative reward vector is:  [0.12151211 0.11929144 0.13853115 0.10845304 0.13840081]
average cummulative reward is:  0.12523770636482343
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 174, nodes: 217, edges: 640
[INFO] model update: t: 1393, loss: 46665.97265625
[INFO] Global_t: 1393, Episode_t: 1, Action: 15, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1394, loss: 110605.484375
[INFO] Global_t: 1394, Episode_t: 2, Action: 11, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 1395, loss: 11321.1015625
[INFO] Global_t: 1395, Episode_t: 3, Action: 23, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1396, loss: 33736.76171875
[INFO] Global_t: 1396, Episode_t: 4, Action: 28, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 1397, loss: 52044.3828125
[INFO] Global_t: 1397, Episode_t: 5, Action: 0, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 1398, loss: 18359.88671875
[INFO] Global_t: 1398, Episode_t: 6, Action: 26, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 1399, loss: 106531.78125
[INFO] Global_t: 1399, Episode_t: 7, Action: 12, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1400, loss: 81357.7265625
[INFO] Global_t: 1400, Episode_t: 8, Action: 29, Reward: 1.69, Epsilon: 0.01
 70%|███████   | 1400/2000 [39:16<19:29,  1.95s/it]
[INFO] Global step: 1400, Cumulative rewards: 23.405519999999996, Runtime (s): 2356.70
------------------------------------------------------------
 
graph: 175, nodes: 200, edges: 591
[INFO] model update: t: 1401, loss: 16516.494140625
[INFO] Global_t: 1401, Episode_t: 1, Action: 9, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 1402, loss: 111551.46875
[INFO] Global_t: 1402, Episode_t: 2, Action: 8, Reward: 3.13, Epsilon: 0.01
[INFO] model update: t: 1403, loss: 3047.85498046875
[INFO] Global_t: 1403, Episode_t: 3, Action: 61, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1404, loss: 233087.6875
[INFO] Global_t: 1404, Episode_t: 4, Action: 10, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 1405, loss: 957644.5
[INFO] Global_t: 1405, Episode_t: 5, Action: 6, Reward: 5.06, Epsilon: 0.01
[INFO] model update: t: 1406, loss: 886985.0
[INFO] Global_t: 1406, Episode_t: 6, Action: 44, Reward: 3.24, Epsilon: 0.01
[INFO] model update: t: 1407, loss: 23131.6796875
[INFO] Global_t: 1407, Episode_t: 7, Action: 13, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1408, loss: 480147.0625
[INFO] Global_t: 1408, Episode_t: 8, Action: 1, Reward: 3.40, Epsilon: 0.01
 70%|███████   | 1408/2000 [39:19<14:29,  1.47s/it]
[INFO] Global step: 1408, Cumulative rewards: 27.232919999999993, Runtime (s): 2359.47
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.760205030441284
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7444093227386475
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7337522506713867
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6857693195343018
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7005813121795654
average cummulative reward vector is:  [0.12465553 0.11778102 0.13901557 0.10828388 0.13440995]
average cummulative reward is:  0.12482918866920638
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 176, nodes: 180, edges: 531
[INFO] model update: t: 1409, loss: 504266.75
[INFO] Global_t: 1409, Episode_t: 1, Action: 1, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1410, loss: 130236.6171875
[INFO] Global_t: 1410, Episode_t: 2, Action: 13, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1411, loss: 920591.0
[INFO] Global_t: 1411, Episode_t: 3, Action: 10, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 1412, loss: 230717.8125
[INFO] Global_t: 1412, Episode_t: 4, Action: 0, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 1413, loss: 343316.5
[INFO] Global_t: 1413, Episode_t: 5, Action: 18, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 1414, loss: 1043537.375
[INFO] Global_t: 1414, Episode_t: 6, Action: 5, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1415, loss: 58348.3125
[INFO] Global_t: 1415, Episode_t: 7, Action: 12, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1416, loss: 460368.3125
[INFO] Global_t: 1416, Episode_t: 8, Action: 9, Reward: 2.03, Epsilon: 0.01
 71%|███████   | 1416/2000 [39:42<18:20,  1.88s/it]
[INFO] Global step: 1416, Cumulative rewards: 23.17536, Runtime (s): 2382.29
------------------------------------------------------------
 
graph: 177, nodes: 192, edges: 567
[INFO] model update: t: 1417, loss: 68633.515625
[INFO] Global_t: 1417, Episode_t: 1, Action: 7, Reward: 4.61, Epsilon: 0.01
[INFO] model update: t: 1418, loss: 274009.3125
[INFO] Global_t: 1418, Episode_t: 2, Action: 1, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1419, loss: 221271.765625
[INFO] Global_t: 1419, Episode_t: 3, Action: 18, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 1420, loss: 7949.1689453125
[INFO] Global_t: 1420, Episode_t: 4, Action: 19, Reward: 1.88, Epsilon: 0.01
[INFO] model update: t: 1421, loss: 95129.25
[INFO] Global_t: 1421, Episode_t: 5, Action: 17, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1422, loss: 108082.7890625
[INFO] Global_t: 1422, Episode_t: 6, Action: 34, Reward: 1.63, Epsilon: 0.01
[INFO] model update: t: 1423, loss: 7408.564453125
[INFO] Global_t: 1423, Episode_t: 7, Action: 46, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1424, loss: 42462.28125
[INFO] Global_t: 1424, Episode_t: 8, Action: 10, Reward: 1.63, Epsilon: 0.01
 71%|███████   | 1424/2000 [39:47<14:24,  1.50s/it]
[INFO] Global step: 1424, Cumulative rewards: 19.899480000000004, Runtime (s): 2387.14
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3355464935302734
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.176723480224609
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.311002254486084
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.2677738666534424
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.775071144104004
average cummulative reward vector is:  [0.1218     0.11169861 0.12598743 0.10429883 0.13318629]
average cummulative reward is:  0.11939423298067635
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 178, nodes: 209, edges: 618
[INFO] model update: t: 1425, loss: 44027.828125
[INFO] Global_t: 1425, Episode_t: 1, Action: 6, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1426, loss: 1524.508544921875
[INFO] Global_t: 1426, Episode_t: 2, Action: 12, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 1427, loss: 36014.42578125
[INFO] Global_t: 1427, Episode_t: 3, Action: 10, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1428, loss: 42001.62890625
[INFO] Global_t: 1428, Episode_t: 4, Action: 24, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 1429, loss: 13077.041015625
[INFO] Global_t: 1429, Episode_t: 5, Action: 14, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1430, loss: 15859.373046875
[INFO] Global_t: 1430, Episode_t: 6, Action: 17, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1431, loss: 79977.2109375
[INFO] Global_t: 1431, Episode_t: 7, Action: 22, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1432, loss: 44524.18359375
[INFO] Global_t: 1432, Episode_t: 8, Action: 19, Reward: 2.40, Epsilon: 0.01

[INFO] Global step: 1432, Cumulative rewards: 20.50716, Runtime (s): 2409.67
 72%|███████▏  | 1432/2000 [40:09<17:56,  1.89s/it]------------------------------------------------------------
 
graph: 179, nodes: 205, edges: 606
[INFO] model update: t: 1433, loss: 46743.40625
[INFO] Global_t: 1433, Episode_t: 1, Action: 6, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1434, loss: 301248.8125
[INFO] Global_t: 1434, Episode_t: 2, Action: 13, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1435, loss: 231727.765625
[INFO] Global_t: 1435, Episode_t: 3, Action: 4, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 1436, loss: 7696.271484375
[INFO] Global_t: 1436, Episode_t: 4, Action: 9, Reward: 2.85, Epsilon: 0.01
[INFO] model update: t: 1437, loss: 351633.625
[INFO] Global_t: 1437, Episode_t: 5, Action: 15, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1438, loss: 622910.1875
[INFO] Global_t: 1438, Episode_t: 6, Action: 16, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1439, loss: 129708.9921875
[INFO] Global_t: 1439, Episode_t: 7, Action: 11, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1440, loss: 303828.21875
[INFO] Global_t: 1440, Episode_t: 8, Action: 29, Reward: 2.00, Epsilon: 0.01
 72%|███████▏  | 1440/2000 [40:15<14:32,  1.56s/it]
[INFO] Global step: 1440, Cumulative rewards: 22.0818, Runtime (s): 2415.82
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3579609394073486
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4250500202178955
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.018466949462891
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3966329097747803
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.3734214305877686
average cummulative reward vector is:  [0.12463632 0.11105764 0.13652049 0.10961869 0.1268586 ]
average cummulative reward is:  0.12173834804419278
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 180, nodes: 202, edges: 596
[INFO] model update: t: 1441, loss: 949427.3125
[INFO] Global_t: 1441, Episode_t: 1, Action: 6, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1442, loss: 35702.7265625
[INFO] Global_t: 1442, Episode_t: 2, Action: 10, Reward: 3.31, Epsilon: 0.01
[INFO] model update: t: 1443, loss: 567661.1875
[INFO] Global_t: 1443, Episode_t: 3, Action: 12, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 1444, loss: 1100360.375
[INFO] Global_t: 1444, Episode_t: 4, Action: 21, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 1445, loss: 345683.46875
[INFO] Global_t: 1445, Episode_t: 5, Action: 30, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 1446, loss: 49514.46484375
[INFO] Global_t: 1446, Episode_t: 6, Action: 24, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1447, loss: 564517.125
[INFO] Global_t: 1447, Episode_t: 7, Action: 8, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1448, loss: 727256.875
[INFO] Global_t: 1448, Episode_t: 8, Action: 13, Reward: 1.96, Epsilon: 0.01
 72%|███████▏  | 1448/2000 [40:38<17:48,  1.94s/it]
[INFO] Global step: 1448, Cumulative rewards: 24.199919999999995, Runtime (s): 2438.36
------------------------------------------------------------
 
graph: 181, nodes: 205, edges: 606
[INFO] model update: t: 1449, loss: 129764.6484375
[INFO] Global_t: 1449, Episode_t: 1, Action: 14, Reward: 4.56, Epsilon: 0.01
[INFO] model update: t: 1450, loss: 85785.140625
[INFO] Global_t: 1450, Episode_t: 2, Action: 6, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1451, loss: 202508.65625
[INFO] Global_t: 1451, Episode_t: 3, Action: 9, Reward: 4.28, Epsilon: 0.01
[INFO] model update: t: 1452, loss: 3179.61669921875
[INFO] Global_t: 1452, Episode_t: 4, Action: 29, Reward: 3.74, Epsilon: 0.01
[INFO] model update: t: 1453, loss: 171777.8125
[INFO] Global_t: 1453, Episode_t: 5, Action: 8, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1454, loss: 103660.25
[INFO] Global_t: 1454, Episode_t: 6, Action: 21, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1455, loss: 102939.7265625
[INFO] Global_t: 1455, Episode_t: 7, Action: 10, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 1456, loss: 490569.1875
[INFO] Global_t: 1456, Episode_t: 8, Action: 32, Reward: 3.06, Epsilon: 0.01
 73%|███████▎  | 1456/2000 [40:41<13:21,  1.47s/it]
[INFO] Global step: 1456, Cumulative rewards: 29.0346, Runtime (s): 2441.50
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.250309467315674
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9415299892425537
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.395630359649658
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.424193859100342
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.806758403778076
average cummulative reward vector is:  [0.12069447 0.10854514 0.13070792 0.11052126 0.1229457 ]
average cummulative reward is:  0.11868289933546827
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 182, nodes: 205, edges: 606
[INFO] model update: t: 1457, loss: 6519.05712890625
[INFO] Global_t: 1457, Episode_t: 1, Action: 24, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1458, loss: 461666.3125
[INFO] Global_t: 1458, Episode_t: 2, Action: 10, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1459, loss: 78827.1484375
[INFO] Global_t: 1459, Episode_t: 3, Action: 33, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1460, loss: 133764.46875
[INFO] Global_t: 1460, Episode_t: 4, Action: 29, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 1461, loss: 343183.875
[INFO] Global_t: 1461, Episode_t: 5, Action: 8, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1462, loss: 79346.359375
[INFO] Global_t: 1462, Episode_t: 6, Action: 5, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1463, loss: 15322.2685546875
[INFO] Global_t: 1463, Episode_t: 7, Action: 16, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1464, loss: 71498.765625
[INFO] Global_t: 1464, Episode_t: 8, Action: 17, Reward: 2.77, Epsilon: 0.01
 73%|███████▎  | 1464/2000 [41:03<16:25,  1.84s/it]
[INFO] Global step: 1464, Cumulative rewards: 26.05956, Runtime (s): 2463.04
------------------------------------------------------------
 
graph: 183, nodes: 217, edges: 642
[INFO] model update: t: 1465, loss: 31965.48828125
[INFO] Global_t: 1465, Episode_t: 1, Action: 8, Reward: 4.42, Epsilon: 0.01
[INFO] model update: t: 1466, loss: 3960.4912109375
[INFO] Global_t: 1466, Episode_t: 2, Action: 14, Reward: 4.01, Epsilon: 0.01
[INFO] model update: t: 1467, loss: 42399.1875
[INFO] Global_t: 1467, Episode_t: 3, Action: 17, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 1468, loss: 63682.953125
[INFO] Global_t: 1468, Episode_t: 4, Action: 20, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1469, loss: 28674.06640625
[INFO] Global_t: 1469, Episode_t: 5, Action: 4, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1470, loss: 4689.3427734375
[INFO] Global_t: 1470, Episode_t: 6, Action: 33, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1471, loss: 23973.68359375
[INFO] Global_t: 1471, Episode_t: 7, Action: 11, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1472, loss: 8126.4013671875
[INFO] Global_t: 1472, Episode_t: 8, Action: 12, Reward: 1.96, Epsilon: 0.01

[INFO] Global step: 1472, Cumulative rewards: 21.963119999999996, Runtime (s): 2469.34
 74%|███████▎  | 1472/2000 [41:09<13:24,  1.52s/it]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.593317985534668
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.3358469009399414
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8917019367218018
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.235419273376465
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.448542356491089
average cummulative reward vector is:  [0.13198711 0.1080537  0.13691339 0.10500397 0.13034785]
average cummulative reward is:  0.12246120367399722
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 184, nodes: 196, edges: 579
[INFO] model update: t: 1473, loss: 4287.470703125
[INFO] Global_t: 1473, Episode_t: 1, Action: 5, Reward: 5.81, Epsilon: 0.01
[INFO] model update: t: 1474, loss: 9294.818359375
[INFO] Global_t: 1474, Episode_t: 2, Action: 4, Reward: 3.73, Epsilon: 0.01
[INFO] model update: t: 1475, loss: 1532.8909912109375
[INFO] Global_t: 1475, Episode_t: 3, Action: 27, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 1476, loss: 4505.744140625
[INFO] Global_t: 1476, Episode_t: 4, Action: 19, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 1477, loss: 7826.6337890625
[INFO] Global_t: 1477, Episode_t: 5, Action: 20, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1478, loss: 5322.15478515625
[INFO] Global_t: 1478, Episode_t: 6, Action: 10, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1479, loss: 2732.344482421875
[INFO] Global_t: 1479, Episode_t: 7, Action: 7, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 1480, loss: 5195.34765625
[INFO] Global_t: 1480, Episode_t: 8, Action: 9, Reward: 3.24, Epsilon: 0.01
 74%|███████▍  | 1480/2000 [41:31<16:20,  1.89s/it]
[INFO] Global step: 1480, Cumulative rewards: 29.667120000000004, Runtime (s): 2491.18
------------------------------------------------------------
 
graph: 185, nodes: 180, edges: 530
[INFO] model update: t: 1481, loss: 7332.55029296875
[INFO] Global_t: 1481, Episode_t: 1, Action: 6, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1482, loss: 5964.65234375
[INFO] Global_t: 1482, Episode_t: 2, Action: 1, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1483, loss: 44501.03515625
[INFO] Global_t: 1483, Episode_t: 3, Action: 0, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1484, loss: 85269.53125
[INFO] Global_t: 1484, Episode_t: 4, Action: 18, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1485, loss: 30155.1015625
[INFO] Global_t: 1485, Episode_t: 5, Action: 5, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 1486, loss: 35714.39453125
[INFO] Global_t: 1486, Episode_t: 6, Action: 7, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1487, loss: 111337.25
[INFO] Global_t: 1487, Episode_t: 7, Action: 12, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1488, loss: 23060.16796875
[INFO] Global_t: 1488, Episode_t: 8, Action: 17, Reward: 1.65, Epsilon: 0.01
 74%|███████▍  | 1488/2000 [41:35<12:41,  1.49s/it]
[INFO] Global step: 1488, Cumulative rewards: 21.015239999999995, Runtime (s): 2495.63
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2482824325561523
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.08503270149231
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.296520471572876
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.9890642166137695
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4759581089019775
average cummulative reward vector is:  [0.12027184 0.11724769 0.12598716 0.09785234 0.1211707 ]
average cummulative reward is:  0.11650594422674461
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 186, nodes: 210, edges: 621
[INFO] model update: t: 1489, loss: 23786.70703125
[INFO] Global_t: 1489, Episode_t: 1, Action: 13, Reward: 4.19, Epsilon: 0.01
[INFO] model update: t: 1490, loss: 56659.58984375
[INFO] Global_t: 1490, Episode_t: 2, Action: 18, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 1491, loss: 10818.701171875
[INFO] Global_t: 1491, Episode_t: 3, Action: 7, Reward: 3.28, Epsilon: 0.01
[INFO] model update: t: 1492, loss: 20670.34375
[INFO] Global_t: 1492, Episode_t: 4, Action: 12, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1493, loss: 6110.892578125
[INFO] Global_t: 1493, Episode_t: 5, Action: 45, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 1494, loss: 15008.5625
[INFO] Global_t: 1494, Episode_t: 6, Action: 22, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1495, loss: 28035.615234375
[INFO] Global_t: 1495, Episode_t: 7, Action: 20, Reward: 1.47, Epsilon: 0.01
[INFO] model update: t: 1496, loss: 22359.75390625
[INFO] Global_t: 1496, Episode_t: 8, Action: 32, Reward: 1.78, Epsilon: 0.01
 75%|███████▍  | 1496/2000 [41:57<15:39,  1.86s/it]
[INFO] Global step: 1496, Cumulative rewards: 22.45884, Runtime (s): 2517.57
------------------------------------------------------------
 
graph: 187, nodes: 210, edges: 621
[INFO] model update: t: 1497, loss: 2267.531982421875
[INFO] Global_t: 1497, Episode_t: 1, Action: 22, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 1498, loss: 9675.7822265625
[INFO] Global_t: 1498, Episode_t: 2, Action: 5, Reward: 6.39, Epsilon: 0.01
[INFO] model update: t: 1499, loss: 2190.32568359375
[INFO] Global_t: 1499, Episode_t: 3, Action: 14, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 1500, loss: 5250.32470703125
[INFO] Global_t: 1500, Episode_t: 4, Action: 7, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1501, loss: 15911.84765625
[INFO] Global_t: 1501, Episode_t: 5, Action: 59, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1502, loss: 20477.765625
[INFO] Global_t: 1502, Episode_t: 6, Action: 6, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 1503, loss: 9431.947265625
[INFO] Global_t: 1503, Episode_t: 7, Action: 26, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1504, loss: 7629.7998046875
[INFO] Global_t: 1504, Episode_t: 8, Action: 41, Reward: 2.23, Epsilon: 0.01
 75%|███████▌  | 1504/2000 [42:02<12:18,  1.49s/it]
[INFO] Global step: 1504, Cumulative rewards: 25.73292, Runtime (s): 2522.51
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.204423189163208
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6313488483428955
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5145442485809326
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.3402249813079834
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.126715898513794
average cummulative reward vector is:  [0.11891368 0.11639375 0.12702268 0.10802033 0.11930376]
average cummulative reward is:  0.11793084046996374
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 188, nodes: 198, edges: 585
[INFO] model update: t: 1505, loss: 31889.740234375
[INFO] Global_t: 1505, Episode_t: 1, Action: 1, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 1506, loss: 3335.61083984375
[INFO] Global_t: 1506, Episode_t: 2, Action: 11, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 1507, loss: 61164.06640625
[INFO] Global_t: 1507, Episode_t: 3, Action: 0, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 1508, loss: 79669.765625
[INFO] Global_t: 1508, Episode_t: 4, Action: 10, Reward: 3.23, Epsilon: 0.01
[INFO] model update: t: 1509, loss: 4798.56201171875
[INFO] Global_t: 1509, Episode_t: 5, Action: 54, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1510, loss: 53710.40625
[INFO] Global_t: 1510, Episode_t: 6, Action: 12, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 1511, loss: 93181.109375
[INFO] Global_t: 1511, Episode_t: 7, Action: 5, Reward: 1.74, Epsilon: 0.01
[INFO] model update: t: 1512, loss: 6809.01953125
[INFO] Global_t: 1512, Episode_t: 8, Action: 52, Reward: 1.89, Epsilon: 0.01
 76%|███████▌  | 1512/2000 [42:24<15:04,  1.85s/it]
[INFO] Global step: 1512, Cumulative rewards: 23.13372, Runtime (s): 2544.11
------------------------------------------------------------
 
graph: 189, nodes: 180, edges: 531
[INFO] model update: t: 1513, loss: 71257.0703125
[INFO] Global_t: 1513, Episode_t: 1, Action: 5, Reward: 4.27, Epsilon: 0.01
[INFO] model update: t: 1514, loss: 121372.96875
[INFO] Global_t: 1514, Episode_t: 2, Action: 11, Reward: 3.52, Epsilon: 0.01
[INFO] model update: t: 1515, loss: 8552.0390625
[INFO] Global_t: 1515, Episode_t: 3, Action: 6, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1516, loss: 60216.44921875
[INFO] Global_t: 1516, Episode_t: 4, Action: 14, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1517, loss: 25740.560546875
[INFO] Global_t: 1517, Episode_t: 5, Action: 4, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1518, loss: 18342.615234375
[INFO] Global_t: 1518, Episode_t: 6, Action: 23, Reward: 1.74, Epsilon: 0.01
[INFO] model update: t: 1519, loss: 74297.15625
[INFO] Global_t: 1519, Episode_t: 7, Action: 18, Reward: 1.69, Epsilon: 0.01
[INFO] model update: t: 1520, loss: 40071.140625
[INFO] Global_t: 1520, Episode_t: 8, Action: 42, Reward: 1.45, Epsilon: 0.01
 76%|███████▌  | 1520/2000 [42:28<11:50,  1.48s/it]
[INFO] Global step: 1520, Cumulative rewards: 19.353839999999998, Runtime (s): 2548.98
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2625560760498047
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6787118911743164
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1728463172912598
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.2534148693084717
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.049181699752808
average cummulative reward vector is:  [0.11869395 0.11017546 0.12023033 0.10590093 0.13181855]
average cummulative reward is:  0.11736384423335448
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 190, nodes: 194, edges: 573
[INFO] model update: t: 1521, loss: 12279.7919921875
[INFO] Global_t: 1521, Episode_t: 1, Action: 5, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1522, loss: 5088.89453125
[INFO] Global_t: 1522, Episode_t: 2, Action: 8, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1523, loss: 40762.0703125
[INFO] Global_t: 1523, Episode_t: 3, Action: 3, Reward: 4.07, Epsilon: 0.01
[INFO] model update: t: 1524, loss: 39015.1875
[INFO] Global_t: 1524, Episode_t: 4, Action: 9, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 1525, loss: 5452.216796875
[INFO] Global_t: 1525, Episode_t: 5, Action: 7, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1526, loss: 7800.59423828125
[INFO] Global_t: 1526, Episode_t: 6, Action: 12, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1527, loss: 14582.1435546875
[INFO] Global_t: 1527, Episode_t: 7, Action: 23, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 1528, loss: 3438.4970703125
[INFO] Global_t: 1528, Episode_t: 8, Action: 24, Reward: 2.06, Epsilon: 0.01
 76%|███████▋  | 1528/2000 [42:50<14:25,  1.83s/it]
[INFO] Global step: 1528, Cumulative rewards: 23.414399999999997, Runtime (s): 2570.27
------------------------------------------------------------
 
graph: 191, nodes: 183, edges: 539
[INFO] model update: t: 1529, loss: 13346.091796875
[INFO] Global_t: 1529, Episode_t: 1, Action: 6, Reward: 4.49, Epsilon: 0.01
[INFO] model update: t: 1530, loss: 10148.36328125
[INFO] Global_t: 1530, Episode_t: 2, Action: 12, Reward: 3.67, Epsilon: 0.01
[INFO] model update: t: 1531, loss: 5525.30224609375
[INFO] Global_t: 1531, Episode_t: 3, Action: 5, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1532, loss: 5432.8427734375
[INFO] Global_t: 1532, Episode_t: 4, Action: 10, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 1533, loss: 39486.7578125
[INFO] Global_t: 1533, Episode_t: 5, Action: 58, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1534, loss: 30881.076171875
[INFO] Global_t: 1534, Episode_t: 6, Action: 9, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 1535, loss: 6390.10009765625
[INFO] Global_t: 1535, Episode_t: 7, Action: 15, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 1536, loss: 9812.501953125
[INFO] Global_t: 1536, Episode_t: 8, Action: 36, Reward: 1.87, Epsilon: 0.01
 77%|███████▋  | 1536/2000 [42:55<11:28,  1.48s/it]
[INFO] Global step: 1536, Cumulative rewards: 21.628800000000002, Runtime (s): 2575.61
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4305148124694824
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5128438472747803
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7205042839050293
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.41347599029541
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.1774892807006836
average cummulative reward vector is:  [0.12643105 0.11198866 0.12721913 0.11052056 0.11986505]
average cummulative reward is:  0.11920489004663018
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 192, nodes: 214, edges: 633
[INFO] model update: t: 1537, loss: 21424.7578125
[INFO] Global_t: 1537, Episode_t: 1, Action: 10, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1538, loss: 5471.4111328125
[INFO] Global_t: 1538, Episode_t: 2, Action: 9, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1539, loss: 14377.703125
[INFO] Global_t: 1539, Episode_t: 3, Action: 1, Reward: 3.28, Epsilon: 0.01
[INFO] model update: t: 1540, loss: 18095.65625
[INFO] Global_t: 1540, Episode_t: 4, Action: 2, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1541, loss: 3054.169921875
[INFO] Global_t: 1541, Episode_t: 5, Action: 11, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 1542, loss: 27937.044921875
[INFO] Global_t: 1542, Episode_t: 6, Action: 18, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 1543, loss: 26275.501953125
[INFO] Global_t: 1543, Episode_t: 7, Action: 12, Reward: 1.51, Epsilon: 0.01
[INFO] model update: t: 1544, loss: 2273.75244140625
[INFO] Global_t: 1544, Episode_t: 8, Action: 15, Reward: 2.24, Epsilon: 0.01
 77%|███████▋  | 1544/2000 [43:17<14:13,  1.87s/it]
[INFO] Global step: 1544, Cumulative rewards: 24.27648, Runtime (s): 2597.83
------------------------------------------------------------
 
graph: 193, nodes: 218, edges: 645
[INFO] model update: t: 1545, loss: 13032.33203125
[INFO] Global_t: 1545, Episode_t: 1, Action: 6, Reward: 5.07, Epsilon: 0.01
[INFO] model update: t: 1546, loss: 5634.734375
[INFO] Global_t: 1546, Episode_t: 2, Action: 1, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 1547, loss: 7491.01123046875
[INFO] Global_t: 1547, Episode_t: 3, Action: 23, Reward: 2.87, Epsilon: 0.01
[INFO] model update: t: 1548, loss: 17374.31640625
[INFO] Global_t: 1548, Episode_t: 4, Action: 46, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1549, loss: 1107.90283203125
[INFO] Global_t: 1549, Episode_t: 5, Action: 16, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 1550, loss: 22010.17578125
[INFO] Global_t: 1550, Episode_t: 6, Action: 26, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1551, loss: 10231.634765625
[INFO] Global_t: 1551, Episode_t: 7, Action: 9, Reward: 3.33, Epsilon: 0.01
[INFO] model update: t: 1552, loss: 29747.25
[INFO] Global_t: 1552, Episode_t: 8, Action: 11, Reward: 3.39, Epsilon: 0.01
 78%|███████▊  | 1552/2000 [43:22<11:02,  1.48s/it]
[INFO] Global step: 1552, Cumulative rewards: 25.26708, Runtime (s): 2602.34
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.493687152862549
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.258099794387817
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3602447509765625
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.184720993041992
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7363078594207764
average cummulative reward vector is:  [0.129225   0.11465602 0.1282541  0.10261939 0.1254422 ]
average cummulative reward is:  0.12003934274072278
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 194, nodes: 213, edges: 630
[INFO] model update: t: 1553, loss: 235914.9375
[INFO] Global_t: 1553, Episode_t: 1, Action: 3, Reward: 5.43, Epsilon: 0.01
[INFO] model update: t: 1554, loss: 641292.625
[INFO] Global_t: 1554, Episode_t: 2, Action: 24, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 1555, loss: 1239397.375
[INFO] Global_t: 1555, Episode_t: 3, Action: 18, Reward: 3.23, Epsilon: 0.01
[INFO] model update: t: 1556, loss: 1429042.25
[INFO] Global_t: 1556, Episode_t: 4, Action: 23, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1557, loss: 330204.4375
[INFO] Global_t: 1557, Episode_t: 5, Action: 14, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 1558, loss: 626695.875
[INFO] Global_t: 1558, Episode_t: 6, Action: 26, Reward: 2.85, Epsilon: 0.01
[INFO] model update: t: 1559, loss: 1611643.5
[INFO] Global_t: 1559, Episode_t: 7, Action: 12, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1560, loss: 368848.9375
[INFO] Global_t: 1560, Episode_t: 8, Action: 11, Reward: 2.95, Epsilon: 0.01
 78%|███████▊  | 1560/2000 [43:45<13:59,  1.91s/it]
[INFO] Global step: 1560, Cumulative rewards: 26.355119999999996, Runtime (s): 2625.61
------------------------------------------------------------
 
graph: 195, nodes: 189, edges: 558
[INFO] model update: t: 1561, loss: 5901258.0
[INFO] Global_t: 1561, Episode_t: 1, Action: 7, Reward: 4.14, Epsilon: 0.01
[INFO] model update: t: 1562, loss: 5353449.5
[INFO] Global_t: 1562, Episode_t: 2, Action: 1, Reward: 3.23, Epsilon: 0.01
[INFO] model update: t: 1563, loss: 317151.90625
[INFO] Global_t: 1563, Episode_t: 3, Action: 12, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 1564, loss: 3452468.25
[INFO] Global_t: 1564, Episode_t: 4, Action: 5, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1565, loss: 11374143.0
[INFO] Global_t: 1565, Episode_t: 5, Action: 10, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 1566, loss: 5698640.0
[INFO] Global_t: 1566, Episode_t: 6, Action: 13, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1567, loss: 10022.888671875
[INFO] Global_t: 1567, Episode_t: 7, Action: 29, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 1568, loss: 4372123.5
[INFO] Global_t: 1568, Episode_t: 8, Action: 18, Reward: 1.31, Epsilon: 0.01
 78%|███████▊  | 1568/2000 [43:51<11:11,  1.55s/it]
[INFO] Global step: 1568, Cumulative rewards: 19.882799999999996, Runtime (s): 2631.45
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2335126399993896
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.048482179641724
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3617053031921387
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.270820379257202
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.049903154373169
average cummulative reward vector is:  [0.11892342 0.12239398 0.12866066 0.10685958 0.13249194]
average cummulative reward is:  0.12186591463898826
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 196, nodes: 208, edges: 615
[INFO] model update: t: 1569, loss: 7975255.0
[INFO] Global_t: 1569, Episode_t: 1, Action: 5, Reward: 4.60, Epsilon: 0.01
[INFO] model update: t: 1570, loss: 5239594.5
[INFO] Global_t: 1570, Episode_t: 2, Action: 9, Reward: 4.12, Epsilon: 0.01
[INFO] model update: t: 1571, loss: 552405.125
[INFO] Global_t: 1571, Episode_t: 3, Action: 4, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 1572, loss: 10694640.0
[INFO] Global_t: 1572, Episode_t: 4, Action: 32, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 1573, loss: 9617520.0
[INFO] Global_t: 1573, Episode_t: 5, Action: 17, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1574, loss: 99067.578125
[INFO] Global_t: 1574, Episode_t: 6, Action: 6, Reward: 1.91, Epsilon: 0.01
[INFO] model update: t: 1575, loss: 9213510.0
[INFO] Global_t: 1575, Episode_t: 7, Action: 55, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 1576, loss: 3528173.0
[INFO] Global_t: 1576, Episode_t: 8, Action: 1, Reward: 1.45, Epsilon: 0.01
 79%|███████▉  | 1576/2000 [44:14<13:52,  1.96s/it]
[INFO] Global step: 1576, Cumulative rewards: 21.801120000000004, Runtime (s): 2654.77
------------------------------------------------------------
 
graph: 197, nodes: 197, edges: 582
[INFO] model update: t: 1577, loss: 2202443.25
[INFO] Global_t: 1577, Episode_t: 1, Action: 2, Reward: 5.09, Epsilon: 0.01
[INFO] model update: t: 1578, loss: 14128324.0
[INFO] Global_t: 1578, Episode_t: 2, Action: 6, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1579, loss: 14262970.0
[INFO] Global_t: 1579, Episode_t: 3, Action: 5, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1580, loss: 59905.5078125
[INFO] Global_t: 1580, Episode_t: 4, Action: 7, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 1581, loss: 10358078.0
[INFO] Global_t: 1581, Episode_t: 5, Action: 10, Reward: 3.24, Epsilon: 0.01
[INFO] model update: t: 1582, loss: 16953260.0
[INFO] Global_t: 1582, Episode_t: 6, Action: 16, Reward: 1.71, Epsilon: 0.01
[INFO] model update: t: 1583, loss: 21121088.0
[INFO] Global_t: 1583, Episode_t: 7, Action: 22, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1584, loss: 39461.30078125
[INFO] Global_t: 1584, Episode_t: 8, Action: 31, Reward: 2.52, Epsilon: 0.01

[INFO] Global step: 1584, Cumulative rewards: 24.44184, Runtime (s): 2659.53
 79%|███████▉  | 1584/2000 [44:19<10:45,  1.55s/it]------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.0897774696350098
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.836115598678589
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8500239849090576
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.0699963569641113
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.329059600830078
average cummulative reward vector is:  [0.11433316 0.1223963  0.12657049 0.10024953 0.12555215]
average cummulative reward is:  0.11782032584844533
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 198, nodes: 187, edges: 552
[INFO] model update: t: 1585, loss: 18753940.0
[INFO] Global_t: 1585, Episode_t: 1, Action: 5, Reward: 5.25, Epsilon: 0.01
[INFO] model update: t: 1586, loss: 9226577.0
[INFO] Global_t: 1586, Episode_t: 2, Action: 13, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1587, loss: 1571079.75
[INFO] Global_t: 1587, Episode_t: 3, Action: 15, Reward: 2.23, Epsilon: 0.01
[INFO] model update: t: 1588, loss: 15066801.0
[INFO] Global_t: 1588, Episode_t: 4, Action: 17, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1589, loss: 2788122.25
[INFO] Global_t: 1589, Episode_t: 5, Action: 20, Reward: 2.17, Epsilon: 0.01
[INFO] model update: t: 1590, loss: 4914217.0
[INFO] Global_t: 1590, Episode_t: 6, Action: 8, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1591, loss: 18839428.0
[INFO] Global_t: 1591, Episode_t: 7, Action: 22, Reward: 1.64, Epsilon: 0.01
[INFO] model update: t: 1592, loss: 2758975.0
[INFO] Global_t: 1592, Episode_t: 8, Action: 12, Reward: 1.84, Epsilon: 0.01
 80%|███████▉  | 1592/2000 [44:42<13:09,  1.93s/it]
[INFO] Global step: 1592, Cumulative rewards: 21.119039999999995, Runtime (s): 2682.12
------------------------------------------------------------
 
graph: 199, nodes: 216, edges: 638
[INFO] model update: t: 1593, loss: 4647070.0
[INFO] Global_t: 1593, Episode_t: 1, Action: 8, Reward: 4.76, Epsilon: 0.01
[INFO] model update: t: 1594, loss: 22413660.0
[INFO] Global_t: 1594, Episode_t: 2, Action: 7, Reward: 3.82, Epsilon: 0.01
[INFO] model update: t: 1595, loss: 22281488.0
[INFO] Global_t: 1595, Episode_t: 3, Action: 31, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 1596, loss: 1083660.625
[INFO] Global_t: 1596, Episode_t: 4, Action: 9, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 1597, loss: 10088800.0
[INFO] Global_t: 1597, Episode_t: 5, Action: 11, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 1598, loss: 17605994.0
[INFO] Global_t: 1598, Episode_t: 6, Action: 0, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1599, loss: 3043444.75
[INFO] Global_t: 1599, Episode_t: 7, Action: 28, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1600, loss: 1890602.5
[INFO] Global_t: 1600, Episode_t: 8, Action: 23, Reward: 1.78, Epsilon: 0.01
 80%|████████  | 1600/2000 [44:47<10:21,  1.55s/it]
[INFO] Global step: 1600, Cumulative rewards: 22.254480000000004, Runtime (s): 2687.42
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.300393581390381
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6693918704986572
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3446099758148193
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5717062950134277
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.3986458778381348
average cummulative reward vector is:  [0.11292026 0.11700417 0.12861148 0.10254206 0.12670618]
average cummulative reward is:  0.11755682882097254
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  1
graph: 0, nodes: 180, edges: 531
[INFO] model update: t: 1601, loss: 4815463.0
[INFO] Global_t: 1601, Episode_t: 1, Action: 4, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1602, loss: 75633.875
[INFO] Global_t: 1602, Episode_t: 2, Action: 20, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1603, loss: 3293172.5
[INFO] Global_t: 1603, Episode_t: 3, Action: 11, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 1604, loss: 5031744.0
[INFO] Global_t: 1604, Episode_t: 4, Action: 22, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1605, loss: 56888.4609375
[INFO] Global_t: 1605, Episode_t: 5, Action: 6, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1606, loss: 3118746.5
[INFO] Global_t: 1606, Episode_t: 6, Action: 12, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1607, loss: 1070611.25
[INFO] Global_t: 1607, Episode_t: 7, Action: 14, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 1608, loss: 341289.1875
[INFO] Global_t: 1608, Episode_t: 8, Action: 17, Reward: 1.92, Epsilon: 0.01
 80%|████████  | 1608/2000 [45:08<12:16,  1.88s/it]
[INFO] Global step: 1608, Cumulative rewards: 23.405399999999993, Runtime (s): 2708.56
------------------------------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] model update: t: 1609, loss: 1307530.5
[INFO] Global_t: 1609, Episode_t: 1, Action: 6, Reward: 4.66, Epsilon: 0.01
[INFO] model update: t: 1610, loss: 50861.1875
[INFO] Global_t: 1610, Episode_t: 2, Action: 27, Reward: 3.91, Epsilon: 0.01
[INFO] model update: t: 1611, loss: 783263.0625
[INFO] Global_t: 1611, Episode_t: 3, Action: 7, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 1612, loss: 699754.875
[INFO] Global_t: 1612, Episode_t: 4, Action: 12, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 1613, loss: 107552.625
[INFO] Global_t: 1613, Episode_t: 5, Action: 40, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1614, loss: 1238873.875
[INFO] Global_t: 1614, Episode_t: 6, Action: 8, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 1615, loss: 802974.3125
[INFO] Global_t: 1615, Episode_t: 7, Action: 22, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 1616, loss: 677516.25
[INFO] Global_t: 1616, Episode_t: 8, Action: 29, Reward: 1.02, Epsilon: 0.01
 81%|████████  | 1616/2000 [45:15<10:04,  1.57s/it]
[INFO] Global step: 1616, Cumulative rewards: 20.980560000000004, Runtime (s): 2715.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.296579599380493
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4264304637908936
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4856672286987305
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.479426622390747
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.577147960662842
average cummulative reward vector is:  [0.12241474 0.10919792 0.12087596 0.11288972 0.13463011]
average cummulative reward is:  0.12000168738919499
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] model update: t: 1617, loss: 5338596.0
[INFO] Global_t: 1617, Episode_t: 1, Action: 60, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1618, loss: 8943239.0
[INFO] Global_t: 1618, Episode_t: 2, Action: 6, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1619, loss: 289339.5625
[INFO] Global_t: 1619, Episode_t: 3, Action: 11, Reward: 4.21, Epsilon: 0.01
[INFO] model update: t: 1620, loss: 5445380.0
[INFO] Global_t: 1620, Episode_t: 4, Action: 24, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1621, loss: 6426225.5
[INFO] Global_t: 1621, Episode_t: 5, Action: 35, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 1622, loss: 2910532.0
[INFO] Global_t: 1622, Episode_t: 6, Action: 8, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 1623, loss: 16613928.0
[INFO] Global_t: 1623, Episode_t: 7, Action: 18, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1624, loss: 10608062.0
[INFO] Global_t: 1624, Episode_t: 8, Action: 5, Reward: 2.25, Epsilon: 0.01
 81%|████████  | 1624/2000 [45:37<11:59,  1.91s/it]
[INFO] Global step: 1624, Cumulative rewards: 28.70892, Runtime (s): 2737.10
------------------------------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] model update: t: 1625, loss: 2352199.5
[INFO] Global_t: 1625, Episode_t: 1, Action: 9, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1626, loss: 20374490.0
[INFO] Global_t: 1626, Episode_t: 2, Action: 13, Reward: 4.03, Epsilon: 0.01
[INFO] model update: t: 1627, loss: 6503944.5
[INFO] Global_t: 1627, Episode_t: 3, Action: 7, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 1628, loss: 952022.25
[INFO] Global_t: 1628, Episode_t: 4, Action: 1, Reward: 3.89, Epsilon: 0.01
[INFO] model update: t: 1629, loss: 7034293.0
[INFO] Global_t: 1629, Episode_t: 5, Action: 35, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1630, loss: 105357.2265625
[INFO] Global_t: 1630, Episode_t: 6, Action: 16, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 1631, loss: 8811489.0
[INFO] Global_t: 1631, Episode_t: 7, Action: 59, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1632, loss: 4297327.5
[INFO] Global_t: 1632, Episode_t: 8, Action: 5, Reward: 2.52, Epsilon: 0.01
 82%|████████▏ | 1632/2000 [45:41<09:17,  1.52s/it]
[INFO] Global step: 1632, Cumulative rewards: 25.482000000000003, Runtime (s): 2741.80
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.6968634128570557
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.512788772583008
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.29142165184021
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5764548778533936
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5819966793060303
average cummulative reward vector is:  [0.12285447 0.11275741 0.12688279 0.10551822 0.13505   ]
average cummulative reward is:  0.12061257845518585
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] model update: t: 1633, loss: 1132768.75
[INFO] Global_t: 1633, Episode_t: 1, Action: 2, Reward: 3.78, Epsilon: 0.01
[INFO] model update: t: 1634, loss: 8960410.0
[INFO] Global_t: 1634, Episode_t: 2, Action: 33, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 1635, loss: 8620148.0
[INFO] Global_t: 1635, Episode_t: 3, Action: 5, Reward: 4.30, Epsilon: 0.01
[INFO] model update: t: 1636, loss: 55357.81640625
[INFO] Global_t: 1636, Episode_t: 4, Action: 17, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1637, loss: 5914298.0
[INFO] Global_t: 1637, Episode_t: 5, Action: 19, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1638, loss: 3021579.75
[INFO] Global_t: 1638, Episode_t: 6, Action: 10, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1639, loss: 808525.5625
[INFO] Global_t: 1639, Episode_t: 7, Action: 12, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 1640, loss: 4229237.0
[INFO] Global_t: 1640, Episode_t: 8, Action: 83, Reward: 1.78, Epsilon: 0.01
 82%|████████▏ | 1640/2000 [46:04<11:22,  1.90s/it]
[INFO] Global step: 1640, Cumulative rewards: 20.56716, Runtime (s): 2764.07
------------------------------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] model update: t: 1641, loss: 76256.140625
[INFO] Global_t: 1641, Episode_t: 1, Action: 5, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1642, loss: 5077375.0
[INFO] Global_t: 1642, Episode_t: 2, Action: 2, Reward: 4.82, Epsilon: 0.01
[INFO] model update: t: 1643, loss: 13658225.0
[INFO] Global_t: 1643, Episode_t: 3, Action: 6, Reward: 4.32, Epsilon: 0.01
[INFO] model update: t: 1644, loss: 3783595.0
[INFO] Global_t: 1644, Episode_t: 4, Action: 23, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 1645, loss: 1807388.0
[INFO] Global_t: 1645, Episode_t: 5, Action: 17, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 1646, loss: 7424029.0
[INFO] Global_t: 1646, Episode_t: 6, Action: 28, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1647, loss: 72311.984375
[INFO] Global_t: 1647, Episode_t: 7, Action: 10, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 1648, loss: 4595799.5
[INFO] Global_t: 1648, Episode_t: 8, Action: 14, Reward: 2.16, Epsilon: 0.01
 82%|████████▏ | 1648/2000 [46:08<08:51,  1.51s/it]
[INFO] Global step: 1648, Cumulative rewards: 25.1154, Runtime (s): 2768.94
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.1210880279541016
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.115018367767334
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.404294967651367
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.431535005569458
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7049663066864014
average cummulative reward vector is:  [0.11283684 0.12068287 0.12953497 0.11173855 0.11889194]
average cummulative reward is:  0.11873703440779386
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 1649, loss: 853076.625
[INFO] Global_t: 1649, Episode_t: 1, Action: 11, Reward: 4.09, Epsilon: 0.01
[INFO] model update: t: 1650, loss: 1633534.375
[INFO] Global_t: 1650, Episode_t: 2, Action: 5, Reward: 5.41, Epsilon: 0.01
[INFO] model update: t: 1651, loss: 1486660.25
[INFO] Global_t: 1651, Episode_t: 3, Action: 8, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 1652, loss: 248657.59375
[INFO] Global_t: 1652, Episode_t: 4, Action: 7, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1653, loss: 1050471.25
[INFO] Global_t: 1653, Episode_t: 5, Action: 6, Reward: 1.33, Epsilon: 0.01
[INFO] model update: t: 1654, loss: 85053.640625
[INFO] Global_t: 1654, Episode_t: 6, Action: 16, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 1655, loss: 1230148.25
[INFO] Global_t: 1655, Episode_t: 7, Action: 26, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1656, loss: 22415.828125
[INFO] Global_t: 1656, Episode_t: 8, Action: 137, Reward: 0.79, Epsilon: 0.01
 83%|████████▎ | 1656/2000 [46:32<11:05,  1.93s/it]
[INFO] Global step: 1656, Cumulative rewards: 20.4642, Runtime (s): 2792.35
------------------------------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 1657, loss: 896537.5
[INFO] Global_t: 1657, Episode_t: 1, Action: 6, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1658, loss: 453410.34375
[INFO] Global_t: 1658, Episode_t: 2, Action: 3, Reward: 4.71, Epsilon: 0.01
[INFO] model update: t: 1659, loss: 55625.671875
[INFO] Global_t: 1659, Episode_t: 3, Action: 22, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1660, loss: 491495.5
[INFO] Global_t: 1660, Episode_t: 4, Action: 12, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 1661, loss: 357169.625
[INFO] Global_t: 1661, Episode_t: 5, Action: 10, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1662, loss: 18120.33984375
[INFO] Global_t: 1662, Episode_t: 6, Action: 13, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1663, loss: 193787.3125
[INFO] Global_t: 1663, Episode_t: 7, Action: 1, Reward: 1.40, Epsilon: 0.01
[INFO] model update: t: 1664, loss: 30066.4453125
[INFO] Global_t: 1664, Episode_t: 8, Action: 19, Reward: 1.68, Epsilon: 0.01
 83%|████████▎ | 1664/2000 [46:38<08:46,  1.57s/it]
[INFO] Global step: 1664, Cumulative rewards: 21.17844, Runtime (s): 2798.05
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.433576822280884
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.4898622035980225
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6418330669403076
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.2829267978668213
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.595867156982422
average cummulative reward vector is:  [0.12548947 0.1100838  0.12307678 0.10706729 0.13489597]
average cummulative reward is:  0.12012266067967052
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 1665, loss: 69198.90625
[INFO] Global_t: 1665, Episode_t: 1, Action: 3, Reward: 5.20, Epsilon: 0.01
[INFO] model update: t: 1666, loss: 89807.09375
[INFO] Global_t: 1666, Episode_t: 2, Action: 10, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1667, loss: 30014.8984375
[INFO] Global_t: 1667, Episode_t: 3, Action: 5, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1668, loss: 206813.328125
[INFO] Global_t: 1668, Episode_t: 4, Action: 18, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1669, loss: 82656.25
[INFO] Global_t: 1669, Episode_t: 5, Action: 67, Reward: 1.00, Epsilon: 0.01
[INFO] model update: t: 1670, loss: 29111.015625
[INFO] Global_t: 1670, Episode_t: 6, Action: 21, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 1671, loss: 74621.03125
[INFO] Global_t: 1671, Episode_t: 7, Action: 11, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1672, loss: 4991.96826171875
[INFO] Global_t: 1672, Episode_t: 8, Action: 16, Reward: 2.44, Epsilon: 0.01
 84%|████████▎ | 1672/2000 [47:00<10:30,  1.92s/it]
[INFO] Global step: 1672, Cumulative rewards: 22.319399999999998, Runtime (s): 2820.01
------------------------------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 1673, loss: 49171.546875
[INFO] Global_t: 1673, Episode_t: 1, Action: 11, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1674, loss: 1883.7987060546875
[INFO] Global_t: 1674, Episode_t: 2, Action: 12, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 1675, loss: 47385.51171875
[INFO] Global_t: 1675, Episode_t: 3, Action: 21, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1676, loss: 8809.1962890625
[INFO] Global_t: 1676, Episode_t: 4, Action: 25, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 1677, loss: 40026.53125
[INFO] Global_t: 1677, Episode_t: 5, Action: 13, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1678, loss: 76213.390625
[INFO] Global_t: 1678, Episode_t: 6, Action: 7, Reward: 2.56, Epsilon: 0.01
[INFO] model update: t: 1679, loss: 12620.48828125
[INFO] Global_t: 1679, Episode_t: 7, Action: 0, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1680, loss: 97220.046875
[INFO] Global_t: 1680, Episode_t: 8, Action: 17, Reward: 2.24, Epsilon: 0.01
 84%|████████▍ | 1680/2000 [47:03<07:58,  1.49s/it]
[INFO] Global step: 1680, Cumulative rewards: 25.05156, Runtime (s): 2823.99
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2357211112976074
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.896357297897339
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.2358198165893555
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.376124382019043
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.643841505050659
average cummulative reward vector is:  [0.11954947 0.11596181 0.12227896 0.10805374 0.12648737]
average cummulative reward is:  0.11846626897951096
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 1681, loss: 14161.0126953125
[INFO] Global_t: 1681, Episode_t: 1, Action: 5, Reward: 4.22, Epsilon: 0.01
[INFO] model update: t: 1682, loss: 55038.5703125
[INFO] Global_t: 1682, Episode_t: 2, Action: 7, Reward: 3.18, Epsilon: 0.01
[INFO] model update: t: 1683, loss: 96766.53125
[INFO] Global_t: 1683, Episode_t: 3, Action: 6, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1684, loss: 20567.7734375
[INFO] Global_t: 1684, Episode_t: 4, Action: 13, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1685, loss: 21676.5546875
[INFO] Global_t: 1685, Episode_t: 5, Action: 8, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1686, loss: 21512.587890625
[INFO] Global_t: 1686, Episode_t: 6, Action: 15, Reward: 2.88, Epsilon: 0.01
[INFO] model update: t: 1687, loss: 2358.153564453125
[INFO] Global_t: 1687, Episode_t: 7, Action: 11, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1688, loss: 5617.50048828125
[INFO] Global_t: 1688, Episode_t: 8, Action: 3, Reward: 3.21, Epsilon: 0.01
 84%|████████▍ | 1688/2000 [47:24<09:25,  1.81s/it]
[INFO] Global step: 1688, Cumulative rewards: 26.3712, Runtime (s): 2844.42
------------------------------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 1689, loss: 2073.861083984375
[INFO] Global_t: 1689, Episode_t: 1, Action: 33, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1690, loss: 22220.81640625
[INFO] Global_t: 1690, Episode_t: 2, Action: 6, Reward: 4.87, Epsilon: 0.01
[INFO] model update: t: 1691, loss: 29037.24609375
[INFO] Global_t: 1691, Episode_t: 3, Action: 19, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1692, loss: 3945.06787109375
[INFO] Global_t: 1692, Episode_t: 4, Action: 17, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1693, loss: 37905.75
[INFO] Global_t: 1693, Episode_t: 5, Action: 37, Reward: 1.52, Epsilon: 0.01
[INFO] model update: t: 1694, loss: 105851.59375
[INFO] Global_t: 1694, Episode_t: 6, Action: 9, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 1695, loss: 28047.837890625
[INFO] Global_t: 1695, Episode_t: 7, Action: 7, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1696, loss: 51156.37109375
[INFO] Global_t: 1696, Episode_t: 8, Action: 22, Reward: 1.50, Epsilon: 0.01
 85%|████████▍ | 1696/2000 [47:30<07:31,  1.48s/it]
[INFO] Global step: 1696, Cumulative rewards: 21.569879999999998, Runtime (s): 2850.19
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5962374210357666
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7684531211853027
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.825434446334839
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.466301441192627
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4475555419921875
average cummulative reward vector is:  [0.13187632 0.12064074 0.12586721 0.11115304 0.12963978]
average cummulative reward is:  0.12383541839487652
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 1697, loss: 175563.46875
[INFO] Global_t: 1697, Episode_t: 1, Action: 45, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1698, loss: 2454.97802734375
[INFO] Global_t: 1698, Episode_t: 2, Action: 4, Reward: 4.25, Epsilon: 0.01
[INFO] model update: t: 1699, loss: 201137.65625
[INFO] Global_t: 1699, Episode_t: 3, Action: 7, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 1700, loss: 242016.34375
[INFO] Global_t: 1700, Episode_t: 4, Action: 8, Reward: 2.90, Epsilon: 0.01
[INFO] model update: t: 1701, loss: 7106.7109375
[INFO] Global_t: 1701, Episode_t: 5, Action: 32, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1702, loss: 109197.921875
[INFO] Global_t: 1702, Episode_t: 6, Action: 17, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1703, loss: 37136.1171875
[INFO] Global_t: 1703, Episode_t: 7, Action: 49, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1704, loss: 37528.23828125
[INFO] Global_t: 1704, Episode_t: 8, Action: 13, Reward: 2.09, Epsilon: 0.01
 85%|████████▌ | 1704/2000 [47:53<09:25,  1.91s/it]
[INFO] Global step: 1704, Cumulative rewards: 21.507119999999997, Runtime (s): 2873.40
------------------------------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 1705, loss: 60083.8515625
[INFO] Global_t: 1705, Episode_t: 1, Action: 1, Reward: 4.88, Epsilon: 0.01
[INFO] model update: t: 1706, loss: 18512.828125
[INFO] Global_t: 1706, Episode_t: 2, Action: 6, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1707, loss: 117609.109375
[INFO] Global_t: 1707, Episode_t: 3, Action: 9, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1708, loss: 139328.484375
[INFO] Global_t: 1708, Episode_t: 4, Action: 12, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1709, loss: 25322.15625
[INFO] Global_t: 1709, Episode_t: 5, Action: 35, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 1710, loss: 49284.70703125
[INFO] Global_t: 1710, Episode_t: 6, Action: 21, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1711, loss: 56037.73828125
[INFO] Global_t: 1711, Episode_t: 7, Action: 16, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 1712, loss: 20149.736328125
[INFO] Global_t: 1712, Episode_t: 8, Action: 27, Reward: 2.21, Epsilon: 0.01
 86%|████████▌ | 1712/2000 [47:58<07:18,  1.52s/it]
[INFO] Global step: 1712, Cumulative rewards: 22.082160000000002, Runtime (s): 2878.33
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.699108362197876
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.5558836460113525
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.628432512283325
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.406782388687134
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5444560050964355
average cummulative reward vector is:  [0.12606763 0.1140794  0.13528689 0.1021028  0.12744167]
average cummulative reward is:  0.1209956770755963
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 1713, loss: 152268.5625
[INFO] Global_t: 1713, Episode_t: 1, Action: 9, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1714, loss: 70597.09375
[INFO] Global_t: 1714, Episode_t: 2, Action: 0, Reward: 3.42, Epsilon: 0.01
[INFO] model update: t: 1715, loss: 28056.10546875
[INFO] Global_t: 1715, Episode_t: 3, Action: 77, Reward: 1.57, Epsilon: 0.01
[INFO] model update: t: 1716, loss: 93296.6953125
[INFO] Global_t: 1716, Episode_t: 4, Action: 5, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 1717, loss: 6880.51416015625
[INFO] Global_t: 1717, Episode_t: 5, Action: 14, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1718, loss: 111620.15625
[INFO] Global_t: 1718, Episode_t: 6, Action: 11, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1719, loss: 14799.9482421875
[INFO] Global_t: 1719, Episode_t: 7, Action: 6, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 1720, loss: 60896.55859375
[INFO] Global_t: 1720, Episode_t: 8, Action: 27, Reward: 1.73, Epsilon: 0.01
 86%|████████▌ | 1720/2000 [48:20<08:53,  1.91s/it]
[INFO] Global step: 1720, Cumulative rewards: 23.652600000000003, Runtime (s): 2900.77
------------------------------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 1721, loss: 63055.015625
[INFO] Global_t: 1721, Episode_t: 1, Action: 6, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1722, loss: 17100.34375
[INFO] Global_t: 1722, Episode_t: 2, Action: 8, Reward: 3.84, Epsilon: 0.01
[INFO] model update: t: 1723, loss: 115015.859375
[INFO] Global_t: 1723, Episode_t: 3, Action: 0, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 1724, loss: 1279.664794921875
[INFO] Global_t: 1724, Episode_t: 4, Action: 1, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1725, loss: 126476.90625
[INFO] Global_t: 1725, Episode_t: 5, Action: 12, Reward: 2.64, Epsilon: 0.01
[INFO] model update: t: 1726, loss: 93110.453125
[INFO] Global_t: 1726, Episode_t: 6, Action: 17, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1727, loss: 15762.47265625
[INFO] Global_t: 1727, Episode_t: 7, Action: 24, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 1728, loss: 143949.265625
[INFO] Global_t: 1728, Episode_t: 8, Action: 10, Reward: 2.39, Epsilon: 0.01
 86%|████████▋ | 1728/2000 [48:25<06:51,  1.51s/it]
[INFO] Global step: 1728, Cumulative rewards: 24.05508, Runtime (s): 2905.54
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3306872844696045
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.919940710067749
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7142035961151123
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.799725294113159
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.412426233291626
average cummulative reward vector is:  [0.11994868 0.11349282 0.13909945 0.12286612 0.14425511]
average cummulative reward is:  0.12793243817174435
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 1729, loss: 31594.71875
[INFO] Global_t: 1729, Episode_t: 1, Action: 7, Reward: 4.34, Epsilon: 0.01
[INFO] model update: t: 1730, loss: 77549.2578125
[INFO] Global_t: 1730, Episode_t: 2, Action: 11, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1731, loss: 163051.875
[INFO] Global_t: 1731, Episode_t: 3, Action: 6, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1732, loss: 11116.564453125
[INFO] Global_t: 1732, Episode_t: 4, Action: 3, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1733, loss: 187493.65625
[INFO] Global_t: 1733, Episode_t: 5, Action: 23, Reward: 2.59, Epsilon: 0.01
[INFO] model update: t: 1734, loss: 41001.8125
[INFO] Global_t: 1734, Episode_t: 6, Action: 18, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1735, loss: 88379.265625
[INFO] Global_t: 1735, Episode_t: 7, Action: 36, Reward: 1.46, Epsilon: 0.01
[INFO] model update: t: 1736, loss: 279391.5
[INFO] Global_t: 1736, Episode_t: 8, Action: 20, Reward: 2.16, Epsilon: 0.01

[INFO] Global step: 1736, Cumulative rewards: 22.513439999999996, Runtime (s): 2929.52
------------------------------------------------------------
 
 87%|████████▋ | 1736/2000 [48:49<08:37,  1.96s/it]graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 1737, loss: 24059.431640625
[INFO] Global_t: 1737, Episode_t: 1, Action: 4, Reward: 4.99, Epsilon: 0.01
[INFO] model update: t: 1738, loss: 124690.3671875
[INFO] Global_t: 1738, Episode_t: 2, Action: 2, Reward: 3.01, Epsilon: 0.01
[INFO] model update: t: 1739, loss: 149844.375
[INFO] Global_t: 1739, Episode_t: 3, Action: 19, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 1740, loss: 15652.865234375
[INFO] Global_t: 1740, Episode_t: 4, Action: 3, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1741, loss: 85200.4921875
[INFO] Global_t: 1741, Episode_t: 5, Action: 8, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1742, loss: 95433.046875
[INFO] Global_t: 1742, Episode_t: 6, Action: 24, Reward: 2.88, Epsilon: 0.01
[INFO] model update: t: 1743, loss: 11280.09375
[INFO] Global_t: 1743, Episode_t: 7, Action: 23, Reward: 2.12, Epsilon: 0.01
[INFO] model update: t: 1744, loss: 126176.59375
[INFO] Global_t: 1744, Episode_t: 8, Action: 12, Reward: 2.01, Epsilon: 0.01
 87%|████████▋ | 1744/2000 [48:54<06:40,  1.57s/it]
[INFO] Global step: 1744, Cumulative rewards: 24.438959999999998, Runtime (s): 2934.72
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.3808324337005615
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9693267345428467
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.8627541065216064
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.4656193256378174
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4512884616851807
average cummulative reward vector is:  [0.11904816 0.12204792 0.1293459  0.11182126 0.12998548]
average cummulative reward is:  0.1224497443507917
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 1745, loss: 82472.1875
[INFO] Global_t: 1745, Episode_t: 1, Action: 10, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 1746, loss: 1926.1756591796875
[INFO] Global_t: 1746, Episode_t: 2, Action: 4, Reward: 4.94, Epsilon: 0.01
[INFO] model update: t: 1747, loss: 94899.9375
[INFO] Global_t: 1747, Episode_t: 3, Action: 6, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 1748, loss: 163795.21875
[INFO] Global_t: 1748, Episode_t: 4, Action: 1, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1749, loss: 24291.35546875
[INFO] Global_t: 1749, Episode_t: 5, Action: 31, Reward: 1.67, Epsilon: 0.01
[INFO] model update: t: 1750, loss: 69455.0078125
[INFO] Global_t: 1750, Episode_t: 6, Action: 13, Reward: 2.18, Epsilon: 0.01
[INFO] model update: t: 1751, loss: 32975.765625
[INFO] Global_t: 1751, Episode_t: 7, Action: 7, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1752, loss: 8116.1787109375
[INFO] Global_t: 1752, Episode_t: 8, Action: 12, Reward: 1.39, Epsilon: 0.01
 88%|████████▊ | 1752/2000 [49:19<08:18,  2.01s/it]
[INFO] Global step: 1752, Cumulative rewards: 21.305999999999997, Runtime (s): 2959.08
------------------------------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 1753, loss: 43367.8203125
[INFO] Global_t: 1753, Episode_t: 1, Action: 8, Reward: 5.08, Epsilon: 0.01
[INFO] model update: t: 1754, loss: 46074.234375
[INFO] Global_t: 1754, Episode_t: 2, Action: 13, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1755, loss: 13859.208984375
[INFO] Global_t: 1755, Episode_t: 3, Action: 11, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1756, loss: 2657.18505859375
[INFO] Global_t: 1756, Episode_t: 4, Action: 17, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 1757, loss: 6957.56640625
[INFO] Global_t: 1757, Episode_t: 5, Action: 4, Reward: 3.45, Epsilon: 0.01
[INFO] model update: t: 1758, loss: 2428.802734375
[INFO] Global_t: 1758, Episode_t: 6, Action: 9, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 1759, loss: 8725.859375
[INFO] Global_t: 1759, Episode_t: 7, Action: 23, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 1760, loss: 17388.703125
[INFO] Global_t: 1760, Episode_t: 8, Action: 12, Reward: 2.32, Epsilon: 0.01

[INFO] Global step: 1760, Cumulative rewards: 25.776960000000006, Runtime (s): 2963.49
------------------------------------------------------------
 
 88%|████████▊ | 1760/2000 [49:23<06:17,  1.57s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.786520004272461
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.9888815879821777
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.5257275104522705
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.992180824279785
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.403064012527466
average cummulative reward vector is:  [0.12196789 0.12152037 0.12952923 0.11270794 0.12817661]
average cummulative reward is:  0.12278041138166991
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 1761, loss: 3247.833984375
[INFO] Global_t: 1761, Episode_t: 1, Action: 11, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 1762, loss: 20376.90234375
[INFO] Global_t: 1762, Episode_t: 2, Action: 7, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 1763, loss: 18345.8359375
[INFO] Global_t: 1763, Episode_t: 3, Action: 0, Reward: 3.28, Epsilon: 0.01
[INFO] model update: t: 1764, loss: 1736.2044677734375
[INFO] Global_t: 1764, Episode_t: 4, Action: 3, Reward: 4.39, Epsilon: 0.01
[INFO] model update: t: 1765, loss: 7337.82373046875
[INFO] Global_t: 1765, Episode_t: 5, Action: 13, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 1766, loss: 5462.349609375
[INFO] Global_t: 1766, Episode_t: 6, Action: 23, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 1767, loss: 6532.7998046875
[INFO] Global_t: 1767, Episode_t: 7, Action: 10, Reward: 2.10, Epsilon: 0.01
[INFO] model update: t: 1768, loss: 2372.6005859375
[INFO] Global_t: 1768, Episode_t: 8, Action: 15, Reward: 1.78, Epsilon: 0.01
 88%|████████▊ | 1768/2000 [49:48<07:50,  2.03s/it]
[INFO] Global step: 1768, Cumulative rewards: 23.891880000000004, Runtime (s): 2988.19
------------------------------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 1769, loss: 4945.20654296875
[INFO] Global_t: 1769, Episode_t: 1, Action: 6, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1770, loss: 9937.3046875
[INFO] Global_t: 1770, Episode_t: 2, Action: 0, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1771, loss: 1794.663330078125
[INFO] Global_t: 1771, Episode_t: 3, Action: 8, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 1772, loss: 4479.81884765625
[INFO] Global_t: 1772, Episode_t: 4, Action: 9, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1773, loss: 12577.3583984375
[INFO] Global_t: 1773, Episode_t: 5, Action: 13, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1774, loss: 4221.29541015625
[INFO] Global_t: 1774, Episode_t: 6, Action: 34, Reward: 2.19, Epsilon: 0.01
[INFO] model update: t: 1775, loss: 3576.07177734375
[INFO] Global_t: 1775, Episode_t: 7, Action: 5, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1776, loss: 7956.22607421875
[INFO] Global_t: 1776, Episode_t: 8, Action: 21, Reward: 1.74, Epsilon: 0.01
 89%|████████▉ | 1776/2000 [49:53<06:01,  1.61s/it]
[INFO] Global step: 1776, Cumulative rewards: 20.577839999999995, Runtime (s): 2993.38
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5655312538146973
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.64917254447937
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.304290771484375
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  4.210555076599121
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.772988796234131
average cummulative reward vector is:  [0.12393868 0.10152731 0.12188907 0.11690724 0.13069409]
average cummulative reward is:  0.11899127981515042
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 1777, loss: 3139.408935546875
[INFO] Global_t: 1777, Episode_t: 1, Action: 1, Reward: 4.26, Epsilon: 0.01
[INFO] model update: t: 1778, loss: 6339.673828125
[INFO] Global_t: 1778, Episode_t: 2, Action: 17, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 1779, loss: 4597.09228515625
[INFO] Global_t: 1779, Episode_t: 3, Action: 5, Reward: 3.62, Epsilon: 0.01
[INFO] model update: t: 1780, loss: 6779.328125
[INFO] Global_t: 1780, Episode_t: 4, Action: 18, Reward: 2.56, Epsilon: 0.01
[INFO] model update: t: 1781, loss: 17389.73046875
[INFO] Global_t: 1781, Episode_t: 5, Action: 11, Reward: 1.62, Epsilon: 0.01
[INFO] model update: t: 1782, loss: 1446.4029541015625
[INFO] Global_t: 1782, Episode_t: 6, Action: 25, Reward: 1.22, Epsilon: 0.01
[INFO] model update: t: 1783, loss: 11829.19140625
[INFO] Global_t: 1783, Episode_t: 7, Action: 19, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1784, loss: 20208.26171875
[INFO] Global_t: 1784, Episode_t: 8, Action: 15, Reward: 1.47, Epsilon: 0.01
 89%|████████▉ | 1784/2000 [50:17<07:15,  2.02s/it]
[INFO] Global step: 1784, Cumulative rewards: 20.32356, Runtime (s): 3017.08
------------------------------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 1785, loss: 2169.185791015625
[INFO] Global_t: 1785, Episode_t: 1, Action: 12, Reward: 3.87, Epsilon: 0.01
[INFO] model update: t: 1786, loss: 22655.68359375
[INFO] Global_t: 1786, Episode_t: 2, Action: 14, Reward: 3.65, Epsilon: 0.01
[INFO] model update: t: 1787, loss: 14087.779296875
[INFO] Global_t: 1787, Episode_t: 3, Action: 6, Reward: 4.41, Epsilon: 0.01
[INFO] model update: t: 1788, loss: 2621.704345703125
[INFO] Global_t: 1788, Episode_t: 4, Action: 21, Reward: 3.60, Epsilon: 0.01
[INFO] model update: t: 1789, loss: 5657.14111328125
[INFO] Global_t: 1789, Episode_t: 5, Action: 9, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1790, loss: 6641.623046875
[INFO] Global_t: 1790, Episode_t: 6, Action: 16, Reward: 2.63, Epsilon: 0.01
[INFO] model update: t: 1791, loss: 7075.078125
[INFO] Global_t: 1791, Episode_t: 7, Action: 20, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1792, loss: 12198.9794921875
[INFO] Global_t: 1792, Episode_t: 8, Action: 7, Reward: 2.09, Epsilon: 0.01
 90%|████████▉ | 1792/2000 [50:21<05:25,  1.56s/it]
[INFO] Global step: 1792, Cumulative rewards: 25.727399999999996, Runtime (s): 3021.11
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.2470669746398926
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.647843360900879
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.019115686416626
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7130393981933594
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.103074073791504
average cummulative reward vector is:  [0.11590316 0.11156134 0.13130219 0.10951402 0.1329043 ]
average cummulative reward is:  0.12023700120930736
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 1793, loss: 1617.8681640625
[INFO] Global_t: 1793, Episode_t: 1, Action: 0, Reward: 4.70, Epsilon: 0.01
[INFO] model update: t: 1794, loss: 3542.447998046875
[INFO] Global_t: 1794, Episode_t: 2, Action: 8, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1795, loss: 5665.79931640625
[INFO] Global_t: 1795, Episode_t: 3, Action: 13, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 1796, loss: 3309.81396484375
[INFO] Global_t: 1796, Episode_t: 4, Action: 1, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 1797, loss: 3082.06201171875
[INFO] Global_t: 1797, Episode_t: 5, Action: 9, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1798, loss: 1129.845947265625
[INFO] Global_t: 1798, Episode_t: 6, Action: 14, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1799, loss: 3093.10009765625
[INFO] Global_t: 1799, Episode_t: 7, Action: 20, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 1800, loss: 3259.315673828125
[INFO] Global_t: 1800, Episode_t: 8, Action: 21, Reward: 1.76, Epsilon: 0.01
 90%|█████████ | 1800/2000 [50:44<06:35,  1.98s/it]
[INFO] Global step: 1800, Cumulative rewards: 22.629240000000003, Runtime (s): 3044.60
------------------------------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 1801, loss: 3656.896484375
[INFO] Global_t: 1801, Episode_t: 1, Action: 25, Reward: 4.06, Epsilon: 0.01
[INFO] model update: t: 1802, loss: 9120.912109375
[INFO] Global_t: 1802, Episode_t: 2, Action: 17, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 1803, loss: 11054.9677734375
[INFO] Global_t: 1803, Episode_t: 3, Action: 0, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1804, loss: 1640.120849609375
[INFO] Global_t: 1804, Episode_t: 4, Action: 16, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1805, loss: 4159.02783203125
[INFO] Global_t: 1805, Episode_t: 5, Action: 7, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 1806, loss: 2521.02392578125
[INFO] Global_t: 1806, Episode_t: 6, Action: 14, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 1807, loss: 1832.6466064453125
[INFO] Global_t: 1807, Episode_t: 7, Action: 19, Reward: 1.85, Epsilon: 0.01
[INFO] model update: t: 1808, loss: 1492.07421875
[INFO] Global_t: 1808, Episode_t: 8, Action: 9, Reward: 1.65, Epsilon: 0.01
 90%|█████████ | 1808/2000 [50:50<05:05,  1.59s/it]
[INFO] Global step: 1808, Cumulative rewards: 22.555799999999998, Runtime (s): 3050.21
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.439999580383301
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.840118646621704
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.099088430404663
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.5810394287109375
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.439619541168213
average cummulative reward vector is:  [0.123375   0.11976921 0.13405191 0.11058248 0.1242371 ]
average cummulative reward is:  0.12240313978819531
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 1809, loss: 2308.183349609375
[INFO] Global_t: 1809, Episode_t: 1, Action: 0, Reward: 4.67, Epsilon: 0.01
[INFO] model update: t: 1810, loss: 5008.7919921875
[INFO] Global_t: 1810, Episode_t: 2, Action: 5, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1811, loss: 4249.06396484375
[INFO] Global_t: 1811, Episode_t: 3, Action: 1, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1812, loss: 11424.138671875
[INFO] Global_t: 1812, Episode_t: 4, Action: 6, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1813, loss: 3691.263671875
[INFO] Global_t: 1813, Episode_t: 5, Action: 2, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 1814, loss: 7241.57958984375
[INFO] Global_t: 1814, Episode_t: 6, Action: 35, Reward: 1.84, Epsilon: 0.01
[INFO] model update: t: 1815, loss: 4483.8251953125
[INFO] Global_t: 1815, Episode_t: 7, Action: 14, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1816, loss: 1165.163330078125
[INFO] Global_t: 1816, Episode_t: 8, Action: 25, Reward: 2.19, Epsilon: 0.01
 91%|█████████ | 1816/2000 [51:13<06:04,  1.98s/it]
[INFO] Global step: 1816, Cumulative rewards: 23.56284, Runtime (s): 3073.23
------------------------------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 1817, loss: 4498.24853515625
[INFO] Global_t: 1817, Episode_t: 1, Action: 6, Reward: 4.58, Epsilon: 0.01
[INFO] model update: t: 1818, loss: 3832.307861328125
[INFO] Global_t: 1818, Episode_t: 2, Action: 18, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1819, loss: 2644.281005859375
[INFO] Global_t: 1819, Episode_t: 3, Action: 7, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 1820, loss: 5749.9775390625
[INFO] Global_t: 1820, Episode_t: 4, Action: 1, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1821, loss: 1941.3896484375
[INFO] Global_t: 1821, Episode_t: 5, Action: 27, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1822, loss: 4662.10400390625
[INFO] Global_t: 1822, Episode_t: 6, Action: 9, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 1823, loss: 4496.5732421875
[INFO] Global_t: 1823, Episode_t: 7, Action: 26, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1824, loss: 6634.76220703125
[INFO] Global_t: 1824, Episode_t: 8, Action: 20, Reward: 2.47, Epsilon: 0.01
 91%|█████████ | 1824/2000 [51:16<04:27,  1.52s/it]
[INFO] Global step: 1824, Cumulative rewards: 24.244799999999998, Runtime (s): 3076.89
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.522210121154785
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.149864673614502
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.7065281867980957
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.7303874492645264
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.295758008956909
average cummulative reward vector is:  [0.12621868 0.11432685 0.12905437 0.10604299 0.12060108]
average cummulative reward is:  0.1192487947140201
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 1825, loss: 16405.69140625
[INFO] Global_t: 1825, Episode_t: 1, Action: 7, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 1826, loss: 1920.415771484375
[INFO] Global_t: 1826, Episode_t: 2, Action: 21, Reward: 3.69, Epsilon: 0.01
[INFO] model update: t: 1827, loss: 9943.4560546875
[INFO] Global_t: 1827, Episode_t: 3, Action: 12, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 1828, loss: 5547.890625
[INFO] Global_t: 1828, Episode_t: 4, Action: 8, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 1829, loss: 4065.90234375
[INFO] Global_t: 1829, Episode_t: 5, Action: 1, Reward: 3.68, Epsilon: 0.01
[INFO] model update: t: 1830, loss: 8524.3837890625
[INFO] Global_t: 1830, Episode_t: 6, Action: 11, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1831, loss: 2416.3935546875
[INFO] Global_t: 1831, Episode_t: 7, Action: 14, Reward: 2.07, Epsilon: 0.01
[INFO] model update: t: 1832, loss: 9408.0029296875
[INFO] Global_t: 1832, Episode_t: 8, Action: 25, Reward: 1.97, Epsilon: 0.01
 92%|█████████▏| 1832/2000 [51:40<05:29,  1.96s/it]
[INFO] Global step: 1832, Cumulative rewards: 24.103920000000002, Runtime (s): 3100.80
------------------------------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 1833, loss: 1967.124755859375
[INFO] Global_t: 1833, Episode_t: 1, Action: 7, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 1834, loss: 4683.796875
[INFO] Global_t: 1834, Episode_t: 2, Action: 21, Reward: 3.71, Epsilon: 0.01
[INFO] model update: t: 1835, loss: 16808.24609375
[INFO] Global_t: 1835, Episode_t: 3, Action: 8, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 1836, loss: 18018.38671875
[INFO] Global_t: 1836, Episode_t: 4, Action: 79, Reward: 1.37, Epsilon: 0.01
[INFO] model update: t: 1837, loss: 1244.366455078125
[INFO] Global_t: 1837, Episode_t: 5, Action: 20, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 1838, loss: 21417.1640625
[INFO] Global_t: 1838, Episode_t: 6, Action: 62, Reward: 1.59, Epsilon: 0.01
[INFO] model update: t: 1839, loss: 9297.3935546875
[INFO] Global_t: 1839, Episode_t: 7, Action: 6, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1840, loss: 23584.10546875
[INFO] Global_t: 1840, Episode_t: 8, Action: 57, Reward: 2.29, Epsilon: 0.01
 92%|█████████▏| 1840/2000 [51:46<04:15,  1.60s/it]
[INFO] Global step: 1840, Cumulative rewards: 21.36012, Runtime (s): 3106.82
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4269397258758545
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.081393480300903
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4966986179351807
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.534566879272461
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.9745829105377197
average cummulative reward vector is:  [0.11998553 0.11490579 0.12700902 0.11158925 0.13244516]
average cummulative reward is:  0.12118694867460807
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 1841, loss: 37903.65625
[INFO] Global_t: 1841, Episode_t: 1, Action: 6, Reward: 4.44, Epsilon: 0.01
[INFO] model update: t: 1842, loss: 31630.787109375
[INFO] Global_t: 1842, Episode_t: 2, Action: 17, Reward: 3.63, Epsilon: 0.01
[INFO] model update: t: 1843, loss: 241229.4375
[INFO] Global_t: 1843, Episode_t: 3, Action: 12, Reward: 3.99, Epsilon: 0.01
[INFO] model update: t: 1844, loss: 299828.84375
[INFO] Global_t: 1844, Episode_t: 4, Action: 10, Reward: 4.47, Epsilon: 0.01
[INFO] model update: t: 1845, loss: 40214.609375
[INFO] Global_t: 1845, Episode_t: 5, Action: 18, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 1846, loss: 61915.25
[INFO] Global_t: 1846, Episode_t: 6, Action: 4, Reward: 3.26, Epsilon: 0.01
[INFO] model update: t: 1847, loss: 343584.53125
[INFO] Global_t: 1847, Episode_t: 7, Action: 37, Reward: 2.88, Epsilon: 0.01
[INFO] model update: t: 1848, loss: 230074.59375
[INFO] Global_t: 1848, Episode_t: 8, Action: 15, Reward: 2.93, Epsilon: 0.01
 92%|█████████▏| 1848/2000 [52:09<04:56,  1.95s/it]
[INFO] Global step: 1848, Cumulative rewards: 28.63044, Runtime (s): 3129.03
------------------------------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 1849, loss: 23483.626953125
[INFO] Global_t: 1849, Episode_t: 1, Action: 3, Reward: 5.40, Epsilon: 0.01
[INFO] model update: t: 1850, loss: 219659.703125
[INFO] Global_t: 1850, Episode_t: 2, Action: 12, Reward: 3.41, Epsilon: 0.01
[INFO] model update: t: 1851, loss: 27072.8203125
[INFO] Global_t: 1851, Episode_t: 3, Action: 11, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 1852, loss: 111483.5703125
[INFO] Global_t: 1852, Episode_t: 4, Action: 16, Reward: 2.81, Epsilon: 0.01
[INFO] model update: t: 1853, loss: 342098.75
[INFO] Global_t: 1853, Episode_t: 5, Action: 35, Reward: 2.67, Epsilon: 0.01
[INFO] model update: t: 1854, loss: 144185.90625
[INFO] Global_t: 1854, Episode_t: 6, Action: 17, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 1855, loss: 18545.28125
[INFO] Global_t: 1855, Episode_t: 7, Action: 6, Reward: 2.78, Epsilon: 0.01
[INFO] model update: t: 1856, loss: 183831.78125
[INFO] Global_t: 1856, Episode_t: 8, Action: 32, Reward: 2.55, Epsilon: 0.01

[INFO] Global step: 1856, Cumulative rewards: 24.340799999999998, Runtime (s): 3134.10
------------------------------------------------------------
 
 93%|█████████▎| 1856/2000 [52:14<03:44,  1.56s/it]
--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.373298406600952
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.952850341796875
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.862556219100952
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.649986743927002
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.797579050064087
average cummulative reward vector is:  [0.11785132 0.11695023 0.12596639 0.11267056 0.13871022]
average cummulative reward is:  0.12242974330300102
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 1857, loss: 83788.5703125
[INFO] Global_t: 1857, Episode_t: 1, Action: 7, Reward: 4.51, Epsilon: 0.01
[INFO] model update: t: 1858, loss: 30138.181640625
[INFO] Global_t: 1858, Episode_t: 2, Action: 8, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 1859, loss: 174828.3125
[INFO] Global_t: 1859, Episode_t: 3, Action: 29, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1860, loss: 26152.82421875
[INFO] Global_t: 1860, Episode_t: 4, Action: 26, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1861, loss: 63547.2734375
[INFO] Global_t: 1861, Episode_t: 5, Action: 15, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 1862, loss: 181402.40625
[INFO] Global_t: 1862, Episode_t: 6, Action: 5, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 1863, loss: 70432.796875
[INFO] Global_t: 1863, Episode_t: 7, Action: 18, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 1864, loss: 18172.7578125
[INFO] Global_t: 1864, Episode_t: 8, Action: 6, Reward: 2.15, Epsilon: 0.01
 93%|█████████▎| 1864/2000 [52:38<04:33,  2.01s/it]
[INFO] Global step: 1864, Cumulative rewards: 22.155479999999997, Runtime (s): 3158.60
------------------------------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 1865, loss: 165520.125
[INFO] Global_t: 1865, Episode_t: 1, Action: 10, Reward: 3.24, Epsilon: 0.01
[INFO] model update: t: 1866, loss: 190997.59375
[INFO] Global_t: 1866, Episode_t: 2, Action: 18, Reward: 3.95, Epsilon: 0.01
[INFO] model update: t: 1867, loss: 5362.36474609375
[INFO] Global_t: 1867, Episode_t: 3, Action: 16, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1868, loss: 221537.28125
[INFO] Global_t: 1868, Episode_t: 4, Action: 12, Reward: 3.28, Epsilon: 0.01
[INFO] model update: t: 1869, loss: 134342.40625
[INFO] Global_t: 1869, Episode_t: 5, Action: 7, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1870, loss: 53031.984375
[INFO] Global_t: 1870, Episode_t: 6, Action: 19, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 1871, loss: 258615.125
[INFO] Global_t: 1871, Episode_t: 7, Action: 23, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 1872, loss: 11351.7890625
[INFO] Global_t: 1872, Episode_t: 8, Action: 11, Reward: 2.41, Epsilon: 0.01
 94%|█████████▎| 1872/2000 [52:44<03:26,  1.61s/it]
[INFO] Global step: 1872, Cumulative rewards: 26.525640000000003, Runtime (s): 3164.13
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  4.062387943267822
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.809027671813965
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.692007303237915
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.803053379058838
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.4833459854125977
average cummulative reward vector is:  [0.12715553 0.11474375 0.12525437 0.12050771 0.12638548]
average cummulative reward is:  0.12280936841036609
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 1873, loss: 110729.59375
[INFO] Global_t: 1873, Episode_t: 1, Action: 1, Reward: 5.39, Epsilon: 0.01
[INFO] model update: t: 1874, loss: 70922.921875
[INFO] Global_t: 1874, Episode_t: 2, Action: 4, Reward: 4.93, Epsilon: 0.01
[INFO] model update: t: 1875, loss: 1317.6279296875
[INFO] Global_t: 1875, Episode_t: 3, Action: 15, Reward: 3.58, Epsilon: 0.01
[INFO] model update: t: 1876, loss: 34563.328125
[INFO] Global_t: 1876, Episode_t: 4, Action: 26, Reward: 4.30, Epsilon: 0.01
[INFO] model update: t: 1877, loss: 17802.5625
[INFO] Global_t: 1877, Episode_t: 5, Action: 9, Reward: 3.55, Epsilon: 0.01
[INFO] model update: t: 1878, loss: 17017.26171875
[INFO] Global_t: 1878, Episode_t: 6, Action: 21, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 1879, loss: 34482.4609375
[INFO] Global_t: 1879, Episode_t: 7, Action: 18, Reward: 2.63, Epsilon: 0.01
[INFO] model update: t: 1880, loss: 5116.095703125
[INFO] Global_t: 1880, Episode_t: 8, Action: 16, Reward: 2.52, Epsilon: 0.01
 94%|█████████▍| 1880/2000 [53:07<04:01,  2.01s/it]
[INFO] Global step: 1880, Cumulative rewards: 30.35772, Runtime (s): 3187.70
------------------------------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 1881, loss: 15505.8525390625
[INFO] Global_t: 1881, Episode_t: 1, Action: 8, Reward: 4.39, Epsilon: 0.01
[INFO] model update: t: 1882, loss: 15580.412109375
[INFO] Global_t: 1882, Episode_t: 2, Action: 11, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1883, loss: 5321.19482421875
[INFO] Global_t: 1883, Episode_t: 3, Action: 15, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 1884, loss: 20792.02734375
[INFO] Global_t: 1884, Episode_t: 4, Action: 6, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 1885, loss: 6470.658203125
[INFO] Global_t: 1885, Episode_t: 5, Action: 5, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 1886, loss: 6438.7978515625
[INFO] Global_t: 1886, Episode_t: 6, Action: 3, Reward: 3.12, Epsilon: 0.01
[INFO] model update: t: 1887, loss: 7245.34228515625
[INFO] Global_t: 1887, Episode_t: 7, Action: 9, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 1888, loss: 2104.53662109375
[INFO] Global_t: 1888, Episode_t: 8, Action: 19, Reward: 1.55, Epsilon: 0.01
 94%|█████████▍| 1888/2000 [53:13<03:02,  1.63s/it]
[INFO] Global step: 1888, Cumulative rewards: 21.661559999999998, Runtime (s): 3193.69
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5627944469451904
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.972369909286499
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.6497392654418945
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6638760566711426
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5510220527648926
average cummulative reward vector is:  [0.11311342 0.12112384 0.13168361 0.10523248 0.13164194]
average cummulative reward is:  0.12055905646439724
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 1889, loss: 2452.35400390625
[INFO] Global_t: 1889, Episode_t: 1, Action: 7, Reward: 3.96, Epsilon: 0.01
[INFO] model update: t: 1890, loss: 2241.05859375
[INFO] Global_t: 1890, Episode_t: 2, Action: 5, Reward: 5.30, Epsilon: 0.01
[INFO] model update: t: 1891, loss: 2730.57568359375
[INFO] Global_t: 1891, Episode_t: 3, Action: 1, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 1892, loss: 1608.432861328125
[INFO] Global_t: 1892, Episode_t: 4, Action: 24, Reward: 2.94, Epsilon: 0.01
[INFO] model update: t: 1893, loss: 4058.048583984375
[INFO] Global_t: 1893, Episode_t: 5, Action: 10, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 1894, loss: 2010.5662841796875
[INFO] Global_t: 1894, Episode_t: 6, Action: 13, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1895, loss: 3405.62646484375
[INFO] Global_t: 1895, Episode_t: 7, Action: 11, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 1896, loss: 2168.578369140625
[INFO] Global_t: 1896, Episode_t: 8, Action: 21, Reward: 2.36, Epsilon: 0.01
 95%|█████████▍| 1896/2000 [53:36<03:26,  1.98s/it]
[INFO] Global step: 1896, Cumulative rewards: 24.291959999999996, Runtime (s): 3216.12
------------------------------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 1897, loss: 3621.349609375
[INFO] Global_t: 1897, Episode_t: 1, Action: 10, Reward: 4.00, Epsilon: 0.01
[INFO] model update: t: 1898, loss: 1989.550537109375
[INFO] Global_t: 1898, Episode_t: 2, Action: 39, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 1899, loss: 9302.2724609375
[INFO] Global_t: 1899, Episode_t: 3, Action: 13, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1900, loss: 3733.844482421875
[INFO] Global_t: 1900, Episode_t: 4, Action: 27, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1901, loss: 2905.537353515625
[INFO] Global_t: 1901, Episode_t: 5, Action: 31, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 1902, loss: 24111.9921875
[INFO] Global_t: 1902, Episode_t: 6, Action: 15, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1903, loss: 16855.98828125
[INFO] Global_t: 1903, Episode_t: 7, Action: 6, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 1904, loss: 3855.2490234375
[INFO] Global_t: 1904, Episode_t: 8, Action: 37, Reward: 1.79, Epsilon: 0.01

[INFO] Global step: 1904, Cumulative rewards: 20.728559999999995, Runtime (s): 3223.85
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
 95%|█████████▌| 1904/2000 [53:43<02:41,  1.68s/it]runtime for one graph is:  3.330559253692627
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.332268476486206
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.3890321254730225
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.547914505004883
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.5036489963531494
average cummulative reward vector is:  [0.11605842 0.11258009 0.12228579 0.11390467 0.11988038]
average cummulative reward is:  0.11694187104724665
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 1905, loss: 39090.8828125
[INFO] Global_t: 1905, Episode_t: 1, Action: 11, Reward: 5.22, Epsilon: 0.01
[INFO] model update: t: 1906, loss: 23755.4609375
[INFO] Global_t: 1906, Episode_t: 2, Action: 22, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 1907, loss: 1528.1685791015625
[INFO] Global_t: 1907, Episode_t: 3, Action: 58, Reward: 3.38, Epsilon: 0.01
[INFO] model update: t: 1908, loss: 20005.75390625
[INFO] Global_t: 1908, Episode_t: 4, Action: 6, Reward: 2.27, Epsilon: 0.01
[INFO] model update: t: 1909, loss: 18565.447265625
[INFO] Global_t: 1909, Episode_t: 5, Action: 10, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1910, loss: 4790.27685546875
[INFO] Global_t: 1910, Episode_t: 6, Action: 80, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 1911, loss: 31578.26171875
[INFO] Global_t: 1911, Episode_t: 7, Action: 49, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1912, loss: 11111.1650390625
[INFO] Global_t: 1912, Episode_t: 8, Action: 14, Reward: 1.99, Epsilon: 0.01
 96%|█████████▌| 1912/2000 [54:06<02:58,  2.02s/it]
[INFO] Global step: 1912, Cumulative rewards: 23.606519999999996, Runtime (s): 3246.45
------------------------------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 1913, loss: 5226.33837890625
[INFO] Global_t: 1913, Episode_t: 1, Action: 162, Reward: 2.08, Epsilon: 0.01
[INFO] model update: t: 1914, loss: 14688.84375
[INFO] Global_t: 1914, Episode_t: 2, Action: 3, Reward: 3.98, Epsilon: 0.01
[INFO] model update: t: 1915, loss: 4396.1025390625
[INFO] Global_t: 1915, Episode_t: 3, Action: 6, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 1916, loss: 35268.68359375
[INFO] Global_t: 1916, Episode_t: 4, Action: 8, Reward: 3.13, Epsilon: 0.01
[INFO] model update: t: 1917, loss: 19847.671875
[INFO] Global_t: 1917, Episode_t: 5, Action: 14, Reward: 1.54, Epsilon: 0.01
[INFO] model update: t: 1918, loss: 1736.7706298828125
[INFO] Global_t: 1918, Episode_t: 6, Action: 11, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 1919, loss: 20101.517578125
[INFO] Global_t: 1919, Episode_t: 7, Action: 22, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 1920, loss: 43716.4453125
[INFO] Global_t: 1920, Episode_t: 8, Action: 12, Reward: 1.91, Epsilon: 0.01
 96%|█████████▌| 1920/2000 [54:12<02:10,  1.63s/it]
[INFO] Global step: 1920, Cumulative rewards: 19.65468, Runtime (s): 3252.26
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.4098658561706543
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.905122995376587
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.9949734210968018
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.6344263553619385
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.10725474357605
average cummulative reward vector is:  [0.12022816 0.11656134 0.13499044 0.11265911 0.13375618]
average cummulative reward is:  0.12363904651820619
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 1921, loss: 21183.0078125
[INFO] Global_t: 1921, Episode_t: 1, Action: 5, Reward: 5.37, Epsilon: 0.01
[INFO] model update: t: 1922, loss: 21943.7421875
[INFO] Global_t: 1922, Episode_t: 2, Action: 4, Reward: 3.73, Epsilon: 0.01
[INFO] model update: t: 1923, loss: 196994.5
[INFO] Global_t: 1923, Episode_t: 3, Action: 9, Reward: 3.54, Epsilon: 0.01
[INFO] model update: t: 1924, loss: 147704.609375
[INFO] Global_t: 1924, Episode_t: 4, Action: 6, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 1925, loss: 52728.3359375
[INFO] Global_t: 1925, Episode_t: 5, Action: 1, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 1926, loss: 1669.429443359375
[INFO] Global_t: 1926, Episode_t: 6, Action: 11, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1927, loss: 26613.65625
[INFO] Global_t: 1927, Episode_t: 7, Action: 12, Reward: 1.97, Epsilon: 0.01
[INFO] model update: t: 1928, loss: 32415.4296875
[INFO] Global_t: 1928, Episode_t: 8, Action: 13, Reward: 1.81, Epsilon: 0.01
 96%|█████████▋| 1928/2000 [54:35<02:24,  2.00s/it]
[INFO] Global step: 1928, Cumulative rewards: 24.71256, Runtime (s): 3275.16
------------------------------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 1929, loss: 2154.254150390625
[INFO] Global_t: 1929, Episode_t: 1, Action: 4, Reward: 4.11, Epsilon: 0.01
[INFO] model update: t: 1930, loss: 50323.4921875
[INFO] Global_t: 1930, Episode_t: 2, Action: 25, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 1931, loss: 67679.1875
[INFO] Global_t: 1931, Episode_t: 3, Action: 16, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 1932, loss: 36664.0859375
[INFO] Global_t: 1932, Episode_t: 4, Action: 11, Reward: 3.02, Epsilon: 0.01
[INFO] model update: t: 1933, loss: 10937.185546875
[INFO] Global_t: 1933, Episode_t: 5, Action: 31, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 1934, loss: 6759.064453125
[INFO] Global_t: 1934, Episode_t: 6, Action: 29, Reward: 2.08, Epsilon: 0.01
[INFO] model update: t: 1935, loss: 13497.23828125
[INFO] Global_t: 1935, Episode_t: 7, Action: 46, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1936, loss: 6282.24462890625
[INFO] Global_t: 1936, Episode_t: 8, Action: 8, Reward: 2.85, Epsilon: 0.01
 97%|█████████▋| 1936/2000 [54:40<01:41,  1.59s/it]
[INFO] Global step: 1936, Cumulative rewards: 23.04696, Runtime (s): 3280.19
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.811633825302124
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.6176180839538574
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  4.084259033203125
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.683107852935791
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.666425943374634
average cummulative reward vector is:  [0.12363289 0.11052384 0.14030301 0.11120654 0.13123253]
average cummulative reward is:  0.12337976234634215
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 1937, loss: 30681.5234375
[INFO] Global_t: 1937, Episode_t: 1, Action: 8, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 1938, loss: 4625.078125
[INFO] Global_t: 1938, Episode_t: 2, Action: 10, Reward: 3.80, Epsilon: 0.01
[INFO] model update: t: 1939, loss: 67746.7890625
[INFO] Global_t: 1939, Episode_t: 3, Action: 0, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 1940, loss: 121150.65625
[INFO] Global_t: 1940, Episode_t: 4, Action: 25, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 1941, loss: 29739.134765625
[INFO] Global_t: 1941, Episode_t: 5, Action: 22, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 1942, loss: 10186.93359375
[INFO] Global_t: 1942, Episode_t: 6, Action: 5, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 1943, loss: 29568.271484375
[INFO] Global_t: 1943, Episode_t: 7, Action: 18, Reward: 1.50, Epsilon: 0.01
[INFO] model update: t: 1944, loss: 12812.08984375
[INFO] Global_t: 1944, Episode_t: 8, Action: 34, Reward: 1.75, Epsilon: 0.01
 97%|█████████▋| 1944/2000 [55:05<01:55,  2.07s/it]
[INFO] Global step: 1944, Cumulative rewards: 22.210919999999994, Runtime (s): 3305.62
------------------------------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 1945, loss: 5946.642578125
[INFO] Global_t: 1945, Episode_t: 1, Action: 5, Reward: 4.83, Epsilon: 0.01
[INFO] model update: t: 1946, loss: 40365.40625
[INFO] Global_t: 1946, Episode_t: 2, Action: 13, Reward: 3.57, Epsilon: 0.01
[INFO] model update: t: 1947, loss: 50879.74609375
[INFO] Global_t: 1947, Episode_t: 3, Action: 9, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 1948, loss: 8632.013671875
[INFO] Global_t: 1948, Episode_t: 4, Action: 6, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 1949, loss: 5473.13427734375
[INFO] Global_t: 1949, Episode_t: 5, Action: 17, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 1950, loss: 15844.275390625
[INFO] Global_t: 1950, Episode_t: 6, Action: 22, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 1951, loss: 6886.16455078125
[INFO] Global_t: 1951, Episode_t: 7, Action: 25, Reward: 1.36, Epsilon: 0.01
[INFO] model update: t: 1952, loss: 18745.392578125
[INFO] Global_t: 1952, Episode_t: 8, Action: 30, Reward: 1.41, Epsilon: 0.01
 98%|█████████▊| 1952/2000 [55:11<01:19,  1.67s/it]
[INFO] Global step: 1952, Cumulative rewards: 20.399879999999996, Runtime (s): 3311.45
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.949559450149536
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.719947576522827
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.4623770713806152
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.686206817626953
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.772866725921631
average cummulative reward vector is:  [0.12392921 0.11617199 0.12563497 0.10775911 0.13877581]
average cummulative reward is:  0.12245421850915957
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 1953, loss: 4167.93994140625
[INFO] Global_t: 1953, Episode_t: 1, Action: 7, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1954, loss: 8552.1396484375
[INFO] Global_t: 1954, Episode_t: 2, Action: 4, Reward: 4.36, Epsilon: 0.01
[INFO] model update: t: 1955, loss: 11590.7109375
[INFO] Global_t: 1955, Episode_t: 3, Action: 9, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 1956, loss: 5041.42333984375
[INFO] Global_t: 1956, Episode_t: 4, Action: 8, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 1957, loss: 926.9117431640625
[INFO] Global_t: 1957, Episode_t: 5, Action: 25, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1958, loss: 10892.2734375
[INFO] Global_t: 1958, Episode_t: 6, Action: 29, Reward: 1.61, Epsilon: 0.01
[INFO] model update: t: 1959, loss: 19034.6796875
[INFO] Global_t: 1959, Episode_t: 7, Action: 27, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 1960, loss: 28451.509765625
[INFO] Global_t: 1960, Episode_t: 8, Action: 13, Reward: 2.28, Epsilon: 0.01
 98%|█████████▊| 1960/2000 [55:40<01:29,  2.24s/it]
[INFO] Global step: 1960, Cumulative rewards: 23.256840000000004, Runtime (s): 3340.22
------------------------------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 1961, loss: 32714.85546875
[INFO] Global_t: 1961, Episode_t: 1, Action: 4, Reward: 4.58, Epsilon: 0.01
[INFO] model update: t: 1962, loss: 4767.5224609375
[INFO] Global_t: 1962, Episode_t: 2, Action: 5, Reward: 5.03, Epsilon: 0.01
[INFO] model update: t: 1963, loss: 26597.578125
[INFO] Global_t: 1963, Episode_t: 3, Action: 2, Reward: 2.70, Epsilon: 0.01
[INFO] model update: t: 1964, loss: 105083.15625
[INFO] Global_t: 1964, Episode_t: 4, Action: 11, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 1965, loss: 68277.25
[INFO] Global_t: 1965, Episode_t: 5, Action: 7, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 1966, loss: 8132.8876953125
[INFO] Global_t: 1966, Episode_t: 6, Action: 8, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 1967, loss: 140032.09375
[INFO] Global_t: 1967, Episode_t: 7, Action: 12, Reward: 1.41, Epsilon: 0.01
[INFO] model update: t: 1968, loss: 307872.28125
[INFO] Global_t: 1968, Episode_t: 8, Action: 10, Reward: 1.68, Epsilon: 0.01
 98%|█████████▊| 1968/2000 [55:47<00:59,  1.86s/it]
[INFO] Global step: 1968, Cumulative rewards: 21.313319999999997, Runtime (s): 3347.95
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.5277700424194336
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.7990427017211914
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.499133348464966
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.2037901878356934
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.852773666381836
average cummulative reward vector is:  [0.12487974 0.10505972 0.12961448 0.10099416 0.12836048]
average cummulative reward is:  0.11778171653762337
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 1969, loss: 163522.328125
[INFO] Global_t: 1969, Episode_t: 1, Action: 8, Reward: 4.53, Epsilon: 0.01
[INFO] model update: t: 1970, loss: 51792.546875
[INFO] Global_t: 1970, Episode_t: 2, Action: 6, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 1971, loss: 243259.84375
[INFO] Global_t: 1971, Episode_t: 3, Action: 5, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 1972, loss: 32569.259765625
[INFO] Global_t: 1972, Episode_t: 4, Action: 14, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 1973, loss: 85362.375
[INFO] Global_t: 1973, Episode_t: 5, Action: 22, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 1974, loss: 249469.3125
[INFO] Global_t: 1974, Episode_t: 6, Action: 21, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 1975, loss: 1917.0035400390625
[INFO] Global_t: 1975, Episode_t: 7, Action: 23, Reward: 1.49, Epsilon: 0.01
[INFO] model update: t: 1976, loss: 263213.1875
[INFO] Global_t: 1976, Episode_t: 8, Action: 9, Reward: 2.72, Epsilon: 0.01
 99%|█████████▉| 1976/2000 [56:11<00:52,  2.19s/it]
[INFO] Global step: 1976, Cumulative rewards: 25.970879999999994, Runtime (s): 3371.67
------------------------------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 1977, loss: 439721.3125
[INFO] Global_t: 1977, Episode_t: 1, Action: 5, Reward: 4.65, Epsilon: 0.01
[INFO] model update: t: 1978, loss: 186886.265625
[INFO] Global_t: 1978, Episode_t: 2, Action: 4, Reward: 4.16, Epsilon: 0.01
[INFO] model update: t: 1979, loss: 4860.84912109375
[INFO] Global_t: 1979, Episode_t: 3, Action: 3, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 1980, loss: 96902.140625
[INFO] Global_t: 1980, Episode_t: 4, Action: 1, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 1981, loss: 97263.859375
[INFO] Global_t: 1981, Episode_t: 5, Action: 11, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1982, loss: 17210.71875
[INFO] Global_t: 1982, Episode_t: 6, Action: 25, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1983, loss: 304102.59375
[INFO] Global_t: 1983, Episode_t: 7, Action: 10, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 1984, loss: 461762.90625
[INFO] Global_t: 1984, Episode_t: 8, Action: 28, Reward: 2.05, Epsilon: 0.01
 99%|█████████▉| 1984/2000 [56:34<00:38,  2.39s/it]
[INFO] Global step: 1984, Cumulative rewards: 22.22448, Runtime (s): 3394.46
------------------------------------------------------------
 

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.666435956954956
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  3.687955141067505
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.1836395263671875
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.779238224029541
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  3.7187392711639404
average cummulative reward vector is:  [0.11795237 0.11182546 0.11927377 0.10370467 0.13027581]
average cummulative reward is:  0.1166064162449256
--------------------------------------------------end evaluation--------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 1985, loss: 270913.59375
[INFO] Global_t: 1985, Episode_t: 1, Action: 5, Reward: 3.66, Epsilon: 0.01
[INFO] model update: t: 1986, loss: 161570.125
[INFO] Global_t: 1986, Episode_t: 2, Action: 28, Reward: 3.86, Epsilon: 0.01
[INFO] model update: t: 1987, loss: 13629.525390625
[INFO] Global_t: 1987, Episode_t: 3, Action: 11, Reward: 4.08, Epsilon: 0.01
[INFO] model update: t: 1988, loss: 52448.4140625
[INFO] Global_t: 1988, Episode_t: 4, Action: 7, Reward: 3.46, Epsilon: 0.01
[INFO] model update: t: 1989, loss: 106977.6328125
[INFO] Global_t: 1989, Episode_t: 5, Action: 16, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 1990, loss: 72563.2890625
[INFO] Global_t: 1990, Episode_t: 6, Action: 13, Reward: 3.15, Epsilon: 0.01
[INFO] model update: t: 1991, loss: 2239.723876953125
[INFO] Global_t: 1991, Episode_t: 7, Action: 6, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 1992, loss: 43915.2890625
[INFO] Global_t: 1992, Episode_t: 8, Action: 27, Reward: 2.07, Epsilon: 0.01
100%|█████████▉| 1992/2000 [57:00<00:21,  2.63s/it]
[INFO] Global step: 1992, Cumulative rewards: 26.154239999999998, Runtime (s): 3420.07
------------------------------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 1993, loss: 25201.54296875
[INFO] Global_t: 1993, Episode_t: 1, Action: 3, Reward: 5.91, Epsilon: 0.01
[INFO] model update: t: 1994, loss: 3678.59912109375
[INFO] Global_t: 1994, Episode_t: 2, Action: 5, Reward: 5.14, Epsilon: 0.01
[INFO] model update: t: 1995, loss: 27776.79296875
[INFO] Global_t: 1995, Episode_t: 3, Action: 6, Reward: 2.69, Epsilon: 0.01
[INFO] model update: t: 1996, loss: 22432.78125
[INFO] Global_t: 1996, Episode_t: 4, Action: 15, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 1997, loss: 10769.6611328125
[INFO] Global_t: 1997, Episode_t: 5, Action: 13, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 1998, loss: 3950.99658203125
[INFO] Global_t: 1998, Episode_t: 6, Action: 17, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 1999, loss: 5259.982421875
[INFO] Global_t: 1999, Episode_t: 7, Action: 18, Reward: 2.48, Epsilon: 0.01

--------------------------------------------------start evaluation--------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  3.7326979637145996
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  4.0299670696258545
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  3.982006788253784
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.448796510696411
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  4.043616771697998
average cummulative reward vector is:  [0.11880184 0.11851829 0.13119262 0.1058285  0.1428414 ]
average cummulative reward is:  0.12343653092309588
--------------------------------------------------end evaluation--------------------------------------------------
 
epoch:  2
