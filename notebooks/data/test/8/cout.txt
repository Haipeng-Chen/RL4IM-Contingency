[INFO 15:31:19] Experiments Running command 'my_main'
[INFO 15:31:19] Experiments Started run with ID "8"
[DEBUG 15:31:19] Experiments Starting Heartbeat
[DEBUG 15:31:19] my_main Started
Loading train graph:  powerlaw
train graphs in total:  200
Loading test graph:  powerlaw
merged graphs length:  205
epoch:  0
graph: 0, nodes: 180, edges: 531
[INFO] Global_t: 1, Episode_t: 1, Action: 33, Reward: 2.83, Epsilon: 0.99
[INFO] Global_t: 2, Episode_t: 2, Action: 94, Reward: 1.41, Epsilon: 0.99
[INFO] Global_t: 3, Episode_t: 3, Action: 149, Reward: 1.36, Epsilon: 0.99
[INFO] Global_t: 4, Episode_t: 4, Action: 93, Reward: 1.93, Epsilon: 0.99
[INFO] Global_t: 5, Episode_t: 5, Action: 160, Reward: 1.08, Epsilon: 0.99
[INFO] Global_t: 6, Episode_t: 6, Action: 22, Reward: 3.20, Epsilon: 0.99
[INFO] Global step: 6, Cumulative rewards: 11.811239999999998, Runtime (s): 1.11
--------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] Global_t: 7, Episode_t: 1, Action: 95, Reward: 2.42, Epsilon: 0.99
[INFO] Global_t: 8, Episode_t: 2, Action: 178, Reward: 1.46, Epsilon: 0.99
[INFO] Global_t: 9, Episode_t: 3, Action: 36, Reward: 2.93, Epsilon: 0.99
[INFO] Global_t: 10, Episode_t: 4, Action: 193, Reward: 1.89, Epsilon: 0.99
[INFO] Global_t: 11, Episode_t: 5, Action: 196, Reward: 1.71, Epsilon: 0.99
[INFO] Global_t: 12, Episode_t: 6, Action: 183, Reward: 1.26, Epsilon: 0.98
[INFO] Global step: 12, Cumulative rewards: 11.66916, Runtime (s): 2.13
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  0.6831412315368652
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  0.6546809673309326
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  0.6856920719146729
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  0.6566057205200195
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  0.7441725730895996
average cummulative reward vector is:  [0.03408132 0.02830949 0.03675164 0.02897991 0.04030645]
average cummulative reward is:  0.0336857608058872
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] Global_t: 13, Episode_t: 1, Action: 102, Reward: 1.54, Epsilon: 0.98
[INFO] Global_t: 14, Episode_t: 2, Action: 14, Reward: 2.97, Epsilon: 0.98
[INFO] Global_t: 15, Episode_t: 3, Action: 174, Reward: 1.76, Epsilon: 0.98
[INFO] Global_t: 16, Episode_t: 4, Action: 114, Reward: 1.74, Epsilon: 0.98
[INFO] Global_t: 17, Episode_t: 5, Action: 137, Reward: 1.93, Epsilon: 0.98
[INFO] Global_t: 18, Episode_t: 6, Action: 132, Reward: 1.20, Epsilon: 0.98
[INFO] Global step: 18, Cumulative rewards: 11.129879999999998, Runtime (s): 7.08
--------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] Global_t: 19, Episode_t: 1, Action: 122, Reward: 1.67, Epsilon: 0.98
[INFO] Global_t: 20, Episode_t: 2, Action: 18, Reward: 3.63, Epsilon: 0.98
[INFO] Global_t: 21, Episode_t: 3, Action: 180, Reward: 1.17, Epsilon: 0.98
[INFO] Global_t: 22, Episode_t: 4, Action: 32, Reward: 1.49, Epsilon: 0.98
[INFO] Global_t: 23, Episode_t: 5, Action: 114, Reward: 1.29, Epsilon: 0.98
[INFO] Global_t: 24, Episode_t: 6, Action: 174, Reward: 1.41, Epsilon: 0.98
[INFO] Global step: 24, Cumulative rewards: 10.65792, Runtime (s): 8.43
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  0.7121357917785645
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  0.7254502773284912
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  0.7112758159637451
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  0.6516292095184326
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  0.7331187725067139
average cummulative reward vector is:  [0.03669526 0.03045255 0.03519454 0.02855467 0.03681747]
average cummulative reward is:  0.033542898197758506
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] Global_t: 25, Episode_t: 1, Action: 142, Reward: 1.24, Epsilon: 0.98
[INFO] Global_t: 26, Episode_t: 2, Action: 64, Reward: 2.28, Epsilon: 0.98
[INFO] Global_t: 27, Episode_t: 3, Action: 156, Reward: 1.70, Epsilon: 0.98
[INFO] Global_t: 28, Episode_t: 4, Action: 145, Reward: 1.33, Epsilon: 0.98
[INFO] Global_t: 29, Episode_t: 5, Action: 94, Reward: 1.95, Epsilon: 0.98
[INFO] Global_t: 30, Episode_t: 6, Action: 132, Reward: 1.48, Epsilon: 0.98
[INFO] Global step: 30, Cumulative rewards: 9.97308, Runtime (s): 13.04
--------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] Global_t: 31, Episode_t: 1, Action: 79, Reward: 1.55, Epsilon: 0.98
[INFO] Global_t: 32, Episode_t: 2, Action: 146, Reward: 1.53, Epsilon: 0.97
[INFO] Global_t: 33, Episode_t: 3, Action: 159, Reward: 1.31, Epsilon: 0.97
[INFO] Global_t: 34, Episode_t: 4, Action: 175, Reward: 1.87, Epsilon: 0.97
[INFO] Global_t: 35, Episode_t: 5, Action: 118, Reward: 2.09, Epsilon: 0.97
[INFO] Global_t: 36, Episode_t: 6, Action: 90, Reward: 1.73, Epsilon: 0.97
[INFO] Global step: 36, Cumulative rewards: 10.0818, Runtime (s): 14.03
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  0.8243849277496338
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  0.7100880146026611
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  0.6959192752838135
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  0.7490344047546387
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  0.7699978351593018
average cummulative reward vector is:  [0.04022632 0.03188843 0.03761694 0.03544603 0.04223898]
average cummulative reward is:  0.03748333762762337
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] Global_t: 37, Episode_t: 1, Action: 100, Reward: 1.85, Epsilon: 0.97
[INFO] Global_t: 38, Episode_t: 2, Action: 138, Reward: 1.62, Epsilon: 0.97
[INFO] Global_t: 39, Episode_t: 3, Action: 170, Reward: 1.10, Epsilon: 0.97
[INFO] Global_t: 40, Episode_t: 4, Action: 30, Reward: 2.13, Epsilon: 0.97
[INFO] Global_t: 41, Episode_t: 5, Action: 144, Reward: 1.15, Epsilon: 0.97
[INFO] Global_t: 42, Episode_t: 6, Action: 36, Reward: 2.11, Epsilon: 0.97
[INFO] Global step: 42, Cumulative rewards: 9.95124, Runtime (s): 18.86
--------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] Global_t: 43, Episode_t: 1, Action: 163, Reward: 1.57, Epsilon: 0.97
[INFO] Global_t: 44, Episode_t: 2, Action: 135, Reward: 1.07, Epsilon: 0.97
[INFO] Global_t: 45, Episode_t: 3, Action: 156, Reward: 1.51, Epsilon: 0.97
[INFO] Global_t: 46, Episode_t: 4, Action: 96, Reward: 1.43, Epsilon: 0.97
[INFO] Global_t: 47, Episode_t: 5, Action: 0, Reward: 5.84, Epsilon: 0.97
[INFO] Global_t: 48, Episode_t: 6, Action: 45, Reward: 1.99, Epsilon: 0.97
[INFO] Global step: 48, Cumulative rewards: 13.415399999999998, Runtime (s): 20.12
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  0.7580795288085938
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  0.6608903408050537
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  0.6732027530670166
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  0.6612112522125244
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  0.71213698387146
average cummulative reward vector is:  [0.03945816 0.02886157 0.03570246 0.02872477 0.03808629]
average cummulative reward is:  0.03416664953258504
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] Global_t: 49, Episode_t: 1, Action: 63, Reward: 2.02, Epsilon: 0.97
[INFO] Global_t: 50, Episode_t: 2, Action: 47, Reward: 1.99, Epsilon: 0.97
[INFO] Global_t: 51, Episode_t: 3, Action: 79, Reward: 1.47, Epsilon: 0.97
[INFO] Global_t: 52, Episode_t: 4, Action: 162, Reward: 1.12, Epsilon: 0.97
[INFO] Global_t: 53, Episode_t: 5, Action: 124, Reward: 1.71, Epsilon: 0.96
[INFO] Global_t: 54, Episode_t: 6, Action: 37, Reward: 1.61, Epsilon: 0.96
[INFO] Global step: 54, Cumulative rewards: 9.913679999999998, Runtime (s): 24.90
--------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 55, loss: 12560508928.0
[INFO] Global_t: 55, Episode_t: 1, Action: 187, Reward: 1.55, Epsilon: 0.96
[INFO] model update: t: 56, loss: 11619398582272.0
[INFO] Global_t: 56, Episode_t: 2, Action: 124, Reward: 1.91, Epsilon: 0.96
[INFO] model update: t: 57, loss: 17230592000.0
[INFO] Global_t: 57, Episode_t: 3, Action: 113, Reward: 2.27, Epsilon: 0.96
[INFO] model update: t: 58, loss: 287624986624.0
[INFO] Global_t: 58, Episode_t: 4, Action: 56, Reward: 1.51, Epsilon: 0.96
[INFO] model update: t: 59, loss: 228629512192.0
[INFO] Global_t: 59, Episode_t: 5, Action: 207, Reward: 1.73, Epsilon: 0.96
[INFO] model update: t: 60, loss: 1486496896.0
[INFO] Global_t: 60, Episode_t: 6, Action: 45, Reward: 1.92, Epsilon: 0.96
[INFO] Global step: 60, Cumulative rewards: 10.89228, Runtime (s): 26.86
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.663107395172119
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.468539237976074
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.4814789295196533
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  3.0685195922851562
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.620781421661377
average cummulative reward vector is:  [0.12776263 0.10358519 0.12474727 0.12743014 0.12946452]
average cummulative reward is:  0.12259794816792868
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 61, loss: 348382724096.0
[INFO] Global_t: 61, Episode_t: 1, Action: 51, Reward: 2.52, Epsilon: 0.96
[INFO] model update: t: 62, loss: 2012354560.0
[INFO] Global_t: 62, Episode_t: 2, Action: 80, Reward: 1.89, Epsilon: 0.96
[INFO] model update: t: 63, loss: 232308998144.0
[INFO] Global_t: 63, Episode_t: 3, Action: 44, Reward: 1.78, Epsilon: 0.96
[INFO] model update: t: 64, loss: 28179734528.0
[INFO] Global_t: 64, Episode_t: 4, Action: 10, Reward: 3.27, Epsilon: 0.96
[INFO] model update: t: 65, loss: 159764742144.0
[INFO] Global_t: 65, Episode_t: 5, Action: 99, Reward: 1.84, Epsilon: 0.96
[INFO] model update: t: 66, loss: 18226876416.0
[INFO] Global_t: 66, Episode_t: 6, Action: 186, Reward: 1.18, Epsilon: 0.96
[INFO] Global step: 66, Cumulative rewards: 12.48156, Runtime (s): 41.77
--------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 67, loss: 137400713216.0
[INFO] Global_t: 67, Episode_t: 1, Action: 123, Reward: 1.74, Epsilon: 0.96
[INFO] model update: t: 68, loss: 96059793408.0
[INFO] Global_t: 68, Episode_t: 2, Action: 60, Reward: 2.71, Epsilon: 0.96
[INFO] model update: t: 69, loss: 12563070976.0
[INFO] Global_t: 69, Episode_t: 3, Action: 23, Reward: 2.40, Epsilon: 0.96
[INFO] model update: t: 70, loss: 93870817280.0
[INFO] Global_t: 70, Episode_t: 4, Action: 192, Reward: 1.01, Epsilon: 0.96
[INFO] model update: t: 71, loss: 23736516608.0
[INFO] Global_t: 71, Episode_t: 5, Action: 130, Reward: 1.98, Epsilon: 0.96
[INFO] model update: t: 72, loss: 3414807552.0
[INFO] Global_t: 72, Episode_t: 6, Action: 22, Reward: 2.79, Epsilon: 0.96
[INFO] Global step: 72, Cumulative rewards: 12.637080000000001, Runtime (s): 43.53
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.621258497238159
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.9511771202087402
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.515735387802124
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.792550563812256
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.402838945388794
average cummulative reward vector is:  [0.12389342 0.12168519 0.12511612 0.11712103 0.11814489]
average cummulative reward is:  0.12119212939337949
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 73, loss: 40353988608.0
[INFO] Global_t: 73, Episode_t: 1, Action: 27, Reward: 2.74, Epsilon: 0.95
[INFO] model update: t: 74, loss: 31776608256.0
[INFO] Global_t: 74, Episode_t: 2, Action: 150, Reward: 1.48, Epsilon: 0.95
[INFO] model update: t: 75, loss: 3463277824.0
[INFO] Global_t: 75, Episode_t: 3, Action: 52, Reward: 1.57, Epsilon: 0.95
[INFO] model update: t: 76, loss: 5733314048.0
[INFO] Global_t: 76, Episode_t: 4, Action: 171, Reward: 1.88, Epsilon: 0.95
[INFO] model update: t: 77, loss: 21500030976.0
[INFO] Global_t: 77, Episode_t: 5, Action: 78, Reward: 1.71, Epsilon: 0.95
[INFO] model update: t: 78, loss: 18165641216.0
[INFO] Global_t: 78, Episode_t: 6, Action: 158, Reward: 1.93, Epsilon: 0.95
[INFO] Global step: 78, Cumulative rewards: 11.296199999999999, Runtime (s): 58.39
--------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 79, loss: 5368489984.0
[INFO] Global_t: 79, Episode_t: 1, Action: 140, Reward: 2.38, Epsilon: 0.95
[INFO] model update: t: 80, loss: 374900288.0
[INFO] Global_t: 80, Episode_t: 2, Action: 22, Reward: 2.27, Epsilon: 0.95
[INFO] model update: t: 81, loss: 9745105920.0
[INFO] Global_t: 81, Episode_t: 3, Action: 1, Reward: 4.97, Epsilon: 0.95
[INFO] model update: t: 82, loss: 10103478272.0
[INFO] Global_t: 82, Episode_t: 4, Action: 171, Reward: 1.43, Epsilon: 0.95
[INFO] model update: t: 83, loss: 5760543744.0
[INFO] Global_t: 83, Episode_t: 5, Action: 69, Reward: 1.64, Epsilon: 0.95
[INFO] model update: t: 84, loss: 1113954048.0
[INFO] Global_t: 84, Episode_t: 6, Action: 3, Reward: 3.99, Epsilon: 0.95
[INFO] Global step: 84, Cumulative rewards: 16.67616, Runtime (s): 60.96
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.5460093021392822
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.7071640491485596
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.582918405532837
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.684649705886841
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  2.712584972381592
average cummulative reward vector is:  [0.12204842 0.11372593 0.1306071  0.11238318 0.13118629]
average cummulative reward is:  0.12199018373927364
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 85, loss: 871536256.0
[INFO] Global_t: 85, Episode_t: 1, Action: 13, Reward: 5.10, Epsilon: 0.95
[INFO] model update: t: 86, loss: 4096902656.0
[INFO] Global_t: 86, Episode_t: 2, Action: 123, Reward: 1.82, Epsilon: 0.95
[INFO] model update: t: 87, loss: 6620387328.0
[INFO] Global_t: 87, Episode_t: 3, Action: 185, Reward: 1.45, Epsilon: 0.95
[INFO] model update: t: 88, loss: 3834106880.0
[INFO] Global_t: 88, Episode_t: 4, Action: 142, Reward: 0.98, Epsilon: 0.95
[INFO] model update: t: 89, loss: 398722624.0
[INFO] Global_t: 89, Episode_t: 5, Action: 36, Reward: 2.44, Epsilon: 0.95
[INFO] model update: t: 90, loss: 438245024.0
[INFO] Global_t: 90, Episode_t: 6, Action: 100, Reward: 1.95, Epsilon: 0.95
[INFO] Global step: 90, Cumulative rewards: 13.749959999999996, Runtime (s): 76.07
--------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 91, loss: 2532748800.0
[INFO] Global_t: 91, Episode_t: 1, Action: 127, Reward: 1.25, Epsilon: 0.95
[INFO] model update: t: 92, loss: 3477782528.0
[INFO] Global_t: 92, Episode_t: 2, Action: 186, Reward: 1.02, Epsilon: 0.95
[INFO] model update: t: 93, loss: 2199552000.0
[INFO] Global_t: 93, Episode_t: 3, Action: 148, Reward: 1.44, Epsilon: 0.94
[INFO] model update: t: 94, loss: 741834752.0
[INFO] Global_t: 94, Episode_t: 4, Action: 105, Reward: 1.65, Epsilon: 0.94
[INFO] model update: t: 95, loss: 7128699.0
[INFO] Global_t: 95, Episode_t: 5, Action: 87, Reward: 2.21, Epsilon: 0.94
[INFO] model update: t: 96, loss: 551785280.0
[INFO] Global_t: 96, Episode_t: 6, Action: 50, Reward: 2.22, Epsilon: 0.94
[INFO] Global step: 96, Cumulative rewards: 9.785039999999999, Runtime (s): 77.44
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.338937282562256
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.053565263748169
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  2.181279182434082
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.1576030254364014
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.8497793674468994
average cummulative reward vector is:  [0.11181789 0.08763125 0.11157213 0.09251752 0.09332258]
average cummulative reward is:  0.09937227597880607
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 97, loss: 1390632320.0
[INFO] Global_t: 97, Episode_t: 1, Action: 159, Reward: 1.08, Epsilon: 0.94
[INFO] model update: t: 98, loss: 1988185856.0
[INFO] Global_t: 98, Episode_t: 2, Action: 63, Reward: 1.25, Epsilon: 0.94
[INFO] model update: t: 99, loss: 1009877504.0
[INFO] Global_t: 99, Episode_t: 3, Action: 4, Reward: 5.93, Epsilon: 0.94
[INFO] model update: t: 100, loss: 186667344.0
[INFO] Global_t: 100, Episode_t: 4, Action: 92, Reward: 1.27, Epsilon: 0.94
[INFO] model update: t: 101, loss: 13321532.0
[INFO] Global_t: 101, Episode_t: 5, Action: 23, Reward: 3.19, Epsilon: 0.94
[INFO] model update: t: 102, loss: 362458432.0
[INFO] Global_t: 102, Episode_t: 6, Action: 157, Reward: 0.91, Epsilon: 0.94
[INFO] Global step: 102, Cumulative rewards: 13.6344, Runtime (s): 90.68
--------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 103, loss: 688696128.0
[INFO] Global_t: 103, Episode_t: 1, Action: 112, Reward: 1.47, Epsilon: 0.94
[INFO] model update: t: 104, loss: 754575808.0
[INFO] Global_t: 104, Episode_t: 2, Action: 13, Reward: 5.35, Epsilon: 0.94
[INFO] model update: t: 105, loss: 564214336.0
[INFO] Global_t: 105, Episode_t: 3, Action: 1, Reward: 4.51, Epsilon: 0.94
[INFO] model update: t: 106, loss: 108290896.0
[INFO] Global_t: 106, Episode_t: 4, Action: 84, Reward: 1.43, Epsilon: 0.94
[INFO] model update: t: 107, loss: 18747068.0
[INFO] Global_t: 107, Episode_t: 5, Action: 25, Reward: 1.82, Epsilon: 0.94
[INFO] model update: t: 108, loss: 206865376.0
[INFO] Global_t: 108, Episode_t: 6, Action: 93, Reward: 0.78, Epsilon: 0.94
[INFO] Global step: 108, Cumulative rewards: 15.359160000000001, Runtime (s): 93.05
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3109397888183594
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5091831684112549
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2749848365783691
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3409018516540527
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2726812362670898
average cummulative reward vector is:  [0.06263026 0.06653843 0.06729508 0.05872009 0.06492661]
average cummulative reward is:  0.06402209548244071
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 109, loss: 407587008.0
[INFO] Global_t: 109, Episode_t: 1, Action: 198, Reward: 1.73, Epsilon: 0.94
[INFO] model update: t: 110, loss: 608988096.0
[INFO] Global_t: 110, Episode_t: 2, Action: 177, Reward: 1.38, Epsilon: 0.94
[INFO] model update: t: 111, loss: 289201504.0
[INFO] Global_t: 111, Episode_t: 3, Action: 68, Reward: 1.40, Epsilon: 0.94
[INFO] model update: t: 112, loss: 63321980.0
[INFO] Global_t: 112, Episode_t: 4, Action: 36, Reward: 2.09, Epsilon: 0.94
[INFO] model update: t: 113, loss: 26822394.0
[INFO] Global_t: 113, Episode_t: 5, Action: 72, Reward: 1.80, Epsilon: 0.94
[INFO] model update: t: 114, loss: 159853136.0
[INFO] Global_t: 114, Episode_t: 6, Action: 117, Reward: 1.28, Epsilon: 0.93
[INFO] Global step: 114, Cumulative rewards: 9.679680000000001, Runtime (s): 101.58
--------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 115, loss: 247149680.0
[INFO] Global_t: 115, Episode_t: 1, Action: 81, Reward: 2.28, Epsilon: 0.93
[INFO] model update: t: 116, loss: 313899136.0
[INFO] Global_t: 116, Episode_t: 2, Action: 160, Reward: 1.38, Epsilon: 0.93
[INFO] model update: t: 117, loss: 111803568.0
[INFO] Global_t: 117, Episode_t: 3, Action: 136, Reward: 1.75, Epsilon: 0.93
[INFO] model update: t: 118, loss: 19866904.0
[INFO] Global_t: 118, Episode_t: 4, Action: 2, Reward: 6.84, Epsilon: 0.93
[INFO] model update: t: 119, loss: 26281080.0
[INFO] Global_t: 119, Episode_t: 5, Action: 91, Reward: 2.41, Epsilon: 0.93
[INFO] model update: t: 120, loss: 117209744.0
[INFO] Global_t: 120, Episode_t: 6, Action: 140, Reward: 1.26, Epsilon: 0.93
[INFO] Global step: 120, Cumulative rewards: 15.917159999999999, Runtime (s): 103.72
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2553517818450928
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3795270919799805
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3264832496643066
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2568409442901611
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2060654163360596
average cummulative reward vector is:  [0.06295342 0.0607412  0.06997268 0.05492897 0.06122634]
average cummulative reward is:  0.06196452368012041
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 121, loss: 149925408.0
[INFO] Global_t: 121, Episode_t: 1, Action: 74, Reward: 2.29, Epsilon: 0.93
[INFO] model update: t: 122, loss: 128181136.0
[INFO] Global_t: 122, Episode_t: 2, Action: 60, Reward: 2.41, Epsilon: 0.93
[INFO] model update: t: 123, loss: 73313032.0
[INFO] Global_t: 123, Episode_t: 3, Action: 152, Reward: 1.17, Epsilon: 0.93
[INFO] model update: t: 124, loss: 13273790.0
[INFO] Global_t: 124, Episode_t: 4, Action: 21, Reward: 3.41, Epsilon: 0.93
[INFO] model update: t: 125, loss: 15417353.0
[INFO] Global_t: 125, Episode_t: 5, Action: 49, Reward: 2.22, Epsilon: 0.93
[INFO] model update: t: 126, loss: 58371036.0
[INFO] Global_t: 126, Episode_t: 6, Action: 209, Reward: 2.03, Epsilon: 0.93
[INFO] Global step: 126, Cumulative rewards: 13.53348, Runtime (s): 111.75
--------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 127, loss: 72070528.0
[INFO] Global_t: 127, Episode_t: 1, Action: 82, Reward: 1.80, Epsilon: 0.93
[INFO] model update: t: 128, loss: 59495416.0
[INFO] Global_t: 128, Episode_t: 2, Action: 84, Reward: 1.97, Epsilon: 0.93
[INFO] model update: t: 129, loss: 22591634.0
[INFO] Global_t: 129, Episode_t: 3, Action: 101, Reward: 1.57, Epsilon: 0.93
[INFO] model update: t: 130, loss: 4426052.0
[INFO] Global_t: 130, Episode_t: 4, Action: 179, Reward: 1.26, Epsilon: 0.93
[INFO] model update: t: 131, loss: 7422259.0
[INFO] Global_t: 131, Episode_t: 5, Action: 93, Reward: 0.93, Epsilon: 0.93
[INFO] model update: t: 132, loss: 24876330.0
[INFO] Global_t: 132, Episode_t: 6, Action: 73, Reward: 1.67, Epsilon: 0.93
[INFO] Global step: 132, Cumulative rewards: 9.201479999999998, Runtime (s): 113.35
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2475709915161133
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3747198581695557
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2435331344604492
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3375766277313232
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3835012912750244
average cummulative reward vector is:  [0.06160395 0.05908449 0.06501858 0.05668692 0.06976989]
average cummulative reward is:  0.06243276514102064
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 133, loss: 47590712.0
[INFO] Global_t: 133, Episode_t: 1, Action: 88, Reward: 1.62, Epsilon: 0.93
[INFO] model update: t: 134, loss: 31525468.0
[INFO] Global_t: 134, Episode_t: 2, Action: 94, Reward: 1.89, Epsilon: 0.92
[INFO] model update: t: 135, loss: 11675696.0
[INFO] Global_t: 135, Episode_t: 3, Action: 72, Reward: 2.07, Epsilon: 0.92
[INFO] model update: t: 136, loss: 1668182.125
[INFO] Global_t: 136, Episode_t: 4, Action: 69, Reward: 1.58, Epsilon: 0.92
[INFO] model update: t: 137, loss: 6381887.0
[INFO] Global_t: 137, Episode_t: 5, Action: 23, Reward: 2.57, Epsilon: 0.92
[INFO] model update: t: 138, loss: 17992370.0
[INFO] Global_t: 138, Episode_t: 6, Action: 149, Reward: 1.95, Epsilon: 0.92
[INFO] Global step: 138, Cumulative rewards: 11.680919999999997, Runtime (s): 121.38
--------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 139, loss: 26059716.0
[INFO] Global_t: 139, Episode_t: 1, Action: 81, Reward: 2.06, Epsilon: 0.92
[INFO] model update: t: 140, loss: 15463794.0
[INFO] Global_t: 140, Episode_t: 2, Action: 88, Reward: 2.06, Epsilon: 0.92
[INFO] model update: t: 141, loss: 5402905.5
[INFO] Global_t: 141, Episode_t: 3, Action: 75, Reward: 1.53, Epsilon: 0.92
[INFO] model update: t: 142, loss: 794185.625
[INFO] Global_t: 142, Episode_t: 4, Action: 49, Reward: 2.07, Epsilon: 0.92
[INFO] model update: t: 143, loss: 4482047.5
[INFO] Global_t: 143, Episode_t: 5, Action: 128, Reward: 1.41, Epsilon: 0.92
[INFO] model update: t: 144, loss: 10240942.0
[INFO] Global_t: 144, Episode_t: 6, Action: 198, Reward: 1.17, Epsilon: 0.92
[INFO] Global step: 144, Cumulative rewards: 10.29936, Runtime (s): 123.00
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3654837608337402
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2019438743591309
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2173163890838623
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3875749111175537
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2479181289672852
average cummulative reward vector is:  [0.06326474 0.05052685 0.06162951 0.05732453 0.0629828 ]
average cummulative reward is:  0.05914568505997671
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 145, loss: 10999025.0
[INFO] Global_t: 145, Episode_t: 1, Action: 186, Reward: 1.81, Epsilon: 0.92
[INFO] model update: t: 146, loss: 10177712.0
[INFO] Global_t: 146, Episode_t: 2, Action: 133, Reward: 1.29, Epsilon: 0.92
[INFO] model update: t: 147, loss: 2093158.25
[INFO] Global_t: 147, Episode_t: 3, Action: 88, Reward: 2.29, Epsilon: 0.92
[INFO] model update: t: 148, loss: 910852.875
[INFO] Global_t: 148, Episode_t: 4, Action: 75, Reward: 1.77, Epsilon: 0.92
[INFO] model update: t: 149, loss: 3959624.5
[INFO] Global_t: 149, Episode_t: 5, Action: 69, Reward: 1.92, Epsilon: 0.92
[INFO] model update: t: 150, loss: 7943870.5
[INFO] Global_t: 150, Episode_t: 6, Action: 87, Reward: 1.60, Epsilon: 0.92
[INFO] Global step: 150, Cumulative rewards: 10.677119999999999, Runtime (s): 131.29
--------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 151, loss: 7644895.5
[INFO] Global_t: 151, Episode_t: 1, Action: 3, Reward: 6.59, Epsilon: 0.92
[INFO] model update: t: 152, loss: 3615024.0
[INFO] Global_t: 152, Episode_t: 2, Action: 29, Reward: 2.36, Epsilon: 0.92
[INFO] model update: t: 153, loss: 1585996.625
[INFO] Global_t: 153, Episode_t: 3, Action: 90, Reward: 1.41, Epsilon: 0.92
[INFO] model update: t: 154, loss: 542559.25
[INFO] Global_t: 154, Episode_t: 4, Action: 40, Reward: 1.62, Epsilon: 0.92
[INFO] model update: t: 155, loss: 2855148.5
[INFO] Global_t: 155, Episode_t: 5, Action: 167, Reward: 1.01, Epsilon: 0.91
[INFO] model update: t: 156, loss: 4645398.5
[INFO] Global_t: 156, Episode_t: 6, Action: 54, Reward: 1.07, Epsilon: 0.91
[INFO] Global step: 156, Cumulative rewards: 14.051639999999999, Runtime (s): 134.11
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.1956110000610352
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3038270473480225
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2504651546478271
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.343111515045166
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.307509183883667
average cummulative reward vector is:  [0.05903526 0.05621736 0.06459372 0.05882827 0.06703387]
average cummulative reward is:  0.06114169642235594
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 157, loss: 4361609.0
[INFO] Global_t: 157, Episode_t: 1, Action: 63, Reward: 2.09, Epsilon: 0.91
[INFO] model update: t: 158, loss: 2541513.5
[INFO] Global_t: 158, Episode_t: 2, Action: 25, Reward: 2.82, Epsilon: 0.91
[INFO] model update: t: 159, loss: 1159590.75
[INFO] Global_t: 159, Episode_t: 3, Action: 92, Reward: 1.62, Epsilon: 0.91
[INFO] model update: t: 160, loss: 1052616.875
[INFO] Global_t: 160, Episode_t: 4, Action: 73, Reward: 1.81, Epsilon: 0.91
[INFO] model update: t: 161, loss: 2354836.5
[INFO] Global_t: 161, Episode_t: 5, Action: 43, Reward: 1.96, Epsilon: 0.91
[INFO] model update: t: 162, loss: 3149232.0
[INFO] Global_t: 162, Episode_t: 6, Action: 59, Reward: 1.20, Epsilon: 0.91
[INFO] Global step: 162, Cumulative rewards: 11.496479999999998, Runtime (s): 142.55
--------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 163, loss: 2805245.75
[INFO] Global_t: 163, Episode_t: 1, Action: 68, Reward: 1.66, Epsilon: 0.91
[INFO] model update: t: 164, loss: 1371966.875
[INFO] Global_t: 164, Episode_t: 2, Action: 111, Reward: 1.75, Epsilon: 0.91
[INFO] model update: t: 165, loss: 753552.4375
[INFO] Global_t: 165, Episode_t: 3, Action: 188, Reward: 1.51, Epsilon: 0.91
[INFO] model update: t: 166, loss: 901792.625
[INFO] Global_t: 166, Episode_t: 4, Action: 126, Reward: 1.20, Epsilon: 0.91
[INFO] model update: t: 167, loss: 1996429.75
[INFO] Global_t: 167, Episode_t: 5, Action: 85, Reward: 1.56, Epsilon: 0.91
[INFO] model update: t: 168, loss: 2000014.75
[INFO] Global_t: 168, Episode_t: 6, Action: 176, Reward: 1.14, Epsilon: 0.91
[INFO] Global step: 168, Cumulative rewards: 8.82552, Runtime (s): 144.07
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.262831687927246
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.270395278930664
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2860753536224365
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3528552055358887
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.392528772354126
average cummulative reward vector is:  [0.06280684 0.05420231 0.06695628 0.05951005 0.07185242]
average cummulative reward is:  0.06306558143137883
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 169, loss: 1373425.0
[INFO] Global_t: 169, Episode_t: 1, Action: 46, Reward: 2.02, Epsilon: 0.91
[INFO] model update: t: 170, loss: 382723.375
[INFO] Global_t: 170, Episode_t: 2, Action: 122, Reward: 1.33, Epsilon: 0.91
[INFO] model update: t: 171, loss: 389778.125
[INFO] Global_t: 171, Episode_t: 3, Action: 118, Reward: 1.39, Epsilon: 0.91
[INFO] model update: t: 172, loss: 1901619.625
[INFO] Global_t: 172, Episode_t: 4, Action: 157, Reward: 1.87, Epsilon: 0.91
[INFO] model update: t: 173, loss: 1396306.25
[INFO] Global_t: 173, Episode_t: 5, Action: 108, Reward: 1.41, Epsilon: 0.91
[INFO] model update: t: 174, loss: 1339499.625
[INFO] Global_t: 174, Episode_t: 6, Action: 59, Reward: 1.77, Epsilon: 0.91
[INFO] Global step: 174, Cumulative rewards: 9.78936, Runtime (s): 152.19
--------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 175, loss: 432908.125
[INFO] Global_t: 175, Episode_t: 1, Action: 36, Reward: 2.53, Epsilon: 0.90
[INFO] model update: t: 176, loss: 288616.6875
[INFO] Global_t: 176, Episode_t: 2, Action: 98, Reward: 1.76, Epsilon: 0.90
[INFO] model update: t: 177, loss: 720688.125
[INFO] Global_t: 177, Episode_t: 3, Action: 22, Reward: 3.32, Epsilon: 0.90
[INFO] model update: t: 178, loss: 608437.875
[INFO] Global_t: 178, Episode_t: 4, Action: 118, Reward: 1.85, Epsilon: 0.90
[INFO] model update: t: 179, loss: 919664.5625
[INFO] Global_t: 179, Episode_t: 5, Action: 184, Reward: 1.18, Epsilon: 0.90
[INFO] model update: t: 180, loss: 304573.75
[INFO] Global_t: 180, Episode_t: 6, Action: 112, Reward: 1.22, Epsilon: 0.90
[INFO] Global step: 180, Cumulative rewards: 11.85588, Runtime (s): 153.85
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3300223350524902
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4659843444824219
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3081979751586914
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3813447952270508
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2449162006378174
average cummulative reward vector is:  [0.06374711 0.06445486 0.06802104 0.06090537 0.06335081]
average cummulative reward is:  0.06409583698180474
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 181, loss: 251112.78125
[INFO] Global_t: 181, Episode_t: 1, Action: 9, Reward: 5.03, Epsilon: 0.90
[INFO] model update: t: 182, loss: 257865.453125
[INFO] Global_t: 182, Episode_t: 2, Action: 34, Reward: 1.69, Epsilon: 0.90
[INFO] model update: t: 183, loss: 392320.21875
[INFO] Global_t: 183, Episode_t: 3, Action: 15, Reward: 2.97, Epsilon: 0.90
[INFO] model update: t: 184, loss: 366925.5
[INFO] Global_t: 184, Episode_t: 4, Action: 154, Reward: 1.32, Epsilon: 0.90
[INFO] model update: t: 185, loss: 738587.25
[INFO] Global_t: 185, Episode_t: 5, Action: 158, Reward: 1.26, Epsilon: 0.90
[INFO] model update: t: 186, loss: 273762.09375
[INFO] Global_t: 186, Episode_t: 6, Action: 89, Reward: 1.30, Epsilon: 0.90
[INFO] Global step: 186, Cumulative rewards: 13.574039999999997, Runtime (s): 163.38
--------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 187, loss: 197132.578125
[INFO] Global_t: 187, Episode_t: 1, Action: 181, Reward: 1.18, Epsilon: 0.90
[INFO] model update: t: 188, loss: 569098.1875
[INFO] Global_t: 188, Episode_t: 2, Action: 58, Reward: 1.55, Epsilon: 0.90
[INFO] model update: t: 189, loss: 479632.75
[INFO] Global_t: 189, Episode_t: 3, Action: 91, Reward: 2.18, Epsilon: 0.90
[INFO] model update: t: 190, loss: 633392.875
[INFO] Global_t: 190, Episode_t: 4, Action: 64, Reward: 2.11, Epsilon: 0.90
[INFO] model update: t: 191, loss: 440331.125
[INFO] Global_t: 191, Episode_t: 5, Action: 90, Reward: 1.75, Epsilon: 0.90
[INFO] model update: t: 192, loss: 147158.171875
[INFO] Global_t: 192, Episode_t: 6, Action: 147, Reward: 1.31, Epsilon: 0.90
[INFO] Global step: 192, Cumulative rewards: 10.079999999999998, Runtime (s): 164.61
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2879414558410645
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3953518867492676
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1770002841949463
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.1795175075531006
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2701010704040527
average cummulative reward vector is:  [0.06434474 0.06051944 0.05979344 0.05013037 0.06415968]
average cummulative reward is:  0.05978953503212621
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 193, loss: 153151.28125
[INFO] Global_t: 193, Episode_t: 1, Action: 161, Reward: 2.02, Epsilon: 0.90
[INFO] model update: t: 194, loss: 148028.359375
[INFO] Global_t: 194, Episode_t: 2, Action: 53, Reward: 2.09, Epsilon: 0.90
[INFO] model update: t: 195, loss: 340860.40625
[INFO] Global_t: 195, Episode_t: 3, Action: 24, Reward: 2.32, Epsilon: 0.89
[INFO] model update: t: 196, loss: 333455.125
[INFO] Global_t: 196, Episode_t: 4, Action: 113, Reward: 2.12, Epsilon: 0.89
[INFO] model update: t: 197, loss: 208225.5
[INFO] Global_t: 197, Episode_t: 5, Action: 9, Reward: 4.20, Epsilon: 0.89
[INFO] model update: t: 198, loss: 223649.4375
[INFO] Global_t: 198, Episode_t: 6, Action: 119, Reward: 1.57, Epsilon: 0.89
[INFO] Global step: 198, Cumulative rewards: 14.314440000000001, Runtime (s): 172.78
--------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 199, loss: 96318.046875
[INFO] Global_t: 199, Episode_t: 1, Action: 37, Reward: 2.87, Epsilon: 0.89
[INFO] model update: t: 200, loss: 222952.84375
[INFO] Global_t: 200, Episode_t: 2, Action: 71, Reward: 1.83, Epsilon: 0.89
[INFO] model update: t: 201, loss: 175585.328125
[INFO] Global_t: 201, Episode_t: 3, Action: 144, Reward: 1.81, Epsilon: 0.89
[INFO] model update: t: 202, loss: 238053.90625
[INFO] Global_t: 202, Episode_t: 4, Action: 191, Reward: 1.80, Epsilon: 0.89
[INFO] model update: t: 203, loss: 94041.4296875
[INFO] Global_t: 203, Episode_t: 5, Action: 34, Reward: 1.84, Epsilon: 0.89
[INFO] model update: t: 204, loss: 104724.2265625
[INFO] Global_t: 204, Episode_t: 6, Action: 39, Reward: 2.24, Epsilon: 0.89
[INFO] Global step: 204, Cumulative rewards: 12.39528, Runtime (s): 174.96
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2765822410583496
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3424303531646729
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1747028827667236
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.434596300125122
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3912947177886963
average cummulative reward vector is:  [0.06245289 0.05655278 0.05734809 0.05923505 0.06958602]
average cummulative reward is:  0.061034965636132435
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 205, loss: 136417.65625
[INFO] Global_t: 205, Episode_t: 1, Action: 152, Reward: 1.88, Epsilon: 0.89
[INFO] model update: t: 206, loss: 161938.15625
[INFO] Global_t: 206, Episode_t: 2, Action: 117, Reward: 1.78, Epsilon: 0.89
[INFO] model update: t: 207, loss: 77013.8125
[INFO] Global_t: 207, Episode_t: 3, Action: 160, Reward: 2.19, Epsilon: 0.89
[INFO] model update: t: 208, loss: 47251.3203125
[INFO] Global_t: 208, Episode_t: 4, Action: 196, Reward: 1.95, Epsilon: 0.89
[INFO] model update: t: 209, loss: 50221.77734375
[INFO] Global_t: 209, Episode_t: 5, Action: 174, Reward: 1.35, Epsilon: 0.89
[INFO] model update: t: 210, loss: 86644.4453125
[INFO] Global_t: 210, Episode_t: 6, Action: 158, Reward: 1.53, Epsilon: 0.89
[INFO] Global step: 210, Cumulative rewards: 10.674960000000002, Runtime (s): 183.73
--------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 211, loss: 73405.96875
[INFO] Global_t: 211, Episode_t: 1, Action: 25, Reward: 2.87, Epsilon: 0.89
[INFO] model update: t: 212, loss: 95514.296875
[INFO] Global_t: 212, Episode_t: 2, Action: 140, Reward: 1.27, Epsilon: 0.89
[INFO] model update: t: 213, loss: 66012.8125
[INFO] Global_t: 213, Episode_t: 3, Action: 121, Reward: 1.27, Epsilon: 0.89
[INFO] model update: t: 214, loss: 77841.390625
[INFO] Global_t: 214, Episode_t: 4, Action: 111, Reward: 1.67, Epsilon: 0.89
[INFO] model update: t: 215, loss: 107222.546875
[INFO] Global_t: 215, Episode_t: 5, Action: 97, Reward: 1.86, Epsilon: 0.89
[INFO] model update: t: 216, loss: 49688.0625
[INFO] Global_t: 216, Episode_t: 6, Action: 125, Reward: 1.69, Epsilon: 0.88
[INFO] Global step: 216, Cumulative rewards: 10.639439999999999, Runtime (s): 185.45
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.194849967956543
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.378704309463501
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2283282279968262
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2940125465393066
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2640647888183594
average cummulative reward vector is:  [0.05868605 0.05937801 0.06271448 0.05668458 0.06422231]
average cummulative reward is:  0.060337086806472894
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 217, loss: 46666.9375
[INFO] Global_t: 217, Episode_t: 1, Action: 74, Reward: 1.82, Epsilon: 0.88
[INFO] model update: t: 218, loss: 53774.31640625
[INFO] Global_t: 218, Episode_t: 2, Action: 33, Reward: 4.07, Epsilon: 0.88
[INFO] model update: t: 219, loss: 105522.6328125
[INFO] Global_t: 219, Episode_t: 3, Action: 124, Reward: 1.99, Epsilon: 0.88
[INFO] model update: t: 220, loss: 42812.59375
[INFO] Global_t: 220, Episode_t: 4, Action: 25, Reward: 1.91, Epsilon: 0.88
[INFO] model update: t: 221, loss: 59351.953125
[INFO] Global_t: 221, Episode_t: 5, Action: 90, Reward: 2.04, Epsilon: 0.88
[INFO] model update: t: 222, loss: 77216.53125
[INFO] Global_t: 222, Episode_t: 6, Action: 112, Reward: 1.84, Epsilon: 0.88
[INFO] Global step: 222, Cumulative rewards: 13.667759999999998, Runtime (s): 193.61
--------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 223, loss: 125065.84375
[INFO] Global_t: 223, Episode_t: 1, Action: 93, Reward: 1.40, Epsilon: 0.88
[INFO] model update: t: 224, loss: 156857.25
[INFO] Global_t: 224, Episode_t: 2, Action: 3, Reward: 6.11, Epsilon: 0.88
[INFO] model update: t: 225, loss: 36263.35546875
[INFO] Global_t: 225, Episode_t: 3, Action: 134, Reward: 1.45, Epsilon: 0.88
[INFO] model update: t: 226, loss: 110272.90625
[INFO] Global_t: 226, Episode_t: 4, Action: 131, Reward: 2.39, Epsilon: 0.88
[INFO] model update: t: 227, loss: 173181.828125
[INFO] Global_t: 227, Episode_t: 5, Action: 154, Reward: 1.81, Epsilon: 0.88
[INFO] model update: t: 228, loss: 148853.40625
[INFO] Global_t: 228, Episode_t: 6, Action: 173, Reward: 2.18, Epsilon: 0.88
[INFO] Global step: 228, Cumulative rewards: 15.338159999999998, Runtime (s): 195.19
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3081157207489014
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2516534328460693
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2601649761199951
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.284452199935913
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2471861839294434
average cummulative reward vector is:  [0.06529237 0.05366852 0.06502705 0.05622383 0.06311156]
average cummulative reward is:  0.060664665407076976
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 229, loss: 104127.171875
[INFO] Global_t: 229, Episode_t: 1, Action: 0, Reward: 5.19, Epsilon: 0.88
[INFO] model update: t: 230, loss: 121338.53125
[INFO] Global_t: 230, Episode_t: 2, Action: 122, Reward: 1.32, Epsilon: 0.88
[INFO] model update: t: 231, loss: 64452.26953125
[INFO] Global_t: 231, Episode_t: 3, Action: 43, Reward: 2.15, Epsilon: 0.88
[INFO] model update: t: 232, loss: 112211.15625
[INFO] Global_t: 232, Episode_t: 4, Action: 181, Reward: 2.21, Epsilon: 0.88
[INFO] model update: t: 233, loss: 144448.28125
[INFO] Global_t: 233, Episode_t: 5, Action: 71, Reward: 1.77, Epsilon: 0.88
[INFO] model update: t: 234, loss: 117571.4921875
[INFO] Global_t: 234, Episode_t: 6, Action: 150, Reward: 1.97, Epsilon: 0.88
[INFO] Global step: 234, Cumulative rewards: 14.606279999999998, Runtime (s): 203.32
--------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 235, loss: 86227.9765625
[INFO] Global_t: 235, Episode_t: 1, Action: 134, Reward: 1.55, Epsilon: 0.88
[INFO] model update: t: 236, loss: 111640.6015625
[INFO] Global_t: 236, Episode_t: 2, Action: 12, Reward: 3.37, Epsilon: 0.87
[INFO] model update: t: 237, loss: 55366.27734375
[INFO] Global_t: 237, Episode_t: 3, Action: 106, Reward: 2.08, Epsilon: 0.87
[INFO] model update: t: 238, loss: 83130.1875
[INFO] Global_t: 238, Episode_t: 4, Action: 87, Reward: 1.59, Epsilon: 0.87
[INFO] model update: t: 239, loss: 90270.546875
[INFO] Global_t: 239, Episode_t: 5, Action: 95, Reward: 1.88, Epsilon: 0.87
[INFO] model update: t: 240, loss: 91229.8515625
[INFO] Global_t: 240, Episode_t: 6, Action: 149, Reward: 1.28, Epsilon: 0.87
[INFO] Global step: 240, Cumulative rewards: 11.748599999999998, Runtime (s): 205.01
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2614021301269531
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4718959331512451
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2941462993621826
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4442944526672363
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3330683708190918
average cummulative reward vector is:  [0.06283263 0.06427731 0.06704754 0.06404346 0.06820215]
average cummulative reward is:  0.06528061917178565
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 241, loss: 67844.09375
[INFO] Global_t: 241, Episode_t: 1, Action: 71, Reward: 2.59, Epsilon: 0.87
[INFO] model update: t: 242, loss: 73863.5
[INFO] Global_t: 242, Episode_t: 2, Action: 58, Reward: 2.54, Epsilon: 0.87
[INFO] model update: t: 243, loss: 81207.5546875
[INFO] Global_t: 243, Episode_t: 3, Action: 54, Reward: 1.92, Epsilon: 0.87
[INFO] model update: t: 244, loss: 68314.03125
[INFO] Global_t: 244, Episode_t: 4, Action: 88, Reward: 1.77, Epsilon: 0.87
[INFO] model update: t: 245, loss: 73070.984375
[INFO] Global_t: 245, Episode_t: 5, Action: 168, Reward: 1.45, Epsilon: 0.87
[INFO] model update: t: 246, loss: 68421.7109375
[INFO] Global_t: 246, Episode_t: 6, Action: 65, Reward: 1.39, Epsilon: 0.87
[INFO] Global step: 246, Cumulative rewards: 11.65692, Runtime (s): 213.52
--------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 247, loss: 71170.671875
[INFO] Global_t: 247, Episode_t: 1, Action: 175, Reward: 1.40, Epsilon: 0.87
[INFO] model update: t: 248, loss: 86754.2109375
[INFO] Global_t: 248, Episode_t: 2, Action: 95, Reward: 1.85, Epsilon: 0.87
[INFO] model update: t: 249, loss: 131802.765625
[INFO] Global_t: 249, Episode_t: 3, Action: 76, Reward: 1.70, Epsilon: 0.87
[INFO] model update: t: 250, loss: 92505.1875
[INFO] Global_t: 250, Episode_t: 4, Action: 150, Reward: 1.18, Epsilon: 0.87
[INFO] model update: t: 251, loss: 37142.09765625
[INFO] Global_t: 251, Episode_t: 5, Action: 164, Reward: 1.18, Epsilon: 0.87
[INFO] model update: t: 252, loss: 70587.984375
[INFO] Global_t: 252, Episode_t: 6, Action: 107, Reward: 1.70, Epsilon: 0.87
[INFO] Global step: 252, Cumulative rewards: 9.008039999999998, Runtime (s): 214.98
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2978124618530273
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.314208745956421
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.134634256362915
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.389587640762329
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2723324298858643
average cummulative reward vector is:  [0.06495211 0.05650579 0.05720273 0.06125164 0.06517258]
average cummulative reward is:  0.061016968139962414
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 253, loss: 50931.3125
[INFO] Global_t: 253, Episode_t: 1, Action: 151, Reward: 1.35, Epsilon: 0.87
[INFO] model update: t: 254, loss: 93483.46875
[INFO] Global_t: 254, Episode_t: 2, Action: 183, Reward: 1.28, Epsilon: 0.87
[INFO] model update: t: 255, loss: 61318.45703125
[INFO] Global_t: 255, Episode_t: 3, Action: 44, Reward: 2.09, Epsilon: 0.87
[INFO] model update: t: 256, loss: 67304.640625
[INFO] Global_t: 256, Episode_t: 4, Action: 77, Reward: 1.94, Epsilon: 0.87
[INFO] model update: t: 257, loss: 38390.30859375
[INFO] Global_t: 257, Episode_t: 5, Action: 141, Reward: 2.36, Epsilon: 0.86
[INFO] model update: t: 258, loss: 84775.4453125
[INFO] Global_t: 258, Episode_t: 6, Action: 111, Reward: 2.28, Epsilon: 0.86
[INFO] Global step: 258, Cumulative rewards: 11.3064, Runtime (s): 222.89
--------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 259, loss: 79908.796875
[INFO] Global_t: 259, Episode_t: 1, Action: 181, Reward: 1.76, Epsilon: 0.86
[INFO] model update: t: 260, loss: 48556.15234375
[INFO] Global_t: 260, Episode_t: 2, Action: 41, Reward: 2.31, Epsilon: 0.86
[INFO] model update: t: 261, loss: 79351.6015625
[INFO] Global_t: 261, Episode_t: 3, Action: 53, Reward: 1.63, Epsilon: 0.86
[INFO] model update: t: 262, loss: 107949.171875
[INFO] Global_t: 262, Episode_t: 4, Action: 92, Reward: 1.90, Epsilon: 0.86
[INFO] model update: t: 263, loss: 109664.5703125
[INFO] Global_t: 263, Episode_t: 5, Action: 154, Reward: 1.40, Epsilon: 0.86
[INFO] model update: t: 264, loss: 65730.109375
[INFO] Global_t: 264, Episode_t: 6, Action: 131, Reward: 1.10, Epsilon: 0.86
[INFO] Global step: 264, Cumulative rewards: 10.092719999999998, Runtime (s): 224.79
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.371903657913208
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4800918102264404
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3849492073059082
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4331133365631104
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2535419464111328
average cummulative reward vector is:  [0.06778263 0.06492292 0.07268142 0.06366121 0.0630043 ]
average cummulative reward is:  0.06641049700783623
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 265, loss: 98925.8984375
[INFO] Global_t: 265, Episode_t: 1, Action: 38, Reward: 1.71, Epsilon: 0.86
[INFO] model update: t: 266, loss: 72334.1171875
[INFO] Global_t: 266, Episode_t: 2, Action: 40, Reward: 1.93, Epsilon: 0.86
[INFO] model update: t: 267, loss: 83183.46875
[INFO] Global_t: 267, Episode_t: 3, Action: 140, Reward: 1.21, Epsilon: 0.86
[INFO] model update: t: 268, loss: 75019.71875
[INFO] Global_t: 268, Episode_t: 4, Action: 55, Reward: 2.30, Epsilon: 0.86
[INFO] model update: t: 269, loss: 44384.23046875
[INFO] Global_t: 269, Episode_t: 5, Action: 111, Reward: 1.67, Epsilon: 0.86
[INFO] model update: t: 270, loss: 90842.3671875
[INFO] Global_t: 270, Episode_t: 6, Action: 162, Reward: 1.85, Epsilon: 0.86
[INFO] Global step: 270, Cumulative rewards: 10.67652, Runtime (s): 233.28
--------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 271, loss: 45548.4375
[INFO] Global_t: 271, Episode_t: 1, Action: 102, Reward: 1.96, Epsilon: 0.86
[INFO] model update: t: 272, loss: 69867.046875
[INFO] Global_t: 272, Episode_t: 2, Action: 123, Reward: 2.16, Epsilon: 0.86
[INFO] model update: t: 273, loss: 48967.484375
[INFO] Global_t: 273, Episode_t: 3, Action: 115, Reward: 1.70, Epsilon: 0.86
[INFO] model update: t: 274, loss: 126831.9375
[INFO] Global_t: 274, Episode_t: 4, Action: 32, Reward: 1.86, Epsilon: 0.86
[INFO] model update: t: 275, loss: 93250.75
[INFO] Global_t: 275, Episode_t: 5, Action: 69, Reward: 1.59, Epsilon: 0.86
[INFO] model update: t: 276, loss: 72277.6796875
[INFO] Global_t: 276, Episode_t: 6, Action: 15, Reward: 2.26, Epsilon: 0.86
[INFO] Global step: 276, Cumulative rewards: 11.5302, Runtime (s): 234.86
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2781972885131836
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.439971685409546
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3343334197998047
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.31113862991333
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3351445198059082
average cummulative reward vector is:  [0.06256842 0.06039028 0.06871557 0.05720678 0.06834677]
average cummulative reward is:  0.06344556449907682
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 277, loss: 54133.2109375
[INFO] Global_t: 277, Episode_t: 1, Action: 63, Reward: 2.04, Epsilon: 0.85
[INFO] model update: t: 278, loss: 89494.921875
[INFO] Global_t: 278, Episode_t: 2, Action: 86, Reward: 2.01, Epsilon: 0.85
[INFO] model update: t: 279, loss: 51330.8984375
[INFO] Global_t: 279, Episode_t: 3, Action: 148, Reward: 1.80, Epsilon: 0.85
[INFO] model update: t: 280, loss: 72731.4375
[INFO] Global_t: 280, Episode_t: 4, Action: 92, Reward: 1.63, Epsilon: 0.85
[INFO] model update: t: 281, loss: 44520.421875
[INFO] Global_t: 281, Episode_t: 5, Action: 44, Reward: 2.29, Epsilon: 0.85
[INFO] model update: t: 282, loss: 49978.0234375
[INFO] Global_t: 282, Episode_t: 6, Action: 102, Reward: 1.33, Epsilon: 0.85
[INFO] Global step: 282, Cumulative rewards: 11.105639999999998, Runtime (s): 243.69
--------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 283, loss: 42647.078125
[INFO] Global_t: 283, Episode_t: 1, Action: 87, Reward: 1.85, Epsilon: 0.85
[INFO] model update: t: 284, loss: 112083.984375
[INFO] Global_t: 284, Episode_t: 2, Action: 4, Reward: 4.17, Epsilon: 0.85
[INFO] model update: t: 285, loss: 79467.75
[INFO] Global_t: 285, Episode_t: 3, Action: 7, Reward: 4.31, Epsilon: 0.85
[INFO] model update: t: 286, loss: 89764.5078125
[INFO] Global_t: 286, Episode_t: 4, Action: 69, Reward: 2.19, Epsilon: 0.85
[INFO] model update: t: 287, loss: 100805.0390625
[INFO] Global_t: 287, Episode_t: 5, Action: 39, Reward: 2.08, Epsilon: 0.85
[INFO] model update: t: 288, loss: 87150.328125
[INFO] Global_t: 288, Episode_t: 6, Action: 50, Reward: 1.65, Epsilon: 0.85
[INFO] Global step: 288, Cumulative rewards: 16.25976, Runtime (s): 245.32
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2538633346557617
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3045835494995117
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2549877166748047
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.1971449851989746
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3065197467803955
average cummulative reward vector is:  [0.06227184 0.0565669  0.06487404 0.05131145 0.06659194]
average cummulative reward is:  0.060323233610252026
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 289, loss: 100264.609375
[INFO] Global_t: 289, Episode_t: 1, Action: 14, Reward: 4.22, Epsilon: 0.85
[INFO] model update: t: 290, loss: 42946.98046875
[INFO] Global_t: 290, Episode_t: 2, Action: 114, Reward: 1.40, Epsilon: 0.85
[INFO] model update: t: 291, loss: 36928.6015625
[INFO] Global_t: 291, Episode_t: 3, Action: 126, Reward: 1.79, Epsilon: 0.85
[INFO] model update: t: 292, loss: 74752.5
[INFO] Global_t: 292, Episode_t: 4, Action: 174, Reward: 1.06, Epsilon: 0.85
[INFO] model update: t: 293, loss: 100372.6015625
[INFO] Global_t: 293, Episode_t: 5, Action: 70, Reward: 1.14, Epsilon: 0.85
[INFO] model update: t: 294, loss: 111883.53125
[INFO] Global_t: 294, Episode_t: 6, Action: 59, Reward: 1.83, Epsilon: 0.85
[INFO] Global step: 294, Cumulative rewards: 11.44956, Runtime (s): 253.54
--------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 295, loss: 96093.375
[INFO] Global_t: 295, Episode_t: 1, Action: 119, Reward: 1.55, Epsilon: 0.85
[INFO] model update: t: 296, loss: 59305.36328125
[INFO] Global_t: 296, Episode_t: 2, Action: 131, Reward: 2.10, Epsilon: 0.85
[INFO] model update: t: 297, loss: 69459.75
[INFO] Global_t: 297, Episode_t: 3, Action: 183, Reward: 1.34, Epsilon: 0.84
[INFO] model update: t: 298, loss: 49704.55078125
[INFO] Global_t: 298, Episode_t: 4, Action: 193, Reward: 1.23, Epsilon: 0.84
[INFO] model update: t: 299, loss: 124551.78125
[INFO] Global_t: 299, Episode_t: 5, Action: 93, Reward: 2.06, Epsilon: 0.84
[INFO] model update: t: 300, loss: 39500.40625
[INFO] Global_t: 300, Episode_t: 6, Action: 138, Reward: 2.23, Epsilon: 0.84
[INFO] Global step: 300, Cumulative rewards: 10.500720000000001, Runtime (s): 255.06
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2434544563293457
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3889667987823486
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1471476554870605
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3901257514953613
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.400562047958374
average cummulative reward vector is:  [0.06167579 0.06047037 0.0588776  0.06078061 0.07245806]
average cummulative reward is:  0.0628524854930469
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 301, loss: 55148.109375
[INFO] Global_t: 301, Episode_t: 1, Action: 172, Reward: 1.04, Epsilon: 0.84
[INFO] model update: t: 302, loss: 89089.65625
[INFO] Global_t: 302, Episode_t: 2, Action: 111, Reward: 2.42, Epsilon: 0.84
[INFO] model update: t: 303, loss: 119017.453125
[INFO] Global_t: 303, Episode_t: 3, Action: 73, Reward: 1.43, Epsilon: 0.84
[INFO] model update: t: 304, loss: 86820.5859375
[INFO] Global_t: 304, Episode_t: 4, Action: 183, Reward: 1.40, Epsilon: 0.84
[INFO] model update: t: 305, loss: 79710.15625
[INFO] Global_t: 305, Episode_t: 5, Action: 31, Reward: 2.84, Epsilon: 0.84
[INFO] model update: t: 306, loss: 50578.23046875
[INFO] Global_t: 306, Episode_t: 6, Action: 160, Reward: 2.33, Epsilon: 0.84
[INFO] Global step: 306, Cumulative rewards: 11.46612, Runtime (s): 263.47
--------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 307, loss: 67472.828125
[INFO] Global_t: 307, Episode_t: 1, Action: 152, Reward: 1.51, Epsilon: 0.84
[INFO] model update: t: 308, loss: 74743.375
[INFO] Global_t: 308, Episode_t: 2, Action: 149, Reward: 2.31, Epsilon: 0.84
[INFO] model update: t: 309, loss: 47352.015625
[INFO] Global_t: 309, Episode_t: 3, Action: 11, Reward: 4.77, Epsilon: 0.84
[INFO] model update: t: 310, loss: 59934.6875
[INFO] Global_t: 310, Episode_t: 4, Action: 127, Reward: 1.44, Epsilon: 0.84
[INFO] model update: t: 311, loss: 77871.625
[INFO] Global_t: 311, Episode_t: 5, Action: 80, Reward: 1.50, Epsilon: 0.84
[INFO] model update: t: 312, loss: 70938.9765625
[INFO] Global_t: 312, Episode_t: 6, Action: 56, Reward: 1.71, Epsilon: 0.84
[INFO] Global step: 312, Cumulative rewards: 13.22808, Runtime (s): 266.00
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2254655361175537
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4061076641082764
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2177774906158447
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.37007737159729
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.324310302734375
average cummulative reward vector is:  [0.06009079 0.06108403 0.06210055 0.0600229  0.0678121 ]
average cummulative reward is:  0.06222207153400093
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 313, loss: 54138.171875
[INFO] Global_t: 313, Episode_t: 1, Action: 5, Reward: 6.16, Epsilon: 0.84
[INFO] model update: t: 314, loss: 51476.578125
[INFO] Global_t: 314, Episode_t: 2, Action: 189, Reward: 1.25, Epsilon: 0.84
[INFO] model update: t: 315, loss: 72928.46875
[INFO] Global_t: 315, Episode_t: 3, Action: 50, Reward: 1.73, Epsilon: 0.84
[INFO] model update: t: 316, loss: 60658.9140625
[INFO] Global_t: 316, Episode_t: 4, Action: 184, Reward: 1.01, Epsilon: 0.84
[INFO] model update: t: 317, loss: 95580.0625
[INFO] Global_t: 317, Episode_t: 5, Action: 78, Reward: 1.97, Epsilon: 0.84
[INFO] model update: t: 318, loss: 110539.5703125
[INFO] Global_t: 318, Episode_t: 6, Action: 117, Reward: 0.89, Epsilon: 0.83
[INFO] Global step: 318, Cumulative rewards: 13.023839999999998, Runtime (s): 275.39
--------------------------------------
 
graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 319, loss: 42487.43359375
[INFO] Global_t: 319, Episode_t: 1, Action: 75, Reward: 2.63, Epsilon: 0.83
[INFO] model update: t: 320, loss: 41738.89453125
[INFO] Global_t: 320, Episode_t: 2, Action: 123, Reward: 1.55, Epsilon: 0.83
[INFO] model update: t: 321, loss: 57786.2890625
[INFO] Global_t: 321, Episode_t: 3, Action: 147, Reward: 2.13, Epsilon: 0.83
[INFO] model update: t: 322, loss: 155168.109375
[INFO] Global_t: 322, Episode_t: 4, Action: 87, Reward: 1.46, Epsilon: 0.83
[INFO] model update: t: 323, loss: 98739.875
[INFO] Global_t: 323, Episode_t: 5, Action: 61, Reward: 2.19, Epsilon: 0.83
[INFO] model update: t: 324, loss: 71104.296875
[INFO] Global_t: 324, Episode_t: 6, Action: 68, Reward: 2.18, Epsilon: 0.83
[INFO] Global step: 324, Cumulative rewards: 12.13368, Runtime (s): 276.83
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3135993480682373
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3254220485687256
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3372437953948975
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.290029525756836
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3308277130126953
average cummulative reward vector is:  [0.06589316 0.05620926 0.07048361 0.05530234 0.06715403]
average cummulative reward is:  0.06300847848360716
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 325, loss: 71838.4453125
[INFO] Global_t: 325, Episode_t: 1, Action: 153, Reward: 1.64, Epsilon: 0.83
[INFO] model update: t: 326, loss: 51495.046875
[INFO] Global_t: 326, Episode_t: 2, Action: 119, Reward: 1.21, Epsilon: 0.83
[INFO] model update: t: 327, loss: 44239.0390625
[INFO] Global_t: 327, Episode_t: 3, Action: 108, Reward: 1.33, Epsilon: 0.83
[INFO] model update: t: 328, loss: 68506.6328125
[INFO] Global_t: 328, Episode_t: 4, Action: 132, Reward: 2.26, Epsilon: 0.83
[INFO] model update: t: 329, loss: 70418.421875
[INFO] Global_t: 329, Episode_t: 5, Action: 121, Reward: 1.58, Epsilon: 0.83
[INFO] model update: t: 330, loss: 30619.96484375
[INFO] Global_t: 330, Episode_t: 6, Action: 80, Reward: 2.23, Epsilon: 0.83
[INFO] Global step: 330, Cumulative rewards: 10.259519999999998, Runtime (s): 284.97
--------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 331, loss: 38463.0390625
[INFO] Global_t: 331, Episode_t: 1, Action: 46, Reward: 2.39, Epsilon: 0.83
[INFO] model update: t: 332, loss: 94483.015625
[INFO] Global_t: 332, Episode_t: 2, Action: 45, Reward: 2.14, Epsilon: 0.83
[INFO] model update: t: 333, loss: 83615.0
[INFO] Global_t: 333, Episode_t: 3, Action: 36, Reward: 2.60, Epsilon: 0.83
[INFO] model update: t: 334, loss: 52242.828125
[INFO] Global_t: 334, Episode_t: 4, Action: 66, Reward: 1.65, Epsilon: 0.83
[INFO] model update: t: 335, loss: 73741.828125
[INFO] Global_t: 335, Episode_t: 5, Action: 60, Reward: 1.40, Epsilon: 0.83
[INFO] model update: t: 336, loss: 89945.7890625
[INFO] Global_t: 336, Episode_t: 6, Action: 176, Reward: 1.72, Epsilon: 0.83
[INFO] Global step: 336, Cumulative rewards: 11.902079999999998, Runtime (s): 286.82
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.1325559616088867
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3503036499023438
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2929496765136719
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2905828952789307
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4840004444122314
average cummulative reward vector is:  [0.05425763 0.05831667 0.06596366 0.05567407 0.07708548]
average cummulative reward is:  0.062259501747865674
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 337, loss: 67563.3125
[INFO] Global_t: 337, Episode_t: 1, Action: 51, Reward: 2.01, Epsilon: 0.83
[INFO] model update: t: 338, loss: 77291.7265625
[INFO] Global_t: 338, Episode_t: 2, Action: 39, Reward: 2.03, Epsilon: 0.82
[INFO] model update: t: 339, loss: 39469.2265625
[INFO] Global_t: 339, Episode_t: 3, Action: 21, Reward: 3.47, Epsilon: 0.82
[INFO] model update: t: 340, loss: 58008.8125
[INFO] Global_t: 340, Episode_t: 4, Action: 38, Reward: 2.52, Epsilon: 0.82
[INFO] model update: t: 341, loss: 36405.109375
[INFO] Global_t: 341, Episode_t: 5, Action: 28, Reward: 1.90, Epsilon: 0.82
[INFO] model update: t: 342, loss: 77328.671875
[INFO] Global_t: 342, Episode_t: 6, Action: 30, Reward: 1.83, Epsilon: 0.82
[INFO] Global step: 342, Cumulative rewards: 13.776959999999999, Runtime (s): 295.48
--------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 343, loss: 58006.6015625
[INFO] Global_t: 343, Episode_t: 1, Action: 15, Reward: 2.21, Epsilon: 0.82
[INFO] model update: t: 344, loss: 61189.90234375
[INFO] Global_t: 344, Episode_t: 2, Action: 86, Reward: 2.17, Epsilon: 0.82
[INFO] model update: t: 345, loss: 72471.0
[INFO] Global_t: 345, Episode_t: 3, Action: 6, Reward: 2.88, Epsilon: 0.82
[INFO] model update: t: 346, loss: 51660.28125
[INFO] Global_t: 346, Episode_t: 4, Action: 99, Reward: 1.46, Epsilon: 0.82
[INFO] model update: t: 347, loss: 81008.40625
[INFO] Global_t: 347, Episode_t: 5, Action: 74, Reward: 1.65, Epsilon: 0.82
[INFO] model update: t: 348, loss: 111860.9453125
[INFO] Global_t: 348, Episode_t: 6, Action: 193, Reward: 1.32, Epsilon: 0.82
[INFO] Global step: 348, Cumulative rewards: 11.687879999999998, Runtime (s): 297.40
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.367767095565796
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.280998706817627
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.26558518409729
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3708240985870361
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3760690689086914
average cummulative reward vector is:  [0.06788816 0.05228843 0.06359754 0.06026916 0.07104516]
average cummulative reward is:  0.0630176889946193
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 349, loss: 53848.0625
[INFO] Global_t: 349, Episode_t: 1, Action: 162, Reward: 1.67, Epsilon: 0.82
[INFO] model update: t: 350, loss: 83972.734375
[INFO] Global_t: 350, Episode_t: 2, Action: 136, Reward: 1.41, Epsilon: 0.82
[INFO] model update: t: 351, loss: 47105.49609375
[INFO] Global_t: 351, Episode_t: 3, Action: 111, Reward: 1.62, Epsilon: 0.82
[INFO] model update: t: 352, loss: 97714.8359375
[INFO] Global_t: 352, Episode_t: 4, Action: 46, Reward: 2.59, Epsilon: 0.82
[INFO] model update: t: 353, loss: 61284.0
[INFO] Global_t: 353, Episode_t: 5, Action: 213, Reward: 1.95, Epsilon: 0.82
[INFO] model update: t: 354, loss: 73535.484375
[INFO] Global_t: 354, Episode_t: 6, Action: 61, Reward: 2.06, Epsilon: 0.82
[INFO] Global step: 354, Cumulative rewards: 11.304, Runtime (s): 305.71
--------------------------------------
 
graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 355, loss: 78753.609375
[INFO] Global_t: 355, Episode_t: 1, Action: 127, Reward: 1.61, Epsilon: 0.82
[INFO] model update: t: 356, loss: 71249.34375
[INFO] Global_t: 356, Episode_t: 2, Action: 22, Reward: 2.33, Epsilon: 0.82
[INFO] model update: t: 357, loss: 47131.69921875
[INFO] Global_t: 357, Episode_t: 3, Action: 86, Reward: 1.38, Epsilon: 0.82
[INFO] model update: t: 358, loss: 60785.6171875
[INFO] Global_t: 358, Episode_t: 4, Action: 189, Reward: 1.14, Epsilon: 0.82
[INFO] model update: t: 359, loss: 50296.3125
[INFO] Global_t: 359, Episode_t: 5, Action: 41, Reward: 1.52, Epsilon: 0.81
[INFO] model update: t: 360, loss: 41931.86328125
[INFO] Global_t: 360, Episode_t: 6, Action: 146, Reward: 1.47, Epsilon: 0.81
[INFO] Global step: 360, Cumulative rewards: 9.444239999999999, Runtime (s): 307.52
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.314708948135376
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2338521480560303
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3711450099945068
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2633161544799805
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5214953422546387
average cummulative reward vector is:  [0.06526211 0.05042708 0.07128251 0.05193271 0.07732124]
average cummulative reward is:  0.0632451298194414
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 361, loss: 86066.578125
[INFO] Global_t: 361, Episode_t: 1, Action: 121, Reward: 1.47, Epsilon: 0.81
[INFO] model update: t: 362, loss: 62933.49609375
[INFO] Global_t: 362, Episode_t: 2, Action: 153, Reward: 1.47, Epsilon: 0.81
[INFO] model update: t: 363, loss: 41641.6484375
[INFO] Global_t: 363, Episode_t: 3, Action: 184, Reward: 1.85, Epsilon: 0.81
[INFO] model update: t: 364, loss: 57429.0234375
[INFO] Global_t: 364, Episode_t: 4, Action: 83, Reward: 1.58, Epsilon: 0.81
[INFO] model update: t: 365, loss: 58382.41796875
[INFO] Global_t: 365, Episode_t: 5, Action: 21, Reward: 2.00, Epsilon: 0.81
[INFO] model update: t: 366, loss: 35996.68359375
[INFO] Global_t: 366, Episode_t: 6, Action: 22, Reward: 2.15, Epsilon: 0.81
[INFO] Global step: 366, Cumulative rewards: 10.510919999999999, Runtime (s): 315.77
--------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 367, loss: 61937.109375
[INFO] Global_t: 367, Episode_t: 1, Action: 53, Reward: 2.76, Epsilon: 0.81
[INFO] model update: t: 368, loss: 70563.90625
[INFO] Global_t: 368, Episode_t: 2, Action: 199, Reward: 2.11, Epsilon: 0.81
[INFO] model update: t: 369, loss: 44938.96484375
[INFO] Global_t: 369, Episode_t: 3, Action: 112, Reward: 1.75, Epsilon: 0.81
[INFO] model update: t: 370, loss: 54153.00390625
[INFO] Global_t: 370, Episode_t: 4, Action: 30, Reward: 2.49, Epsilon: 0.81
[INFO] model update: t: 371, loss: 68127.09375
[INFO] Global_t: 371, Episode_t: 5, Action: 51, Reward: 2.17, Epsilon: 0.81
[INFO] model update: t: 372, loss: 59950.2109375
[INFO] Global_t: 372, Episode_t: 6, Action: 191, Reward: 2.29, Epsilon: 0.81
[INFO] Global step: 372, Cumulative rewards: 13.575240000000003, Runtime (s): 317.26
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3606295585632324
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3716795444488525
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.219001054763794
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3223810195922852
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2675116062164307
average cummulative reward vector is:  [0.06764211 0.05792083 0.06309781 0.05549042 0.06258978]
average cummulative reward is:  0.06134819166222514
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 373, loss: 49913.71484375
[INFO] Global_t: 373, Episode_t: 1, Action: 82, Reward: 2.07, Epsilon: 0.81
[INFO] model update: t: 374, loss: 52707.171875
[INFO] Global_t: 374, Episode_t: 2, Action: 163, Reward: 1.09, Epsilon: 0.81
[INFO] model update: t: 375, loss: 47083.5625
[INFO] Global_t: 375, Episode_t: 3, Action: 85, Reward: 1.88, Epsilon: 0.81
[INFO] model update: t: 376, loss: 79507.046875
[INFO] Global_t: 376, Episode_t: 4, Action: 12, Reward: 3.99, Epsilon: 0.81
[INFO] model update: t: 377, loss: 61182.0546875
[INFO] Global_t: 377, Episode_t: 5, Action: 124, Reward: 1.57, Epsilon: 0.81
[INFO] model update: t: 378, loss: 56575.9453125
[INFO] Global_t: 378, Episode_t: 6, Action: 145, Reward: 1.35, Epsilon: 0.81
[INFO] Global step: 378, Cumulative rewards: 11.94864, Runtime (s): 325.55
--------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 379, loss: 60680.7578125
[INFO] Global_t: 379, Episode_t: 1, Action: 63, Reward: 1.78, Epsilon: 0.80
[INFO] model update: t: 380, loss: 52395.09375
[INFO] Global_t: 380, Episode_t: 2, Action: 86, Reward: 2.08, Epsilon: 0.80
[INFO] model update: t: 381, loss: 39527.9921875
[INFO] Global_t: 381, Episode_t: 3, Action: 131, Reward: 1.32, Epsilon: 0.80
[INFO] model update: t: 382, loss: 64639.7890625
[INFO] Global_t: 382, Episode_t: 4, Action: 22, Reward: 2.12, Epsilon: 0.80
[INFO] model update: t: 383, loss: 39678.0546875
[INFO] Global_t: 383, Episode_t: 5, Action: 28, Reward: 1.69, Epsilon: 0.80
[INFO] model update: t: 384, loss: 49466.53125
[INFO] Global_t: 384, Episode_t: 6, Action: 113, Reward: 1.40, Epsilon: 0.80
[INFO] Global step: 384, Cumulative rewards: 10.388639999999999, Runtime (s): 327.11
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4249119758605957
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4255449771881104
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2194859981536865
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.1496355533599854
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2021288871765137
average cummulative reward vector is:  [0.07145737 0.06091505 0.06320656 0.0488285  0.06062554]
average cummulative reward is:  0.06100660288034078
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 385, loss: 73637.671875
[INFO] Global_t: 385, Episode_t: 1, Action: 38, Reward: 2.68, Epsilon: 0.80
[INFO] model update: t: 386, loss: 77235.484375
[INFO] Global_t: 386, Episode_t: 2, Action: 46, Reward: 2.18, Epsilon: 0.80
[INFO] model update: t: 387, loss: 60016.8984375
[INFO] Global_t: 387, Episode_t: 3, Action: 119, Reward: 2.19, Epsilon: 0.80
[INFO] model update: t: 388, loss: 63523.625
[INFO] Global_t: 388, Episode_t: 4, Action: 148, Reward: 1.17, Epsilon: 0.80
[INFO] model update: t: 389, loss: 45331.01171875
[INFO] Global_t: 389, Episode_t: 5, Action: 178, Reward: 1.71, Epsilon: 0.80
[INFO] model update: t: 390, loss: 71014.171875
[INFO] Global_t: 390, Episode_t: 6, Action: 152, Reward: 1.45, Epsilon: 0.80
[INFO] Global step: 390, Cumulative rewards: 11.37576, Runtime (s): 335.13
--------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 391, loss: 45197.14453125
[INFO] Global_t: 391, Episode_t: 1, Action: 136, Reward: 1.86, Epsilon: 0.80
[INFO] model update: t: 392, loss: 38024.296875
[INFO] Global_t: 392, Episode_t: 2, Action: 27, Reward: 3.14, Epsilon: 0.80
[INFO] model update: t: 393, loss: 44915.07421875
[INFO] Global_t: 393, Episode_t: 3, Action: 16, Reward: 3.25, Epsilon: 0.80
[INFO] model update: t: 394, loss: 66818.96875
[INFO] Global_t: 394, Episode_t: 4, Action: 137, Reward: 1.54, Epsilon: 0.80
[INFO] model update: t: 395, loss: 58824.953125
[INFO] Global_t: 395, Episode_t: 5, Action: 83, Reward: 1.34, Epsilon: 0.80
[INFO] model update: t: 396, loss: 70853.265625
[INFO] Global_t: 396, Episode_t: 6, Action: 23, Reward: 2.22, Epsilon: 0.80
[INFO] Global step: 396, Cumulative rewards: 13.350360000000002, Runtime (s): 337.68
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4692552089691162
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.452010154724121
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3614497184753418
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.24212646484375
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2858853340148926
average cummulative reward vector is:  [0.07407658 0.06203333 0.07277049 0.05392523 0.06588199]
average cummulative reward is:  0.06573752539523042
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 397, loss: 34019.2890625
[INFO] Global_t: 397, Episode_t: 1, Action: 80, Reward: 2.09, Epsilon: 0.80
[INFO] model update: t: 398, loss: 34896.31640625
[INFO] Global_t: 398, Episode_t: 2, Action: 163, Reward: 1.40, Epsilon: 0.80
[INFO] model update: t: 399, loss: 70567.2421875
[INFO] Global_t: 399, Episode_t: 3, Action: 144, Reward: 1.06, Epsilon: 0.79
[INFO] model update: t: 400, loss: 112933.5703125
[INFO] Global_t: 400, Episode_t: 4, Action: 33, Reward: 1.97, Epsilon: 0.79
[INFO] model update: t: 401, loss: 54494.43359375
[INFO] Global_t: 401, Episode_t: 5, Action: 117, Reward: 1.25, Epsilon: 0.79
[INFO] model update: t: 402, loss: 132353.25
[INFO] Global_t: 402, Episode_t: 6, Action: 197, Reward: 1.96, Epsilon: 0.79
[INFO] Global step: 402, Cumulative rewards: 9.73344, Runtime (s): 345.74
--------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 403, loss: 97519.6875
[INFO] Global_t: 403, Episode_t: 1, Action: 8, Reward: 5.68, Epsilon: 0.79
[INFO] model update: t: 404, loss: 62782.890625
[INFO] Global_t: 404, Episode_t: 2, Action: 66, Reward: 2.29, Epsilon: 0.79
[INFO] model update: t: 405, loss: 107716.90625
[INFO] Global_t: 405, Episode_t: 3, Action: 27, Reward: 2.12, Epsilon: 0.79
[INFO] model update: t: 406, loss: 100831.21875
[INFO] Global_t: 406, Episode_t: 4, Action: 131, Reward: 1.08, Epsilon: 0.79
[INFO] model update: t: 407, loss: 167790.15625
[INFO] Global_t: 407, Episode_t: 5, Action: 44, Reward: 1.81, Epsilon: 0.79
[INFO] model update: t: 408, loss: 45450.0625
[INFO] Global_t: 408, Episode_t: 6, Action: 86, Reward: 1.23, Epsilon: 0.79
[INFO] Global step: 408, Cumulative rewards: 14.22096, Runtime (s): 348.19
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3276233673095703
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3715989589691162
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2753849029541016
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2542240619659424
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3056209087371826
average cummulative reward vector is:  [0.06663105 0.05781343 0.06676339 0.05453668 0.06659892]
average cummulative reward is:  0.062468694701964075
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 409, loss: 100113.15625
[INFO] Global_t: 409, Episode_t: 1, Action: 114, Reward: 2.35, Epsilon: 0.79
[INFO] model update: t: 410, loss: 121106.6328125
[INFO] Global_t: 410, Episode_t: 2, Action: 140, Reward: 2.32, Epsilon: 0.79
[INFO] model update: t: 411, loss: 102787.84375
[INFO] Global_t: 411, Episode_t: 3, Action: 131, Reward: 2.50, Epsilon: 0.79
[INFO] model update: t: 412, loss: 89086.9453125
[INFO] Global_t: 412, Episode_t: 4, Action: 199, Reward: 1.71, Epsilon: 0.79
[INFO] model update: t: 413, loss: 47521.2734375
[INFO] Global_t: 413, Episode_t: 5, Action: 206, Reward: 1.52, Epsilon: 0.79
[INFO] model update: t: 414, loss: 193939.015625
[INFO] Global_t: 414, Episode_t: 6, Action: 110, Reward: 2.00, Epsilon: 0.79
[INFO] Global step: 414, Cumulative rewards: 12.394559999999998, Runtime (s): 356.35
--------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 415, loss: 83470.828125
[INFO] Global_t: 415, Episode_t: 1, Action: 65, Reward: 1.70, Epsilon: 0.79
[INFO] model update: t: 416, loss: 33911.41015625
[INFO] Global_t: 416, Episode_t: 2, Action: 50, Reward: 2.25, Epsilon: 0.79
[INFO] model update: t: 417, loss: 73212.6328125
[INFO] Global_t: 417, Episode_t: 3, Action: 110, Reward: 1.53, Epsilon: 0.79
[INFO] model update: t: 418, loss: 65365.9296875
[INFO] Global_t: 418, Episode_t: 4, Action: 97, Reward: 1.96, Epsilon: 0.79
[INFO] model update: t: 419, loss: 80037.171875
[INFO] Global_t: 419, Episode_t: 5, Action: 126, Reward: 2.12, Epsilon: 0.79
[INFO] model update: t: 420, loss: 38541.03125
[INFO] Global_t: 420, Episode_t: 6, Action: 170, Reward: 1.86, Epsilon: 0.78
[INFO] Global step: 420, Cumulative rewards: 11.423880000000002, Runtime (s): 357.94
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2758140563964844
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3394792079925537
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2451810836791992
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2950084209442139
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3233797550201416
average cummulative reward vector is:  [0.06009342 0.05634792 0.06513169 0.0568007  0.06775323]
average cummulative reward is:  0.061225391689880074
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 421, loss: 75441.859375
[INFO] Global_t: 421, Episode_t: 1, Action: 104, Reward: 2.32, Epsilon: 0.78
[INFO] model update: t: 422, loss: 112802.8125
[INFO] Global_t: 422, Episode_t: 2, Action: 42, Reward: 2.22, Epsilon: 0.78
[INFO] model update: t: 423, loss: 43276.25
[INFO] Global_t: 423, Episode_t: 3, Action: 155, Reward: 1.73, Epsilon: 0.78
[INFO] model update: t: 424, loss: 41996.421875
[INFO] Global_t: 424, Episode_t: 4, Action: 131, Reward: 2.19, Epsilon: 0.78
[INFO] model update: t: 425, loss: 37834.04296875
[INFO] Global_t: 425, Episode_t: 5, Action: 188, Reward: 1.80, Epsilon: 0.78
[INFO] model update: t: 426, loss: 79465.671875
[INFO] Global_t: 426, Episode_t: 6, Action: 70, Reward: 1.78, Epsilon: 0.78
[INFO] Global step: 426, Cumulative rewards: 12.03984, Runtime (s): 366.16
--------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 427, loss: 42494.19140625
[INFO] Global_t: 427, Episode_t: 1, Action: 182, Reward: 1.37, Epsilon: 0.78
[INFO] model update: t: 428, loss: 81626.71875
[INFO] Global_t: 428, Episode_t: 2, Action: 87, Reward: 1.25, Epsilon: 0.78
[INFO] model update: t: 429, loss: 87846.953125
[INFO] Global_t: 429, Episode_t: 3, Action: 18, Reward: 2.98, Epsilon: 0.78
[INFO] model update: t: 430, loss: 41245.40234375
[INFO] Global_t: 430, Episode_t: 4, Action: 157, Reward: 1.23, Epsilon: 0.78
[INFO] model update: t: 431, loss: 50539.66015625
[INFO] Global_t: 431, Episode_t: 5, Action: 28, Reward: 2.48, Epsilon: 0.78
[INFO] model update: t: 432, loss: 56936.1328125
[INFO] Global_t: 432, Episode_t: 6, Action: 125, Reward: 2.11, Epsilon: 0.78
[INFO] Global step: 432, Cumulative rewards: 11.407680000000001, Runtime (s): 367.82
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.383002519607544
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4005539417266846
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.139880895614624
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2920689582824707
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2073516845703125
average cummulative reward vector is:  [0.06892763 0.05933727 0.05840519 0.05653341 0.06016048]
average cummulative reward is:  0.0606727972880435
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 433, loss: 45939.21875
[INFO] Global_t: 433, Episode_t: 1, Action: 32, Reward: 1.99, Epsilon: 0.78
[INFO] model update: t: 434, loss: 26914.16015625
[INFO] Global_t: 434, Episode_t: 2, Action: 7, Reward: 5.21, Epsilon: 0.78
[INFO] model update: t: 435, loss: 20550.0390625
[INFO] Global_t: 435, Episode_t: 3, Action: 60, Reward: 1.43, Epsilon: 0.78
[INFO] model update: t: 436, loss: 38041.12890625
[INFO] Global_t: 436, Episode_t: 4, Action: 123, Reward: 1.42, Epsilon: 0.78
[INFO] model update: t: 437, loss: 70206.203125
[INFO] Global_t: 437, Episode_t: 5, Action: 20, Reward: 3.23, Epsilon: 0.78
[INFO] model update: t: 438, loss: 36948.34375
[INFO] Global_t: 438, Episode_t: 6, Action: 82, Reward: 1.36, Epsilon: 0.78
[INFO] Global step: 438, Cumulative rewards: 14.644919999999999, Runtime (s): 376.17
--------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 439, loss: 51358.5234375
[INFO] Global_t: 439, Episode_t: 1, Action: 194, Reward: 1.34, Epsilon: 0.78
[INFO] model update: t: 440, loss: 77286.546875
[INFO] Global_t: 440, Episode_t: 2, Action: 158, Reward: 2.12, Epsilon: 0.77
[INFO] model update: t: 441, loss: 48698.45703125
[INFO] Global_t: 441, Episode_t: 3, Action: 42, Reward: 2.07, Epsilon: 0.77
[INFO] model update: t: 442, loss: 62913.578125
[INFO] Global_t: 442, Episode_t: 4, Action: 48, Reward: 1.25, Epsilon: 0.77
[INFO] model update: t: 443, loss: 76032.9921875
[INFO] Global_t: 443, Episode_t: 5, Action: 100, Reward: 1.04, Epsilon: 0.77
[INFO] model update: t: 444, loss: 65530.96875
[INFO] Global_t: 444, Episode_t: 6, Action: 0, Reward: 3.85, Epsilon: 0.77
[INFO] Global step: 444, Cumulative rewards: 11.672639999999998, Runtime (s): 378.06
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3809733390808105
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4809927940368652
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3586781024932861
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.529137134552002
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4783527851104736
average cummulative reward vector is:  [0.06909895 0.06282894 0.07135929 0.06586028 0.0744914 ]
average cummulative reward is:  0.06872777007887734
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 445, loss: 53598.1171875
[INFO] Global_t: 445, Episode_t: 1, Action: 69, Reward: 2.35, Epsilon: 0.77
[INFO] model update: t: 446, loss: 72944.96875
[INFO] Global_t: 446, Episode_t: 2, Action: 102, Reward: 2.11, Epsilon: 0.77
[INFO] model update: t: 447, loss: 79212.78125
[INFO] Global_t: 447, Episode_t: 3, Action: 36, Reward: 3.16, Epsilon: 0.77
[INFO] model update: t: 448, loss: 92734.328125
[INFO] Global_t: 448, Episode_t: 4, Action: 150, Reward: 1.35, Epsilon: 0.77
[INFO] model update: t: 449, loss: 41692.3203125
[INFO] Global_t: 449, Episode_t: 5, Action: 195, Reward: 1.11, Epsilon: 0.77
[INFO] model update: t: 450, loss: 46593.171875
[INFO] Global_t: 450, Episode_t: 6, Action: 29, Reward: 1.71, Epsilon: 0.77
[INFO] Global step: 450, Cumulative rewards: 11.7996, Runtime (s): 387.45
--------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 451, loss: 33296.1328125
[INFO] Global_t: 451, Episode_t: 1, Action: 107, Reward: 2.76, Epsilon: 0.77
[INFO] model update: t: 452, loss: 51122.6171875
[INFO] Global_t: 452, Episode_t: 2, Action: 45, Reward: 1.99, Epsilon: 0.77
[INFO] model update: t: 453, loss: 54778.3125
[INFO] Global_t: 453, Episode_t: 3, Action: 118, Reward: 1.25, Epsilon: 0.77
[INFO] model update: t: 454, loss: 25664.40625
[INFO] Global_t: 454, Episode_t: 4, Action: 48, Reward: 2.29, Epsilon: 0.77
[INFO] model update: t: 455, loss: 35668.60546875
[INFO] Global_t: 455, Episode_t: 5, Action: 83, Reward: 2.12, Epsilon: 0.77
[INFO] model update: t: 456, loss: 35850.828125
[INFO] Global_t: 456, Episode_t: 6, Action: 21, Reward: 2.28, Epsilon: 0.77
[INFO] Global step: 456, Cumulative rewards: 12.698399999999998, Runtime (s): 389.61
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2902779579162598
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2506027221679688
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3423736095428467
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2488982677459717
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2941231727600098
average cummulative reward vector is:  [0.06222395 0.05375093 0.07102131 0.05440981 0.06581613]
average cummulative reward is:  0.06144442537722541
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 457, loss: 75785.1171875
[INFO] Global_t: 457, Episode_t: 1, Action: 134, Reward: 1.27, Epsilon: 0.77
[INFO] model update: t: 458, loss: 73479.796875
[INFO] Global_t: 458, Episode_t: 2, Action: 153, Reward: 1.21, Epsilon: 0.77
[INFO] model update: t: 459, loss: 36182.15625
[INFO] Global_t: 459, Episode_t: 3, Action: 41, Reward: 3.03, Epsilon: 0.77
[INFO] model update: t: 460, loss: 83372.34375
[INFO] Global_t: 460, Episode_t: 4, Action: 104, Reward: 1.94, Epsilon: 0.77
[INFO] model update: t: 461, loss: 91377.921875
[INFO] Global_t: 461, Episode_t: 5, Action: 58, Reward: 2.23, Epsilon: 0.76
[INFO] model update: t: 462, loss: 42865.40625
[INFO] Global_t: 462, Episode_t: 6, Action: 146, Reward: 1.39, Epsilon: 0.76
[INFO] Global step: 462, Cumulative rewards: 11.075040000000001, Runtime (s): 397.95
--------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 463, loss: 93420.9765625
[INFO] Global_t: 463, Episode_t: 1, Action: 193, Reward: 1.10, Epsilon: 0.76
[INFO] model update: t: 464, loss: 47883.5078125
[INFO] Global_t: 464, Episode_t: 2, Action: 108, Reward: 2.22, Epsilon: 0.76
[INFO] model update: t: 465, loss: 99363.734375
[INFO] Global_t: 465, Episode_t: 3, Action: 60, Reward: 2.08, Epsilon: 0.76
[INFO] model update: t: 466, loss: 54475.83203125
[INFO] Global_t: 466, Episode_t: 4, Action: 41, Reward: 2.16, Epsilon: 0.76
[INFO] model update: t: 467, loss: 80341.46875
[INFO] Global_t: 467, Episode_t: 5, Action: 143, Reward: 1.53, Epsilon: 0.76
[INFO] model update: t: 468, loss: 62367.2265625
[INFO] Global_t: 468, Episode_t: 6, Action: 174, Reward: 1.06, Epsilon: 0.76
[INFO] Global step: 468, Cumulative rewards: 10.13772, Runtime (s): 399.81
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.276543140411377
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2953696250915527
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2306206226348877
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3412237167358398
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.307204008102417
average cummulative reward vector is:  [0.05997553 0.05567731 0.06350847 0.05618762 0.06410914]
average cummulative reward is:  0.059891613536667124
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 469, loss: 42239.3359375
[INFO] Global_t: 469, Episode_t: 1, Action: 64, Reward: 1.92, Epsilon: 0.76
[INFO] model update: t: 470, loss: 37333.1796875
[INFO] Global_t: 470, Episode_t: 2, Action: 3, Reward: 4.43, Epsilon: 0.76
[INFO] model update: t: 471, loss: 88861.71875
[INFO] Global_t: 471, Episode_t: 3, Action: 87, Reward: 1.32, Epsilon: 0.76
[INFO] model update: t: 472, loss: 36829.78515625
[INFO] Global_t: 472, Episode_t: 4, Action: 117, Reward: 0.86, Epsilon: 0.76
[INFO] model update: t: 473, loss: 58131.31640625
[INFO] Global_t: 473, Episode_t: 5, Action: 102, Reward: 1.33, Epsilon: 0.76
[INFO] model update: t: 474, loss: 69647.21875
[INFO] Global_t: 474, Episode_t: 6, Action: 148, Reward: 1.11, Epsilon: 0.76
[INFO] Global step: 474, Cumulative rewards: 10.979519999999997, Runtime (s): 407.96
--------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 475, loss: 65013.015625
[INFO] Global_t: 475, Episode_t: 1, Action: 10, Reward: 3.41, Epsilon: 0.76
[INFO] model update: t: 476, loss: 70490.8125
[INFO] Global_t: 476, Episode_t: 2, Action: 195, Reward: 1.27, Epsilon: 0.76
[INFO] model update: t: 477, loss: 61438.45703125
[INFO] Global_t: 477, Episode_t: 3, Action: 68, Reward: 1.79, Epsilon: 0.76
[INFO] model update: t: 478, loss: 47954.4140625
[INFO] Global_t: 478, Episode_t: 4, Action: 21, Reward: 2.77, Epsilon: 0.76
[INFO] model update: t: 479, loss: 57911.125
[INFO] Global_t: 479, Episode_t: 5, Action: 18, Reward: 1.34, Epsilon: 0.76
[INFO] model update: t: 480, loss: 32173.11328125
[INFO] Global_t: 480, Episode_t: 6, Action: 180, Reward: 0.90, Epsilon: 0.76
[INFO] Global step: 480, Cumulative rewards: 11.49192, Runtime (s): 410.06
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.371673822402954
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.379406213760376
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2435119152069092
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3215396404266357
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.343930959701538
average cummulative reward vector is:  [0.06654684 0.05933519 0.06459727 0.05759556 0.06820242]
average cummulative reward is:  0.0632554550305027
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 481, loss: 44678.546875
[INFO] Global_t: 481, Episode_t: 1, Action: 136, Reward: 1.97, Epsilon: 0.75
[INFO] model update: t: 482, loss: 55770.98828125
[INFO] Global_t: 482, Episode_t: 2, Action: 111, Reward: 1.54, Epsilon: 0.75
[INFO] model update: t: 483, loss: 76823.4765625
[INFO] Global_t: 483, Episode_t: 3, Action: 196, Reward: 1.23, Epsilon: 0.75
[INFO] model update: t: 484, loss: 39373.859375
[INFO] Global_t: 484, Episode_t: 4, Action: 216, Reward: 1.58, Epsilon: 0.75
[INFO] model update: t: 485, loss: 56724.296875
[INFO] Global_t: 485, Episode_t: 5, Action: 67, Reward: 2.19, Epsilon: 0.75
[INFO] model update: t: 486, loss: 84391.046875
[INFO] Global_t: 486, Episode_t: 6, Action: 19, Reward: 3.72, Epsilon: 0.75
[INFO] Global step: 486, Cumulative rewards: 12.231839999999998, Runtime (s): 418.50
--------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 487, loss: 63144.5703125
[INFO] Global_t: 487, Episode_t: 1, Action: 160, Reward: 1.88, Epsilon: 0.75
[INFO] model update: t: 488, loss: 69038.796875
[INFO] Global_t: 488, Episode_t: 2, Action: 171, Reward: 1.07, Epsilon: 0.75
[INFO] model update: t: 489, loss: 43313.203125
[INFO] Global_t: 489, Episode_t: 3, Action: 93, Reward: 1.79, Epsilon: 0.75
[INFO] model update: t: 490, loss: 29239.1171875
[INFO] Global_t: 490, Episode_t: 4, Action: 144, Reward: 1.05, Epsilon: 0.75
[INFO] model update: t: 491, loss: 55658.171875
[INFO] Global_t: 491, Episode_t: 5, Action: 107, Reward: 1.27, Epsilon: 0.75
[INFO] model update: t: 492, loss: 63611.078125
[INFO] Global_t: 492, Episode_t: 6, Action: 140, Reward: 1.69, Epsilon: 0.75
[INFO] Global step: 492, Cumulative rewards: 8.7564, Runtime (s): 420.07
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3403944969177246
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4811549186706543
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1907374858856201
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3048017024993896
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4222257137298584
average cummulative reward vector is:  [0.06488921 0.06423843 0.06153798 0.05573061 0.06992016]
average cummulative reward is:  0.06326327667225526
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
[INFO] model update: t: 493, loss: 40334.2109375
[INFO] Global_t: 493, Episode_t: 1, Action: 3, Reward: 4.66, Epsilon: 0.75
[INFO] model update: t: 494, loss: 34188.9375
[INFO] Global_t: 494, Episode_t: 2, Action: 33, Reward: 2.12, Epsilon: 0.75
[INFO] model update: t: 495, loss: 46905.46484375
[INFO] Global_t: 495, Episode_t: 3, Action: 61, Reward: 1.51, Epsilon: 0.75
[INFO] model update: t: 496, loss: 45294.546875
[INFO] Global_t: 496, Episode_t: 4, Action: 161, Reward: 1.87, Epsilon: 0.75
[INFO] model update: t: 497, loss: 53635.42578125
[INFO] Global_t: 497, Episode_t: 5, Action: 107, Reward: 1.51, Epsilon: 0.75
[INFO] model update: t: 498, loss: 46792.12890625
[INFO] Global_t: 498, Episode_t: 6, Action: 34, Reward: 2.76, Epsilon: 0.75
[INFO] Global step: 498, Cumulative rewards: 14.422679999999998, Runtime (s): 428.65
--------------------------------------
 
graph: 83, nodes: 198, edges: 584
[INFO] model update: t: 499, loss: 76330.6171875
[INFO] Global_t: 499, Episode_t: 1, Action: 103, Reward: 1.84, Epsilon: 0.75
[INFO] model update: t: 500, loss: 39721.67578125
[INFO] Global_t: 500, Episode_t: 2, Action: 133, Reward: 1.49, Epsilon: 0.75
[INFO] model update: t: 501, loss: 62659.984375
[INFO] Global_t: 501, Episode_t: 3, Action: 181, Reward: 2.12, Epsilon: 0.74
[INFO] model update: t: 502, loss: 83705.6953125
[INFO] Global_t: 502, Episode_t: 4, Action: 68, Reward: 1.63, Epsilon: 0.74
[INFO] model update: t: 503, loss: 44978.953125
[INFO] Global_t: 503, Episode_t: 5, Action: 113, Reward: 1.54, Epsilon: 0.74
[INFO] model update: t: 504, loss: 45208.33203125
[INFO] Global_t: 504, Episode_t: 6, Action: 131, Reward: 1.27, Epsilon: 0.74
[INFO] Global step: 504, Cumulative rewards: 9.880799999999999, Runtime (s): 430.07
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2938082218170166
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.455711841583252
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2362053394317627
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.392411470413208
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3989765644073486
average cummulative reward vector is:  [0.06184289 0.06281875 0.06430383 0.06192407 0.07145618]
average cummulative reward is:  0.06446914361794276
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 84, nodes: 205, edges: 606
[INFO] model update: t: 505, loss: 41980.05078125
[INFO] Global_t: 505, Episode_t: 1, Action: 108, Reward: 1.61, Epsilon: 0.74
[INFO] model update: t: 506, loss: 44075.48828125
[INFO] Global_t: 506, Episode_t: 2, Action: 101, Reward: 2.01, Epsilon: 0.74
[INFO] model update: t: 507, loss: 101766.2265625
[INFO] Global_t: 507, Episode_t: 3, Action: 166, Reward: 2.09, Epsilon: 0.74
[INFO] model update: t: 508, loss: 28842.26171875
[INFO] Global_t: 508, Episode_t: 4, Action: 62, Reward: 1.97, Epsilon: 0.74
[INFO] model update: t: 509, loss: 60261.15625
[INFO] Global_t: 509, Episode_t: 5, Action: 92, Reward: 1.13, Epsilon: 0.74
[INFO] model update: t: 510, loss: 83781.234375
[INFO] Global_t: 510, Episode_t: 6, Action: 55, Reward: 1.21, Epsilon: 0.74
[INFO] Global step: 510, Cumulative rewards: 10.039200000000001, Runtime (s): 438.79
--------------------------------------
 
graph: 85, nodes: 212, edges: 627
[INFO] model update: t: 511, loss: 74394.875
[INFO] Global_t: 511, Episode_t: 1, Action: 3, Reward: 6.72, Epsilon: 0.74
[INFO] model update: t: 512, loss: 62513.9921875
[INFO] Global_t: 512, Episode_t: 2, Action: 29, Reward: 2.04, Epsilon: 0.74
[INFO] model update: t: 513, loss: 29372.30078125
[INFO] Global_t: 513, Episode_t: 3, Action: 48, Reward: 2.49, Epsilon: 0.74
[INFO] model update: t: 514, loss: 38838.16015625
[INFO] Global_t: 514, Episode_t: 4, Action: 72, Reward: 1.58, Epsilon: 0.74
[INFO] model update: t: 515, loss: 41160.38671875
[INFO] Global_t: 515, Episode_t: 5, Action: 79, Reward: 1.97, Epsilon: 0.74
[INFO] model update: t: 516, loss: 45173.9609375
[INFO] Global_t: 516, Episode_t: 6, Action: 26, Reward: 2.09, Epsilon: 0.74
[INFO] Global step: 516, Cumulative rewards: 16.883519999999997, Runtime (s): 441.19
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3629140853881836
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4016196727752686
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2500648498535156
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3775525093078613
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3749241828918457
average cummulative reward vector is:  [0.06289289 0.06033218 0.06429426 0.06022103 0.07012043]
average cummulative reward is:  0.06357215822055201
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 86, nodes: 200, edges: 591
[INFO] model update: t: 517, loss: 36864.640625
[INFO] Global_t: 517, Episode_t: 1, Action: 186, Reward: 1.53, Epsilon: 0.74
[INFO] model update: t: 518, loss: 31395.751953125
[INFO] Global_t: 518, Episode_t: 2, Action: 177, Reward: 2.19, Epsilon: 0.74
[INFO] model update: t: 519, loss: 26431.81640625
[INFO] Global_t: 519, Episode_t: 3, Action: 12, Reward: 4.02, Epsilon: 0.74
[INFO] model update: t: 520, loss: 33033.65625
[INFO] Global_t: 520, Episode_t: 4, Action: 76, Reward: 1.31, Epsilon: 0.74
[INFO] model update: t: 521, loss: 20848.970703125
[INFO] Global_t: 521, Episode_t: 5, Action: 194, Reward: 1.51, Epsilon: 0.74
[INFO] model update: t: 522, loss: 74611.1484375
[INFO] Global_t: 522, Episode_t: 6, Action: 6, Reward: 3.96, Epsilon: 0.73
[INFO] Global step: 522, Cumulative rewards: 14.516639999999999, Runtime (s): 450.39
--------------------------------------
 
graph: 87, nodes: 218, edges: 645
[INFO] model update: t: 523, loss: 57774.92578125
[INFO] Global_t: 523, Episode_t: 1, Action: 194, Reward: 1.26, Epsilon: 0.73
[INFO] model update: t: 524, loss: 45028.53125
[INFO] Global_t: 524, Episode_t: 2, Action: 1, Reward: 3.79, Epsilon: 0.73
[INFO] model update: t: 525, loss: 56238.140625
[INFO] Global_t: 525, Episode_t: 3, Action: 190, Reward: 1.04, Epsilon: 0.73
[INFO] model update: t: 526, loss: 51009.71875
[INFO] Global_t: 526, Episode_t: 4, Action: 17, Reward: 3.32, Epsilon: 0.73
[INFO] model update: t: 527, loss: 49010.796875
[INFO] Global_t: 527, Episode_t: 5, Action: 109, Reward: 1.97, Epsilon: 0.73
[INFO] model update: t: 528, loss: 52830.58203125
[INFO] Global_t: 528, Episode_t: 6, Action: 97, Reward: 1.68, Epsilon: 0.73
[INFO] Global step: 528, Cumulative rewards: 13.059719999999999, Runtime (s): 452.07
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4984238147735596
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4389965534210205
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2316648960113525
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4058349132537842
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.334301233291626
average cummulative reward vector is:  [0.07477868 0.06116667 0.0629418  0.06099159 0.06803817]
average cummulative reward is:  0.0655833829967878
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 88, nodes: 204, edges: 603
[INFO] model update: t: 529, loss: 46495.328125
[INFO] Global_t: 529, Episode_t: 1, Action: 165, Reward: 1.70, Epsilon: 0.73
[INFO] model update: t: 530, loss: 77927.59375
[INFO] Global_t: 530, Episode_t: 2, Action: 200, Reward: 1.24, Epsilon: 0.73
[INFO] model update: t: 531, loss: 63156.84765625
[INFO] Global_t: 531, Episode_t: 3, Action: 44, Reward: 2.06, Epsilon: 0.73
[INFO] model update: t: 532, loss: 65011.3203125
[INFO] Global_t: 532, Episode_t: 4, Action: 38, Reward: 1.79, Epsilon: 0.73
[INFO] model update: t: 533, loss: 53342.53125
[INFO] Global_t: 533, Episode_t: 5, Action: 201, Reward: 1.47, Epsilon: 0.73
[INFO] model update: t: 534, loss: 62865.11328125
[INFO] Global_t: 534, Episode_t: 6, Action: 8, Reward: 2.97, Epsilon: 0.73
[INFO] Global step: 534, Cumulative rewards: 11.23776, Runtime (s): 460.70
--------------------------------------
 
graph: 89, nodes: 199, edges: 588
[INFO] model update: t: 535, loss: 28810.146484375
[INFO] Global_t: 535, Episode_t: 1, Action: 44, Reward: 2.45, Epsilon: 0.73
[INFO] model update: t: 536, loss: 43482.6953125
[INFO] Global_t: 536, Episode_t: 2, Action: 140, Reward: 1.96, Epsilon: 0.73
[INFO] model update: t: 537, loss: 66865.1796875
[INFO] Global_t: 537, Episode_t: 3, Action: 16, Reward: 2.03, Epsilon: 0.73
[INFO] model update: t: 538, loss: 51978.7109375
[INFO] Global_t: 538, Episode_t: 4, Action: 107, Reward: 1.86, Epsilon: 0.73
[INFO] model update: t: 539, loss: 68711.5
[INFO] Global_t: 539, Episode_t: 5, Action: 40, Reward: 1.96, Epsilon: 0.73
[INFO] model update: t: 540, loss: 45180.359375
[INFO] Global_t: 540, Episode_t: 6, Action: 170, Reward: 1.39, Epsilon: 0.73
[INFO] Global step: 540, Cumulative rewards: 11.6502, Runtime (s): 462.24
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4271504878997803
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4413347244262695
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2728962898254395
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3959577083587646
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.474017858505249
average cummulative reward vector is:  [0.07182474 0.06220185 0.06602432 0.0610271  0.0759672 ]
average cummulative reward is:  0.06740904254773228
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 90, nodes: 207, edges: 612
[INFO] model update: t: 541, loss: 49500.60546875
[INFO] Global_t: 541, Episode_t: 1, Action: 141, Reward: 1.82, Epsilon: 0.73
[INFO] model update: t: 542, loss: 26171.8671875
[INFO] Global_t: 542, Episode_t: 2, Action: 54, Reward: 1.92, Epsilon: 0.72
[INFO] model update: t: 543, loss: 80425.0390625
[INFO] Global_t: 543, Episode_t: 3, Action: 181, Reward: 1.41, Epsilon: 0.72
[INFO] model update: t: 544, loss: 66217.8984375
[INFO] Global_t: 544, Episode_t: 4, Action: 83, Reward: 2.00, Epsilon: 0.72
[INFO] model update: t: 545, loss: 25778.359375
[INFO] Global_t: 545, Episode_t: 5, Action: 119, Reward: 1.39, Epsilon: 0.72
[INFO] model update: t: 546, loss: 23552.1640625
[INFO] Global_t: 546, Episode_t: 6, Action: 22, Reward: 2.90, Epsilon: 0.72
[INFO] Global step: 546, Cumulative rewards: 11.436720000000001, Runtime (s): 470.84
--------------------------------------
 
graph: 91, nodes: 198, edges: 585
[INFO] model update: t: 547, loss: 42812.65625
[INFO] Global_t: 547, Episode_t: 1, Action: 94, Reward: 2.03, Epsilon: 0.72
[INFO] model update: t: 548, loss: 37528.5859375
[INFO] Global_t: 548, Episode_t: 2, Action: 102, Reward: 1.21, Epsilon: 0.72
[INFO] model update: t: 549, loss: 45675.453125
[INFO] Global_t: 549, Episode_t: 3, Action: 42, Reward: 2.62, Epsilon: 0.72
[INFO] model update: t: 550, loss: 39386.81640625
[INFO] Global_t: 550, Episode_t: 4, Action: 158, Reward: 2.19, Epsilon: 0.72
[INFO] model update: t: 551, loss: 62544.46875
[INFO] Global_t: 551, Episode_t: 5, Action: 53, Reward: 1.93, Epsilon: 0.72
[INFO] model update: t: 552, loss: 54486.0
[INFO] Global_t: 552, Episode_t: 6, Action: 57, Reward: 2.06, Epsilon: 0.72
[INFO] Global step: 552, Cumulative rewards: 12.054479999999998, Runtime (s): 472.35
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3304765224456787
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3622734546661377
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.261047601699829
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2603049278259277
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2751710414886475
average cummulative reward vector is:  [0.06144763 0.0561412  0.06486038 0.05423248 0.06377715]
average cummulative reward is:  0.060091768993892146
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 92, nodes: 183, edges: 539
[INFO] model update: t: 553, loss: 48305.359375
[INFO] Global_t: 553, Episode_t: 1, Action: 36, Reward: 2.65, Epsilon: 0.72
[INFO] model update: t: 554, loss: 38865.6328125
[INFO] Global_t: 554, Episode_t: 2, Action: 120, Reward: 2.00, Epsilon: 0.72
[INFO] model update: t: 555, loss: 39683.12109375
[INFO] Global_t: 555, Episode_t: 3, Action: 158, Reward: 1.63, Epsilon: 0.72
[INFO] model update: t: 556, loss: 48463.5703125
[INFO] Global_t: 556, Episode_t: 4, Action: 74, Reward: 1.64, Epsilon: 0.72
[INFO] model update: t: 557, loss: 31442.203125
[INFO] Global_t: 557, Episode_t: 5, Action: 58, Reward: 2.13, Epsilon: 0.72
[INFO] model update: t: 558, loss: 32790.86328125
[INFO] Global_t: 558, Episode_t: 6, Action: 5, Reward: 3.84, Epsilon: 0.72
[INFO] Global step: 558, Cumulative rewards: 13.88964, Runtime (s): 480.84
--------------------------------------
 
graph: 93, nodes: 217, edges: 642
[INFO] model update: t: 559, loss: 57576.40625
[INFO] Global_t: 559, Episode_t: 1, Action: 79, Reward: 2.11, Epsilon: 0.72
[INFO] model update: t: 560, loss: 45792.41015625
[INFO] Global_t: 560, Episode_t: 2, Action: 11, Reward: 3.44, Epsilon: 0.72
[INFO] model update: t: 561, loss: 38474.90625
[INFO] Global_t: 561, Episode_t: 3, Action: 171, Reward: 1.42, Epsilon: 0.72
[INFO] model update: t: 562, loss: 19562.513671875
[INFO] Global_t: 562, Episode_t: 4, Action: 170, Reward: 1.76, Epsilon: 0.72
[INFO] model update: t: 563, loss: 61279.4140625
[INFO] Global_t: 563, Episode_t: 5, Action: 23, Reward: 1.97, Epsilon: 0.71
[INFO] model update: t: 564, loss: 41807.28515625
[INFO] Global_t: 564, Episode_t: 6, Action: 194, Reward: 1.04, Epsilon: 0.71
[INFO] Global step: 564, Cumulative rewards: 11.735159999999999, Runtime (s): 482.83
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4036815166473389
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2527954578399658
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1718473434448242
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3168487548828125
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4080519676208496
average cummulative reward vector is:  [0.07040211 0.05336435 0.05966749 0.05760304 0.07238387]
average cummulative reward is:  0.06268417036094541
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 94, nodes: 198, edges: 585
[INFO] model update: t: 565, loss: 74076.546875
[INFO] Global_t: 565, Episode_t: 1, Action: 109, Reward: 2.10, Epsilon: 0.71
[INFO] model update: t: 566, loss: 52363.38671875
[INFO] Global_t: 566, Episode_t: 2, Action: 150, Reward: 2.12, Epsilon: 0.71
[INFO] model update: t: 567, loss: 52296.734375
[INFO] Global_t: 567, Episode_t: 3, Action: 5, Reward: 4.43, Epsilon: 0.71
[INFO] model update: t: 568, loss: 51448.81640625
[INFO] Global_t: 568, Episode_t: 4, Action: 20, Reward: 1.75, Epsilon: 0.71
[INFO] model update: t: 569, loss: 25753.85546875
[INFO] Global_t: 569, Episode_t: 5, Action: 128, Reward: 1.89, Epsilon: 0.71
[INFO] model update: t: 570, loss: 41012.9609375
[INFO] Global_t: 570, Episode_t: 6, Action: 27, Reward: 2.52, Epsilon: 0.71
[INFO] Global step: 570, Cumulative rewards: 14.802720000000003, Runtime (s): 491.10
--------------------------------------
 
graph: 95, nodes: 202, edges: 597
[INFO] model update: t: 571, loss: 47419.5703125
[INFO] Global_t: 571, Episode_t: 1, Action: 16, Reward: 3.47, Epsilon: 0.71
[INFO] model update: t: 572, loss: 47735.07421875
[INFO] Global_t: 572, Episode_t: 2, Action: 75, Reward: 2.33, Epsilon: 0.71
[INFO] model update: t: 573, loss: 36008.09375
[INFO] Global_t: 573, Episode_t: 3, Action: 83, Reward: 1.87, Epsilon: 0.71
[INFO] model update: t: 574, loss: 26833.771484375
[INFO] Global_t: 574, Episode_t: 4, Action: 193, Reward: 2.43, Epsilon: 0.71
[INFO] model update: t: 575, loss: 35698.91015625
[INFO] Global_t: 575, Episode_t: 5, Action: 65, Reward: 2.16, Epsilon: 0.71
[INFO] model update: t: 576, loss: 43983.8984375
[INFO] Global_t: 576, Episode_t: 6, Action: 82, Reward: 1.81, Epsilon: 0.71
[INFO] Global step: 576, Cumulative rewards: 14.0718, Runtime (s): 493.00
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2953126430511475
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2043218612670898
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3025622367858887
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.233144998550415
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3573377132415771
average cummulative reward vector is:  [0.06347816 0.05048634 0.06826694 0.05320047 0.06941075]
average cummulative reward is:  0.0609685320711863
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 96, nodes: 200, edges: 591
[INFO] model update: t: 577, loss: 61792.2890625
[INFO] Global_t: 577, Episode_t: 1, Action: 177, Reward: 2.02, Epsilon: 0.71
[INFO] model update: t: 578, loss: 33079.3828125
[INFO] Global_t: 578, Episode_t: 2, Action: 100, Reward: 1.66, Epsilon: 0.71
[INFO] model update: t: 579, loss: 46462.4921875
[INFO] Global_t: 579, Episode_t: 3, Action: 175, Reward: 1.65, Epsilon: 0.71
[INFO] model update: t: 580, loss: 37850.203125
[INFO] Global_t: 580, Episode_t: 4, Action: 89, Reward: 2.03, Epsilon: 0.71
[INFO] model update: t: 581, loss: 42222.08984375
[INFO] Global_t: 581, Episode_t: 5, Action: 135, Reward: 1.29, Epsilon: 0.71
[INFO] model update: t: 582, loss: 45299.43359375
[INFO] Global_t: 582, Episode_t: 6, Action: 183, Reward: 2.17, Epsilon: 0.71
[INFO] Global step: 582, Cumulative rewards: 10.81164, Runtime (s): 500.71
--------------------------------------
 
graph: 97, nodes: 206, edges: 609
[INFO] model update: t: 583, loss: 25428.52734375
[INFO] Global_t: 583, Episode_t: 1, Action: 138, Reward: 1.32, Epsilon: 0.70
[INFO] model update: t: 584, loss: 27880.06640625
[INFO] Global_t: 584, Episode_t: 2, Action: 166, Reward: 2.27, Epsilon: 0.70
[INFO] model update: t: 585, loss: 59188.78125
[INFO] Global_t: 585, Episode_t: 3, Action: 20, Reward: 3.12, Epsilon: 0.70
[INFO] model update: t: 586, loss: 48853.6015625
[INFO] Global_t: 586, Episode_t: 4, Action: 12, Reward: 1.85, Epsilon: 0.70
[INFO] model update: t: 587, loss: 54812.7109375
[INFO] Global_t: 587, Episode_t: 5, Action: 110, Reward: 1.53, Epsilon: 0.70
[INFO] model update: t: 588, loss: 40825.54296875
[INFO] Global_t: 588, Episode_t: 6, Action: 139, Reward: 1.13, Epsilon: 0.70
[INFO] Global step: 588, Cumulative rewards: 11.22228, Runtime (s): 502.53
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3788466453552246
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.1977307796478271
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.213653564453125
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4488890171051025
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.43528413772583
average cummulative reward vector is:  [0.06863184 0.05050069 0.05684727 0.06143037 0.0743121 ]
average cummulative reward is:  0.06234445498304795
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 98, nodes: 206, edges: 607
[INFO] model update: t: 589, loss: 57395.265625
[INFO] Global_t: 589, Episode_t: 1, Action: 180, Reward: 1.04, Epsilon: 0.70
[INFO] model update: t: 590, loss: 54367.0625
[INFO] Global_t: 590, Episode_t: 2, Action: 169, Reward: 1.34, Epsilon: 0.70
[INFO] model update: t: 591, loss: 30241.970703125
[INFO] Global_t: 591, Episode_t: 3, Action: 74, Reward: 2.38, Epsilon: 0.70
[INFO] model update: t: 592, loss: 28126.646484375
[INFO] Global_t: 592, Episode_t: 4, Action: 106, Reward: 1.72, Epsilon: 0.70
[INFO] model update: t: 593, loss: 54439.421875
[INFO] Global_t: 593, Episode_t: 5, Action: 24, Reward: 2.34, Epsilon: 0.70
[INFO] model update: t: 594, loss: 27988.935546875
[INFO] Global_t: 594, Episode_t: 6, Action: 43, Reward: 1.72, Epsilon: 0.70
[INFO] Global step: 594, Cumulative rewards: 10.533360000000002, Runtime (s): 510.84
--------------------------------------
 
graph: 99, nodes: 181, edges: 533
[INFO] model update: t: 595, loss: 38825.2734375
[INFO] Global_t: 595, Episode_t: 1, Action: 98, Reward: 2.32, Epsilon: 0.70
[INFO] model update: t: 596, loss: 42681.5703125
[INFO] Global_t: 596, Episode_t: 2, Action: 42, Reward: 2.40, Epsilon: 0.70
[INFO] model update: t: 597, loss: 43874.171875
[INFO] Global_t: 597, Episode_t: 3, Action: 158, Reward: 1.59, Epsilon: 0.70
[INFO] model update: t: 598, loss: 43150.2265625
[INFO] Global_t: 598, Episode_t: 4, Action: 150, Reward: 2.05, Epsilon: 0.70
[INFO] model update: t: 599, loss: 22582.021484375
[INFO] Global_t: 599, Episode_t: 5, Action: 125, Reward: 1.61, Epsilon: 0.70
[INFO] model update: t: 600, loss: 38154.28125
[INFO] Global_t: 600, Episode_t: 6, Action: 45, Reward: 2.30, Epsilon: 0.70
[INFO] Global step: 600, Cumulative rewards: 12.27612, Runtime (s): 512.39
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.414524793624878
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.377575397491455
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1507456302642822
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3392508029937744
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2862961292266846
average cummulative reward vector is:  [0.06866711 0.05953796 0.05838333 0.05821659 0.0653336 ]
average cummulative reward is:  0.06202771849900771
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 100, nodes: 188, edges: 555
[INFO] model update: t: 601, loss: 29757.630859375
[INFO] Global_t: 601, Episode_t: 1, Action: 171, Reward: 2.35, Epsilon: 0.70
[INFO] model update: t: 602, loss: 36433.76171875
[INFO] Global_t: 602, Episode_t: 2, Action: 135, Reward: 2.37, Epsilon: 0.70
[INFO] model update: t: 603, loss: 69242.34375
[INFO] Global_t: 603, Episode_t: 3, Action: 29, Reward: 2.09, Epsilon: 0.70
[INFO] model update: t: 604, loss: 61662.5546875
[INFO] Global_t: 604, Episode_t: 4, Action: 148, Reward: 1.35, Epsilon: 0.69
[INFO] model update: t: 605, loss: 22477.189453125
[INFO] Global_t: 605, Episode_t: 5, Action: 84, Reward: 1.67, Epsilon: 0.69
[INFO] model update: t: 606, loss: 29842.86328125
[INFO] Global_t: 606, Episode_t: 6, Action: 113, Reward: 1.46, Epsilon: 0.69
[INFO] Global step: 606, Cumulative rewards: 11.2998, Runtime (s): 520.51
--------------------------------------
 
graph: 101, nodes: 211, edges: 624
[INFO] model update: t: 607, loss: 51432.0625
[INFO] Global_t: 607, Episode_t: 1, Action: 124, Reward: 2.11, Epsilon: 0.69
[INFO] model update: t: 608, loss: 37751.1796875
[INFO] Global_t: 608, Episode_t: 2, Action: 15, Reward: 3.46, Epsilon: 0.69
[INFO] model update: t: 609, loss: 50997.67578125
[INFO] Global_t: 609, Episode_t: 3, Action: 26, Reward: 2.46, Epsilon: 0.69
[INFO] model update: t: 610, loss: 63635.140625
[INFO] Global_t: 610, Episode_t: 4, Action: 197, Reward: 0.99, Epsilon: 0.69
[INFO] model update: t: 611, loss: 11075.98046875
[INFO] Global_t: 611, Episode_t: 5, Action: 143, Reward: 1.30, Epsilon: 0.69
[INFO] model update: t: 612, loss: 40287.2890625
[INFO] Global_t: 612, Episode_t: 6, Action: 115, Reward: 1.68, Epsilon: 0.69
[INFO] Global step: 612, Cumulative rewards: 11.9904, Runtime (s): 522.99
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4995315074920654
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.382448434829712
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.344949722290039
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.250213623046875
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.33062744140625
average cummulative reward vector is:  [0.07552026 0.05985625 0.07100055 0.05424696 0.06802742]
average cummulative reward is:  0.06573028831552867
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 102, nodes: 180, edges: 531
[INFO] model update: t: 613, loss: 27904.1171875
[INFO] Global_t: 613, Episode_t: 1, Action: 75, Reward: 1.62, Epsilon: 0.69
[INFO] model update: t: 614, loss: 80267.4375
[INFO] Global_t: 614, Episode_t: 2, Action: 26, Reward: 2.25, Epsilon: 0.69
[INFO] model update: t: 615, loss: 43818.921875
[INFO] Global_t: 615, Episode_t: 3, Action: 162, Reward: 1.57, Epsilon: 0.69
[INFO] model update: t: 616, loss: 59614.7109375
[INFO] Global_t: 616, Episode_t: 4, Action: 24, Reward: 2.04, Epsilon: 0.69
[INFO] model update: t: 617, loss: 16221.138671875
[INFO] Global_t: 617, Episode_t: 5, Action: 85, Reward: 2.70, Epsilon: 0.69
[INFO] model update: t: 618, loss: 37541.45703125
[INFO] Global_t: 618, Episode_t: 6, Action: 106, Reward: 1.88, Epsilon: 0.69
[INFO] Global step: 618, Cumulative rewards: 12.05664, Runtime (s): 531.34
--------------------------------------
 
graph: 103, nodes: 187, edges: 551
[INFO] model update: t: 619, loss: 35581.90625
[INFO] Global_t: 619, Episode_t: 1, Action: 68, Reward: 1.42, Epsilon: 0.69
[INFO] model update: t: 620, loss: 27359.408203125
[INFO] Global_t: 620, Episode_t: 2, Action: 145, Reward: 2.12, Epsilon: 0.69
[INFO] model update: t: 621, loss: 34295.84375
[INFO] Global_t: 621, Episode_t: 3, Action: 123, Reward: 1.30, Epsilon: 0.69
[INFO] model update: t: 622, loss: 47162.91796875
[INFO] Global_t: 622, Episode_t: 4, Action: 23, Reward: 1.85, Epsilon: 0.69
[INFO] model update: t: 623, loss: 62988.3359375
[INFO] Global_t: 623, Episode_t: 5, Action: 26, Reward: 2.13, Epsilon: 0.69
[INFO] model update: t: 624, loss: 38247.87890625
[INFO] Global_t: 624, Episode_t: 6, Action: 121, Reward: 1.99, Epsilon: 0.68
[INFO] Global step: 624, Cumulative rewards: 10.816320000000001, Runtime (s): 532.93
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4594764709472656
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5762972831726074
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2078816890716553
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2061631679534912
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4572370052337646
average cummulative reward vector is:  [0.07253447 0.0689037  0.06238443 0.05197126 0.07555914]
average cummulative reward is:  0.06627060101692234
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 104, nodes: 185, edges: 546
[INFO] model update: t: 625, loss: 37489.7734375
[INFO] Global_t: 625, Episode_t: 1, Action: 165, Reward: 2.13, Epsilon: 0.68
[INFO] model update: t: 626, loss: 67837.6015625
[INFO] Global_t: 626, Episode_t: 2, Action: 111, Reward: 2.19, Epsilon: 0.68
[INFO] model update: t: 627, loss: 35016.4453125
[INFO] Global_t: 627, Episode_t: 3, Action: 89, Reward: 2.10, Epsilon: 0.68
[INFO] model update: t: 628, loss: 48006.9765625
[INFO] Global_t: 628, Episode_t: 4, Action: 1, Reward: 3.48, Epsilon: 0.68
[INFO] model update: t: 629, loss: 29849.15234375
[INFO] Global_t: 629, Episode_t: 5, Action: 145, Reward: 1.40, Epsilon: 0.68
[INFO] model update: t: 630, loss: 31709.4375
[INFO] Global_t: 630, Episode_t: 6, Action: 37, Reward: 2.42, Epsilon: 0.68
[INFO] Global step: 630, Cumulative rewards: 13.726799999999999, Runtime (s): 541.64
--------------------------------------
 
graph: 105, nodes: 180, edges: 531
[INFO] model update: t: 631, loss: 23988.921875
[INFO] Global_t: 631, Episode_t: 1, Action: 125, Reward: 1.04, Epsilon: 0.68
[INFO] model update: t: 632, loss: 37228.046875
[INFO] Global_t: 632, Episode_t: 2, Action: 138, Reward: 1.37, Epsilon: 0.68
[INFO] model update: t: 633, loss: 28345.32421875
[INFO] Global_t: 633, Episode_t: 3, Action: 106, Reward: 1.77, Epsilon: 0.68
[INFO] model update: t: 634, loss: 69702.828125
[INFO] Global_t: 634, Episode_t: 4, Action: 85, Reward: 1.92, Epsilon: 0.68
[INFO] model update: t: 635, loss: 55048.984375
[INFO] Global_t: 635, Episode_t: 5, Action: 146, Reward: 1.26, Epsilon: 0.68
[INFO] model update: t: 636, loss: 49967.82421875
[INFO] Global_t: 636, Episode_t: 6, Action: 120, Reward: 1.25, Epsilon: 0.68
[INFO] Global step: 636, Cumulative rewards: 8.60712, Runtime (s): 543.06
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.470393419265747
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3436706066131592
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1700165271759033
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4746921062469482
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2195565700531006
average cummulative reward vector is:  [0.07336842 0.05793819 0.06022623 0.06562407 0.06162634]
average cummulative reward is:  0.06375665090237101
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 106, nodes: 206, edges: 608
[INFO] model update: t: 637, loss: 18434.3203125
[INFO] Global_t: 637, Episode_t: 1, Action: 84, Reward: 2.30, Epsilon: 0.68
[INFO] model update: t: 638, loss: 45895.09375
[INFO] Global_t: 638, Episode_t: 2, Action: 200, Reward: 1.19, Epsilon: 0.68
[INFO] model update: t: 639, loss: 49392.73046875
[INFO] Global_t: 639, Episode_t: 3, Action: 120, Reward: 1.81, Epsilon: 0.68
[INFO] model update: t: 640, loss: 18508.59765625
[INFO] Global_t: 640, Episode_t: 4, Action: 103, Reward: 1.45, Epsilon: 0.68
[INFO] model update: t: 641, loss: 21512.7734375
[INFO] Global_t: 641, Episode_t: 5, Action: 72, Reward: 1.06, Epsilon: 0.68
[INFO] model update: t: 642, loss: 43983.41015625
[INFO] Global_t: 642, Episode_t: 6, Action: 113, Reward: 1.85, Epsilon: 0.68
[INFO] Global step: 642, Cumulative rewards: 9.654839999999998, Runtime (s): 551.33
--------------------------------------
 
graph: 107, nodes: 205, edges: 606
[INFO] model update: t: 643, loss: 38453.65234375
[INFO] Global_t: 643, Episode_t: 1, Action: 45, Reward: 1.84, Epsilon: 0.68
[INFO] model update: t: 644, loss: 38713.2734375
[INFO] Global_t: 644, Episode_t: 2, Action: 135, Reward: 2.45, Epsilon: 0.67
[INFO] model update: t: 645, loss: 23906.630859375
[INFO] Global_t: 645, Episode_t: 3, Action: 118, Reward: 1.68, Epsilon: 0.67
[INFO] model update: t: 646, loss: 36330.5078125
[INFO] Global_t: 646, Episode_t: 4, Action: 200, Reward: 1.89, Epsilon: 0.67
[INFO] model update: t: 647, loss: 35404.08203125
[INFO] Global_t: 647, Episode_t: 5, Action: 133, Reward: 1.77, Epsilon: 0.67
[INFO] model update: t: 648, loss: 58758.1328125
[INFO] Global_t: 648, Episode_t: 6, Action: 0, Reward: 3.09, Epsilon: 0.67
[INFO] Global step: 648, Cumulative rewards: 12.727440000000001, Runtime (s): 553.08
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5154812335968018
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.336482286453247
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2976200580596924
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2493505477905273
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4121043682098389
average cummulative reward vector is:  [0.07640263 0.05706343 0.06344153 0.05456005 0.07255914]
average cummulative reward is:  0.06480535481468726
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 108, nodes: 215, edges: 636
[INFO] model update: t: 649, loss: 25358.90625
[INFO] Global_t: 649, Episode_t: 1, Action: 97, Reward: 2.37, Epsilon: 0.67
[INFO] model update: t: 650, loss: 45109.21875
[INFO] Global_t: 650, Episode_t: 2, Action: 73, Reward: 2.12, Epsilon: 0.67
[INFO] model update: t: 651, loss: 28892.328125
[INFO] Global_t: 651, Episode_t: 3, Action: 164, Reward: 1.47, Epsilon: 0.67
[INFO] model update: t: 652, loss: 39797.19921875
[INFO] Global_t: 652, Episode_t: 4, Action: 211, Reward: 1.21, Epsilon: 0.67
[INFO] model update: t: 653, loss: 40169.4765625
[INFO] Global_t: 653, Episode_t: 5, Action: 190, Reward: 1.81, Epsilon: 0.67
[INFO] model update: t: 654, loss: 39856.10546875
[INFO] Global_t: 654, Episode_t: 6, Action: 207, Reward: 2.32, Epsilon: 0.67
[INFO] Global step: 654, Cumulative rewards: 11.297039999999999, Runtime (s): 561.57
--------------------------------------
 
graph: 109, nodes: 186, edges: 549
[INFO] model update: t: 655, loss: 43602.3515625
[INFO] Global_t: 655, Episode_t: 1, Action: 167, Reward: 2.01, Epsilon: 0.67
[INFO] model update: t: 656, loss: 34351.16796875
[INFO] Global_t: 656, Episode_t: 2, Action: 181, Reward: 1.30, Epsilon: 0.67
[INFO] model update: t: 657, loss: 30706.892578125
[INFO] Global_t: 657, Episode_t: 3, Action: 59, Reward: 1.62, Epsilon: 0.67
[INFO] model update: t: 658, loss: 48465.7109375
[INFO] Global_t: 658, Episode_t: 4, Action: 3, Reward: 5.62, Epsilon: 0.67
[INFO] model update: t: 659, loss: 17393.9296875
[INFO] Global_t: 659, Episode_t: 5, Action: 78, Reward: 1.53, Epsilon: 0.67
[INFO] model update: t: 660, loss: 29815.603515625
[INFO] Global_t: 660, Episode_t: 6, Action: 69, Reward: 2.10, Epsilon: 0.67
[INFO] Global step: 660, Cumulative rewards: 14.17956, Runtime (s): 563.40
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3862013816833496
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.366034746170044
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2697851657867432
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5281050205230713
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3418676853179932
average cummulative reward vector is:  [0.06638026 0.05852222 0.06584399 0.06831121 0.06854597]
average cummulative reward is:  0.06552073142927234
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 110, nodes: 180, edges: 531
[INFO] model update: t: 661, loss: 25854.8671875
[INFO] Global_t: 661, Episode_t: 1, Action: 58, Reward: 2.25, Epsilon: 0.67
[INFO] model update: t: 662, loss: 25488.1015625
[INFO] Global_t: 662, Episode_t: 2, Action: 9, Reward: 2.58, Epsilon: 0.67
[INFO] model update: t: 663, loss: 40525.7578125
[INFO] Global_t: 663, Episode_t: 3, Action: 114, Reward: 1.95, Epsilon: 0.67
[INFO] model update: t: 664, loss: 103132.03125
[INFO] Global_t: 664, Episode_t: 4, Action: 42, Reward: 1.75, Epsilon: 0.67
[INFO] model update: t: 665, loss: 58186.171875
[INFO] Global_t: 665, Episode_t: 5, Action: 35, Reward: 1.95, Epsilon: 0.66
[INFO] model update: t: 666, loss: 40006.95703125
[INFO] Global_t: 666, Episode_t: 6, Action: 15, Reward: 1.98, Epsilon: 0.66
[INFO] Global step: 666, Cumulative rewards: 12.455639999999999, Runtime (s): 572.44
--------------------------------------
 
graph: 111, nodes: 200, edges: 591
[INFO] model update: t: 667, loss: 87105.8359375
[INFO] Global_t: 667, Episode_t: 1, Action: 67, Reward: 1.78, Epsilon: 0.66
[INFO] model update: t: 668, loss: 65552.875
[INFO] Global_t: 668, Episode_t: 2, Action: 162, Reward: 1.51, Epsilon: 0.66
[INFO] model update: t: 669, loss: 83147.4921875
[INFO] Global_t: 669, Episode_t: 3, Action: 92, Reward: 2.24, Epsilon: 0.66
[INFO] model update: t: 670, loss: 71830.4375
[INFO] Global_t: 670, Episode_t: 4, Action: 150, Reward: 2.06, Epsilon: 0.66
[INFO] model update: t: 671, loss: 65692.078125
[INFO] Global_t: 671, Episode_t: 5, Action: 169, Reward: 1.36, Epsilon: 0.66
[INFO] model update: t: 672, loss: 40223.5625
[INFO] Global_t: 672, Episode_t: 6, Action: 155, Reward: 1.62, Epsilon: 0.66
[INFO] Global step: 672, Cumulative rewards: 10.58184, Runtime (s): 573.90
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4607667922973633
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6010057926177979
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3741085529327393
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2911109924316406
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4168734550476074
average cummulative reward vector is:  [0.07334605 0.07000139 0.07186339 0.05610397 0.07306317]
average cummulative reward is:  0.0688755947008475
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 112, nodes: 216, edges: 639
[INFO] model update: t: 673, loss: 30936.78125
[INFO] Global_t: 673, Episode_t: 1, Action: 105, Reward: 1.89, Epsilon: 0.66
[INFO] model update: t: 674, loss: 43775.6484375
[INFO] Global_t: 674, Episode_t: 2, Action: 152, Reward: 1.14, Epsilon: 0.66
[INFO] model update: t: 675, loss: 46809.25
[INFO] Global_t: 675, Episode_t: 3, Action: 190, Reward: 1.99, Epsilon: 0.66
[INFO] model update: t: 676, loss: 85832.4453125
[INFO] Global_t: 676, Episode_t: 4, Action: 202, Reward: 1.12, Epsilon: 0.66
[INFO] model update: t: 677, loss: 51710.01953125
[INFO] Global_t: 677, Episode_t: 5, Action: 98, Reward: 2.04, Epsilon: 0.66
[INFO] model update: t: 678, loss: 37520.5234375
[INFO] Global_t: 678, Episode_t: 6, Action: 16, Reward: 2.26, Epsilon: 0.66
[INFO] Global step: 678, Cumulative rewards: 10.447919999999998, Runtime (s): 582.41
--------------------------------------
 
graph: 113, nodes: 217, edges: 642
[INFO] model update: t: 679, loss: 81376.5390625
[INFO] Global_t: 679, Episode_t: 1, Action: 107, Reward: 2.33, Epsilon: 0.66
[INFO] model update: t: 680, loss: 61947.08203125
[INFO] Global_t: 680, Episode_t: 2, Action: 190, Reward: 1.26, Epsilon: 0.66
[INFO] model update: t: 681, loss: 18876.9140625
[INFO] Global_t: 681, Episode_t: 3, Action: 36, Reward: 2.34, Epsilon: 0.66
[INFO] model update: t: 682, loss: 29924.587890625
[INFO] Global_t: 682, Episode_t: 4, Action: 167, Reward: 1.51, Epsilon: 0.66
[INFO] model update: t: 683, loss: 53061.66015625
[INFO] Global_t: 683, Episode_t: 5, Action: 142, Reward: 1.72, Epsilon: 0.66
[INFO] model update: t: 684, loss: 19387.2421875
[INFO] Global_t: 684, Episode_t: 6, Action: 175, Reward: 2.32, Epsilon: 0.66
[INFO] Global step: 684, Cumulative rewards: 11.486159999999998, Runtime (s): 583.96
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2663753032684326
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3660943508148193
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.1292531490325928
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3289308547973633
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.270190954208374
average cummulative reward vector is:  [0.06243658 0.05837199 0.05750082 0.05801776 0.0644164 ]
average cummulative reward is:  0.0601487088438097
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 114, nodes: 190, edges: 561
[INFO] model update: t: 685, loss: 52043.21875
[INFO] Global_t: 685, Episode_t: 1, Action: 123, Reward: 1.75, Epsilon: 0.65
[INFO] model update: t: 686, loss: 60741.5625
[INFO] Global_t: 686, Episode_t: 2, Action: 111, Reward: 1.61, Epsilon: 0.65
[INFO] model update: t: 687, loss: 47105.2734375
[INFO] Global_t: 687, Episode_t: 3, Action: 160, Reward: 1.90, Epsilon: 0.65
[INFO] model update: t: 688, loss: 30583.28515625
[INFO] Global_t: 688, Episode_t: 4, Action: 147, Reward: 1.37, Epsilon: 0.65
[INFO] model update: t: 689, loss: 34520.421875
[INFO] Global_t: 689, Episode_t: 5, Action: 132, Reward: 1.41, Epsilon: 0.65
[INFO] model update: t: 690, loss: 37535.46875
[INFO] Global_t: 690, Episode_t: 6, Action: 120, Reward: 1.34, Epsilon: 0.65
[INFO] Global step: 690, Cumulative rewards: 9.37068, Runtime (s): 592.17
--------------------------------------
 
graph: 115, nodes: 198, edges: 585
[INFO] model update: t: 691, loss: 17803.578125
[INFO] Global_t: 691, Episode_t: 1, Action: 177, Reward: 1.73, Epsilon: 0.65
[INFO] model update: t: 692, loss: 62246.55859375
[INFO] Global_t: 692, Episode_t: 2, Action: 23, Reward: 2.10, Epsilon: 0.65
[INFO] model update: t: 693, loss: 36796.28515625
[INFO] Global_t: 693, Episode_t: 3, Action: 87, Reward: 2.35, Epsilon: 0.65
[INFO] model update: t: 694, loss: 59040.75
[INFO] Global_t: 694, Episode_t: 4, Action: 83, Reward: 1.60, Epsilon: 0.65
[INFO] model update: t: 695, loss: 27718.955078125
[INFO] Global_t: 695, Episode_t: 5, Action: 46, Reward: 2.34, Epsilon: 0.65
[INFO] model update: t: 696, loss: 67219.9375
[INFO] Global_t: 696, Episode_t: 6, Action: 168, Reward: 1.20, Epsilon: 0.65
[INFO] Global step: 696, Cumulative rewards: 11.322479999999999, Runtime (s): 593.91
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3264248371124268
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4717519283294678
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2986717224121094
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.417741060256958
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2509067058563232
average cummulative reward vector is:  [0.06550026 0.06399028 0.06752568 0.06300818 0.06312608]
average cummulative reward is:  0.06463009536693849
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 116, nodes: 182, edges: 537
[INFO] model update: t: 697, loss: 15104.7177734375
[INFO] Global_t: 697, Episode_t: 1, Action: 46, Reward: 1.80, Epsilon: 0.65
[INFO] model update: t: 698, loss: 52903.69140625
[INFO] Global_t: 698, Episode_t: 2, Action: 120, Reward: 1.32, Epsilon: 0.65
[INFO] model update: t: 699, loss: 49849.890625
[INFO] Global_t: 699, Episode_t: 3, Action: 89, Reward: 1.90, Epsilon: 0.65
[INFO] model update: t: 700, loss: 29765.19921875
[INFO] Global_t: 700, Episode_t: 4, Action: 2, Reward: 5.03, Epsilon: 0.65
[INFO] model update: t: 701, loss: 12053.25390625
[INFO] Global_t: 701, Episode_t: 5, Action: 150, Reward: 1.45, Epsilon: 0.65
[INFO] model update: t: 702, loss: 32140.3203125
[INFO] Global_t: 702, Episode_t: 6, Action: 12, Reward: 1.90, Epsilon: 0.65
[INFO] Global step: 702, Cumulative rewards: 13.40832, Runtime (s): 602.57
--------------------------------------
 
graph: 117, nodes: 196, edges: 579
[INFO] model update: t: 703, loss: 52134.125
[INFO] Global_t: 703, Episode_t: 1, Action: 106, Reward: 2.07, Epsilon: 0.65
[INFO] model update: t: 704, loss: 67120.609375
[INFO] Global_t: 704, Episode_t: 2, Action: 138, Reward: 1.31, Epsilon: 0.65
[INFO] model update: t: 705, loss: 37840.18359375
[INFO] Global_t: 705, Episode_t: 3, Action: 73, Reward: 2.00, Epsilon: 0.65
[INFO] model update: t: 706, loss: 23653.912109375
[INFO] Global_t: 706, Episode_t: 4, Action: 65, Reward: 1.41, Epsilon: 0.64
[INFO] model update: t: 707, loss: 26600.8125
[INFO] Global_t: 707, Episode_t: 5, Action: 67, Reward: 2.49, Epsilon: 0.64
[INFO] model update: t: 708, loss: 27150.375
[INFO] Global_t: 708, Episode_t: 6, Action: 29, Reward: 2.74, Epsilon: 0.64
[INFO] Global step: 708, Cumulative rewards: 12.01836, Runtime (s): 604.13
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.454620361328125
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4195501804351807
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3104324340820312
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3237242698669434
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3369529247283936
average cummulative reward vector is:  [0.07181211 0.06099792 0.06854918 0.0576     0.06810511]
average cummulative reward is:  0.06541286195691502
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 118, nodes: 180, edges: 531
[INFO] model update: t: 709, loss: 93053.203125
[INFO] Global_t: 709, Episode_t: 1, Action: 150, Reward: 1.52, Epsilon: 0.64
[INFO] model update: t: 710, loss: 42864.4140625
[INFO] Global_t: 710, Episode_t: 2, Action: 135, Reward: 1.68, Epsilon: 0.64
[INFO] model update: t: 711, loss: 67784.171875
[INFO] Global_t: 711, Episode_t: 3, Action: 155, Reward: 1.96, Epsilon: 0.64
[INFO] model update: t: 712, loss: 32695.919921875
[INFO] Global_t: 712, Episode_t: 4, Action: 36, Reward: 2.20, Epsilon: 0.64
[INFO] model update: t: 713, loss: 18820.48828125
[INFO] Global_t: 713, Episode_t: 5, Action: 3, Reward: 4.85, Epsilon: 0.64
[INFO] model update: t: 714, loss: 32555.921875
[INFO] Global_t: 714, Episode_t: 6, Action: 44, Reward: 2.06, Epsilon: 0.64
[INFO] Global step: 714, Cumulative rewards: 14.2668, Runtime (s): 612.59
--------------------------------------
 
graph: 119, nodes: 182, edges: 537
[INFO] model update: t: 715, loss: 30087.935546875
[INFO] Global_t: 715, Episode_t: 1, Action: 177, Reward: 2.16, Epsilon: 0.64
[INFO] model update: t: 716, loss: 61570.8515625
[INFO] Global_t: 716, Episode_t: 2, Action: 144, Reward: 1.42, Epsilon: 0.64
[INFO] model update: t: 717, loss: 37368.07421875
[INFO] Global_t: 717, Episode_t: 3, Action: 27, Reward: 2.99, Epsilon: 0.64
[INFO] model update: t: 718, loss: 36512.78125
[INFO] Global_t: 718, Episode_t: 4, Action: 117, Reward: 1.23, Epsilon: 0.64
[INFO] model update: t: 719, loss: 68373.4375
[INFO] Global_t: 719, Episode_t: 5, Action: 155, Reward: 2.10, Epsilon: 0.64
[INFO] model update: t: 720, loss: 54648.140625
[INFO] Global_t: 720, Episode_t: 6, Action: 178, Reward: 1.14, Epsilon: 0.64
[INFO] Global step: 720, Cumulative rewards: 11.04048, Runtime (s): 614.58
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5300605297088623
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.589813470840454
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2952992916107178
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3655710220336914
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2805209159851074
average cummulative reward vector is:  [0.0739     0.06588241 0.06701202 0.05952967 0.06460054]
average cummulative reward is:  0.06618492795938716
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 120, nodes: 219, edges: 648
[INFO] model update: t: 721, loss: 83863.09375
[INFO] Global_t: 721, Episode_t: 1, Action: 24, Reward: 3.15, Epsilon: 0.64
[INFO] model update: t: 722, loss: 73589.5078125
[INFO] Global_t: 722, Episode_t: 2, Action: 18, Reward: 2.14, Epsilon: 0.64
[INFO] model update: t: 723, loss: 57640.01953125
[INFO] Global_t: 723, Episode_t: 3, Action: 69, Reward: 2.08, Epsilon: 0.64
[INFO] model update: t: 724, loss: 47844.23828125
[INFO] Global_t: 724, Episode_t: 4, Action: 175, Reward: 2.12, Epsilon: 0.64
[INFO] model update: t: 725, loss: 89435.59375
[INFO] Global_t: 725, Episode_t: 5, Action: 78, Reward: 2.30, Epsilon: 0.64
[INFO] model update: t: 726, loss: 47263.81640625
[INFO] Global_t: 726, Episode_t: 6, Action: 95, Reward: 1.94, Epsilon: 0.63
[INFO] Global step: 726, Cumulative rewards: 13.726799999999999, Runtime (s): 623.42
--------------------------------------
 
graph: 121, nodes: 182, edges: 536
[INFO] model update: t: 727, loss: 61197.31640625
[INFO] Global_t: 727, Episode_t: 1, Action: 129, Reward: 1.72, Epsilon: 0.63
[INFO] model update: t: 728, loss: 82145.03125
[INFO] Global_t: 728, Episode_t: 2, Action: 94, Reward: 1.50, Epsilon: 0.63
[INFO] model update: t: 729, loss: 15523.462890625
[INFO] Global_t: 729, Episode_t: 3, Action: 142, Reward: 1.69, Epsilon: 0.63
[INFO] model update: t: 730, loss: 51830.1328125
[INFO] Global_t: 730, Episode_t: 4, Action: 170, Reward: 1.34, Epsilon: 0.63
[INFO] model update: t: 731, loss: 25981.126953125
[INFO] Global_t: 731, Episode_t: 5, Action: 116, Reward: 1.86, Epsilon: 0.63
[INFO] model update: t: 732, loss: 34811.94140625
[INFO] Global_t: 732, Episode_t: 6, Action: 95, Reward: 1.87, Epsilon: 0.63
[INFO] Global step: 732, Cumulative rewards: 9.98988, Runtime (s): 625.18
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3515524864196777
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.469867467880249
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3102431297302246
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3398826122283936
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4105408191680908
average cummulative reward vector is:  [0.06651474 0.06391713 0.0683847  0.0587236  0.07251075]
average cummulative reward is:  0.06601018334885998
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 122, nodes: 206, edges: 609
[INFO] model update: t: 733, loss: 63328.4375
[INFO] Global_t: 733, Episode_t: 1, Action: 35, Reward: 1.77, Epsilon: 0.63
[INFO] model update: t: 734, loss: 79189.953125
[INFO] Global_t: 734, Episode_t: 2, Action: 53, Reward: 2.20, Epsilon: 0.63
[INFO] model update: t: 735, loss: 42007.453125
[INFO] Global_t: 735, Episode_t: 3, Action: 156, Reward: 1.45, Epsilon: 0.63
[INFO] model update: t: 736, loss: 55496.7109375
[INFO] Global_t: 736, Episode_t: 4, Action: 3, Reward: 6.61, Epsilon: 0.63
[INFO] model update: t: 737, loss: 66214.421875
[INFO] Global_t: 737, Episode_t: 5, Action: 15, Reward: 2.23, Epsilon: 0.63
[INFO] model update: t: 738, loss: 63872.7578125
[INFO] Global_t: 738, Episode_t: 6, Action: 183, Reward: 0.98, Epsilon: 0.63
[INFO] Global step: 738, Cumulative rewards: 15.238799999999998, Runtime (s): 633.88
--------------------------------------
 
graph: 123, nodes: 182, edges: 537
[INFO] model update: t: 739, loss: 44810.2109375
[INFO] Global_t: 739, Episode_t: 1, Action: 150, Reward: 1.94, Epsilon: 0.63
[INFO] model update: t: 740, loss: 46071.33984375
[INFO] Global_t: 740, Episode_t: 2, Action: 103, Reward: 2.07, Epsilon: 0.63
[INFO] model update: t: 741, loss: 21682.3984375
[INFO] Global_t: 741, Episode_t: 3, Action: 78, Reward: 1.44, Epsilon: 0.63
[INFO] model update: t: 742, loss: 42750.671875
[INFO] Global_t: 742, Episode_t: 4, Action: 87, Reward: 1.63, Epsilon: 0.63
[INFO] model update: t: 743, loss: 44868.296875
[INFO] Global_t: 743, Episode_t: 5, Action: 37, Reward: 1.99, Epsilon: 0.63
[INFO] model update: t: 744, loss: 50970.5625
[INFO] Global_t: 744, Episode_t: 6, Action: 118, Reward: 1.56, Epsilon: 0.63
[INFO] Global step: 744, Cumulative rewards: 10.635479999999998, Runtime (s): 635.66
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4905414581298828
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5084114074707031
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2836053371429443
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2513561248779297
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4595203399658203
average cummulative reward vector is:  [0.07148368 0.06551574 0.06676776 0.05399509 0.0752207 ]
average cummulative reward is:  0.06659659537935674
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 124, nodes: 194, edges: 573
[INFO] model update: t: 745, loss: 43005.0625
[INFO] Global_t: 745, Episode_t: 1, Action: 66, Reward: 2.53, Epsilon: 0.63
[INFO] model update: t: 746, loss: 35479.08203125
[INFO] Global_t: 746, Episode_t: 2, Action: 126, Reward: 1.75, Epsilon: 0.62
[INFO] model update: t: 747, loss: 53500.84375
[INFO] Global_t: 747, Episode_t: 3, Action: 163, Reward: 1.85, Epsilon: 0.62
[INFO] model update: t: 748, loss: 53554.15625
[INFO] Global_t: 748, Episode_t: 4, Action: 70, Reward: 1.79, Epsilon: 0.62
[INFO] model update: t: 749, loss: 40319.9765625
[INFO] Global_t: 749, Episode_t: 5, Action: 99, Reward: 1.58, Epsilon: 0.62
[INFO] model update: t: 750, loss: 83673.375
[INFO] Global_t: 750, Episode_t: 6, Action: 57, Reward: 1.81, Epsilon: 0.62
[INFO] Global step: 750, Cumulative rewards: 11.310120000000001, Runtime (s): 644.70
--------------------------------------
 
graph: 125, nodes: 209, edges: 617
[INFO] model update: t: 751, loss: 25146.7109375
[INFO] Global_t: 751, Episode_t: 1, Action: 76, Reward: 1.34, Epsilon: 0.62
[INFO] model update: t: 752, loss: 76672.8828125
[INFO] Global_t: 752, Episode_t: 2, Action: 143, Reward: 2.31, Epsilon: 0.62
[INFO] model update: t: 753, loss: 49422.2109375
[INFO] Global_t: 753, Episode_t: 3, Action: 189, Reward: 1.48, Epsilon: 0.62
[INFO] model update: t: 754, loss: 46783.6640625
[INFO] Global_t: 754, Episode_t: 4, Action: 162, Reward: 1.28, Epsilon: 0.62
[INFO] model update: t: 755, loss: 37381.37890625
[INFO] Global_t: 755, Episode_t: 5, Action: 180, Reward: 1.47, Epsilon: 0.62
[INFO] model update: t: 756, loss: 37625.921875
[INFO] Global_t: 756, Episode_t: 6, Action: 65, Reward: 2.11, Epsilon: 0.62
[INFO] Global step: 756, Cumulative rewards: 9.9954, Runtime (s): 646.28
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4283733367919922
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4218878746032715
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4168446063995361
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3061251640319824
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2800347805023193
average cummulative reward vector is:  [0.07053553 0.06111389 0.07506393 0.05681121 0.0644328 ]
average cummulative reward is:  0.06559147205662072
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 126, nodes: 218, edges: 645
[INFO] model update: t: 757, loss: 41062.3046875
[INFO] Global_t: 757, Episode_t: 1, Action: 43, Reward: 1.86, Epsilon: 0.62
[INFO] model update: t: 758, loss: 33146.59375
[INFO] Global_t: 758, Episode_t: 2, Action: 55, Reward: 2.67, Epsilon: 0.62
[INFO] model update: t: 759, loss: 39634.328125
[INFO] Global_t: 759, Episode_t: 3, Action: 21, Reward: 3.10, Epsilon: 0.62
[INFO] model update: t: 760, loss: 97209.0234375
[INFO] Global_t: 760, Episode_t: 4, Action: 98, Reward: 1.33, Epsilon: 0.62
[INFO] model update: t: 761, loss: 28328.287109375
[INFO] Global_t: 761, Episode_t: 5, Action: 138, Reward: 1.69, Epsilon: 0.62
[INFO] model update: t: 762, loss: 53341.77734375
[INFO] Global_t: 762, Episode_t: 6, Action: 14, Reward: 4.07, Epsilon: 0.62
[INFO] Global step: 762, Cumulative rewards: 14.733599999999996, Runtime (s): 655.51
--------------------------------------
 
graph: 127, nodes: 189, edges: 558
[INFO] model update: t: 763, loss: 71309.6328125
[INFO] Global_t: 763, Episode_t: 1, Action: 111, Reward: 2.18, Epsilon: 0.62
[INFO] model update: t: 764, loss: 38076.6015625
[INFO] Global_t: 764, Episode_t: 2, Action: 30, Reward: 2.60, Epsilon: 0.62
[INFO] model update: t: 765, loss: 20070.4453125
[INFO] Global_t: 765, Episode_t: 3, Action: 38, Reward: 2.08, Epsilon: 0.62
[INFO] model update: t: 766, loss: 38290.8671875
[INFO] Global_t: 766, Episode_t: 4, Action: 53, Reward: 1.95, Epsilon: 0.62
[INFO] model update: t: 767, loss: 41437.140625
[INFO] Global_t: 767, Episode_t: 5, Action: 150, Reward: 1.06, Epsilon: 0.61
[INFO] model update: t: 768, loss: 49611.24609375
[INFO] Global_t: 768, Episode_t: 6, Action: 100, Reward: 1.23, Epsilon: 0.61
[INFO] Global step: 768, Cumulative rewards: 11.091239999999999, Runtime (s): 657.72
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.490976333618164
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6411585807800293
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3358983993530273
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.428337812423706
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.431389331817627
average cummulative reward vector is:  [0.06649526 0.06559352 0.06799563 0.06143014 0.06760914]
average cummulative reward is:  0.06582473801271518
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 128, nodes: 198, edges: 585
[INFO] model update: t: 769, loss: 49544.0
[INFO] Global_t: 769, Episode_t: 1, Action: 63, Reward: 2.20, Epsilon: 0.61
[INFO] model update: t: 770, loss: 68127.125
[INFO] Global_t: 770, Episode_t: 2, Action: 20, Reward: 2.79, Epsilon: 0.61
[INFO] model update: t: 771, loss: 42314.78125
[INFO] Global_t: 771, Episode_t: 3, Action: 70, Reward: 2.05, Epsilon: 0.61
[INFO] model update: t: 772, loss: 76029.1953125
[INFO] Global_t: 772, Episode_t: 4, Action: 122, Reward: 1.01, Epsilon: 0.61
[INFO] model update: t: 773, loss: 46723.796875
[INFO] Global_t: 773, Episode_t: 5, Action: 96, Reward: 1.10, Epsilon: 0.61
[INFO] model update: t: 774, loss: 82072.5390625
[INFO] Global_t: 774, Episode_t: 6, Action: 79, Reward: 1.64, Epsilon: 0.61
[INFO] Global step: 774, Cumulative rewards: 10.77648, Runtime (s): 667.45
--------------------------------------
 
graph: 129, nodes: 211, edges: 624
[INFO] model update: t: 775, loss: 79579.7890625
[INFO] Global_t: 775, Episode_t: 1, Action: 183, Reward: 1.31, Epsilon: 0.61
[INFO] model update: t: 776, loss: 100810.859375
[INFO] Global_t: 776, Episode_t: 2, Action: 9, Reward: 2.23, Epsilon: 0.61
[INFO] model update: t: 777, loss: 54943.61328125
[INFO] Global_t: 777, Episode_t: 3, Action: 163, Reward: 2.32, Epsilon: 0.61
[INFO] model update: t: 778, loss: 51885.34375
[INFO] Global_t: 778, Episode_t: 4, Action: 146, Reward: 1.74, Epsilon: 0.61
[INFO] model update: t: 779, loss: 42838.234375
[INFO] Global_t: 779, Episode_t: 5, Action: 77, Reward: 1.87, Epsilon: 0.61
[INFO] model update: t: 780, loss: 56650.75
[INFO] Global_t: 780, Episode_t: 6, Action: 115, Reward: 1.81, Epsilon: 0.61
[INFO] Global step: 780, Cumulative rewards: 11.273879999999998, Runtime (s): 669.13
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4121625423431396
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5056440830230713
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2054800987243652
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4038159847259521
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4994747638702393
average cummulative reward vector is:  [0.06872553 0.0639338  0.06052732 0.06070654 0.07072151]
average cummulative reward is:  0.06492293848977523
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 130, nodes: 205, edges: 606
[INFO] model update: t: 781, loss: 46014.265625
[INFO] Global_t: 781, Episode_t: 1, Action: 6, Reward: 7.11, Epsilon: 0.61
[INFO] model update: t: 782, loss: 76604.90625
[INFO] Global_t: 782, Episode_t: 2, Action: 20, Reward: 2.34, Epsilon: 0.61
[INFO] model update: t: 783, loss: 55629.671875
[INFO] Global_t: 783, Episode_t: 3, Action: 36, Reward: 2.66, Epsilon: 0.61
[INFO] model update: t: 784, loss: 58282.65234375
[INFO] Global_t: 784, Episode_t: 4, Action: 0, Reward: 3.48, Epsilon: 0.61
[INFO] model update: t: 785, loss: 57597.9765625
[INFO] Global_t: 785, Episode_t: 5, Action: 5, Reward: 2.63, Epsilon: 0.61
[INFO] model update: t: 786, loss: 202077.609375
[INFO] Global_t: 786, Episode_t: 6, Action: 194, Reward: 1.17, Epsilon: 0.61
[INFO] Global step: 786, Cumulative rewards: 19.39164, Runtime (s): 679.54
--------------------------------------
 
graph: 131, nodes: 210, edges: 620
[INFO] model update: t: 787, loss: 40996.1484375
[INFO] Global_t: 787, Episode_t: 1, Action: 148, Reward: 1.62, Epsilon: 0.60
[INFO] model update: t: 788, loss: 45997.171875
[INFO] Global_t: 788, Episode_t: 2, Action: 182, Reward: 2.14, Epsilon: 0.60
[INFO] model update: t: 789, loss: 49942.3671875
[INFO] Global_t: 789, Episode_t: 3, Action: 178, Reward: 2.28, Epsilon: 0.60
[INFO] model update: t: 790, loss: 172857.859375
[INFO] Global_t: 790, Episode_t: 4, Action: 177, Reward: 1.93, Epsilon: 0.60
[INFO] model update: t: 791, loss: 24271.05078125
[INFO] Global_t: 791, Episode_t: 5, Action: 5, Reward: 5.49, Epsilon: 0.60
[INFO] model update: t: 792, loss: 38269.37890625
[INFO] Global_t: 792, Episode_t: 6, Action: 7, Reward: 3.37, Epsilon: 0.60
[INFO] Global step: 792, Cumulative rewards: 16.82556, Runtime (s): 681.68
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3388009071350098
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2596900463104248
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3288352489471436
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3410024642944336
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.353041172027588
average cummulative reward vector is:  [0.06220921 0.05148218 0.06211011 0.05720888 0.06747742]
average cummulative reward is:  0.060097558720274155
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 132, nodes: 213, edges: 630
[INFO] model update: t: 793, loss: 172010.265625
[INFO] Global_t: 793, Episode_t: 1, Action: 23, Reward: 2.12, Epsilon: 0.60
[INFO] model update: t: 794, loss: 58706.5625
[INFO] Global_t: 794, Episode_t: 2, Action: 128, Reward: 2.42, Epsilon: 0.60
[INFO] model update: t: 795, loss: 56844.8359375
[INFO] Global_t: 795, Episode_t: 3, Action: 156, Reward: 2.03, Epsilon: 0.60
[INFO] model update: t: 796, loss: 158801.109375
[INFO] Global_t: 796, Episode_t: 4, Action: 187, Reward: 1.60, Epsilon: 0.60
[INFO] model update: t: 797, loss: 29717.26171875
[INFO] Global_t: 797, Episode_t: 5, Action: 188, Reward: 1.15, Epsilon: 0.60
[INFO] model update: t: 798, loss: 83603.375
[INFO] Global_t: 798, Episode_t: 6, Action: 21, Reward: 4.32, Epsilon: 0.60
[INFO] Global step: 798, Cumulative rewards: 13.63824, Runtime (s): 690.14
--------------------------------------
 
graph: 133, nodes: 213, edges: 630
[INFO] model update: t: 799, loss: 62024.1640625
[INFO] Global_t: 799, Episode_t: 1, Action: 174, Reward: 1.36, Epsilon: 0.60
[INFO] model update: t: 800, loss: 38805.73828125
[INFO] Global_t: 800, Episode_t: 2, Action: 95, Reward: 1.99, Epsilon: 0.60
[INFO] model update: t: 801, loss: 44976.69140625
[INFO] Global_t: 801, Episode_t: 3, Action: 168, Reward: 2.22, Epsilon: 0.60
[INFO] model update: t: 802, loss: 67282.8203125
[INFO] Global_t: 802, Episode_t: 4, Action: 124, Reward: 1.54, Epsilon: 0.60
[INFO] model update: t: 803, loss: 79310.21875
[INFO] Global_t: 803, Episode_t: 5, Action: 172, Reward: 1.49, Epsilon: 0.60
[INFO] model update: t: 804, loss: 44344.515625
[INFO] Global_t: 804, Episode_t: 6, Action: 78, Reward: 2.03, Epsilon: 0.60
[INFO] Global step: 804, Cumulative rewards: 10.62936, Runtime (s): 692.00
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4880867004394531
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4571547508239746
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2793316841125488
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3264358043670654
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.561586618423462
average cummulative reward vector is:  [0.07232711 0.06197847 0.05983224 0.0561771  0.07999059]
average cummulative reward is:  0.06606110242482528
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 134, nodes: 215, edges: 635
[INFO] model update: t: 805, loss: 99807.984375
[INFO] Global_t: 805, Episode_t: 1, Action: 147, Reward: 2.29, Epsilon: 0.60
[INFO] model update: t: 806, loss: 42036.08203125
[INFO] Global_t: 806, Episode_t: 2, Action: 169, Reward: 1.46, Epsilon: 0.60
[INFO] model update: t: 807, loss: 44545.6171875
[INFO] Global_t: 807, Episode_t: 3, Action: 160, Reward: 2.10, Epsilon: 0.60
[INFO] model update: t: 808, loss: 30702.7109375
[INFO] Global_t: 808, Episode_t: 4, Action: 117, Reward: 2.25, Epsilon: 0.59
[INFO] model update: t: 809, loss: 107248.2421875
[INFO] Global_t: 809, Episode_t: 5, Action: 69, Reward: 2.28, Epsilon: 0.59
[INFO] model update: t: 810, loss: 21505.087890625
[INFO] Global_t: 810, Episode_t: 6, Action: 148, Reward: 2.55, Epsilon: 0.59
[INFO] Global step: 810, Cumulative rewards: 12.922199999999998, Runtime (s): 700.98
--------------------------------------
 
graph: 135, nodes: 211, edges: 624
[INFO] model update: t: 811, loss: 46824.64453125
[INFO] Global_t: 811, Episode_t: 1, Action: 188, Reward: 1.26, Epsilon: 0.59
[INFO] model update: t: 812, loss: 47275.0546875
[INFO] Global_t: 812, Episode_t: 2, Action: 111, Reward: 1.81, Epsilon: 0.59
[INFO] model update: t: 813, loss: 79269.7734375
[INFO] Global_t: 813, Episode_t: 3, Action: 63, Reward: 2.06, Epsilon: 0.59
[INFO] model update: t: 814, loss: 29694.73828125
[INFO] Global_t: 814, Episode_t: 4, Action: 38, Reward: 2.81, Epsilon: 0.59
[INFO] model update: t: 815, loss: 34894.0625
[INFO] Global_t: 815, Episode_t: 5, Action: 3, Reward: 5.45, Epsilon: 0.59
[INFO] model update: t: 816, loss: 50818.9296875
[INFO] Global_t: 816, Episode_t: 6, Action: 95, Reward: 1.60, Epsilon: 0.59
[INFO] Global step: 816, Cumulative rewards: 14.996280000000002, Runtime (s): 703.20
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5545833110809326
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4564669132232666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.242412805557251
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3916213512420654
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4204978942871094
average cummulative reward vector is:  [0.07606895 0.05687685 0.0624806  0.06009322 0.07082876]
average cummulative reward is:  0.06526967761061894
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 136, nodes: 211, edges: 624
[INFO] model update: t: 817, loss: 29596.400390625
[INFO] Global_t: 817, Episode_t: 1, Action: 105, Reward: 2.45, Epsilon: 0.59
[INFO] model update: t: 818, loss: 68759.375
[INFO] Global_t: 818, Episode_t: 2, Action: 144, Reward: 2.21, Epsilon: 0.59
[INFO] model update: t: 819, loss: 92470.359375
[INFO] Global_t: 819, Episode_t: 3, Action: 23, Reward: 2.69, Epsilon: 0.59
[INFO] model update: t: 820, loss: 44698.44140625
[INFO] Global_t: 820, Episode_t: 4, Action: 13, Reward: 2.24, Epsilon: 0.59
[INFO] model update: t: 821, loss: 45465.9765625
[INFO] Global_t: 821, Episode_t: 5, Action: 132, Reward: 1.36, Epsilon: 0.59
[INFO] model update: t: 822, loss: 30801.16796875
[INFO] Global_t: 822, Episode_t: 6, Action: 71, Reward: 1.75, Epsilon: 0.59
[INFO] Global step: 822, Cumulative rewards: 12.71208, Runtime (s): 712.50
--------------------------------------
 
graph: 137, nodes: 210, edges: 621
[INFO] model update: t: 823, loss: 64151.5546875
[INFO] Global_t: 823, Episode_t: 1, Action: 57, Reward: 2.21, Epsilon: 0.59
[INFO] model update: t: 824, loss: 29737.0546875
[INFO] Global_t: 824, Episode_t: 2, Action: 50, Reward: 2.24, Epsilon: 0.59
[INFO] model update: t: 825, loss: 52042.2109375
[INFO] Global_t: 825, Episode_t: 3, Action: 157, Reward: 1.93, Epsilon: 0.59
[INFO] model update: t: 826, loss: 61359.640625
[INFO] Global_t: 826, Episode_t: 4, Action: 172, Reward: 2.13, Epsilon: 0.59
[INFO] model update: t: 827, loss: 13707.755859375
[INFO] Global_t: 827, Episode_t: 5, Action: 151, Reward: 1.91, Epsilon: 0.59
[INFO] model update: t: 828, loss: 90623.734375
[INFO] Global_t: 828, Episode_t: 6, Action: 122, Reward: 2.16, Epsilon: 0.58
[INFO] Global step: 828, Cumulative rewards: 12.572399999999998, Runtime (s): 714.46
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3427348136901855
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.601525068283081
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.370666742324829
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3376541137695312
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.361539363861084
average cummulative reward vector is:  [0.06450421 0.06225162 0.07035574 0.05720093 0.06793817]
average cummulative reward is:  0.06445013504481086
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 138, nodes: 185, edges: 545
[INFO] model update: t: 829, loss: 60878.6796875
[INFO] Global_t: 829, Episode_t: 1, Action: 30, Reward: 2.30, Epsilon: 0.58
[INFO] model update: t: 830, loss: 84282.578125
[INFO] Global_t: 830, Episode_t: 2, Action: 45, Reward: 2.08, Epsilon: 0.58
[INFO] model update: t: 831, loss: 96355.671875
[INFO] Global_t: 831, Episode_t: 3, Action: 143, Reward: 2.25, Epsilon: 0.58
[INFO] model update: t: 832, loss: 68859.203125
[INFO] Global_t: 832, Episode_t: 4, Action: 164, Reward: 2.19, Epsilon: 0.58
[INFO] model update: t: 833, loss: 64557.015625
[INFO] Global_t: 833, Episode_t: 5, Action: 23, Reward: 1.89, Epsilon: 0.58
[INFO] model update: t: 834, loss: 105740.2109375
[INFO] Global_t: 834, Episode_t: 6, Action: 82, Reward: 1.82, Epsilon: 0.58
[INFO] Global step: 834, Cumulative rewards: 12.528, Runtime (s): 723.31
--------------------------------------
 
graph: 139, nodes: 184, edges: 543
[INFO] model update: t: 835, loss: 40224.28125
[INFO] Global_t: 835, Episode_t: 1, Action: 178, Reward: 1.28, Epsilon: 0.58
[INFO] model update: t: 836, loss: 64120.5546875
[INFO] Global_t: 836, Episode_t: 2, Action: 65, Reward: 2.24, Epsilon: 0.58
[INFO] model update: t: 837, loss: 127552.5390625
[INFO] Global_t: 837, Episode_t: 3, Action: 49, Reward: 2.24, Epsilon: 0.58
[INFO] model update: t: 838, loss: 40134.58984375
[INFO] Global_t: 838, Episode_t: 4, Action: 5, Reward: 4.48, Epsilon: 0.58
[INFO] model update: t: 839, loss: 28918.962890625
[INFO] Global_t: 839, Episode_t: 5, Action: 166, Reward: 1.55, Epsilon: 0.58
[INFO] model update: t: 840, loss: 127347.8125
[INFO] Global_t: 840, Episode_t: 6, Action: 173, Reward: 1.67, Epsilon: 0.58
[INFO] Global step: 840, Cumulative rewards: 13.453079999999998, Runtime (s): 725.11
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6127560138702393
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.434471845626831
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3935279846191406
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.519857406616211
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2492101192474365
average cummulative reward vector is:  [0.07249    0.0604162  0.0712235  0.06700304 0.0618043 ]
average cummulative reward is:  0.06658740788598191
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 140, nodes: 220, edges: 651
[INFO] model update: t: 841, loss: 61098.28515625
[INFO] Global_t: 841, Episode_t: 1, Action: 200, Reward: 2.40, Epsilon: 0.58
[INFO] model update: t: 842, loss: 55979.36328125
[INFO] Global_t: 842, Episode_t: 2, Action: 170, Reward: 1.35, Epsilon: 0.58
[INFO] model update: t: 843, loss: 74558.8515625
[INFO] Global_t: 843, Episode_t: 3, Action: 41, Reward: 2.75, Epsilon: 0.58
[INFO] model update: t: 844, loss: 54089.5546875
[INFO] Global_t: 844, Episode_t: 4, Action: 6, Reward: 5.88, Epsilon: 0.58
[INFO] model update: t: 845, loss: 72245.734375
[INFO] Global_t: 845, Episode_t: 5, Action: 182, Reward: 1.55, Epsilon: 0.58
[INFO] model update: t: 846, loss: 79861.015625
[INFO] Global_t: 846, Episode_t: 6, Action: 57, Reward: 2.48, Epsilon: 0.58
[INFO] Global step: 846, Cumulative rewards: 16.404719999999998, Runtime (s): 734.28
--------------------------------------
 
graph: 141, nodes: 205, edges: 606
[INFO] model update: t: 847, loss: 28382.6328125
[INFO] Global_t: 847, Episode_t: 1, Action: 156, Reward: 1.63, Epsilon: 0.58
[INFO] model update: t: 848, loss: 28785.626953125
[INFO] Global_t: 848, Episode_t: 2, Action: 188, Reward: 1.56, Epsilon: 0.57
[INFO] model update: t: 849, loss: 60048.94140625
[INFO] Global_t: 849, Episode_t: 3, Action: 53, Reward: 2.23, Epsilon: 0.57
[INFO] model update: t: 850, loss: 18983.01953125
[INFO] Global_t: 850, Episode_t: 4, Action: 70, Reward: 1.65, Epsilon: 0.57
[INFO] model update: t: 851, loss: 40882.13671875
[INFO] Global_t: 851, Episode_t: 5, Action: 15, Reward: 2.79, Epsilon: 0.57
[INFO] model update: t: 852, loss: 91037.609375
[INFO] Global_t: 852, Episode_t: 6, Action: 126, Reward: 1.46, Epsilon: 0.57
[INFO] Global step: 852, Cumulative rewards: 11.307599999999999, Runtime (s): 736.22
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5490520000457764
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4102108478546143
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.338263988494873
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2247354984283447
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3705828189849854
average cummulative reward vector is:  [0.07139    0.05948102 0.06756339 0.05144346 0.0694621 ]
average cummulative reward is:  0.06386799224295588
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 142, nodes: 201, edges: 593
[INFO] model update: t: 853, loss: 28414.822265625
[INFO] Global_t: 853, Episode_t: 1, Action: 79, Reward: 2.34, Epsilon: 0.57
[INFO] model update: t: 854, loss: 69256.3203125
[INFO] Global_t: 854, Episode_t: 2, Action: 135, Reward: 2.27, Epsilon: 0.57
[INFO] model update: t: 855, loss: 76159.953125
[INFO] Global_t: 855, Episode_t: 3, Action: 26, Reward: 2.34, Epsilon: 0.57
[INFO] model update: t: 856, loss: 42438.37890625
[INFO] Global_t: 856, Episode_t: 4, Action: 167, Reward: 1.07, Epsilon: 0.57
[INFO] model update: t: 857, loss: 114983.4296875
[INFO] Global_t: 857, Episode_t: 5, Action: 52, Reward: 2.03, Epsilon: 0.57
[INFO] model update: t: 858, loss: 46195.0703125
[INFO] Global_t: 858, Episode_t: 6, Action: 87, Reward: 2.05, Epsilon: 0.57
[INFO] Global step: 858, Cumulative rewards: 12.105, Runtime (s): 745.14
--------------------------------------
 
graph: 143, nodes: 194, edges: 573
[INFO] model update: t: 859, loss: 52996.9609375
[INFO] Global_t: 859, Episode_t: 1, Action: 109, Reward: 1.33, Epsilon: 0.57
[INFO] model update: t: 860, loss: 71200.046875
[INFO] Global_t: 860, Episode_t: 2, Action: 58, Reward: 2.03, Epsilon: 0.57
[INFO] model update: t: 861, loss: 57740.65625
[INFO] Global_t: 861, Episode_t: 3, Action: 47, Reward: 1.46, Epsilon: 0.57
[INFO] model update: t: 862, loss: 40881.6796875
[INFO] Global_t: 862, Episode_t: 4, Action: 74, Reward: 1.94, Epsilon: 0.57
[INFO] model update: t: 863, loss: 73681.8984375
[INFO] Global_t: 863, Episode_t: 5, Action: 123, Reward: 1.28, Epsilon: 0.57
[INFO] model update: t: 864, loss: 56236.2734375
[INFO] Global_t: 864, Episode_t: 6, Action: 120, Reward: 1.86, Epsilon: 0.57
[INFO] Global step: 864, Cumulative rewards: 9.899879999999998, Runtime (s): 746.89
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4478108882904053
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4445836544036865
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3378686904907227
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.489372730255127
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3176097869873047
average cummulative reward vector is:  [0.07123289 0.06200648 0.06966503 0.06515607 0.06669328]
average cummulative reward is:  0.06695075157539512
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 144, nodes: 219, edges: 648
[INFO] model update: t: 865, loss: 19868.78515625
[INFO] Global_t: 865, Episode_t: 1, Action: 62, Reward: 2.15, Epsilon: 0.57
[INFO] model update: t: 866, loss: 84233.890625
[INFO] Global_t: 866, Episode_t: 2, Action: 91, Reward: 2.58, Epsilon: 0.57
[INFO] model update: t: 867, loss: 28152.314453125
[INFO] Global_t: 867, Episode_t: 3, Action: 106, Reward: 2.07, Epsilon: 0.57
[INFO] model update: t: 868, loss: 30335.30078125
[INFO] Global_t: 868, Episode_t: 4, Action: 190, Reward: 1.23, Epsilon: 0.57
[INFO] model update: t: 869, loss: 87231.96875
[INFO] Global_t: 869, Episode_t: 5, Action: 38, Reward: 1.99, Epsilon: 0.56
[INFO] model update: t: 870, loss: 42581.671875
[INFO] Global_t: 870, Episode_t: 6, Action: 156, Reward: 0.75, Epsilon: 0.56
[INFO] Global step: 870, Cumulative rewards: 10.779960000000003, Runtime (s): 756.02
--------------------------------------
 
graph: 145, nodes: 217, edges: 642
[INFO] model update: t: 871, loss: 154348.015625
[INFO] Global_t: 871, Episode_t: 1, Action: 180, Reward: 2.28, Epsilon: 0.56
[INFO] model update: t: 872, loss: 67310.5234375
[INFO] Global_t: 872, Episode_t: 2, Action: 130, Reward: 1.61, Epsilon: 0.56
[INFO] model update: t: 873, loss: 60321.984375
[INFO] Global_t: 873, Episode_t: 3, Action: 165, Reward: 2.56, Epsilon: 0.56
[INFO] model update: t: 874, loss: 75223.578125
[INFO] Global_t: 874, Episode_t: 4, Action: 13, Reward: 3.18, Epsilon: 0.56
[INFO] model update: t: 875, loss: 59215.3984375
[INFO] Global_t: 875, Episode_t: 5, Action: 75, Reward: 2.08, Epsilon: 0.56
[INFO] model update: t: 876, loss: 58938.99609375
[INFO] Global_t: 876, Episode_t: 6, Action: 41, Reward: 1.95, Epsilon: 0.56
[INFO] Global step: 876, Cumulative rewards: 13.658879999999998, Runtime (s): 758.36
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.606719970703125
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4768891334533691
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3573782444000244
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3327887058258057
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.477494716644287
average cummulative reward vector is:  [0.07948105 0.06261134 0.06767022 0.05589907 0.07506425]
average cummulative reward is:  0.06814518530715903
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 146, nodes: 207, edges: 612
[INFO] model update: t: 877, loss: 58532.625
[INFO] Global_t: 877, Episode_t: 1, Action: 134, Reward: 1.43, Epsilon: 0.56
[INFO] model update: t: 878, loss: 50138.9296875
[INFO] Global_t: 878, Episode_t: 2, Action: 72, Reward: 2.17, Epsilon: 0.56
[INFO] model update: t: 879, loss: 64626.609375
[INFO] Global_t: 879, Episode_t: 3, Action: 81, Reward: 2.06, Epsilon: 0.56
[INFO] model update: t: 880, loss: 28912.4453125
[INFO] Global_t: 880, Episode_t: 4, Action: 145, Reward: 2.23, Epsilon: 0.56
[INFO] model update: t: 881, loss: 22403.849609375
[INFO] Global_t: 881, Episode_t: 5, Action: 127, Reward: 1.36, Epsilon: 0.56
[INFO] model update: t: 882, loss: 28000.96875
[INFO] Global_t: 882, Episode_t: 6, Action: 42, Reward: 2.23, Epsilon: 0.56
[INFO] Global step: 882, Cumulative rewards: 11.47548, Runtime (s): 767.29
--------------------------------------
 
graph: 147, nodes: 202, edges: 597
[INFO] model update: t: 883, loss: 23084.85546875
[INFO] Global_t: 883, Episode_t: 1, Action: 98, Reward: 2.23, Epsilon: 0.56
[INFO] model update: t: 884, loss: 50361.25
[INFO] Global_t: 884, Episode_t: 2, Action: 116, Reward: 1.63, Epsilon: 0.56
[INFO] model update: t: 885, loss: 36313.31640625
[INFO] Global_t: 885, Episode_t: 3, Action: 134, Reward: 2.41, Epsilon: 0.56
[INFO] model update: t: 886, loss: 76484.625
[INFO] Global_t: 886, Episode_t: 4, Action: 108, Reward: 2.15, Epsilon: 0.56
[INFO] model update: t: 887, loss: 22347.6875
[INFO] Global_t: 887, Episode_t: 5, Action: 63, Reward: 2.00, Epsilon: 0.56
[INFO] model update: t: 888, loss: 27348.578125
[INFO] Global_t: 888, Episode_t: 6, Action: 13, Reward: 3.21, Epsilon: 0.56
[INFO] Global step: 888, Cumulative rewards: 13.638, Runtime (s): 769.28
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4541330337524414
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5989103317260742
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2199559211730957
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.347287654876709
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4341185092926025
average cummulative reward vector is:  [0.07115526 0.0685419  0.06126803 0.0583257  0.07249032]
average cummulative reward is:  0.06635624352163054
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 148, nodes: 199, edges: 587
[INFO] model update: t: 889, loss: 51623.32421875
[INFO] Global_t: 889, Episode_t: 1, Action: 162, Reward: 1.87, Epsilon: 0.55
[INFO] model update: t: 890, loss: 30894.603515625
[INFO] Global_t: 890, Episode_t: 2, Action: 121, Reward: 2.16, Epsilon: 0.55
[INFO] model update: t: 891, loss: 24457.00390625
[INFO] Global_t: 891, Episode_t: 3, Action: 76, Reward: 2.14, Epsilon: 0.55
[INFO] model update: t: 892, loss: 71144.1328125
[INFO] Global_t: 892, Episode_t: 4, Action: 88, Reward: 1.59, Epsilon: 0.55
[INFO] model update: t: 893, loss: 116035.8828125
[INFO] Global_t: 893, Episode_t: 5, Action: 72, Reward: 1.68, Epsilon: 0.55
[INFO] model update: t: 894, loss: 23052.595703125
[INFO] Global_t: 894, Episode_t: 6, Action: 115, Reward: 1.13, Epsilon: 0.55
[INFO] Global step: 894, Cumulative rewards: 10.57056, Runtime (s): 777.99
--------------------------------------
 
graph: 149, nodes: 208, edges: 615
[INFO] model update: t: 895, loss: 25805.6640625
[INFO] Global_t: 895, Episode_t: 1, Action: 78, Reward: 2.01, Epsilon: 0.55
[INFO] model update: t: 896, loss: 60108.23828125
[INFO] Global_t: 896, Episode_t: 2, Action: 167, Reward: 2.45, Epsilon: 0.55
[INFO] model update: t: 897, loss: 25464.64453125
[INFO] Global_t: 897, Episode_t: 3, Action: 179, Reward: 1.86, Epsilon: 0.55
[INFO] model update: t: 898, loss: 81137.546875
[INFO] Global_t: 898, Episode_t: 4, Action: 5, Reward: 6.29, Epsilon: 0.55
[INFO] model update: t: 899, loss: 33555.71875
[INFO] Global_t: 899, Episode_t: 5, Action: 134, Reward: 1.96, Epsilon: 0.55
[INFO] model update: t: 900, loss: 30674.50390625
[INFO] Global_t: 900, Episode_t: 6, Action: 31, Reward: 2.15, Epsilon: 0.55
[INFO] Global step: 900, Cumulative rewards: 16.71048, Runtime (s): 780.10
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.376638412475586
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4560368061065674
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.259627103805542
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.445751667022705
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3691504001617432
average cummulative reward vector is:  [0.06735947 0.06207755 0.06445574 0.06274252 0.06657177]
average cummulative reward is:  0.06464141104869184
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 150, nodes: 216, edges: 639
[INFO] model update: t: 901, loss: 34873.95703125
[INFO] Global_t: 901, Episode_t: 1, Action: 53, Reward: 2.33, Epsilon: 0.55
[INFO] model update: t: 902, loss: 101318.65625
[INFO] Global_t: 902, Episode_t: 2, Action: 84, Reward: 2.04, Epsilon: 0.55
[INFO] model update: t: 903, loss: 67945.2578125
[INFO] Global_t: 903, Episode_t: 3, Action: 8, Reward: 3.17, Epsilon: 0.55
[INFO] model update: t: 904, loss: 26528.6796875
[INFO] Global_t: 904, Episode_t: 4, Action: 35, Reward: 1.86, Epsilon: 0.55
[INFO] model update: t: 905, loss: 31725.18359375
[INFO] Global_t: 905, Episode_t: 5, Action: 43, Reward: 1.84, Epsilon: 0.55
[INFO] model update: t: 906, loss: 22927.10546875
[INFO] Global_t: 906, Episode_t: 6, Action: 79, Reward: 1.48, Epsilon: 0.55
[INFO] Global step: 906, Cumulative rewards: 12.72516, Runtime (s): 789.36
--------------------------------------
 
graph: 151, nodes: 204, edges: 601
[INFO] model update: t: 907, loss: 65322.81640625
[INFO] Global_t: 907, Episode_t: 1, Action: 189, Reward: 2.19, Epsilon: 0.55
[INFO] model update: t: 908, loss: 29997.86328125
[INFO] Global_t: 908, Episode_t: 2, Action: 141, Reward: 1.69, Epsilon: 0.55
[INFO] model update: t: 909, loss: 64436.890625
[INFO] Global_t: 909, Episode_t: 3, Action: 161, Reward: 1.05, Epsilon: 0.55
[INFO] model update: t: 910, loss: 51968.8046875
[INFO] Global_t: 910, Episode_t: 4, Action: 75, Reward: 1.90, Epsilon: 0.54
[INFO] model update: t: 911, loss: 18384.8671875
[INFO] Global_t: 911, Episode_t: 5, Action: 100, Reward: 2.24, Epsilon: 0.54
[INFO] model update: t: 912, loss: 37171.671875
[INFO] Global_t: 912, Episode_t: 6, Action: 137, Reward: 2.13, Epsilon: 0.54
[INFO] Global step: 912, Cumulative rewards: 11.19972, Runtime (s): 790.84
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4584722518920898
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5158376693725586
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.434079647064209
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3833074569702148
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.530945062637329
average cummulative reward vector is:  [0.071515   0.06522569 0.07457541 0.06023294 0.07385296]
average cummulative reward is:  0.0690804010389982
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 152, nodes: 208, edges: 615
[INFO] model update: t: 913, loss: 49933.8671875
[INFO] Global_t: 913, Episode_t: 1, Action: 11, Reward: 2.53, Epsilon: 0.54
[INFO] model update: t: 914, loss: 34187.1484375
[INFO] Global_t: 914, Episode_t: 2, Action: 29, Reward: 2.33, Epsilon: 0.54
[INFO] model update: t: 915, loss: 57870.109375
[INFO] Global_t: 915, Episode_t: 3, Action: 186, Reward: 1.70, Epsilon: 0.54
[INFO] model update: t: 916, loss: 72028.6171875
[INFO] Global_t: 916, Episode_t: 4, Action: 174, Reward: 1.50, Epsilon: 0.54
[INFO] model update: t: 917, loss: 40196.828125
[INFO] Global_t: 917, Episode_t: 5, Action: 70, Reward: 2.31, Epsilon: 0.54
[INFO] model update: t: 918, loss: 37154.8359375
[INFO] Global_t: 918, Episode_t: 6, Action: 145, Reward: 2.00, Epsilon: 0.54
[INFO] Global step: 918, Cumulative rewards: 12.36084, Runtime (s): 799.81
--------------------------------------
 
graph: 153, nodes: 211, edges: 623
[INFO] model update: t: 919, loss: 76949.390625
[INFO] Global_t: 919, Episode_t: 1, Action: 114, Reward: 1.17, Epsilon: 0.54
[INFO] model update: t: 920, loss: 25947.78515625
[INFO] Global_t: 920, Episode_t: 2, Action: 120, Reward: 1.30, Epsilon: 0.54
[INFO] model update: t: 921, loss: 30673.734375
[INFO] Global_t: 921, Episode_t: 3, Action: 42, Reward: 2.11, Epsilon: 0.54
[INFO] model update: t: 922, loss: 31250.375
[INFO] Global_t: 922, Episode_t: 4, Action: 116, Reward: 2.07, Epsilon: 0.54
[INFO] model update: t: 923, loss: 38193.875
[INFO] Global_t: 923, Episode_t: 5, Action: 48, Reward: 3.45, Epsilon: 0.54
[INFO] model update: t: 924, loss: 40452.9453125
[INFO] Global_t: 924, Episode_t: 6, Action: 21, Reward: 2.51, Epsilon: 0.54
[INFO] Global step: 924, Cumulative rewards: 12.6174, Runtime (s): 801.28
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2880833148956299
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.2678940296173096
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2823917865753174
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4434762001037598
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3213715553283691
average cummulative reward vector is:  [0.06248711 0.05275972 0.06519727 0.06276028 0.06653038]
average cummulative reward is:  0.061946950392572156
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 154, nodes: 189, edges: 558
[INFO] model update: t: 925, loss: 125672.421875
[INFO] Global_t: 925, Episode_t: 1, Action: 22, Reward: 3.82, Epsilon: 0.54
[INFO] model update: t: 926, loss: 89393.9296875
[INFO] Global_t: 926, Episode_t: 2, Action: 154, Reward: 1.69, Epsilon: 0.54
[INFO] model update: t: 927, loss: 30928.58984375
[INFO] Global_t: 927, Episode_t: 3, Action: 51, Reward: 2.25, Epsilon: 0.54
[INFO] model update: t: 928, loss: 66273.1484375
[INFO] Global_t: 928, Episode_t: 4, Action: 115, Reward: 2.21, Epsilon: 0.54
[INFO] model update: t: 929, loss: 30776.953125
[INFO] Global_t: 929, Episode_t: 5, Action: 130, Reward: 1.90, Epsilon: 0.54
[INFO] model update: t: 930, loss: 145673.265625
[INFO] Global_t: 930, Episode_t: 6, Action: 177, Reward: 2.26, Epsilon: 0.53
[INFO] Global step: 930, Cumulative rewards: 14.141639999999999, Runtime (s): 809.84
--------------------------------------
 
graph: 155, nodes: 203, edges: 599
[INFO] model update: t: 931, loss: 38853.4921875
[INFO] Global_t: 931, Episode_t: 1, Action: 84, Reward: 2.68, Epsilon: 0.53
[INFO] model update: t: 932, loss: 21011.4453125
[INFO] Global_t: 932, Episode_t: 2, Action: 174, Reward: 2.39, Epsilon: 0.53
[INFO] model update: t: 933, loss: 104823.765625
[INFO] Global_t: 933, Episode_t: 3, Action: 150, Reward: 1.88, Epsilon: 0.53
[INFO] model update: t: 934, loss: 47150.93359375
[INFO] Global_t: 934, Episode_t: 4, Action: 108, Reward: 2.11, Epsilon: 0.53
[INFO] model update: t: 935, loss: 15768.396484375
[INFO] Global_t: 935, Episode_t: 5, Action: 93, Reward: 2.13, Epsilon: 0.53
[INFO] model update: t: 936, loss: 59127.890625
[INFO] Global_t: 936, Episode_t: 6, Action: 199, Reward: 1.09, Epsilon: 0.53
[INFO] Global step: 936, Cumulative rewards: 12.285240000000002, Runtime (s): 811.50
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4255328178405762
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5383548736572266
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3635096549987793
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4788739681243896
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4422144889831543
average cummulative reward vector is:  [0.06971947 0.06572269 0.07036995 0.06446589 0.07338172]
average cummulative reward is:  0.06873194250103236
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 156, nodes: 192, edges: 567
[INFO] model update: t: 937, loss: 35795.40625
[INFO] Global_t: 937, Episode_t: 1, Action: 123, Reward: 2.42, Epsilon: 0.53
[INFO] model update: t: 938, loss: 23968.58203125
[INFO] Global_t: 938, Episode_t: 2, Action: 102, Reward: 1.18, Epsilon: 0.53
[INFO] model update: t: 939, loss: 34281.87109375
[INFO] Global_t: 939, Episode_t: 3, Action: 46, Reward: 2.41, Epsilon: 0.53
[INFO] model update: t: 940, loss: 31968.28125
[INFO] Global_t: 940, Episode_t: 4, Action: 79, Reward: 1.36, Epsilon: 0.53
[INFO] model update: t: 941, loss: 43163.8359375
[INFO] Global_t: 941, Episode_t: 5, Action: 12, Reward: 1.95, Epsilon: 0.53
[INFO] model update: t: 942, loss: 34188.6640625
[INFO] Global_t: 942, Episode_t: 6, Action: 133, Reward: 1.79, Epsilon: 0.53
[INFO] Global step: 942, Cumulative rewards: 11.10216, Runtime (s): 820.65
--------------------------------------
 
graph: 157, nodes: 220, edges: 651
[INFO] model update: t: 943, loss: 64143.68359375
[INFO] Global_t: 943, Episode_t: 1, Action: 124, Reward: 2.15, Epsilon: 0.53
[INFO] model update: t: 944, loss: 35789.34375
[INFO] Global_t: 944, Episode_t: 2, Action: 79, Reward: 2.14, Epsilon: 0.53
[INFO] model update: t: 945, loss: 31191.30859375
[INFO] Global_t: 945, Episode_t: 3, Action: 133, Reward: 2.19, Epsilon: 0.53
[INFO] model update: t: 946, loss: 29884.93359375
[INFO] Global_t: 946, Episode_t: 4, Action: 56, Reward: 1.77, Epsilon: 0.53
[INFO] model update: t: 947, loss: 27943.41796875
[INFO] Global_t: 947, Episode_t: 5, Action: 167, Reward: 1.34, Epsilon: 0.53
[INFO] model update: t: 948, loss: 84281.8125
[INFO] Global_t: 948, Episode_t: 6, Action: 50, Reward: 2.19, Epsilon: 0.53
[INFO] Global step: 948, Cumulative rewards: 11.77872, Runtime (s): 822.82
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.572143316268921
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4474306106567383
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3430593013763428
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.319495439529419
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5418508052825928
average cummulative reward vector is:  [0.07614947 0.06149167 0.06910027 0.05601612 0.07445806]
average cummulative reward is:  0.0674431199172754
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 158, nodes: 209, edges: 618
[INFO] model update: t: 949, loss: 29454.611328125
[INFO] Global_t: 949, Episode_t: 1, Action: 63, Reward: 2.55, Epsilon: 0.53
[INFO] model update: t: 950, loss: 28395.5234375
[INFO] Global_t: 950, Episode_t: 2, Action: 12, Reward: 5.62, Epsilon: 0.52
[INFO] model update: t: 951, loss: 17444.5859375
[INFO] Global_t: 951, Episode_t: 3, Action: 46, Reward: 1.70, Epsilon: 0.52
[INFO] model update: t: 952, loss: 57949.25
[INFO] Global_t: 952, Episode_t: 4, Action: 39, Reward: 1.85, Epsilon: 0.52
[INFO] model update: t: 953, loss: 27554.185546875
[INFO] Global_t: 953, Episode_t: 5, Action: 158, Reward: 1.02, Epsilon: 0.52
[INFO] model update: t: 954, loss: 60077.70703125
[INFO] Global_t: 954, Episode_t: 6, Action: 1, Reward: 6.03, Epsilon: 0.52
[INFO] Global step: 954, Cumulative rewards: 18.76992, Runtime (s): 832.81
--------------------------------------
 
graph: 159, nodes: 191, edges: 564
[INFO] model update: t: 955, loss: 23207.125
[INFO] Global_t: 955, Episode_t: 1, Action: 56, Reward: 1.64, Epsilon: 0.52
[INFO] model update: t: 956, loss: 29613.80859375
[INFO] Global_t: 956, Episode_t: 2, Action: 52, Reward: 2.17, Epsilon: 0.52
[INFO] model update: t: 957, loss: 35806.6484375
[INFO] Global_t: 957, Episode_t: 3, Action: 157, Reward: 2.10, Epsilon: 0.52
[INFO] model update: t: 958, loss: 30387.03125
[INFO] Global_t: 958, Episode_t: 4, Action: 24, Reward: 2.24, Epsilon: 0.52
[INFO] model update: t: 959, loss: 93558.5625
[INFO] Global_t: 959, Episode_t: 5, Action: 74, Reward: 2.13, Epsilon: 0.52
[INFO] model update: t: 960, loss: 41400.4921875
[INFO] Global_t: 960, Episode_t: 6, Action: 27, Reward: 2.23, Epsilon: 0.52
[INFO] Global step: 960, Cumulative rewards: 12.518279999999999, Runtime (s): 834.46
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.259408950805664
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4329915046691895
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3860259056091309
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.463510274887085
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4367506504058838
average cummulative reward vector is:  [0.06050263 0.06101505 0.0713306  0.0592007  0.07258038]
average cummulative reward is:  0.06492587124936107
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 160, nodes: 220, edges: 650
[INFO] model update: t: 961, loss: 36841.15625
[INFO] Global_t: 961, Episode_t: 1, Action: 132, Reward: 2.51, Epsilon: 0.52
[INFO] model update: t: 962, loss: 81788.6953125
[INFO] Global_t: 962, Episode_t: 2, Action: 82, Reward: 2.38, Epsilon: 0.52
[INFO] model update: t: 963, loss: 23097.615234375
[INFO] Global_t: 963, Episode_t: 3, Action: 186, Reward: 2.27, Epsilon: 0.52
[INFO] model update: t: 964, loss: 44847.7890625
[INFO] Global_t: 964, Episode_t: 4, Action: 204, Reward: 1.91, Epsilon: 0.52
[INFO] model update: t: 965, loss: 38082.25390625
[INFO] Global_t: 965, Episode_t: 5, Action: 71, Reward: 1.92, Epsilon: 0.52
[INFO] model update: t: 966, loss: 25034.8984375
[INFO] Global_t: 966, Episode_t: 6, Action: 131, Reward: 2.07, Epsilon: 0.52
[INFO] Global step: 966, Cumulative rewards: 13.070160000000001, Runtime (s): 843.16
--------------------------------------
 
graph: 161, nodes: 194, edges: 573
[INFO] model update: t: 967, loss: 21531.734375
[INFO] Global_t: 967, Episode_t: 1, Action: 102, Reward: 1.91, Epsilon: 0.52
[INFO] model update: t: 968, loss: 39208.7890625
[INFO] Global_t: 968, Episode_t: 2, Action: 91, Reward: 1.59, Epsilon: 0.52
[INFO] model update: t: 969, loss: 43965.8125
[INFO] Global_t: 969, Episode_t: 3, Action: 117, Reward: 1.52, Epsilon: 0.52
[INFO] model update: t: 970, loss: 20330.4921875
[INFO] Global_t: 970, Episode_t: 4, Action: 24, Reward: 2.36, Epsilon: 0.52
[INFO] model update: t: 971, loss: 55981.625
[INFO] Global_t: 971, Episode_t: 5, Action: 162, Reward: 1.92, Epsilon: 0.51
[INFO] model update: t: 972, loss: 43404.2734375
[INFO] Global_t: 972, Episode_t: 6, Action: 21, Reward: 2.26, Epsilon: 0.51
[INFO] Global step: 972, Cumulative rewards: 11.56608, Runtime (s): 844.84
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4345476627349854
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5239737033843994
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3446156978607178
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4295971393585205
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3032441139221191
average cummulative reward vector is:  [0.06907868 0.06480602 0.06924399 0.05819766 0.06483414]
average cummulative reward is:  0.06523209902728624
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 162, nodes: 191, edges: 564
[INFO] model update: t: 973, loss: 56614.796875
[INFO] Global_t: 973, Episode_t: 1, Action: 45, Reward: 2.28, Epsilon: 0.51
[INFO] model update: t: 974, loss: 24511.994140625
[INFO] Global_t: 974, Episode_t: 2, Action: 69, Reward: 2.08, Epsilon: 0.51
[INFO] model update: t: 975, loss: 76153.4453125
[INFO] Global_t: 975, Episode_t: 3, Action: 143, Reward: 2.09, Epsilon: 0.51
[INFO] model update: t: 976, loss: 29722.984375
[INFO] Global_t: 976, Episode_t: 4, Action: 188, Reward: 1.57, Epsilon: 0.51
[INFO] model update: t: 977, loss: 55322.9453125
[INFO] Global_t: 977, Episode_t: 5, Action: 8, Reward: 2.39, Epsilon: 0.51
[INFO] model update: t: 978, loss: 25504.94921875
[INFO] Global_t: 978, Episode_t: 6, Action: 46, Reward: 1.95, Epsilon: 0.51
[INFO] Global step: 978, Cumulative rewards: 12.3672, Runtime (s): 853.52
--------------------------------------
 
graph: 163, nodes: 213, edges: 629
[INFO] model update: t: 979, loss: 28227.0
[INFO] Global_t: 979, Episode_t: 1, Action: 71, Reward: 1.54, Epsilon: 0.51
[INFO] model update: t: 980, loss: 46677.2578125
[INFO] Global_t: 980, Episode_t: 2, Action: 67, Reward: 2.32, Epsilon: 0.51
[INFO] model update: t: 981, loss: 71260.0078125
[INFO] Global_t: 981, Episode_t: 3, Action: 29, Reward: 2.53, Epsilon: 0.51
[INFO] model update: t: 982, loss: 23528.34375
[INFO] Global_t: 982, Episode_t: 4, Action: 134, Reward: 2.30, Epsilon: 0.51
[INFO] model update: t: 983, loss: 51940.4453125
[INFO] Global_t: 983, Episode_t: 5, Action: 174, Reward: 2.14, Epsilon: 0.51
[INFO] model update: t: 984, loss: 40443.53515625
[INFO] Global_t: 984, Episode_t: 6, Action: 210, Reward: 1.86, Epsilon: 0.51
[INFO] Global step: 984, Cumulative rewards: 12.69108, Runtime (s): 854.97
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.449272632598877
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5217657089233398
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.310051441192627
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5105335712432861
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3125121593475342
average cummulative reward vector is:  [0.07064868 0.0654162  0.06683525 0.06207477 0.06581667]
average cummulative reward is:  0.06615831336753523
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 164, nodes: 182, edges: 537
[INFO] model update: t: 985, loss: 28131.505859375
[INFO] Global_t: 985, Episode_t: 1, Action: 21, Reward: 2.01, Epsilon: 0.51
[INFO] model update: t: 986, loss: 31413.484375
[INFO] Global_t: 986, Episode_t: 2, Action: 90, Reward: 1.23, Epsilon: 0.51
[INFO] model update: t: 987, loss: 33965.109375
[INFO] Global_t: 987, Episode_t: 3, Action: 20, Reward: 2.02, Epsilon: 0.51
[INFO] model update: t: 988, loss: 32019.845703125
[INFO] Global_t: 988, Episode_t: 4, Action: 22, Reward: 1.93, Epsilon: 0.51
[INFO] model update: t: 989, loss: 78084.640625
[INFO] Global_t: 989, Episode_t: 5, Action: 7, Reward: 2.65, Epsilon: 0.51
[INFO] model update: t: 990, loss: 22818.53515625
[INFO] Global_t: 990, Episode_t: 6, Action: 87, Reward: 1.49, Epsilon: 0.51
[INFO] Global step: 990, Cumulative rewards: 11.32644, Runtime (s): 864.01
--------------------------------------
 
graph: 165, nodes: 180, edges: 531
[INFO] model update: t: 991, loss: 54240.15234375
[INFO] Global_t: 991, Episode_t: 1, Action: 136, Reward: 2.37, Epsilon: 0.50
[INFO] model update: t: 992, loss: 28714.8828125
[INFO] Global_t: 992, Episode_t: 2, Action: 141, Reward: 2.11, Epsilon: 0.50
[INFO] model update: t: 993, loss: 60025.3203125
[INFO] Global_t: 993, Episode_t: 3, Action: 35, Reward: 2.20, Epsilon: 0.50
[INFO] model update: t: 994, loss: 29612.90234375
[INFO] Global_t: 994, Episode_t: 4, Action: 24, Reward: 2.05, Epsilon: 0.50
[INFO] model update: t: 995, loss: 19062.6328125
[INFO] Global_t: 995, Episode_t: 5, Action: 46, Reward: 2.05, Epsilon: 0.50
[INFO] model update: t: 996, loss: 35847.7734375
[INFO] Global_t: 996, Episode_t: 6, Action: 145, Reward: 1.95, Epsilon: 0.50
[INFO] Global step: 996, Cumulative rewards: 12.724319999999999, Runtime (s): 865.75
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5367639064788818
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4516568183898926
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3802392482757568
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7797367572784424
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.398655891418457
average cummulative reward vector is:  [0.074935   0.06036713 0.06926967 0.07213621 0.06968602]
average cummulative reward is:  0.06927880764388492
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 166, nodes: 185, edges: 544
[INFO] model update: t: 997, loss: 81191.9609375
[INFO] Global_t: 997, Episode_t: 1, Action: 59, Reward: 1.88, Epsilon: 0.50
[INFO] model update: t: 998, loss: 24703.7890625
[INFO] Global_t: 998, Episode_t: 2, Action: 95, Reward: 1.94, Epsilon: 0.50
[INFO] model update: t: 999, loss: 37121.20703125
[INFO] Global_t: 999, Episode_t: 3, Action: 89, Reward: 1.35, Epsilon: 0.50
[INFO] model update: t: 1000, loss: 34200.55078125
[INFO] Global_t: 1000, Episode_t: 4, Action: 152, Reward: 1.26, Epsilon: 0.50
[INFO] model update: t: 1001, loss: 83579.21875
[INFO] Global_t: 1001, Episode_t: 5, Action: 32, Reward: 1.95, Epsilon: 0.50
[INFO] model update: t: 1002, loss: 31944.71484375
[INFO] Global_t: 1002, Episode_t: 6, Action: 9, Reward: 2.41, Epsilon: 0.50
[INFO] Global step: 1002, Cumulative rewards: 10.78872, Runtime (s): 875.17
--------------------------------------
 
graph: 167, nodes: 181, edges: 533
[INFO] model update: t: 1003, loss: 30446.08984375
[INFO] Global_t: 1003, Episode_t: 1, Action: 84, Reward: 1.26, Epsilon: 0.50
[INFO] model update: t: 1004, loss: 44272.3359375
[INFO] Global_t: 1004, Episode_t: 2, Action: 44, Reward: 2.36, Epsilon: 0.50
[INFO] model update: t: 1005, loss: 21378.142578125
[INFO] Global_t: 1005, Episode_t: 3, Action: 162, Reward: 1.22, Epsilon: 0.50
[INFO] model update: t: 1006, loss: 56723.453125
[INFO] Global_t: 1006, Episode_t: 4, Action: 95, Reward: 2.06, Epsilon: 0.50
[INFO] model update: t: 1007, loss: 21892.0546875
[INFO] Global_t: 1007, Episode_t: 5, Action: 81, Reward: 1.77, Epsilon: 0.50
[INFO] model update: t: 1008, loss: 46908.0
[INFO] Global_t: 1008, Episode_t: 6, Action: 144, Reward: 1.40, Epsilon: 0.50
[INFO] Global step: 1008, Cumulative rewards: 10.075680000000002, Runtime (s): 876.52
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.616241216659546
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5735411643981934
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4410121440887451
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3486342430114746
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3707146644592285
average cummulative reward vector is:  [0.07909947 0.06649583 0.06836257 0.05822033 0.06845   ]
average cummulative reward is:  0.06812564048527171
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 168, nodes: 201, edges: 594
[INFO] model update: t: 1009, loss: 38507.484375
[INFO] Global_t: 1009, Episode_t: 1, Action: 171, Reward: 1.54, Epsilon: 0.50
[INFO] model update: t: 1010, loss: 33392.33984375
[INFO] Global_t: 1010, Episode_t: 2, Action: 136, Reward: 1.71, Epsilon: 0.50
[INFO] model update: t: 1011, loss: 32614.251953125
[INFO] Global_t: 1011, Episode_t: 3, Action: 95, Reward: 2.21, Epsilon: 0.50
[INFO] model update: t: 1012, loss: 37763.03125
[INFO] Global_t: 1012, Episode_t: 4, Action: 129, Reward: 1.36, Epsilon: 0.49
[INFO] model update: t: 1013, loss: 54473.66796875
[INFO] Global_t: 1013, Episode_t: 5, Action: 87, Reward: 2.10, Epsilon: 0.49
[INFO] model update: t: 1014, loss: 59365.44921875
[INFO] Global_t: 1014, Episode_t: 6, Action: 109, Reward: 2.04, Epsilon: 0.49
[INFO] Global step: 1014, Cumulative rewards: 10.962719999999997, Runtime (s): 885.53
--------------------------------------
 
graph: 169, nodes: 215, edges: 635
[INFO] model update: t: 1015, loss: 63107.9609375
[INFO] Global_t: 1015, Episode_t: 1, Action: 187, Reward: 2.42, Epsilon: 0.49
[INFO] model update: t: 1016, loss: 18764.166015625
[INFO] Global_t: 1016, Episode_t: 2, Action: 213, Reward: 2.22, Epsilon: 0.49
[INFO] model update: t: 1017, loss: 24666.60546875
[INFO] Global_t: 1017, Episode_t: 3, Action: 39, Reward: 2.39, Epsilon: 0.49
[INFO] model update: t: 1018, loss: 33866.8671875
[INFO] Global_t: 1018, Episode_t: 4, Action: 195, Reward: 1.73, Epsilon: 0.49
[INFO] model update: t: 1019, loss: 34100.5390625
[INFO] Global_t: 1019, Episode_t: 5, Action: 92, Reward: 1.54, Epsilon: 0.49
[INFO] model update: t: 1020, loss: 22349.94140625
[INFO] Global_t: 1020, Episode_t: 6, Action: 145, Reward: 1.62, Epsilon: 0.49
[INFO] Global step: 1020, Cumulative rewards: 11.91996, Runtime (s): 887.47
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4035825729370117
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3941397666931152
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5381181240081787
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3944339752197266
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3604240417480469
average cummulative reward vector is:  [0.06838184 0.05915185 0.07434262 0.06100304 0.06871075]
average cummulative reward is:  0.06631802139585687
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 170, nodes: 206, edges: 609
[INFO] model update: t: 1021, loss: 36422.4609375
[INFO] Global_t: 1021, Episode_t: 1, Action: 45, Reward: 2.65, Epsilon: 0.49
[INFO] model update: t: 1022, loss: 27489.908203125
[INFO] Global_t: 1022, Episode_t: 2, Action: 196, Reward: 1.17, Epsilon: 0.49
[INFO] model update: t: 1023, loss: 46551.53515625
[INFO] Global_t: 1023, Episode_t: 3, Action: 69, Reward: 1.57, Epsilon: 0.49
[INFO] model update: t: 1024, loss: 35147.09765625
[INFO] Global_t: 1024, Episode_t: 4, Action: 25, Reward: 2.14, Epsilon: 0.49
[INFO] model update: t: 1025, loss: 28327.21875
[INFO] Global_t: 1025, Episode_t: 5, Action: 89, Reward: 1.16, Epsilon: 0.49
[INFO] model update: t: 1026, loss: 41616.2890625
[INFO] Global_t: 1026, Episode_t: 6, Action: 15, Reward: 2.22, Epsilon: 0.49
[INFO] Global step: 1026, Cumulative rewards: 10.913879999999999, Runtime (s): 896.59
--------------------------------------
 
graph: 171, nodes: 202, edges: 597
[INFO] model update: t: 1027, loss: 45394.328125
[INFO] Global_t: 1027, Episode_t: 1, Action: 160, Reward: 2.44, Epsilon: 0.49
[INFO] model update: t: 1028, loss: 46957.85546875
[INFO] Global_t: 1028, Episode_t: 2, Action: 144, Reward: 2.11, Epsilon: 0.49
[INFO] model update: t: 1029, loss: 38499.98828125
[INFO] Global_t: 1029, Episode_t: 3, Action: 83, Reward: 1.95, Epsilon: 0.49
[INFO] model update: t: 1030, loss: 39876.8671875
[INFO] Global_t: 1030, Episode_t: 4, Action: 6, Reward: 2.89, Epsilon: 0.49
[INFO] model update: t: 1031, loss: 38824.5234375
[INFO] Global_t: 1031, Episode_t: 5, Action: 52, Reward: 1.86, Epsilon: 0.49
[INFO] model update: t: 1032, loss: 52644.9921875
[INFO] Global_t: 1032, Episode_t: 6, Action: 10, Reward: 2.51, Epsilon: 0.48
[INFO] Global step: 1032, Cumulative rewards: 13.768679999999998, Runtime (s): 898.40
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5052878856658936
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4016122817993164
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3720500469207764
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2090091705322266
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5336039066314697
average cummulative reward vector is:  [0.07394395 0.05908773 0.06382869 0.05097991 0.07863656]
average cummulative reward is:  0.06529536661126675
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 172, nodes: 206, edges: 609
[INFO] model update: t: 1033, loss: 28167.048828125
[INFO] Global_t: 1033, Episode_t: 1, Action: 58, Reward: 3.40, Epsilon: 0.48
[INFO] model update: t: 1034, loss: 30143.4296875
[INFO] Global_t: 1034, Episode_t: 2, Action: 20, Reward: 3.08, Epsilon: 0.48
[INFO] model update: t: 1035, loss: 46448.96875
[INFO] Global_t: 1035, Episode_t: 3, Action: 15, Reward: 2.85, Epsilon: 0.48
[INFO] model update: t: 1036, loss: 14625.8154296875
[INFO] Global_t: 1036, Episode_t: 4, Action: 21, Reward: 3.04, Epsilon: 0.48
[INFO] model update: t: 1037, loss: 53949.99609375
[INFO] Global_t: 1037, Episode_t: 5, Action: 140, Reward: 1.77, Epsilon: 0.48
[INFO] model update: t: 1038, loss: 44059.91796875
[INFO] Global_t: 1038, Episode_t: 6, Action: 97, Reward: 1.31, Epsilon: 0.48
[INFO] Global step: 1038, Cumulative rewards: 15.45876, Runtime (s): 907.66
--------------------------------------
 
graph: 173, nodes: 217, edges: 641
[INFO] model update: t: 1039, loss: 32836.6484375
[INFO] Global_t: 1039, Episode_t: 1, Action: 74, Reward: 3.19, Epsilon: 0.48
[INFO] model update: t: 1040, loss: 37495.5078125
[INFO] Global_t: 1040, Episode_t: 2, Action: 193, Reward: 2.69, Epsilon: 0.48
[INFO] model update: t: 1041, loss: 43337.2734375
[INFO] Global_t: 1041, Episode_t: 3, Action: 37, Reward: 2.74, Epsilon: 0.48
[INFO] model update: t: 1042, loss: 20351.6875
[INFO] Global_t: 1042, Episode_t: 4, Action: 58, Reward: 2.13, Epsilon: 0.48
[INFO] model update: t: 1043, loss: 36991.16796875
[INFO] Global_t: 1043, Episode_t: 5, Action: 114, Reward: 2.31, Epsilon: 0.48
[INFO] model update: t: 1044, loss: 24042.26171875
[INFO] Global_t: 1044, Episode_t: 6, Action: 48, Reward: 2.42, Epsilon: 0.48
[INFO] Global step: 1044, Cumulative rewards: 15.47064, Runtime (s): 909.69
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.369354486465454
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6302053928375244
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4198393821716309
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.334402322769165
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.29941987991333
average cummulative reward vector is:  [0.06694737 0.06521829 0.07011311 0.05644089 0.06480457]
average cummulative reward is:  0.06470484559102568
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 174, nodes: 217, edges: 640
[INFO] model update: t: 1045, loss: 25367.0859375
[INFO] Global_t: 1045, Episode_t: 1, Action: 147, Reward: 1.30, Epsilon: 0.48
[INFO] model update: t: 1046, loss: 16896.51953125
[INFO] Global_t: 1046, Episode_t: 2, Action: 65, Reward: 2.43, Epsilon: 0.48
[INFO] model update: t: 1047, loss: 27620.0703125
[INFO] Global_t: 1047, Episode_t: 3, Action: 159, Reward: 2.04, Epsilon: 0.48
[INFO] model update: t: 1048, loss: 19079.8671875
[INFO] Global_t: 1048, Episode_t: 4, Action: 48, Reward: 1.96, Epsilon: 0.48
[INFO] model update: t: 1049, loss: 45970.16015625
[INFO] Global_t: 1049, Episode_t: 5, Action: 155, Reward: 0.94, Epsilon: 0.48
[INFO] model update: t: 1050, loss: 26230.24609375
[INFO] Global_t: 1050, Episode_t: 6, Action: 195, Reward: 1.21, Epsilon: 0.48
[INFO] Global step: 1050, Cumulative rewards: 9.87852, Runtime (s): 918.34
--------------------------------------
 
graph: 175, nodes: 200, edges: 591
[INFO] model update: t: 1051, loss: 14866.0107421875
[INFO] Global_t: 1051, Episode_t: 1, Action: 91, Reward: 2.28, Epsilon: 0.48
[INFO] model update: t: 1052, loss: 42743.5859375
[INFO] Global_t: 1052, Episode_t: 2, Action: 176, Reward: 1.16, Epsilon: 0.48
[INFO] model update: t: 1053, loss: 39968.01953125
[INFO] Global_t: 1053, Episode_t: 3, Action: 138, Reward: 1.59, Epsilon: 0.47
[INFO] model update: t: 1054, loss: 28269.30078125
[INFO] Global_t: 1054, Episode_t: 4, Action: 194, Reward: 1.54, Epsilon: 0.47
[INFO] model update: t: 1055, loss: 57798.6953125
[INFO] Global_t: 1055, Episode_t: 5, Action: 172, Reward: 1.78, Epsilon: 0.47
[INFO] model update: t: 1056, loss: 50851.109375
[INFO] Global_t: 1056, Episode_t: 6, Action: 43, Reward: 2.56, Epsilon: 0.47
[INFO] Global step: 1056, Cumulative rewards: 10.92144, Runtime (s): 920.00
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5387609004974365
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7094855308532715
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3651483058929443
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4282402992248535
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4092626571655273
average cummulative reward vector is:  [0.07557947 0.06979028 0.06968525 0.06210164 0.07147151]
average cummulative reward is:  0.06972562765079808
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 176, nodes: 180, edges: 531
[INFO] model update: t: 1057, loss: 18838.4140625
[INFO] Global_t: 1057, Episode_t: 1, Action: 156, Reward: 1.20, Epsilon: 0.47
[INFO] model update: t: 1058, loss: 40996.765625
[INFO] Global_t: 1058, Episode_t: 2, Action: 63, Reward: 2.18, Epsilon: 0.47
[INFO] model update: t: 1059, loss: 37692.4765625
[INFO] Global_t: 1059, Episode_t: 3, Action: 129, Reward: 2.08, Epsilon: 0.47
[INFO] model update: t: 1060, loss: 42959.375
[INFO] Global_t: 1060, Episode_t: 4, Action: 23, Reward: 1.99, Epsilon: 0.47
[INFO] model update: t: 1061, loss: 41215.9609375
[INFO] Global_t: 1061, Episode_t: 5, Action: 15, Reward: 2.61, Epsilon: 0.47
[INFO] model update: t: 1062, loss: 15645.69140625
[INFO] Global_t: 1062, Episode_t: 6, Action: 7, Reward: 2.34, Epsilon: 0.47
[INFO] Global step: 1062, Cumulative rewards: 12.410639999999997, Runtime (s): 929.18
--------------------------------------
 
graph: 177, nodes: 192, edges: 567
[INFO] model update: t: 1063, loss: 43499.3984375
[INFO] Global_t: 1063, Episode_t: 1, Action: 116, Reward: 2.24, Epsilon: 0.47
[INFO] model update: t: 1064, loss: 33715.31640625
[INFO] Global_t: 1064, Episode_t: 2, Action: 26, Reward: 2.33, Epsilon: 0.47
[INFO] model update: t: 1065, loss: 22764.6015625
[INFO] Global_t: 1065, Episode_t: 3, Action: 30, Reward: 3.26, Epsilon: 0.47
[INFO] model update: t: 1066, loss: 55059.2421875
[INFO] Global_t: 1066, Episode_t: 4, Action: 12, Reward: 3.73, Epsilon: 0.47
[INFO] model update: t: 1067, loss: 60570.61328125
[INFO] Global_t: 1067, Episode_t: 5, Action: 3, Reward: 4.73, Epsilon: 0.47
[INFO] model update: t: 1068, loss: 24746.58984375
[INFO] Global_t: 1068, Episode_t: 6, Action: 150, Reward: 1.03, Epsilon: 0.47
[INFO] Global step: 1068, Cumulative rewards: 17.321640000000002, Runtime (s): 931.78
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5816447734832764
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4002587795257568
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.308117151260376
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4342327117919922
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2850918769836426
average cummulative reward vector is:  [0.07330237 0.05978264 0.06696503 0.06312196 0.06482849]
average cummulative reward is:  0.06560009837456485
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 178, nodes: 209, edges: 618
[INFO] model update: t: 1069, loss: 145600.28125
[INFO] Global_t: 1069, Episode_t: 1, Action: 112, Reward: 2.35, Epsilon: 0.47
[INFO] model update: t: 1070, loss: 43180.421875
[INFO] Global_t: 1070, Episode_t: 2, Action: 102, Reward: 2.24, Epsilon: 0.47
[INFO] model update: t: 1071, loss: 85688.0
[INFO] Global_t: 1071, Episode_t: 3, Action: 51, Reward: 2.07, Epsilon: 0.47
[INFO] model update: t: 1072, loss: 63615.51953125
[INFO] Global_t: 1072, Episode_t: 4, Action: 80, Reward: 2.01, Epsilon: 0.47
[INFO] model update: t: 1073, loss: 14805.6181640625
[INFO] Global_t: 1073, Episode_t: 5, Action: 84, Reward: 1.72, Epsilon: 0.46
[INFO] model update: t: 1074, loss: 45530.52734375
[INFO] Global_t: 1074, Episode_t: 6, Action: 107, Reward: 2.19, Epsilon: 0.46
[INFO] Global step: 1074, Cumulative rewards: 12.57972, Runtime (s): 940.81
--------------------------------------
 
graph: 179, nodes: 205, edges: 606
[INFO] model update: t: 1075, loss: 54735.61328125
[INFO] Global_t: 1075, Episode_t: 1, Action: 119, Reward: 1.94, Epsilon: 0.46
[INFO] model update: t: 1076, loss: 39216.515625
[INFO] Global_t: 1076, Episode_t: 2, Action: 151, Reward: 2.60, Epsilon: 0.46
[INFO] model update: t: 1077, loss: 62398.125
[INFO] Global_t: 1077, Episode_t: 3, Action: 46, Reward: 2.20, Epsilon: 0.46
[INFO] model update: t: 1078, loss: 69046.9296875
[INFO] Global_t: 1078, Episode_t: 4, Action: 100, Reward: 1.85, Epsilon: 0.46
[INFO] model update: t: 1079, loss: 24796.41796875
[INFO] Global_t: 1079, Episode_t: 5, Action: 12, Reward: 2.15, Epsilon: 0.46
[INFO] model update: t: 1080, loss: 83633.515625
[INFO] Global_t: 1080, Episode_t: 6, Action: 85, Reward: 1.96, Epsilon: 0.46
[INFO] Global step: 1080, Cumulative rewards: 12.70056, Runtime (s): 942.47
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5490469932556152
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4766263961791992
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.265005350112915
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4184787273406982
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.31984281539917
average cummulative reward vector is:  [0.07758026 0.06248449 0.06260219 0.06104369 0.06645054]
average cummulative reward is:  0.06603223378283576
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 180, nodes: 202, edges: 596
[INFO] model update: t: 1081, loss: 48483.0625
[INFO] Global_t: 1081, Episode_t: 1, Action: 196, Reward: 1.30, Epsilon: 0.46
[INFO] model update: t: 1082, loss: 47884.921875
[INFO] Global_t: 1082, Episode_t: 2, Action: 66, Reward: 2.27, Epsilon: 0.46
[INFO] model update: t: 1083, loss: 98925.875
[INFO] Global_t: 1083, Episode_t: 3, Action: 90, Reward: 1.54, Epsilon: 0.46
[INFO] model update: t: 1084, loss: 33711.86328125
[INFO] Global_t: 1084, Episode_t: 4, Action: 51, Reward: 2.04, Epsilon: 0.46
[INFO] model update: t: 1085, loss: 122372.2734375
[INFO] Global_t: 1085, Episode_t: 5, Action: 163, Reward: 1.84, Epsilon: 0.46
[INFO] model update: t: 1086, loss: 23703.359375
[INFO] Global_t: 1086, Episode_t: 6, Action: 84, Reward: 1.78, Epsilon: 0.46
[INFO] Global step: 1086, Cumulative rewards: 10.775520000000002, Runtime (s): 951.15
--------------------------------------
 
graph: 181, nodes: 205, edges: 606
[INFO] model update: t: 1087, loss: 31872.25
[INFO] Global_t: 1087, Episode_t: 1, Action: 78, Reward: 2.63, Epsilon: 0.46
[INFO] model update: t: 1088, loss: 113727.078125
[INFO] Global_t: 1088, Episode_t: 2, Action: 106, Reward: 2.57, Epsilon: 0.46
[INFO] model update: t: 1089, loss: 18059.50390625
[INFO] Global_t: 1089, Episode_t: 3, Action: 115, Reward: 2.54, Epsilon: 0.46
[INFO] model update: t: 1090, loss: 24470.4453125
[INFO] Global_t: 1090, Episode_t: 4, Action: 182, Reward: 1.75, Epsilon: 0.46
[INFO] model update: t: 1091, loss: 30026.634765625
[INFO] Global_t: 1091, Episode_t: 5, Action: 89, Reward: 1.81, Epsilon: 0.46
[INFO] model update: t: 1092, loss: 48308.78125
[INFO] Global_t: 1092, Episode_t: 6, Action: 150, Reward: 1.43, Epsilon: 0.46
[INFO] Global step: 1092, Cumulative rewards: 12.7344, Runtime (s): 953.35
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2859532833099365
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3360965251922607
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4216382503509521
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4708123207092285
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.489259958267212
average cummulative reward vector is:  [0.06050658 0.05270718 0.06864235 0.06099229 0.0688828 ]
average cummulative reward is:  0.06234623800372423
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 182, nodes: 205, edges: 606
[INFO] model update: t: 1093, loss: 49272.0078125
[INFO] Global_t: 1093, Episode_t: 1, Action: 9, Reward: 2.65, Epsilon: 0.45
[INFO] model update: t: 1094, loss: 52438.0
[INFO] Global_t: 1094, Episode_t: 2, Action: 103, Reward: 2.24, Epsilon: 0.45
[INFO] model update: t: 1095, loss: 63303.3125
[INFO] Global_t: 1095, Episode_t: 3, Action: 90, Reward: 2.59, Epsilon: 0.45
[INFO] model update: t: 1096, loss: 35624.30078125
[INFO] Global_t: 1096, Episode_t: 4, Action: 85, Reward: 2.05, Epsilon: 0.45
[INFO] model update: t: 1097, loss: 135601.5
[INFO] Global_t: 1097, Episode_t: 5, Action: 178, Reward: 1.19, Epsilon: 0.45
[INFO] model update: t: 1098, loss: 34321.80859375
[INFO] Global_t: 1098, Episode_t: 6, Action: 19, Reward: 1.80, Epsilon: 0.45
[INFO] Global step: 1098, Cumulative rewards: 12.51924, Runtime (s): 962.45
--------------------------------------
 
graph: 183, nodes: 217, edges: 642
[INFO] model update: t: 1099, loss: 36525.453125
[INFO] Global_t: 1099, Episode_t: 1, Action: 29, Reward: 2.86, Epsilon: 0.45
[INFO] model update: t: 1100, loss: 28334.8203125
[INFO] Global_t: 1100, Episode_t: 2, Action: 197, Reward: 1.34, Epsilon: 0.45
[INFO] model update: t: 1101, loss: 37751.3828125
[INFO] Global_t: 1101, Episode_t: 3, Action: 72, Reward: 2.30, Epsilon: 0.45
[INFO] model update: t: 1102, loss: 64986.203125
[INFO] Global_t: 1102, Episode_t: 4, Action: 198, Reward: 1.14, Epsilon: 0.45
[INFO] model update: t: 1103, loss: 38962.2578125
[INFO] Global_t: 1103, Episode_t: 5, Action: 62, Reward: 2.23, Epsilon: 0.45
[INFO] model update: t: 1104, loss: 82109.1796875
[INFO] Global_t: 1104, Episode_t: 6, Action: 121, Reward: 1.98, Epsilon: 0.45
[INFO] Global step: 1104, Cumulative rewards: 11.846639999999999, Runtime (s): 964.75
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.2819526195526123
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6252660751342773
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3175711631774902
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3990018367767334
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3781712055206299
average cummulative reward vector is:  [0.06063053 0.0685537  0.06597568 0.05889626 0.06726452]
average cummulative reward is:  0.06426413817817553
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 184, nodes: 196, edges: 579
[INFO] model update: t: 1105, loss: 41313.65625
[INFO] Global_t: 1105, Episode_t: 1, Action: 81, Reward: 2.44, Epsilon: 0.45
[INFO] model update: t: 1106, loss: 52350.37890625
[INFO] Global_t: 1106, Episode_t: 2, Action: 92, Reward: 2.42, Epsilon: 0.45
[INFO] model update: t: 1107, loss: 42046.94140625
[INFO] Global_t: 1107, Episode_t: 3, Action: 23, Reward: 2.94, Epsilon: 0.45
[INFO] model update: t: 1108, loss: 48931.24609375
[INFO] Global_t: 1108, Episode_t: 4, Action: 5, Reward: 3.74, Epsilon: 0.45
[INFO] model update: t: 1109, loss: 59137.609375
[INFO] Global_t: 1109, Episode_t: 5, Action: 84, Reward: 1.42, Epsilon: 0.45
[INFO] model update: t: 1110, loss: 32406.87890625
[INFO] Global_t: 1110, Episode_t: 6, Action: 112, Reward: 1.53, Epsilon: 0.45
[INFO] Global step: 1110, Cumulative rewards: 14.47548, Runtime (s): 974.43
--------------------------------------
 
graph: 185, nodes: 180, edges: 530
[INFO] model update: t: 1111, loss: 25536.736328125
[INFO] Global_t: 1111, Episode_t: 1, Action: 162, Reward: 1.46, Epsilon: 0.45
[INFO] model update: t: 1112, loss: 48514.0703125
[INFO] Global_t: 1112, Episode_t: 2, Action: 82, Reward: 2.28, Epsilon: 0.45
[INFO] model update: t: 1113, loss: 27628.72265625
[INFO] Global_t: 1113, Episode_t: 3, Action: 131, Reward: 1.32, Epsilon: 0.45
[INFO] model update: t: 1114, loss: 48359.4375
[INFO] Global_t: 1114, Episode_t: 4, Action: 159, Reward: 1.79, Epsilon: 0.44
[INFO] model update: t: 1115, loss: 61673.875
[INFO] Global_t: 1115, Episode_t: 5, Action: 25, Reward: 2.85, Epsilon: 0.44
[INFO] model update: t: 1116, loss: 30019.32421875
[INFO] Global_t: 1116, Episode_t: 6, Action: 9, Reward: 1.93, Epsilon: 0.44
[INFO] Global step: 1116, Cumulative rewards: 11.637839999999999, Runtime (s): 975.98
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3816704750061035
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.477447271347046
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.482245683670044
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4524037837982178
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4975697994232178
average cummulative reward vector is:  [0.06452421 0.06146968 0.07502049 0.0625014  0.07518253]
average cummulative reward is:  0.06773966140127993
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 186, nodes: 210, edges: 621
[INFO] model update: t: 1117, loss: 18920.759765625
[INFO] Global_t: 1117, Episode_t: 1, Action: 192, Reward: 2.49, Epsilon: 0.44
[INFO] model update: t: 1118, loss: 103158.625
[INFO] Global_t: 1118, Episode_t: 2, Action: 70, Reward: 2.09, Epsilon: 0.44
[INFO] model update: t: 1119, loss: 40147.57421875
[INFO] Global_t: 1119, Episode_t: 3, Action: 69, Reward: 1.96, Epsilon: 0.44
[INFO] model update: t: 1120, loss: 51479.875
[INFO] Global_t: 1120, Episode_t: 4, Action: 152, Reward: 1.19, Epsilon: 0.44
[INFO] model update: t: 1121, loss: 38031.8203125
[INFO] Global_t: 1121, Episode_t: 5, Action: 38, Reward: 2.00, Epsilon: 0.44
[INFO] model update: t: 1122, loss: 46288.44140625
[INFO] Global_t: 1122, Episode_t: 6, Action: 93, Reward: 2.14, Epsilon: 0.44
[INFO] Global step: 1122, Cumulative rewards: 11.867399999999996, Runtime (s): 985.39
--------------------------------------
 
graph: 187, nodes: 210, edges: 621
[INFO] model update: t: 1123, loss: 39900.13671875
[INFO] Global_t: 1123, Episode_t: 1, Action: 171, Reward: 2.92, Epsilon: 0.44
[INFO] model update: t: 1124, loss: 31170.068359375
[INFO] Global_t: 1124, Episode_t: 2, Action: 43, Reward: 2.97, Epsilon: 0.44
[INFO] model update: t: 1125, loss: 48176.64453125
[INFO] Global_t: 1125, Episode_t: 3, Action: 90, Reward: 3.15, Epsilon: 0.44
[INFO] model update: t: 1126, loss: 48310.984375
[INFO] Global_t: 1126, Episode_t: 4, Action: 199, Reward: 1.70, Epsilon: 0.44
[INFO] model update: t: 1127, loss: 23178.92578125
[INFO] Global_t: 1127, Episode_t: 5, Action: 9, Reward: 2.24, Epsilon: 0.44
[INFO] model update: t: 1128, loss: 79500.4609375
[INFO] Global_t: 1128, Episode_t: 6, Action: 18, Reward: 1.97, Epsilon: 0.44
[INFO] Global step: 1128, Cumulative rewards: 14.938200000000002, Runtime (s): 987.53
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.506467342376709
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3253023624420166
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3973469734191895
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.355409860610962
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3677926063537598
average cummulative reward vector is:  [0.06940605 0.0542581  0.07043087 0.05701589 0.06139489]
average cummulative reward is:  0.06250116182479123
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 188, nodes: 198, edges: 585
[INFO] model update: t: 1129, loss: 81251.9921875
[INFO] Global_t: 1129, Episode_t: 1, Action: 39, Reward: 2.30, Epsilon: 0.44
[INFO] model update: t: 1130, loss: 67136.640625
[INFO] Global_t: 1130, Episode_t: 2, Action: 84, Reward: 2.20, Epsilon: 0.44
[INFO] model update: t: 1131, loss: 123216.3515625
[INFO] Global_t: 1131, Episode_t: 3, Action: 9, Reward: 2.44, Epsilon: 0.44
[INFO] model update: t: 1132, loss: 95598.6796875
[INFO] Global_t: 1132, Episode_t: 4, Action: 94, Reward: 1.91, Epsilon: 0.44
[INFO] model update: t: 1133, loss: 112139.3359375
[INFO] Global_t: 1133, Episode_t: 5, Action: 20, Reward: 2.40, Epsilon: 0.44
[INFO] model update: t: 1134, loss: 58318.828125
[INFO] Global_t: 1134, Episode_t: 6, Action: 173, Reward: 1.10, Epsilon: 0.43
[INFO] Global step: 1134, Cumulative rewards: 12.347639999999998, Runtime (s): 996.66
--------------------------------------
 
graph: 189, nodes: 180, edges: 531
[INFO] model update: t: 1135, loss: 37023.08984375
[INFO] Global_t: 1135, Episode_t: 1, Action: 51, Reward: 2.48, Epsilon: 0.43
[INFO] model update: t: 1136, loss: 91283.96875
[INFO] Global_t: 1136, Episode_t: 2, Action: 119, Reward: 2.38, Epsilon: 0.43
[INFO] model update: t: 1137, loss: 35778.9921875
[INFO] Global_t: 1137, Episode_t: 3, Action: 154, Reward: 1.22, Epsilon: 0.43
[INFO] model update: t: 1138, loss: 68545.375
[INFO] Global_t: 1138, Episode_t: 4, Action: 142, Reward: 1.15, Epsilon: 0.43
[INFO] model update: t: 1139, loss: 112977.328125
[INFO] Global_t: 1139, Episode_t: 5, Action: 133, Reward: 1.55, Epsilon: 0.43
[INFO] model update: t: 1140, loss: 25174.65234375
[INFO] Global_t: 1140, Episode_t: 6, Action: 41, Reward: 1.88, Epsilon: 0.43
[INFO] Global step: 1140, Cumulative rewards: 10.664399999999997, Runtime (s): 998.62
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5815019607543945
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4929604530334473
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4160385131835938
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4833130836486816
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2999498844146729
average cummulative reward vector is:  [0.07821842 0.06228565 0.07194098 0.05863925 0.06518548]
average cummulative reward is:  0.0672539578029507
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 190, nodes: 194, edges: 573
[INFO] model update: t: 1141, loss: 110121.84375
[INFO] Global_t: 1141, Episode_t: 1, Action: 26, Reward: 3.63, Epsilon: 0.43
[INFO] model update: t: 1142, loss: 28169.576171875
[INFO] Global_t: 1142, Episode_t: 2, Action: 116, Reward: 1.95, Epsilon: 0.43
[INFO] model update: t: 1143, loss: 19465.212890625
[INFO] Global_t: 1143, Episode_t: 3, Action: 21, Reward: 2.39, Epsilon: 0.43
[INFO] model update: t: 1144, loss: 71786.15625
[INFO] Global_t: 1144, Episode_t: 4, Action: 154, Reward: 1.55, Epsilon: 0.43
[INFO] model update: t: 1145, loss: 67772.078125
[INFO] Global_t: 1145, Episode_t: 5, Action: 17, Reward: 2.11, Epsilon: 0.43
[INFO] model update: t: 1146, loss: 47052.62109375
[INFO] Global_t: 1146, Episode_t: 6, Action: 47, Reward: 2.26, Epsilon: 0.43
[INFO] Global step: 1146, Cumulative rewards: 13.9038, Runtime (s): 1007.96
--------------------------------------
 
graph: 191, nodes: 183, edges: 539
[INFO] model update: t: 1147, loss: 16699.10546875
[INFO] Global_t: 1147, Episode_t: 1, Action: 27, Reward: 2.55, Epsilon: 0.43
[INFO] model update: t: 1148, loss: 26145.041015625
[INFO] Global_t: 1148, Episode_t: 2, Action: 39, Reward: 2.41, Epsilon: 0.43
[INFO] model update: t: 1149, loss: 30040.51953125
[INFO] Global_t: 1149, Episode_t: 3, Action: 50, Reward: 2.43, Epsilon: 0.43
[INFO] model update: t: 1150, loss: 47026.5625
[INFO] Global_t: 1150, Episode_t: 4, Action: 168, Reward: 1.88, Epsilon: 0.43
[INFO] model update: t: 1151, loss: 39635.5546875
[INFO] Global_t: 1151, Episode_t: 5, Action: 11, Reward: 2.10, Epsilon: 0.43
[INFO] model update: t: 1152, loss: 30939.4375
[INFO] Global_t: 1152, Episode_t: 6, Action: 16, Reward: 2.84, Epsilon: 0.43
[INFO] Global step: 1152, Cumulative rewards: 14.21904, Runtime (s): 1009.71
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4139904975891113
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4510042667388916
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3685874938964844
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5400440692901611
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.355668067932129
average cummulative reward vector is:  [0.068625   0.06102593 0.07003934 0.06231565 0.06744247]
average cummulative reward is:  0.06588967950242161
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 192, nodes: 214, edges: 633
[INFO] model update: t: 1153, loss: 29264.63671875
[INFO] Global_t: 1153, Episode_t: 1, Action: 12, Reward: 3.72, Epsilon: 0.43
[INFO] model update: t: 1154, loss: 29045.51171875
[INFO] Global_t: 1154, Episode_t: 2, Action: 170, Reward: 1.37, Epsilon: 0.43
[INFO] model update: t: 1155, loss: 49406.01171875
[INFO] Global_t: 1155, Episode_t: 3, Action: 36, Reward: 2.85, Epsilon: 0.42
[INFO] model update: t: 1156, loss: 15167.9775390625
[INFO] Global_t: 1156, Episode_t: 4, Action: 59, Reward: 1.95, Epsilon: 0.42
[INFO] model update: t: 1157, loss: 43315.15625
[INFO] Global_t: 1157, Episode_t: 5, Action: 38, Reward: 2.42, Epsilon: 0.42
[INFO] model update: t: 1158, loss: 25699.1171875
[INFO] Global_t: 1158, Episode_t: 6, Action: 45, Reward: 2.22, Epsilon: 0.42
[INFO] Global step: 1158, Cumulative rewards: 14.53452, Runtime (s): 1019.02
--------------------------------------
 
graph: 193, nodes: 218, edges: 645
[INFO] model update: t: 1159, loss: 31422.37890625
[INFO] Global_t: 1159, Episode_t: 1, Action: 80, Reward: 2.75, Epsilon: 0.42
[INFO] model update: t: 1160, loss: 22206.27734375
[INFO] Global_t: 1160, Episode_t: 2, Action: 120, Reward: 2.35, Epsilon: 0.42
[INFO] model update: t: 1161, loss: 20084.525390625
[INFO] Global_t: 1161, Episode_t: 3, Action: 82, Reward: 2.00, Epsilon: 0.42
[INFO] model update: t: 1162, loss: 23200.5625
[INFO] Global_t: 1162, Episode_t: 4, Action: 116, Reward: 0.71, Epsilon: 0.42
[INFO] model update: t: 1163, loss: 21133.537109375
[INFO] Global_t: 1163, Episode_t: 5, Action: 15, Reward: 2.66, Epsilon: 0.42
[INFO] model update: t: 1164, loss: 27494.5625
[INFO] Global_t: 1164, Episode_t: 6, Action: 112, Reward: 2.20, Epsilon: 0.42
[INFO] Global step: 1164, Cumulative rewards: 12.677880000000002, Runtime (s): 1021.14
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6091699600219727
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5952999591827393
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3994708061218262
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3027758598327637
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3814170360565186
average cummulative reward vector is:  [0.07934921 0.06820231 0.06564754 0.05539977 0.06837688]
average cummulative reward is:  0.0673951428800615
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 194, nodes: 213, edges: 630
[INFO] model update: t: 1165, loss: 47179.88671875
[INFO] Global_t: 1165, Episode_t: 1, Action: 63, Reward: 2.67, Epsilon: 0.42
[INFO] model update: t: 1166, loss: 31396.400390625
[INFO] Global_t: 1166, Episode_t: 2, Action: 31, Reward: 2.74, Epsilon: 0.42
[INFO] model update: t: 1167, loss: 42420.12890625
[INFO] Global_t: 1167, Episode_t: 3, Action: 115, Reward: 1.53, Epsilon: 0.42
[INFO] model update: t: 1168, loss: 24666.30078125
[INFO] Global_t: 1168, Episode_t: 4, Action: 42, Reward: 2.08, Epsilon: 0.42
[INFO] model update: t: 1169, loss: 17473.8359375
[INFO] Global_t: 1169, Episode_t: 5, Action: 93, Reward: 2.18, Epsilon: 0.42
[INFO] model update: t: 1170, loss: 31974.88671875
[INFO] Global_t: 1170, Episode_t: 6, Action: 60, Reward: 2.30, Epsilon: 0.42
[INFO] Global step: 1170, Cumulative rewards: 13.494359999999997, Runtime (s): 1030.64
--------------------------------------
 
graph: 195, nodes: 189, edges: 558
[INFO] model update: t: 1171, loss: 31964.55859375
[INFO] Global_t: 1171, Episode_t: 1, Action: 27, Reward: 2.62, Epsilon: 0.42
[INFO] model update: t: 1172, loss: 61506.88671875
[INFO] Global_t: 1172, Episode_t: 2, Action: 31, Reward: 2.09, Epsilon: 0.42
[INFO] model update: t: 1173, loss: 34484.88671875
[INFO] Global_t: 1173, Episode_t: 3, Action: 155, Reward: 1.45, Epsilon: 0.42
[INFO] model update: t: 1174, loss: 20018.982421875
[INFO] Global_t: 1174, Episode_t: 4, Action: 37, Reward: 1.79, Epsilon: 0.42
[INFO] model update: t: 1175, loss: 15675.55078125
[INFO] Global_t: 1175, Episode_t: 5, Action: 130, Reward: 1.22, Epsilon: 0.41
[INFO] model update: t: 1176, loss: 21268.78125
[INFO] Global_t: 1176, Episode_t: 6, Action: 22, Reward: 2.12, Epsilon: 0.41
[INFO] Global step: 1176, Cumulative rewards: 11.27832, Runtime (s): 1032.57
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3172757625579834
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6517388820648193
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3403112888336182
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2924563884735107
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4265122413635254
average cummulative reward vector is:  [0.06273684 0.06302963 0.06857404 0.05503224 0.07211989]
average cummulative reward is:  0.06429853018290246
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 196, nodes: 208, edges: 615
[INFO] model update: t: 1177, loss: 38269.23046875
[INFO] Global_t: 1177, Episode_t: 1, Action: 144, Reward: 2.33, Epsilon: 0.41
[INFO] model update: t: 1178, loss: 31389.822265625
[INFO] Global_t: 1178, Episode_t: 2, Action: 112, Reward: 2.14, Epsilon: 0.41
[INFO] model update: t: 1179, loss: 19433.89453125
[INFO] Global_t: 1179, Episode_t: 3, Action: 36, Reward: 2.91, Epsilon: 0.41
[INFO] model update: t: 1180, loss: 53762.578125
[INFO] Global_t: 1180, Episode_t: 4, Action: 126, Reward: 1.71, Epsilon: 0.41
[INFO] model update: t: 1181, loss: 35463.4765625
[INFO] Global_t: 1181, Episode_t: 5, Action: 44, Reward: 1.90, Epsilon: 0.41
[INFO] model update: t: 1182, loss: 29457.3125
[INFO] Global_t: 1182, Episode_t: 6, Action: 138, Reward: 1.37, Epsilon: 0.41
[INFO] Global step: 1182, Cumulative rewards: 12.3612, Runtime (s): 1041.96
--------------------------------------
 
graph: 197, nodes: 197, edges: 582
[INFO] model update: t: 1183, loss: 33225.42578125
[INFO] Global_t: 1183, Episode_t: 1, Action: 120, Reward: 2.08, Epsilon: 0.41
[INFO] model update: t: 1184, loss: 23470.96484375
[INFO] Global_t: 1184, Episode_t: 2, Action: 66, Reward: 2.04, Epsilon: 0.41
[INFO] model update: t: 1185, loss: 62576.4375
[INFO] Global_t: 1185, Episode_t: 3, Action: 102, Reward: 2.12, Epsilon: 0.41
[INFO] model update: t: 1186, loss: 27048.65234375
[INFO] Global_t: 1186, Episode_t: 4, Action: 28, Reward: 2.15, Epsilon: 0.41
[INFO] model update: t: 1187, loss: 40893.0625
[INFO] Global_t: 1187, Episode_t: 5, Action: 72, Reward: 1.91, Epsilon: 0.41
[INFO] model update: t: 1188, loss: 28165.42578125
[INFO] Global_t: 1188, Episode_t: 6, Action: 17, Reward: 2.67, Epsilon: 0.41
[INFO] Global step: 1188, Cumulative rewards: 12.972719999999999, Runtime (s): 1043.55
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3388421535491943
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6696698665618896
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3909432888031006
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3451776504516602
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2939190864562988
average cummulative reward vector is:  [0.06423079 0.06592986 0.07099098 0.05759743 0.0641207 ]
average cummulative reward is:  0.06457395260452518
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 198, nodes: 187, edges: 552
[INFO] model update: t: 1189, loss: 23511.41796875
[INFO] Global_t: 1189, Episode_t: 1, Action: 18, Reward: 2.72, Epsilon: 0.41
[INFO] model update: t: 1190, loss: 35408.19140625
[INFO] Global_t: 1190, Episode_t: 2, Action: 3, Reward: 5.02, Epsilon: 0.41
[INFO] model update: t: 1191, loss: 38137.0390625
[INFO] Global_t: 1191, Episode_t: 3, Action: 91, Reward: 1.96, Epsilon: 0.41
[INFO] model update: t: 1192, loss: 46159.6484375
[INFO] Global_t: 1192, Episode_t: 4, Action: 142, Reward: 2.07, Epsilon: 0.41
[INFO] model update: t: 1193, loss: 30546.31640625
[INFO] Global_t: 1193, Episode_t: 5, Action: 36, Reward: 2.27, Epsilon: 0.41
[INFO] model update: t: 1194, loss: 18713.82421875
[INFO] Global_t: 1194, Episode_t: 6, Action: 24, Reward: 2.00, Epsilon: 0.41
[INFO] Global step: 1194, Cumulative rewards: 16.036320000000003, Runtime (s): 1052.57
--------------------------------------
 
graph: 199, nodes: 216, edges: 638
[INFO] model update: t: 1195, loss: 31458.19140625
[INFO] Global_t: 1195, Episode_t: 1, Action: 127, Reward: 2.04, Epsilon: 0.40
[INFO] model update: t: 1196, loss: 41394.5625
[INFO] Global_t: 1196, Episode_t: 2, Action: 170, Reward: 1.39, Epsilon: 0.40
[INFO] model update: t: 1197, loss: 32674.42578125
[INFO] Global_t: 1197, Episode_t: 3, Action: 110, Reward: 2.48, Epsilon: 0.40
[INFO] model update: t: 1198, loss: 40011.2578125
[INFO] Global_t: 1198, Episode_t: 4, Action: 180, Reward: 1.97, Epsilon: 0.40
[INFO] model update: t: 1199, loss: 19721.107421875
[INFO] Global_t: 1199, Episode_t: 5, Action: 73, Reward: 1.30, Epsilon: 0.40
[INFO] model update: t: 1200, loss: 40409.83203125
[INFO] Global_t: 1200, Episode_t: 6, Action: 215, Reward: 1.32, Epsilon: 0.40
[INFO] Global step: 1200, Cumulative rewards: 10.50696, Runtime (s): 1054.62
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5179696083068848
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4058315753936768
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4190852642059326
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2945101261138916
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3124001026153564
average cummulative reward vector is:  [0.06674579 0.06008657 0.07363497 0.05598738 0.06621344]
average cummulative reward is:  0.06453363205262781
----------------------------------------------end evaluation---------------------------------------------------------
 
epoch:  1
graph: 0, nodes: 180, edges: 531
[INFO] model update: t: 1201, loss: 30131.939453125
[INFO] Global_t: 1201, Episode_t: 1, Action: 51, Reward: 1.52, Epsilon: 0.40
[INFO] model update: t: 1202, loss: 31549.955078125
[INFO] Global_t: 1202, Episode_t: 2, Action: 165, Reward: 2.25, Epsilon: 0.40
[INFO] model update: t: 1203, loss: 30353.2578125
[INFO] Global_t: 1203, Episode_t: 3, Action: 122, Reward: 1.97, Epsilon: 0.40
[INFO] model update: t: 1204, loss: 21176.248046875
[INFO] Global_t: 1204, Episode_t: 4, Action: 80, Reward: 2.08, Epsilon: 0.40
[INFO] model update: t: 1205, loss: 28245.3359375
[INFO] Global_t: 1205, Episode_t: 5, Action: 56, Reward: 2.33, Epsilon: 0.40
[INFO] model update: t: 1206, loss: 34807.328125
[INFO] Global_t: 1206, Episode_t: 6, Action: 35, Reward: 1.50, Epsilon: 0.40
[INFO] Global step: 1206, Cumulative rewards: 11.651279999999998, Runtime (s): 1063.16
--------------------------------------
 
graph: 1, nodes: 217, edges: 642
[INFO] model update: t: 1207, loss: 61192.04296875
[INFO] Global_t: 1207, Episode_t: 1, Action: 47, Reward: 1.46, Epsilon: 0.40
[INFO] model update: t: 1208, loss: 35230.73828125
[INFO] Global_t: 1208, Episode_t: 2, Action: 26, Reward: 3.01, Epsilon: 0.40
[INFO] model update: t: 1209, loss: 77940.265625
[INFO] Global_t: 1209, Episode_t: 3, Action: 158, Reward: 2.44, Epsilon: 0.40
[INFO] model update: t: 1210, loss: 50686.359375
[INFO] Global_t: 1210, Episode_t: 4, Action: 200, Reward: 1.83, Epsilon: 0.40
[INFO] model update: t: 1211, loss: 26652.583984375
[INFO] Global_t: 1211, Episode_t: 5, Action: 122, Reward: 2.33, Epsilon: 0.40
[INFO] model update: t: 1212, loss: 21635.044921875
[INFO] Global_t: 1212, Episode_t: 6, Action: 16, Reward: 2.53, Epsilon: 0.40
[INFO] Global step: 1212, Cumulative rewards: 13.58136, Runtime (s): 1064.79
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5464146137237549
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5555965900421143
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3322787284851074
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.256453037261963
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.1649224758148193
average cummulative reward vector is:  [0.06996026 0.06674375 0.06774699 0.05414322 0.05728629]
average cummulative reward is:  0.06317610446301199
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 2, nodes: 220, edges: 651
[INFO] model update: t: 1213, loss: 28867.931640625
[INFO] Global_t: 1213, Episode_t: 1, Action: 85, Reward: 2.66, Epsilon: 0.40
[INFO] model update: t: 1214, loss: 23555.85546875
[INFO] Global_t: 1214, Episode_t: 2, Action: 124, Reward: 3.06, Epsilon: 0.40
[INFO] model update: t: 1215, loss: 44992.0859375
[INFO] Global_t: 1215, Episode_t: 3, Action: 194, Reward: 2.49, Epsilon: 0.40
[INFO] model update: t: 1216, loss: 29536.81640625
[INFO] Global_t: 1216, Episode_t: 4, Action: 49, Reward: 2.00, Epsilon: 0.39
[INFO] model update: t: 1217, loss: 19029.66015625
[INFO] Global_t: 1217, Episode_t: 5, Action: 177, Reward: 1.11, Epsilon: 0.39
[INFO] model update: t: 1218, loss: 30158.078125
[INFO] Global_t: 1218, Episode_t: 6, Action: 185, Reward: 1.77, Epsilon: 0.39
[INFO] Global step: 1218, Cumulative rewards: 13.098479999999999, Runtime (s): 1073.72
--------------------------------------
 
graph: 3, nodes: 204, edges: 603
[INFO] model update: t: 1219, loss: 32749.41015625
[INFO] Global_t: 1219, Episode_t: 1, Action: 30, Reward: 2.50, Epsilon: 0.39
[INFO] model update: t: 1220, loss: 34123.9375
[INFO] Global_t: 1220, Episode_t: 2, Action: 203, Reward: 2.41, Epsilon: 0.39
[INFO] model update: t: 1221, loss: 21335.64453125
[INFO] Global_t: 1221, Episode_t: 3, Action: 96, Reward: 2.51, Epsilon: 0.39
[INFO] model update: t: 1222, loss: 32638.12890625
[INFO] Global_t: 1222, Episode_t: 4, Action: 185, Reward: 2.19, Epsilon: 0.39
[INFO] model update: t: 1223, loss: 27472.728515625
[INFO] Global_t: 1223, Episode_t: 5, Action: 60, Reward: 1.95, Epsilon: 0.39
[INFO] model update: t: 1224, loss: 20211.30078125
[INFO] Global_t: 1224, Episode_t: 6, Action: 64, Reward: 1.48, Epsilon: 0.39
[INFO] Global step: 1224, Cumulative rewards: 13.03008, Runtime (s): 1075.65
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4983949661254883
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.532132863998413
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3115718364715576
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4727857112884521
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.408092737197876
average cummulative reward vector is:  [0.06461895 0.06524375 0.06689563 0.06493481 0.07155403]
average cummulative reward is:  0.06664943422517965
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 4, nodes: 185, edges: 546
[INFO] model update: t: 1225, loss: 23220.8671875
[INFO] Global_t: 1225, Episode_t: 1, Action: 180, Reward: 2.36, Epsilon: 0.39
[INFO] model update: t: 1226, loss: 40058.65234375
[INFO] Global_t: 1226, Episode_t: 2, Action: 176, Reward: 2.23, Epsilon: 0.39
[INFO] model update: t: 1227, loss: 43463.25
[INFO] Global_t: 1227, Episode_t: 3, Action: 2, Reward: 3.32, Epsilon: 0.39
[INFO] model update: t: 1228, loss: 34613.515625
[INFO] Global_t: 1228, Episode_t: 4, Action: 160, Reward: 1.53, Epsilon: 0.39
[INFO] model update: t: 1229, loss: 51131.359375
[INFO] Global_t: 1229, Episode_t: 5, Action: 72, Reward: 1.86, Epsilon: 0.39
[INFO] model update: t: 1230, loss: 74632.8125
[INFO] Global_t: 1230, Episode_t: 6, Action: 57, Reward: 1.96, Epsilon: 0.39
[INFO] Global step: 1230, Cumulative rewards: 13.257719999999997, Runtime (s): 1084.90
--------------------------------------
 
graph: 5, nodes: 215, edges: 636
[INFO] model update: t: 1231, loss: 18837.4140625
[INFO] Global_t: 1231, Episode_t: 1, Action: 137, Reward: 1.54, Epsilon: 0.39
[INFO] model update: t: 1232, loss: 20735.552734375
[INFO] Global_t: 1232, Episode_t: 2, Action: 89, Reward: 2.38, Epsilon: 0.39
[INFO] model update: t: 1233, loss: 21535.74609375
[INFO] Global_t: 1233, Episode_t: 3, Action: 169, Reward: 2.20, Epsilon: 0.39
[INFO] model update: t: 1234, loss: 48823.1875
[INFO] Global_t: 1234, Episode_t: 4, Action: 152, Reward: 1.14, Epsilon: 0.39
[INFO] model update: t: 1235, loss: 19584.9375
[INFO] Global_t: 1235, Episode_t: 5, Action: 78, Reward: 1.64, Epsilon: 0.39
[INFO] model update: t: 1236, loss: 22514.80859375
[INFO] Global_t: 1236, Episode_t: 6, Action: 104, Reward: 1.46, Epsilon: 0.38
[INFO] Global step: 1236, Cumulative rewards: 10.363919999999998, Runtime (s): 1086.92
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4154102802276611
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5206286907196045
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.258211612701416
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4257464408874512
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3051979541778564
average cummulative reward vector is:  [0.06983158 0.06483519 0.06433989 0.06270304 0.06623065]
average cummulative reward is:  0.0655880674774808
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 6, nodes: 190, edges: 560
[INFO] model update: t: 1237, loss: 59484.1484375
[INFO] Global_t: 1237, Episode_t: 1, Action: 121, Reward: 2.40, Epsilon: 0.38
[INFO] model update: t: 1238, loss: 31302.197265625
[INFO] Global_t: 1238, Episode_t: 2, Action: 56, Reward: 2.01, Epsilon: 0.38
[INFO] model update: t: 1239, loss: 46064.5078125
[INFO] Global_t: 1239, Episode_t: 3, Action: 172, Reward: 2.18, Epsilon: 0.38
[INFO] model update: t: 1240, loss: 42239.40625
[INFO] Global_t: 1240, Episode_t: 4, Action: 5, Reward: 3.82, Epsilon: 0.38
[INFO] model update: t: 1241, loss: 81449.203125
[INFO] Global_t: 1241, Episode_t: 5, Action: 24, Reward: 1.87, Epsilon: 0.38
[INFO] model update: t: 1242, loss: 45855.01953125
[INFO] Global_t: 1242, Episode_t: 6, Action: 20, Reward: 1.46, Epsilon: 0.38
[INFO] Global step: 1242, Cumulative rewards: 13.736640000000001, Runtime (s): 1095.89
--------------------------------------
 
graph: 7, nodes: 184, edges: 542
[INFO] model update: t: 1243, loss: 27181.240234375
[INFO] Global_t: 1243, Episode_t: 1, Action: 82, Reward: 2.00, Epsilon: 0.38
[INFO] model update: t: 1244, loss: 59825.9453125
[INFO] Global_t: 1244, Episode_t: 2, Action: 171, Reward: 2.00, Epsilon: 0.38
[INFO] model update: t: 1245, loss: 46951.12890625
[INFO] Global_t: 1245, Episode_t: 3, Action: 26, Reward: 2.16, Epsilon: 0.38
[INFO] model update: t: 1246, loss: 62408.6484375
[INFO] Global_t: 1246, Episode_t: 4, Action: 98, Reward: 1.17, Epsilon: 0.38
[INFO] model update: t: 1247, loss: 59368.23828125
[INFO] Global_t: 1247, Episode_t: 5, Action: 61, Reward: 1.63, Epsilon: 0.38
[INFO] model update: t: 1248, loss: 21484.66015625
[INFO] Global_t: 1248, Episode_t: 6, Action: 1, Reward: 2.45, Epsilon: 0.38
[INFO] Global step: 1248, Cumulative rewards: 11.39772, Runtime (s): 1097.51
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5073630809783936
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5984292030334473
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2729640007019043
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2384140491485596
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.332587480545044
average cummulative reward vector is:  [0.07369211 0.06849792 0.06487486 0.04998575 0.06402742]
average cummulative reward is:  0.06421561046723856
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 8, nodes: 183, edges: 540
[INFO] model update: t: 1249, loss: 55740.31640625
[INFO] Global_t: 1249, Episode_t: 1, Action: 64, Reward: 2.12, Epsilon: 0.38
[INFO] model update: t: 1250, loss: 35943.41015625
[INFO] Global_t: 1250, Episode_t: 2, Action: 15, Reward: 2.17, Epsilon: 0.38
[INFO] model update: t: 1251, loss: 38218.03515625
[INFO] Global_t: 1251, Episode_t: 3, Action: 170, Reward: 2.18, Epsilon: 0.38
[INFO] model update: t: 1252, loss: 40629.5
[INFO] Global_t: 1252, Episode_t: 4, Action: 134, Reward: 1.37, Epsilon: 0.38
[INFO] model update: t: 1253, loss: 32555.625
[INFO] Global_t: 1253, Episode_t: 5, Action: 92, Reward: 1.67, Epsilon: 0.38
[INFO] model update: t: 1254, loss: 60471.7734375
[INFO] Global_t: 1254, Episode_t: 6, Action: 14, Reward: 1.86, Epsilon: 0.38
[INFO] Global step: 1254, Cumulative rewards: 11.372039999999998, Runtime (s): 1105.99
--------------------------------------
 
graph: 9, nodes: 208, edges: 614
[INFO] model update: t: 1255, loss: 20350.052734375
[INFO] Global_t: 1255, Episode_t: 1, Action: 44, Reward: 2.51, Epsilon: 0.38
[INFO] model update: t: 1256, loss: 21027.751953125
[INFO] Global_t: 1256, Episode_t: 2, Action: 68, Reward: 2.05, Epsilon: 0.38
[INFO] model update: t: 1257, loss: 26907.87109375
[INFO] Global_t: 1257, Episode_t: 3, Action: 16, Reward: 2.87, Epsilon: 0.37
[INFO] model update: t: 1258, loss: 47259.39453125
[INFO] Global_t: 1258, Episode_t: 4, Action: 113, Reward: 1.79, Epsilon: 0.37
[INFO] model update: t: 1259, loss: 38771.5
[INFO] Global_t: 1259, Episode_t: 5, Action: 102, Reward: 1.99, Epsilon: 0.37
[INFO] model update: t: 1260, loss: 53257.453125
[INFO] Global_t: 1260, Episode_t: 6, Action: 29, Reward: 2.16, Epsilon: 0.37
[INFO] Global step: 1260, Cumulative rewards: 13.369319999999998, Runtime (s): 1108.26
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4450218677520752
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6946003437042236
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.443779468536377
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4696097373962402
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4020450115203857
average cummulative reward vector is:  [0.07106763 0.07302731 0.07537022 0.0645243  0.07088629]
average cummulative reward is:  0.07097515087219967
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 10, nodes: 189, edges: 558
[INFO] model update: t: 1261, loss: 39184.3125
[INFO] Global_t: 1261, Episode_t: 1, Action: 159, Reward: 1.50, Epsilon: 0.37
[INFO] model update: t: 1262, loss: 32991.37109375
[INFO] Global_t: 1262, Episode_t: 2, Action: 45, Reward: 2.06, Epsilon: 0.37
[INFO] model update: t: 1263, loss: 51054.1875
[INFO] Global_t: 1263, Episode_t: 3, Action: 33, Reward: 2.01, Epsilon: 0.37
[INFO] model update: t: 1264, loss: 36241.4921875
[INFO] Global_t: 1264, Episode_t: 4, Action: 17, Reward: 2.70, Epsilon: 0.37
[INFO] model update: t: 1265, loss: 40989.6328125
[INFO] Global_t: 1265, Episode_t: 5, Action: 40, Reward: 2.03, Epsilon: 0.37
[INFO] model update: t: 1266, loss: 40602.87109375
[INFO] Global_t: 1266, Episode_t: 6, Action: 170, Reward: 0.94, Epsilon: 0.37
[INFO] Global step: 1266, Cumulative rewards: 11.2374, Runtime (s): 1117.54
--------------------------------------
 
graph: 11, nodes: 205, edges: 606
[INFO] model update: t: 1267, loss: 36669.33203125
[INFO] Global_t: 1267, Episode_t: 1, Action: 81, Reward: 1.61, Epsilon: 0.37
[INFO] model update: t: 1268, loss: 45019.4453125
[INFO] Global_t: 1268, Episode_t: 2, Action: 77, Reward: 2.52, Epsilon: 0.37
[INFO] model update: t: 1269, loss: 39919.91015625
[INFO] Global_t: 1269, Episode_t: 3, Action: 96, Reward: 2.40, Epsilon: 0.37
[INFO] model update: t: 1270, loss: 19952.6171875
[INFO] Global_t: 1270, Episode_t: 4, Action: 78, Reward: 1.62, Epsilon: 0.37
[INFO] model update: t: 1271, loss: 47401.4765625
[INFO] Global_t: 1271, Episode_t: 5, Action: 52, Reward: 1.93, Epsilon: 0.37
[INFO] model update: t: 1272, loss: 45995.0625
[INFO] Global_t: 1272, Episode_t: 6, Action: 127, Reward: 0.85, Epsilon: 0.37
[INFO] Global step: 1272, Cumulative rewards: 10.92324, Runtime (s): 1119.41
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5249519348144531
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7226285934448242
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3840327262878418
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.380086898803711
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4645819664001465
average cummulative reward vector is:  [0.07220658 0.07201759 0.06830191 0.05732173 0.07214624]
average cummulative reward is:  0.06839880992787388
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 12, nodes: 191, edges: 564
[INFO] model update: t: 1273, loss: 74848.40625
[INFO] Global_t: 1273, Episode_t: 1, Action: 3, Reward: 6.81, Epsilon: 0.37
[INFO] model update: t: 1274, loss: 40018.95703125
[INFO] Global_t: 1274, Episode_t: 2, Action: 144, Reward: 1.12, Epsilon: 0.37
[INFO] model update: t: 1275, loss: 87054.2265625
[INFO] Global_t: 1275, Episode_t: 3, Action: 169, Reward: 1.35, Epsilon: 0.37
[INFO] model update: t: 1276, loss: 32279.49609375
[INFO] Global_t: 1276, Episode_t: 4, Action: 127, Reward: 2.26, Epsilon: 0.37
[INFO] model update: t: 1277, loss: 23973.97265625
[INFO] Global_t: 1277, Episode_t: 5, Action: 107, Reward: 1.80, Epsilon: 0.36
[INFO] model update: t: 1278, loss: 45056.72265625
[INFO] Global_t: 1278, Episode_t: 6, Action: 37, Reward: 2.21, Epsilon: 0.36
[INFO] Global step: 1278, Cumulative rewards: 15.54384, Runtime (s): 1129.13
--------------------------------------
 
graph: 13, nodes: 198, edges: 585
[INFO] model update: t: 1279, loss: 22996.201171875
[INFO] Global_t: 1279, Episode_t: 1, Action: 68, Reward: 3.28, Epsilon: 0.36
[INFO] model update: t: 1280, loss: 26834.11328125
[INFO] Global_t: 1280, Episode_t: 2, Action: 96, Reward: 2.14, Epsilon: 0.36
[INFO] model update: t: 1281, loss: 19793.833984375
[INFO] Global_t: 1281, Episode_t: 3, Action: 56, Reward: 2.38, Epsilon: 0.36
[INFO] model update: t: 1282, loss: 18479.41015625
[INFO] Global_t: 1282, Episode_t: 4, Action: 57, Reward: 1.89, Epsilon: 0.36
[INFO] model update: t: 1283, loss: 27767.73046875
[INFO] Global_t: 1283, Episode_t: 5, Action: 80, Reward: 1.56, Epsilon: 0.36
[INFO] model update: t: 1284, loss: 20539.72265625
[INFO] Global_t: 1284, Episode_t: 6, Action: 23, Reward: 1.64, Epsilon: 0.36
[INFO] Global step: 1284, Cumulative rewards: 12.89424, Runtime (s): 1131.23
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4804246425628662
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4431662559509277
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3912832736968994
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2622272968292236
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5078558921813965
average cummulative reward vector is:  [0.07094526 0.06054213 0.07213989 0.05436495 0.07286129]
average cummulative reward is:  0.06617070541830311
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 14, nodes: 204, edges: 603
[INFO] model update: t: 1285, loss: 21134.60546875
[INFO] Global_t: 1285, Episode_t: 1, Action: 93, Reward: 2.62, Epsilon: 0.36
[INFO] model update: t: 1286, loss: 44681.0625
[INFO] Global_t: 1286, Episode_t: 2, Action: 10, Reward: 3.48, Epsilon: 0.36
[INFO] model update: t: 1287, loss: 18210.517578125
[INFO] Global_t: 1287, Episode_t: 3, Action: 72, Reward: 1.74, Epsilon: 0.36
[INFO] model update: t: 1288, loss: 24163.361328125
[INFO] Global_t: 1288, Episode_t: 4, Action: 11, Reward: 4.13, Epsilon: 0.36
[INFO] model update: t: 1289, loss: 9522.974609375
[INFO] Global_t: 1289, Episode_t: 5, Action: 1, Reward: 2.55, Epsilon: 0.36
[INFO] model update: t: 1290, loss: 53642.86328125
[INFO] Global_t: 1290, Episode_t: 6, Action: 109, Reward: 1.93, Epsilon: 0.36
[INFO] Global step: 1290, Cumulative rewards: 16.45188, Runtime (s): 1140.45
--------------------------------------
 
graph: 15, nodes: 188, edges: 555
[INFO] model update: t: 1291, loss: 23736.763671875
[INFO] Global_t: 1291, Episode_t: 1, Action: 114, Reward: 1.82, Epsilon: 0.36
[INFO] model update: t: 1292, loss: 31491.58984375
[INFO] Global_t: 1292, Episode_t: 2, Action: 32, Reward: 2.19, Epsilon: 0.36
[INFO] model update: t: 1293, loss: 24237.16015625
[INFO] Global_t: 1293, Episode_t: 3, Action: 87, Reward: 2.01, Epsilon: 0.36
[INFO] model update: t: 1294, loss: 8463.93359375
[INFO] Global_t: 1294, Episode_t: 4, Action: 99, Reward: 1.54, Epsilon: 0.36
[INFO] model update: t: 1295, loss: 33701.6875
[INFO] Global_t: 1295, Episode_t: 5, Action: 15, Reward: 2.91, Epsilon: 0.36
[INFO] model update: t: 1296, loss: 26799.53515625
[INFO] Global_t: 1296, Episode_t: 6, Action: 21, Reward: 2.44, Epsilon: 0.36
[INFO] Global step: 1296, Cumulative rewards: 12.9012, Runtime (s): 1142.18
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7091784477233887
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6494536399841309
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4087891578674316
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4706270694732666
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2130756378173828
average cummulative reward vector is:  [0.08290737 0.07079097 0.0733582  0.06046168 0.06030995]
average cummulative reward is:  0.06956563316882722
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 16, nodes: 185, edges: 546
[INFO] model update: t: 1297, loss: 15081.5126953125
[INFO] Global_t: 1297, Episode_t: 1, Action: 58, Reward: 2.84, Epsilon: 0.35
[INFO] model update: t: 1298, loss: 16860.5234375
[INFO] Global_t: 1298, Episode_t: 2, Action: 82, Reward: 2.86, Epsilon: 0.35
[INFO] model update: t: 1299, loss: 41121.2578125
[INFO] Global_t: 1299, Episode_t: 3, Action: 99, Reward: 2.10, Epsilon: 0.35
[INFO] model update: t: 1300, loss: 29003.697265625
[INFO] Global_t: 1300, Episode_t: 4, Action: 183, Reward: 2.47, Epsilon: 0.35
[INFO] model update: t: 1301, loss: 20539.005859375
[INFO] Global_t: 1301, Episode_t: 5, Action: 85, Reward: 3.10, Epsilon: 0.35
[INFO] model update: t: 1302, loss: 19241.697265625
[INFO] Global_t: 1302, Episode_t: 6, Action: 149, Reward: 2.45, Epsilon: 0.35
[INFO] Global step: 1302, Cumulative rewards: 15.815039999999998, Runtime (s): 1151.20
--------------------------------------
 
graph: 17, nodes: 195, edges: 576
[INFO] model update: t: 1303, loss: 15310.6015625
[INFO] Global_t: 1303, Episode_t: 1, Action: 3, Reward: 3.51, Epsilon: 0.35
[INFO] model update: t: 1304, loss: 26628.333984375
[INFO] Global_t: 1304, Episode_t: 2, Action: 37, Reward: 2.55, Epsilon: 0.35
[INFO] model update: t: 1305, loss: 28341.869140625
[INFO] Global_t: 1305, Episode_t: 3, Action: 4, Reward: 4.28, Epsilon: 0.35
[INFO] model update: t: 1306, loss: 28611.15625
[INFO] Global_t: 1306, Episode_t: 4, Action: 2, Reward: 1.85, Epsilon: 0.35
[INFO] model update: t: 1307, loss: 24863.048828125
[INFO] Global_t: 1307, Episode_t: 5, Action: 14, Reward: 1.52, Epsilon: 0.35
[INFO] model update: t: 1308, loss: 25821.74609375
[INFO] Global_t: 1308, Episode_t: 6, Action: 25, Reward: 2.00, Epsilon: 0.35
[INFO] Global step: 1308, Cumulative rewards: 15.7074, Runtime (s): 1153.16
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.3328273296356201
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4834811687469482
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3900563716888428
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.428755521774292
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.270813226699829
average cummulative reward vector is:  [0.06473395 0.06318542 0.0716429  0.05886799 0.06379839]
average cummulative reward is:  0.06444572759218618
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 18, nodes: 199, edges: 588
[INFO] model update: t: 1309, loss: 49280.1640625
[INFO] Global_t: 1309, Episode_t: 1, Action: 104, Reward: 2.64, Epsilon: 0.35
[INFO] model update: t: 1310, loss: 39361.8828125
[INFO] Global_t: 1310, Episode_t: 2, Action: 130, Reward: 1.56, Epsilon: 0.35
[INFO] model update: t: 1311, loss: 16942.58203125
[INFO] Global_t: 1311, Episode_t: 3, Action: 7, Reward: 3.64, Epsilon: 0.35
[INFO] model update: t: 1312, loss: 32993.07421875
[INFO] Global_t: 1312, Episode_t: 4, Action: 174, Reward: 1.59, Epsilon: 0.35
[INFO] model update: t: 1313, loss: 25346.08203125
[INFO] Global_t: 1313, Episode_t: 5, Action: 121, Reward: 1.47, Epsilon: 0.35
[INFO] model update: t: 1314, loss: 26727.375
[INFO] Global_t: 1314, Episode_t: 6, Action: 67, Reward: 2.01, Epsilon: 0.35
[INFO] Global step: 1314, Cumulative rewards: 12.916200000000003, Runtime (s): 1162.18
--------------------------------------
 
graph: 19, nodes: 209, edges: 617
[INFO] model update: t: 1315, loss: 38257.90625
[INFO] Global_t: 1315, Episode_t: 1, Action: 150, Reward: 1.73, Epsilon: 0.35
[INFO] model update: t: 1316, loss: 23669.701171875
[INFO] Global_t: 1316, Episode_t: 2, Action: 5, Reward: 2.57, Epsilon: 0.35
[INFO] model update: t: 1317, loss: 34398.296875
[INFO] Global_t: 1317, Episode_t: 3, Action: 191, Reward: 2.52, Epsilon: 0.35
[INFO] model update: t: 1318, loss: 39806.9765625
[INFO] Global_t: 1318, Episode_t: 4, Action: 207, Reward: 0.97, Epsilon: 0.34
[INFO] model update: t: 1319, loss: 27234.49609375
[INFO] Global_t: 1319, Episode_t: 5, Action: 98, Reward: 2.26, Epsilon: 0.34
[INFO] model update: t: 1320, loss: 81857.484375
[INFO] Global_t: 1320, Episode_t: 6, Action: 29, Reward: 2.27, Epsilon: 0.34
[INFO] Global step: 1320, Cumulative rewards: 12.31956, Runtime (s): 1163.92
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5575988292694092
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4840540885925293
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4255521297454834
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.377835988998413
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5459649562835693
average cummulative reward vector is:  [0.076235   0.06300579 0.06928798 0.05974907 0.07980941]
average cummulative reward is:  0.06961744784036497
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 20, nodes: 215, edges: 636
[INFO] model update: t: 1321, loss: 41166.4921875
[INFO] Global_t: 1321, Episode_t: 1, Action: 127, Reward: 1.59, Epsilon: 0.34
[INFO] model update: t: 1322, loss: 68449.7734375
[INFO] Global_t: 1322, Episode_t: 2, Action: 122, Reward: 1.30, Epsilon: 0.34
[INFO] model update: t: 1323, loss: 21392.98828125
[INFO] Global_t: 1323, Episode_t: 3, Action: 145, Reward: 2.41, Epsilon: 0.34
[INFO] model update: t: 1324, loss: 31176.146484375
[INFO] Global_t: 1324, Episode_t: 4, Action: 95, Reward: 2.12, Epsilon: 0.34
[INFO] model update: t: 1325, loss: 55495.4765625
[INFO] Global_t: 1325, Episode_t: 5, Action: 21, Reward: 2.78, Epsilon: 0.34
[INFO] model update: t: 1326, loss: 11414.12890625
[INFO] Global_t: 1326, Episode_t: 6, Action: 184, Reward: 2.09, Epsilon: 0.34
[INFO] Global step: 1326, Cumulative rewards: 12.28896, Runtime (s): 1173.20
--------------------------------------
 
graph: 21, nodes: 189, edges: 558
[INFO] model update: t: 1327, loss: 92660.34375
[INFO] Global_t: 1327, Episode_t: 1, Action: 148, Reward: 2.15, Epsilon: 0.34
[INFO] model update: t: 1328, loss: 16657.009765625
[INFO] Global_t: 1328, Episode_t: 2, Action: 24, Reward: 2.55, Epsilon: 0.34
[INFO] model update: t: 1329, loss: 33584.984375
[INFO] Global_t: 1329, Episode_t: 3, Action: 122, Reward: 1.28, Epsilon: 0.34
[INFO] model update: t: 1330, loss: 10680.5263671875
[INFO] Global_t: 1330, Episode_t: 4, Action: 35, Reward: 2.27, Epsilon: 0.34
[INFO] model update: t: 1331, loss: 38900.0078125
[INFO] Global_t: 1331, Episode_t: 5, Action: 31, Reward: 2.00, Epsilon: 0.34
[INFO] model update: t: 1332, loss: 36680.35546875
[INFO] Global_t: 1332, Episode_t: 6, Action: 27, Reward: 2.18, Epsilon: 0.34
[INFO] Global step: 1332, Cumulative rewards: 12.433559999999998, Runtime (s): 1174.68
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6161251068115234
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6612682342529297
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4645509719848633
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.2559807300567627
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3315553665161133
average cummulative reward vector is:  [0.07829658 0.07099699 0.07175273 0.05436682 0.06751774]
average cummulative reward is:  0.06858617325878735
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 22, nodes: 184, edges: 543
[INFO] model update: t: 1333, loss: 31649.79296875
[INFO] Global_t: 1333, Episode_t: 1, Action: 139, Reward: 1.19, Epsilon: 0.34
[INFO] model update: t: 1334, loss: 44835.6328125
[INFO] Global_t: 1334, Episode_t: 2, Action: 182, Reward: 2.70, Epsilon: 0.34
[INFO] model update: t: 1335, loss: 20019.140625
[INFO] Global_t: 1335, Episode_t: 3, Action: 87, Reward: 1.87, Epsilon: 0.34
[INFO] model update: t: 1336, loss: 30487.6328125
[INFO] Global_t: 1336, Episode_t: 4, Action: 157, Reward: 2.17, Epsilon: 0.34
[INFO] model update: t: 1337, loss: 16862.828125
[INFO] Global_t: 1337, Episode_t: 5, Action: 98, Reward: 1.97, Epsilon: 0.34
[INFO] model update: t: 1338, loss: 54966.5390625
[INFO] Global_t: 1338, Episode_t: 6, Action: 101, Reward: 1.57, Epsilon: 0.33
[INFO] Global step: 1338, Cumulative rewards: 11.47272, Runtime (s): 1183.68
--------------------------------------
 
graph: 23, nodes: 199, edges: 588
[INFO] model update: t: 1339, loss: 25686.27734375
[INFO] Global_t: 1339, Episode_t: 1, Action: 43, Reward: 2.71, Epsilon: 0.33
[INFO] model update: t: 1340, loss: 33742.55859375
[INFO] Global_t: 1340, Episode_t: 2, Action: 82, Reward: 2.23, Epsilon: 0.33
[INFO] model update: t: 1341, loss: 23028.43359375
[INFO] Global_t: 1341, Episode_t: 3, Action: 110, Reward: 2.10, Epsilon: 0.33
[INFO] model update: t: 1342, loss: 30622.46484375
[INFO] Global_t: 1342, Episode_t: 4, Action: 10, Reward: 3.05, Epsilon: 0.33
[INFO] model update: t: 1343, loss: 24359.58203125
[INFO] Global_t: 1343, Episode_t: 5, Action: 22, Reward: 1.97, Epsilon: 0.33
[INFO] model update: t: 1344, loss: 27106.36328125
[INFO] Global_t: 1344, Episode_t: 6, Action: 133, Reward: 1.98, Epsilon: 0.33
[INFO] Global step: 1344, Cumulative rewards: 14.0412, Runtime (s): 1185.62
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6657767295837402
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7770378589630127
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4185194969177246
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.3402531147003174
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.380225419998169
average cummulative reward vector is:  [0.082625   0.07204676 0.07289645 0.05738341 0.07014677]
average cummulative reward is:  0.07101967855103852
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 24, nodes: 214, edges: 633
[INFO] model update: t: 1345, loss: 30689.626953125
[INFO] Global_t: 1345, Episode_t: 1, Action: 66, Reward: 2.25, Epsilon: 0.33
[INFO] model update: t: 1346, loss: 40514.7265625
[INFO] Global_t: 1346, Episode_t: 2, Action: 206, Reward: 1.46, Epsilon: 0.33
[INFO] model update: t: 1347, loss: 29947.865234375
[INFO] Global_t: 1347, Episode_t: 3, Action: 15, Reward: 2.76, Epsilon: 0.33
[INFO] model update: t: 1348, loss: 27581.21875
[INFO] Global_t: 1348, Episode_t: 4, Action: 91, Reward: 1.94, Epsilon: 0.33
[INFO] model update: t: 1349, loss: 24161.3828125
[INFO] Global_t: 1349, Episode_t: 5, Action: 22, Reward: 2.03, Epsilon: 0.33
[INFO] model update: t: 1350, loss: 45586.734375
[INFO] Global_t: 1350, Episode_t: 6, Action: 35, Reward: 2.35, Epsilon: 0.33
[INFO] Global step: 1350, Cumulative rewards: 12.8034, Runtime (s): 1194.66
--------------------------------------
 
graph: 25, nodes: 184, edges: 543
[INFO] model update: t: 1351, loss: 17311.93359375
[INFO] Global_t: 1351, Episode_t: 1, Action: 179, Reward: 2.53, Epsilon: 0.33
[INFO] model update: t: 1352, loss: 19499.58203125
[INFO] Global_t: 1352, Episode_t: 2, Action: 48, Reward: 2.37, Epsilon: 0.33
[INFO] model update: t: 1353, loss: 24461.435546875
[INFO] Global_t: 1353, Episode_t: 3, Action: 114, Reward: 2.37, Epsilon: 0.33
[INFO] model update: t: 1354, loss: 15252.591796875
[INFO] Global_t: 1354, Episode_t: 4, Action: 52, Reward: 1.77, Epsilon: 0.33
[INFO] model update: t: 1355, loss: 17313.064453125
[INFO] Global_t: 1355, Episode_t: 5, Action: 30, Reward: 2.13, Epsilon: 0.33
[INFO] model update: t: 1356, loss: 26183.8828125
[INFO] Global_t: 1356, Episode_t: 6, Action: 29, Reward: 1.91, Epsilon: 0.33
[INFO] Global step: 1356, Cumulative rewards: 13.088999999999999, Runtime (s): 1196.43
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5951964855194092
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.729529857635498
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.47930908203125
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.546769618988037
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3296825885772705
average cummulative reward vector is:  [0.07865526 0.0706375  0.07623005 0.06721589 0.06691102]
average cummulative reward is:  0.07192994543170943
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 26, nodes: 186, edges: 549
[INFO] model update: t: 1357, loss: 27563.76953125
[INFO] Global_t: 1357, Episode_t: 1, Action: 15, Reward: 2.72, Epsilon: 0.33
[INFO] model update: t: 1358, loss: 28929.36328125
[INFO] Global_t: 1358, Episode_t: 2, Action: 70, Reward: 2.49, Epsilon: 0.33
[INFO] model update: t: 1359, loss: 35381.3359375
[INFO] Global_t: 1359, Episode_t: 3, Action: 168, Reward: 1.18, Epsilon: 0.32
[INFO] model update: t: 1360, loss: 34187.0234375
[INFO] Global_t: 1360, Episode_t: 4, Action: 7, Reward: 2.52, Epsilon: 0.32
[INFO] model update: t: 1361, loss: 31060.9375
[INFO] Global_t: 1361, Episode_t: 5, Action: 171, Reward: 1.77, Epsilon: 0.32
[INFO] model update: t: 1362, loss: 32128.27734375
[INFO] Global_t: 1362, Episode_t: 6, Action: 28, Reward: 2.27, Epsilon: 0.32
[INFO] Global step: 1362, Cumulative rewards: 12.96624, Runtime (s): 1205.97
--------------------------------------
 
graph: 27, nodes: 199, edges: 588
[INFO] model update: t: 1363, loss: 17444.130859375
[INFO] Global_t: 1363, Episode_t: 1, Action: 69, Reward: 1.96, Epsilon: 0.32
[INFO] model update: t: 1364, loss: 55690.51953125
[INFO] Global_t: 1364, Episode_t: 2, Action: 20, Reward: 3.00, Epsilon: 0.32
[INFO] model update: t: 1365, loss: 54285.87890625
[INFO] Global_t: 1365, Episode_t: 3, Action: 28, Reward: 2.13, Epsilon: 0.32
[INFO] model update: t: 1366, loss: 16396.748046875
[INFO] Global_t: 1366, Episode_t: 4, Action: 6, Reward: 3.60, Epsilon: 0.32
[INFO] model update: t: 1367, loss: 20321.9921875
[INFO] Global_t: 1367, Episode_t: 5, Action: 43, Reward: 1.84, Epsilon: 0.32
[INFO] model update: t: 1368, loss: 40934.515625
[INFO] Global_t: 1368, Episode_t: 6, Action: 7, Reward: 2.73, Epsilon: 0.32
[INFO] Global step: 1368, Cumulative rewards: 15.26136, Runtime (s): 1208.02
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8232762813568115
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5694398880004883
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3180444240570068
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.423400640487671
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2693028450012207
average cummulative reward vector is:  [0.08585211 0.06696458 0.0676194  0.05942967 0.06327231]
average cummulative reward is:  0.06862761444574968
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 28, nodes: 181, edges: 534
[INFO] model update: t: 1369, loss: 35480.01171875
[INFO] Global_t: 1369, Episode_t: 1, Action: 21, Reward: 3.81, Epsilon: 0.32
[INFO] model update: t: 1370, loss: 28179.712890625
[INFO] Global_t: 1370, Episode_t: 2, Action: 80, Reward: 1.80, Epsilon: 0.32
[INFO] model update: t: 1371, loss: 21171.986328125
[INFO] Global_t: 1371, Episode_t: 3, Action: 10, Reward: 2.51, Epsilon: 0.32
[INFO] model update: t: 1372, loss: 29151.70703125
[INFO] Global_t: 1372, Episode_t: 4, Action: 178, Reward: 0.99, Epsilon: 0.32
[INFO] model update: t: 1373, loss: 24816.0546875
[INFO] Global_t: 1373, Episode_t: 5, Action: 169, Reward: 2.05, Epsilon: 0.32
[INFO] model update: t: 1374, loss: 16579.625
[INFO] Global_t: 1374, Episode_t: 6, Action: 64, Reward: 1.85, Epsilon: 0.32
[INFO] Global step: 1374, Cumulative rewards: 13.01412, Runtime (s): 1217.36
--------------------------------------
 
graph: 29, nodes: 201, edges: 593
[INFO] model update: t: 1375, loss: 24701.58203125
[INFO] Global_t: 1375, Episode_t: 1, Action: 186, Reward: 2.63, Epsilon: 0.32
[INFO] model update: t: 1376, loss: 96850.578125
[INFO] Global_t: 1376, Episode_t: 2, Action: 8, Reward: 3.81, Epsilon: 0.32
[INFO] model update: t: 1377, loss: 39685.0390625
[INFO] Global_t: 1377, Episode_t: 3, Action: 16, Reward: 2.66, Epsilon: 0.32
[INFO] model update: t: 1378, loss: 51050.25
[INFO] Global_t: 1378, Episode_t: 4, Action: 161, Reward: 2.22, Epsilon: 0.32
[INFO] model update: t: 1379, loss: 20613.20703125
[INFO] Global_t: 1379, Episode_t: 5, Action: 194, Reward: 2.11, Epsilon: 0.31
[INFO] model update: t: 1380, loss: 27180.962890625
[INFO] Global_t: 1380, Episode_t: 6, Action: 175, Reward: 2.06, Epsilon: 0.31
[INFO] Global step: 1380, Cumulative rewards: 15.48696, Runtime (s): 1219.36
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8199331760406494
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6880371570587158
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2780468463897705
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.419510841369629
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2822649478912354
average cummulative reward vector is:  [0.09095158 0.07335185 0.06568579 0.0617507  0.06452581]
average cummulative reward is:  0.07125314610702789
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 30, nodes: 217, edges: 641
[INFO] model update: t: 1381, loss: 21878.4140625
[INFO] Global_t: 1381, Episode_t: 1, Action: 117, Reward: 2.15, Epsilon: 0.31
[INFO] model update: t: 1382, loss: 28767.216796875
[INFO] Global_t: 1382, Episode_t: 2, Action: 24, Reward: 2.56, Epsilon: 0.31
[INFO] model update: t: 1383, loss: 22053.615234375
[INFO] Global_t: 1383, Episode_t: 3, Action: 48, Reward: 2.17, Epsilon: 0.31
[INFO] model update: t: 1384, loss: 53942.0234375
[INFO] Global_t: 1384, Episode_t: 4, Action: 63, Reward: 2.07, Epsilon: 0.31
[INFO] model update: t: 1385, loss: 30590.314453125
[INFO] Global_t: 1385, Episode_t: 5, Action: 75, Reward: 1.97, Epsilon: 0.31
[INFO] model update: t: 1386, loss: 30455.28515625
[INFO] Global_t: 1386, Episode_t: 6, Action: 127, Reward: 1.35, Epsilon: 0.31
[INFO] Global step: 1386, Cumulative rewards: 12.2766, Runtime (s): 1228.70
--------------------------------------
 
graph: 31, nodes: 198, edges: 585
[INFO] model update: t: 1387, loss: 20907.798828125
[INFO] Global_t: 1387, Episode_t: 1, Action: 18, Reward: 2.84, Epsilon: 0.31
[INFO] model update: t: 1388, loss: 38609.98828125
[INFO] Global_t: 1388, Episode_t: 2, Action: 3, Reward: 5.00, Epsilon: 0.31
[INFO] model update: t: 1389, loss: 25870.177734375
[INFO] Global_t: 1389, Episode_t: 3, Action: 81, Reward: 2.17, Epsilon: 0.31
[INFO] model update: t: 1390, loss: 9259.115234375
[INFO] Global_t: 1390, Episode_t: 4, Action: 7, Reward: 1.80, Epsilon: 0.31
[INFO] model update: t: 1391, loss: 40787.4453125
[INFO] Global_t: 1391, Episode_t: 5, Action: 6, Reward: 2.98, Epsilon: 0.31
[INFO] model update: t: 1392, loss: 40920.90625
[INFO] Global_t: 1392, Episode_t: 6, Action: 89, Reward: 1.32, Epsilon: 0.31
[INFO] Global step: 1392, Cumulative rewards: 16.12212, Runtime (s): 1231.38
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.4843993186950684
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4280097484588623
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.314337968826294
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6043856143951416
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.478288173675537
average cummulative reward vector is:  [0.07245079 0.06076898 0.06750574 0.06980421 0.07597312]
average cummulative reward is:  0.06930056650942604
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 32, nodes: 203, edges: 599
[INFO] model update: t: 1393, loss: 64392.30078125
[INFO] Global_t: 1393, Episode_t: 1, Action: 101, Reward: 2.42, Epsilon: 0.31
[INFO] model update: t: 1394, loss: 51069.1171875
[INFO] Global_t: 1394, Episode_t: 2, Action: 36, Reward: 2.91, Epsilon: 0.31
[INFO] model update: t: 1395, loss: 48941.28125
[INFO] Global_t: 1395, Episode_t: 3, Action: 57, Reward: 2.40, Epsilon: 0.31
[INFO] model update: t: 1396, loss: 56732.6484375
[INFO] Global_t: 1396, Episode_t: 4, Action: 167, Reward: 2.01, Epsilon: 0.31
[INFO] model update: t: 1397, loss: 15658.3291015625
[INFO] Global_t: 1397, Episode_t: 5, Action: 109, Reward: 1.42, Epsilon: 0.31
[INFO] model update: t: 1398, loss: 41202.953125
[INFO] Global_t: 1398, Episode_t: 6, Action: 126, Reward: 1.85, Epsilon: 0.31
[INFO] Global step: 1398, Cumulative rewards: 13.025640000000001, Runtime (s): 1240.40
--------------------------------------
 
graph: 33, nodes: 200, edges: 591
[INFO] model update: t: 1399, loss: 31297.4765625
[INFO] Global_t: 1399, Episode_t: 1, Action: 134, Reward: 2.04, Epsilon: 0.30
[INFO] model update: t: 1400, loss: 20559.5078125
[INFO] Global_t: 1400, Episode_t: 2, Action: 192, Reward: 1.31, Epsilon: 0.30
[INFO] model update: t: 1401, loss: 25153.42578125
[INFO] Global_t: 1401, Episode_t: 3, Action: 9, Reward: 3.03, Epsilon: 0.30
[INFO] model update: t: 1402, loss: 36735.5078125
[INFO] Global_t: 1402, Episode_t: 4, Action: 8, Reward: 2.65, Epsilon: 0.30
[INFO] model update: t: 1403, loss: 32632.697265625
[INFO] Global_t: 1403, Episode_t: 5, Action: 123, Reward: 1.67, Epsilon: 0.30
[INFO] model update: t: 1404, loss: 29558.5390625
[INFO] Global_t: 1404, Episode_t: 6, Action: 27, Reward: 2.17, Epsilon: 0.30
[INFO] Global step: 1404, Cumulative rewards: 12.866039999999998, Runtime (s): 1242.12
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6522927284240723
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.631803274154663
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4240353107452393
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6681630611419678
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3069467544555664
average cummulative reward vector is:  [0.07925632 0.06860833 0.07086202 0.07260864 0.0660664 ]
average cummulative reward is:  0.07148034273800119
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 34, nodes: 213, edges: 630
[INFO] model update: t: 1405, loss: 24040.01953125
[INFO] Global_t: 1405, Episode_t: 1, Action: 53, Reward: 2.51, Epsilon: 0.30
[INFO] model update: t: 1406, loss: 28515.466796875
[INFO] Global_t: 1406, Episode_t: 2, Action: 13, Reward: 5.41, Epsilon: 0.30
[INFO] model update: t: 1407, loss: 15141.3828125
[INFO] Global_t: 1407, Episode_t: 3, Action: 161, Reward: 1.75, Epsilon: 0.30
[INFO] model update: t: 1408, loss: 37776.7421875
[INFO] Global_t: 1408, Episode_t: 4, Action: 23, Reward: 2.23, Epsilon: 0.30
[INFO] model update: t: 1409, loss: 24225.90625
[INFO] Global_t: 1409, Episode_t: 5, Action: 105, Reward: 1.81, Epsilon: 0.30
[INFO] model update: t: 1410, loss: 31457.203125
[INFO] Global_t: 1410, Episode_t: 6, Action: 147, Reward: 1.26, Epsilon: 0.30
[INFO] Global step: 1410, Cumulative rewards: 14.96748, Runtime (s): 1252.55
--------------------------------------
 
graph: 35, nodes: 189, edges: 558
[INFO] model update: t: 1411, loss: 28094.5625
[INFO] Global_t: 1411, Episode_t: 1, Action: 56, Reward: 2.26, Epsilon: 0.30
[INFO] model update: t: 1412, loss: 79941.2734375
[INFO] Global_t: 1412, Episode_t: 2, Action: 6, Reward: 3.43, Epsilon: 0.30
[INFO] model update: t: 1413, loss: 18706.52734375
[INFO] Global_t: 1413, Episode_t: 3, Action: 125, Reward: 1.95, Epsilon: 0.30
[INFO] model update: t: 1414, loss: 41930.38671875
[INFO] Global_t: 1414, Episode_t: 4, Action: 59, Reward: 1.07, Epsilon: 0.30
[INFO] model update: t: 1415, loss: 51099.38671875
[INFO] Global_t: 1415, Episode_t: 5, Action: 21, Reward: 2.04, Epsilon: 0.30
[INFO] model update: t: 1416, loss: 31639.70703125
[INFO] Global_t: 1416, Episode_t: 6, Action: 15, Reward: 2.56, Epsilon: 0.30
[INFO] Global step: 1416, Cumulative rewards: 13.308359999999999, Runtime (s): 1254.50
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6919467449188232
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5839157104492188
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3239381313323975
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6535584926605225
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.465113878250122
average cummulative reward vector is:  [0.08352711 0.06743611 0.06762514 0.06713505 0.07282527]
average cummulative reward is:  0.07170973370649343
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 36, nodes: 185, edges: 546
[INFO] model update: t: 1417, loss: 29546.234375
[INFO] Global_t: 1417, Episode_t: 1, Action: 112, Reward: 2.13, Epsilon: 0.30
[INFO] model update: t: 1418, loss: 23475.623046875
[INFO] Global_t: 1418, Episode_t: 2, Action: 141, Reward: 1.59, Epsilon: 0.30
[INFO] model update: t: 1419, loss: 15780.59375
[INFO] Global_t: 1419, Episode_t: 3, Action: 138, Reward: 1.40, Epsilon: 0.30
[INFO] model update: t: 1420, loss: 25312.771484375
[INFO] Global_t: 1420, Episode_t: 4, Action: 16, Reward: 2.34, Epsilon: 0.29
[INFO] model update: t: 1421, loss: 12233.234375
[INFO] Global_t: 1421, Episode_t: 5, Action: 144, Reward: 2.05, Epsilon: 0.29
[INFO] model update: t: 1422, loss: 37741.8046875
[INFO] Global_t: 1422, Episode_t: 6, Action: 164, Reward: 1.50, Epsilon: 0.29
[INFO] Global step: 1422, Cumulative rewards: 11.008439999999998, Runtime (s): 1263.97
--------------------------------------
 
graph: 37, nodes: 195, edges: 575
[INFO] model update: t: 1423, loss: 33305.6640625
[INFO] Global_t: 1423, Episode_t: 1, Action: 28, Reward: 2.78, Epsilon: 0.29
[INFO] model update: t: 1424, loss: 33839.0625
[INFO] Global_t: 1424, Episode_t: 2, Action: 46, Reward: 2.83, Epsilon: 0.29
[INFO] model update: t: 1425, loss: 24457.390625
[INFO] Global_t: 1425, Episode_t: 3, Action: 6, Reward: 3.34, Epsilon: 0.29
[INFO] model update: t: 1426, loss: 26811.078125
[INFO] Global_t: 1426, Episode_t: 4, Action: 43, Reward: 2.39, Epsilon: 0.29
[INFO] model update: t: 1427, loss: 19947.767578125
[INFO] Global_t: 1427, Episode_t: 5, Action: 189, Reward: 1.30, Epsilon: 0.29
[INFO] model update: t: 1428, loss: 15608.673828125
[INFO] Global_t: 1428, Episode_t: 6, Action: 147, Reward: 1.83, Epsilon: 0.29
[INFO] Global step: 1428, Cumulative rewards: 14.46204, Runtime (s): 1266.21
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6905052661895752
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7810328006744385
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.472961664199829
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.604243516921997
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3953371047973633
average cummulative reward vector is:  [0.08039789 0.07376157 0.07154863 0.07015561 0.07074409]
average cummulative reward is:  0.0733215592377677
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 38, nodes: 213, edges: 630
[INFO] model update: t: 1429, loss: 25727.9375
[INFO] Global_t: 1429, Episode_t: 1, Action: 32, Reward: 3.00, Epsilon: 0.29
[INFO] model update: t: 1430, loss: 40174.27734375
[INFO] Global_t: 1430, Episode_t: 2, Action: 14, Reward: 3.22, Epsilon: 0.29
[INFO] model update: t: 1431, loss: 22567.99609375
[INFO] Global_t: 1431, Episode_t: 3, Action: 105, Reward: 1.68, Epsilon: 0.29
[INFO] model update: t: 1432, loss: 22821.341796875
[INFO] Global_t: 1432, Episode_t: 4, Action: 7, Reward: 2.27, Epsilon: 0.29
[INFO] model update: t: 1433, loss: 18752.060546875
[INFO] Global_t: 1433, Episode_t: 5, Action: 30, Reward: 2.38, Epsilon: 0.29
[INFO] model update: t: 1434, loss: 17360.75
[INFO] Global_t: 1434, Episode_t: 6, Action: 33, Reward: 2.34, Epsilon: 0.29
[INFO] Global step: 1434, Cumulative rewards: 14.896559999999997, Runtime (s): 1276.64
--------------------------------------
 
graph: 39, nodes: 189, edges: 558
[INFO] model update: t: 1435, loss: 40868.75
[INFO] Global_t: 1435, Episode_t: 1, Action: 95, Reward: 2.51, Epsilon: 0.29
[INFO] model update: t: 1436, loss: 30514.5234375
[INFO] Global_t: 1436, Episode_t: 2, Action: 104, Reward: 1.88, Epsilon: 0.29
[INFO] model update: t: 1437, loss: 14757.947265625
[INFO] Global_t: 1437, Episode_t: 3, Action: 106, Reward: 2.12, Epsilon: 0.29
[INFO] model update: t: 1438, loss: 24840.767578125
[INFO] Global_t: 1438, Episode_t: 4, Action: 114, Reward: 1.78, Epsilon: 0.29
[INFO] model update: t: 1439, loss: 19523.66796875
[INFO] Global_t: 1439, Episode_t: 5, Action: 19, Reward: 2.26, Epsilon: 0.29
[INFO] model update: t: 1440, loss: 40338.9765625
[INFO] Global_t: 1440, Episode_t: 6, Action: 18, Reward: 2.22, Epsilon: 0.28
[INFO] Global step: 1440, Cumulative rewards: 12.76644, Runtime (s): 1278.28
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6108617782592773
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7531218528747559
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.23421311378479
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5276713371276855
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3618988990783691
average cummulative reward vector is:  [0.07969132 0.07183032 0.06283907 0.06673411 0.06908333]
average cummulative reward is:  0.07003563127693303
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 40, nodes: 186, edges: 548
[INFO] model update: t: 1441, loss: 23488.2265625
[INFO] Global_t: 1441, Episode_t: 1, Action: 54, Reward: 2.15, Epsilon: 0.28
[INFO] model update: t: 1442, loss: 26332.861328125
[INFO] Global_t: 1442, Episode_t: 2, Action: 33, Reward: 2.20, Epsilon: 0.28
[INFO] model update: t: 1443, loss: 18385.7109375
[INFO] Global_t: 1443, Episode_t: 3, Action: 40, Reward: 1.96, Epsilon: 0.28
[INFO] model update: t: 1444, loss: 34956.03125
[INFO] Global_t: 1444, Episode_t: 4, Action: 38, Reward: 1.92, Epsilon: 0.28
[INFO] model update: t: 1445, loss: 14879.626953125
[INFO] Global_t: 1445, Episode_t: 5, Action: 34, Reward: 1.96, Epsilon: 0.28
[INFO] model update: t: 1446, loss: 17706.607421875
[INFO] Global_t: 1446, Episode_t: 6, Action: 27, Reward: 2.54, Epsilon: 0.28
[INFO] Global step: 1446, Cumulative rewards: 12.73584, Runtime (s): 1287.48
--------------------------------------
 
graph: 41, nodes: 180, edges: 530
[INFO] model update: t: 1447, loss: 16379.20703125
[INFO] Global_t: 1447, Episode_t: 1, Action: 141, Reward: 2.20, Epsilon: 0.28
[INFO] model update: t: 1448, loss: 26618.34765625
[INFO] Global_t: 1448, Episode_t: 2, Action: 21, Reward: 2.49, Epsilon: 0.28
[INFO] model update: t: 1449, loss: 20337.66015625
[INFO] Global_t: 1449, Episode_t: 3, Action: 12, Reward: 2.53, Epsilon: 0.28
[INFO] model update: t: 1450, loss: 18782.638671875
[INFO] Global_t: 1450, Episode_t: 4, Action: 107, Reward: 2.03, Epsilon: 0.28
[INFO] model update: t: 1451, loss: 12575.18359375
[INFO] Global_t: 1451, Episode_t: 5, Action: 110, Reward: 1.67, Epsilon: 0.28
[INFO] model update: t: 1452, loss: 21817.5234375
[INFO] Global_t: 1452, Episode_t: 6, Action: 17, Reward: 3.31, Epsilon: 0.28
[INFO] Global step: 1452, Cumulative rewards: 14.22936, Runtime (s): 1288.85
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.542863130569458
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7174782752990723
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.405014991760254
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4674792289733887
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4067497253417969
average cummulative reward vector is:  [0.07496763 0.07021597 0.07318443 0.06316262 0.07205511]
average cummulative reward is:  0.07071715087599788
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 42, nodes: 218, edges: 645
[INFO] model update: t: 1453, loss: 42191.45703125
[INFO] Global_t: 1453, Episode_t: 1, Action: 164, Reward: 2.60, Epsilon: 0.28
[INFO] model update: t: 1454, loss: 34581.93359375
[INFO] Global_t: 1454, Episode_t: 2, Action: 65, Reward: 2.66, Epsilon: 0.28
[INFO] model update: t: 1455, loss: 21074.86328125
[INFO] Global_t: 1455, Episode_t: 3, Action: 158, Reward: 1.35, Epsilon: 0.28
[INFO] model update: t: 1456, loss: 24796.091796875
[INFO] Global_t: 1456, Episode_t: 4, Action: 22, Reward: 2.73, Epsilon: 0.28
[INFO] model update: t: 1457, loss: 15523.283203125
[INFO] Global_t: 1457, Episode_t: 5, Action: 185, Reward: 2.28, Epsilon: 0.28
[INFO] model update: t: 1458, loss: 48398.2734375
[INFO] Global_t: 1458, Episode_t: 6, Action: 57, Reward: 2.34, Epsilon: 0.28
[INFO] Global step: 1458, Cumulative rewards: 13.962839999999998, Runtime (s): 1298.23
--------------------------------------
 
graph: 43, nodes: 184, edges: 543
[INFO] model update: t: 1459, loss: 16953.53515625
[INFO] Global_t: 1459, Episode_t: 1, Action: 92, Reward: 2.20, Epsilon: 0.28
[INFO] model update: t: 1460, loss: 22761.744140625
[INFO] Global_t: 1460, Episode_t: 2, Action: 15, Reward: 2.62, Epsilon: 0.28
[INFO] model update: t: 1461, loss: 31042.990234375
[INFO] Global_t: 1461, Episode_t: 3, Action: 14, Reward: 2.21, Epsilon: 0.27
[INFO] model update: t: 1462, loss: 14334.1455078125
[INFO] Global_t: 1462, Episode_t: 4, Action: 7, Reward: 2.62, Epsilon: 0.27
[INFO] model update: t: 1463, loss: 17839.09375
[INFO] Global_t: 1463, Episode_t: 5, Action: 136, Reward: 1.56, Epsilon: 0.27
[INFO] model update: t: 1464, loss: 16585.203125
[INFO] Global_t: 1464, Episode_t: 6, Action: 155, Reward: 1.70, Epsilon: 0.27
[INFO] Global step: 1464, Cumulative rewards: 12.899280000000001, Runtime (s): 1299.76
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6627750396728516
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5695466995239258
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2749977111816406
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4856321811676025
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4576292037963867
average cummulative reward vector is:  [0.07822658 0.06755972 0.06628443 0.06529089 0.07556935]
average cummulative reward is:  0.07058619401765517
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 44, nodes: 200, edges: 591
[INFO] model update: t: 1465, loss: 21320.423828125
[INFO] Global_t: 1465, Episode_t: 1, Action: 21, Reward: 4.33, Epsilon: 0.27
[INFO] model update: t: 1466, loss: 11612.494140625
[INFO] Global_t: 1466, Episode_t: 2, Action: 22, Reward: 2.40, Epsilon: 0.27
[INFO] model update: t: 1467, loss: 25967.0859375
[INFO] Global_t: 1467, Episode_t: 3, Action: 4, Reward: 4.28, Epsilon: 0.27
[INFO] model update: t: 1468, loss: 20488.888671875
[INFO] Global_t: 1468, Episode_t: 4, Action: 143, Reward: 1.43, Epsilon: 0.27
[INFO] model update: t: 1469, loss: 46658.484375
[INFO] Global_t: 1469, Episode_t: 5, Action: 8, Reward: 2.85, Epsilon: 0.27
[INFO] model update: t: 1470, loss: 25427.6171875
[INFO] Global_t: 1470, Episode_t: 6, Action: 189, Reward: 2.15, Epsilon: 0.27
[INFO] Global step: 1470, Cumulative rewards: 17.43744, Runtime (s): 1309.01
--------------------------------------
 
graph: 45, nodes: 191, edges: 564
[INFO] model update: t: 1471, loss: 64889.22265625
[INFO] Global_t: 1471, Episode_t: 1, Action: 103, Reward: 1.22, Epsilon: 0.27
[INFO] model update: t: 1472, loss: 18921.93359375
[INFO] Global_t: 1472, Episode_t: 2, Action: 142, Reward: 1.35, Epsilon: 0.27
[INFO] model update: t: 1473, loss: 75444.171875
[INFO] Global_t: 1473, Episode_t: 3, Action: 123, Reward: 2.26, Epsilon: 0.27
[INFO] model update: t: 1474, loss: 53284.91796875
[INFO] Global_t: 1474, Episode_t: 4, Action: 60, Reward: 1.99, Epsilon: 0.27
[INFO] model update: t: 1475, loss: 29054.9140625
[INFO] Global_t: 1475, Episode_t: 5, Action: 15, Reward: 2.91, Epsilon: 0.27
[INFO] model update: t: 1476, loss: 52123.9609375
[INFO] Global_t: 1476, Episode_t: 6, Action: 23, Reward: 1.71, Epsilon: 0.27
[INFO] Global step: 1476, Cumulative rewards: 11.44764, Runtime (s): 1310.15
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7031679153442383
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5769031047821045
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4473919868469238
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.497016191482544
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4108450412750244
average cummulative reward vector is:  [0.08032921 0.06858218 0.07692213 0.06615958 0.07358629]
average cummulative reward is:  0.07311587747232313
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 46, nodes: 185, edges: 545
[INFO] model update: t: 1477, loss: 10464.9482421875
[INFO] Global_t: 1477, Episode_t: 1, Action: 180, Reward: 2.61, Epsilon: 0.27
[INFO] model update: t: 1478, loss: 91308.96875
[INFO] Global_t: 1478, Episode_t: 2, Action: 13, Reward: 2.82, Epsilon: 0.27
[INFO] model update: t: 1479, loss: 29324.7578125
[INFO] Global_t: 1479, Episode_t: 3, Action: 134, Reward: 2.50, Epsilon: 0.27
[INFO] model update: t: 1480, loss: 67135.734375
[INFO] Global_t: 1480, Episode_t: 4, Action: 167, Reward: 1.92, Epsilon: 0.27
[INFO] model update: t: 1481, loss: 28845.8671875
[INFO] Global_t: 1481, Episode_t: 5, Action: 32, Reward: 2.57, Epsilon: 0.26
[INFO] model update: t: 1482, loss: 17741.1953125
[INFO] Global_t: 1482, Episode_t: 6, Action: 49, Reward: 1.66, Epsilon: 0.26
[INFO] Global step: 1482, Cumulative rewards: 14.0856, Runtime (s): 1319.44
--------------------------------------
 
graph: 47, nodes: 187, edges: 552
[INFO] model update: t: 1483, loss: 32774.3984375
[INFO] Global_t: 1483, Episode_t: 1, Action: 154, Reward: 1.42, Epsilon: 0.26
[INFO] model update: t: 1484, loss: 23623.486328125
[INFO] Global_t: 1484, Episode_t: 2, Action: 0, Reward: 3.58, Epsilon: 0.26
[INFO] model update: t: 1485, loss: 53874.078125
[INFO] Global_t: 1485, Episode_t: 3, Action: 174, Reward: 2.00, Epsilon: 0.26
[INFO] model update: t: 1486, loss: 16375.1416015625
[INFO] Global_t: 1486, Episode_t: 4, Action: 88, Reward: 2.02, Epsilon: 0.26
[INFO] model update: t: 1487, loss: 54031.71484375
[INFO] Global_t: 1487, Episode_t: 5, Action: 19, Reward: 2.14, Epsilon: 0.26
[INFO] model update: t: 1488, loss: 24885.4296875
[INFO] Global_t: 1488, Episode_t: 6, Action: 27, Reward: 1.94, Epsilon: 0.26
[INFO] Global step: 1488, Cumulative rewards: 13.095839999999999, Runtime (s): 1321.04
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8185973167419434
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7512671947479248
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3859331607818604
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.522136926651001
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2108464241027832
average cummulative reward vector is:  [0.08701395 0.07644537 0.07272022 0.06739416 0.06175376]
average cummulative reward is:  0.07306549172747825
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 48, nodes: 180, edges: 531
[INFO] model update: t: 1489, loss: 24501.94921875
[INFO] Global_t: 1489, Episode_t: 1, Action: 54, Reward: 1.55, Epsilon: 0.26
[INFO] model update: t: 1490, loss: 32287.029296875
[INFO] Global_t: 1490, Episode_t: 2, Action: 126, Reward: 1.95, Epsilon: 0.26
[INFO] model update: t: 1491, loss: 14422.494140625
[INFO] Global_t: 1491, Episode_t: 3, Action: 6, Reward: 2.93, Epsilon: 0.26
[INFO] model update: t: 1492, loss: 19724.0
[INFO] Global_t: 1492, Episode_t: 4, Action: 166, Reward: 1.90, Epsilon: 0.26
[INFO] model update: t: 1493, loss: 24092.341796875
[INFO] Global_t: 1493, Episode_t: 5, Action: 121, Reward: 1.39, Epsilon: 0.26
[INFO] model update: t: 1494, loss: 27117.740234375
[INFO] Global_t: 1494, Episode_t: 6, Action: 30, Reward: 2.44, Epsilon: 0.26
[INFO] Global step: 1494, Cumulative rewards: 12.157919999999999, Runtime (s): 1329.96
--------------------------------------
 
graph: 49, nodes: 220, edges: 651
[INFO] model update: t: 1495, loss: 22003.0
[INFO] Global_t: 1495, Episode_t: 1, Action: 155, Reward: 2.68, Epsilon: 0.26
[INFO] model update: t: 1496, loss: 28200.037109375
[INFO] Global_t: 1496, Episode_t: 2, Action: 83, Reward: 2.55, Epsilon: 0.26
[INFO] model update: t: 1497, loss: 20834.927734375
[INFO] Global_t: 1497, Episode_t: 3, Action: 5, Reward: 4.94, Epsilon: 0.26
[INFO] model update: t: 1498, loss: 30627.376953125
[INFO] Global_t: 1498, Episode_t: 4, Action: 24, Reward: 2.60, Epsilon: 0.26
[INFO] model update: t: 1499, loss: 15694.6494140625
[INFO] Global_t: 1499, Episode_t: 5, Action: 6, Reward: 4.04, Epsilon: 0.26
[INFO] model update: t: 1500, loss: 32264.986328125
[INFO] Global_t: 1500, Episode_t: 6, Action: 26, Reward: 2.55, Epsilon: 0.26
[INFO] Global step: 1500, Cumulative rewards: 19.35612, Runtime (s): 1331.65
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7363786697387695
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6686248779296875
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3612020015716553
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6678059101104736
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3388760089874268
average cummulative reward vector is:  [0.08212447 0.07306505 0.07094071 0.0748007  0.06904328]
average cummulative reward is:  0.07399484217349847
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 50, nodes: 212, edges: 627
[INFO] model update: t: 1501, loss: 14892.7509765625
[INFO] Global_t: 1501, Episode_t: 1, Action: 128, Reward: 1.98, Epsilon: 0.26
[INFO] model update: t: 1502, loss: 18045.62109375
[INFO] Global_t: 1502, Episode_t: 2, Action: 6, Reward: 2.76, Epsilon: 0.25
[INFO] model update: t: 1503, loss: 14674.15625
[INFO] Global_t: 1503, Episode_t: 3, Action: 129, Reward: 2.14, Epsilon: 0.25
[INFO] model update: t: 1504, loss: 25220.375
[INFO] Global_t: 1504, Episode_t: 4, Action: 65, Reward: 1.75, Epsilon: 0.25
[INFO] model update: t: 1505, loss: 16803.921875
[INFO] Global_t: 1505, Episode_t: 5, Action: 162, Reward: 1.33, Epsilon: 0.25
[INFO] model update: t: 1506, loss: 32092.453125
[INFO] Global_t: 1506, Episode_t: 6, Action: 64, Reward: 1.74, Epsilon: 0.25
[INFO] Global step: 1506, Cumulative rewards: 11.697479999999999, Runtime (s): 1341.31
--------------------------------------
 
graph: 51, nodes: 217, edges: 642
[INFO] model update: t: 1507, loss: 29199.7734375
[INFO] Global_t: 1507, Episode_t: 1, Action: 29, Reward: 2.20, Epsilon: 0.25
[INFO] model update: t: 1508, loss: 62703.8671875
[INFO] Global_t: 1508, Episode_t: 2, Action: 0, Reward: 4.21, Epsilon: 0.25
[INFO] model update: t: 1509, loss: 46643.4921875
[INFO] Global_t: 1509, Episode_t: 3, Action: 144, Reward: 1.25, Epsilon: 0.25
[INFO] model update: t: 1510, loss: 56424.53125
[INFO] Global_t: 1510, Episode_t: 4, Action: 22, Reward: 2.58, Epsilon: 0.25
[INFO] model update: t: 1511, loss: 47656.28125
[INFO] Global_t: 1511, Episode_t: 5, Action: 149, Reward: 1.67, Epsilon: 0.25
[INFO] model update: t: 1512, loss: 19870.41796875
[INFO] Global_t: 1512, Episode_t: 6, Action: 69, Reward: 2.34, Epsilon: 0.25
[INFO] Global step: 1512, Cumulative rewards: 14.2452, Runtime (s): 1343.31
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.549135446548462
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6828153133392334
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3551011085510254
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.446685552597046
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4742059707641602
average cummulative reward vector is:  [0.07703105 0.07376528 0.0711623  0.06362547 0.07641371]
average cummulative reward is:  0.07239956049169258
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 52, nodes: 208, edges: 615
[INFO] model update: t: 1513, loss: 19528.18359375
[INFO] Global_t: 1513, Episode_t: 1, Action: 78, Reward: 2.45, Epsilon: 0.25
[INFO] model update: t: 1514, loss: 21050.486328125
[INFO] Global_t: 1514, Episode_t: 2, Action: 53, Reward: 1.89, Epsilon: 0.25
[INFO] model update: t: 1515, loss: 41910.68359375
[INFO] Global_t: 1515, Episode_t: 3, Action: 11, Reward: 3.03, Epsilon: 0.25
[INFO] model update: t: 1516, loss: 9913.84765625
[INFO] Global_t: 1516, Episode_t: 4, Action: 151, Reward: 1.13, Epsilon: 0.25
[INFO] model update: t: 1517, loss: 25493.1015625
[INFO] Global_t: 1517, Episode_t: 5, Action: 118, Reward: 1.95, Epsilon: 0.25
[INFO] model update: t: 1518, loss: 43460.875
[INFO] Global_t: 1518, Episode_t: 6, Action: 161, Reward: 1.92, Epsilon: 0.25
[INFO] Global step: 1518, Cumulative rewards: 12.355080000000001, Runtime (s): 1353.01
--------------------------------------
 
graph: 53, nodes: 205, edges: 606
[INFO] model update: t: 1519, loss: 18069.03515625
[INFO] Global_t: 1519, Episode_t: 1, Action: 23, Reward: 2.42, Epsilon: 0.25
[INFO] model update: t: 1520, loss: 30513.20703125
[INFO] Global_t: 1520, Episode_t: 2, Action: 14, Reward: 2.68, Epsilon: 0.25
[INFO] model update: t: 1521, loss: 45206.3359375
[INFO] Global_t: 1521, Episode_t: 3, Action: 124, Reward: 1.78, Epsilon: 0.25
[INFO] model update: t: 1522, loss: 36815.8515625
[INFO] Global_t: 1522, Episode_t: 4, Action: 12, Reward: 3.30, Epsilon: 0.24
[INFO] model update: t: 1523, loss: 37812.19921875
[INFO] Global_t: 1523, Episode_t: 5, Action: 147, Reward: 1.72, Epsilon: 0.24
[INFO] model update: t: 1524, loss: 45921.203125
[INFO] Global_t: 1524, Episode_t: 6, Action: 87, Reward: 1.49, Epsilon: 0.24
[INFO] Global step: 1524, Cumulative rewards: 13.379159999999999, Runtime (s): 1355.03
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6333961486816406
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5415031909942627
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4053082466125488
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5512654781341553
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.338392972946167
average cummulative reward vector is:  [0.08096316 0.0669625  0.07389262 0.06865304 0.06897742]
average cummulative reward is:  0.07188974751671455
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 54, nodes: 185, edges: 546
[INFO] model update: t: 1525, loss: 19774.427734375
[INFO] Global_t: 1525, Episode_t: 1, Action: 84, Reward: 2.26, Epsilon: 0.24
[INFO] model update: t: 1526, loss: 36242.72265625
[INFO] Global_t: 1526, Episode_t: 2, Action: 164, Reward: 2.49, Epsilon: 0.24
[INFO] model update: t: 1527, loss: 22880.435546875
[INFO] Global_t: 1527, Episode_t: 3, Action: 132, Reward: 2.13, Epsilon: 0.24
[INFO] model update: t: 1528, loss: 60014.2578125
[INFO] Global_t: 1528, Episode_t: 4, Action: 36, Reward: 2.06, Epsilon: 0.24
[INFO] model update: t: 1529, loss: 36469.984375
[INFO] Global_t: 1529, Episode_t: 5, Action: 5, Reward: 2.33, Epsilon: 0.24
[INFO] model update: t: 1530, loss: 14049.798828125
[INFO] Global_t: 1530, Episode_t: 6, Action: 80, Reward: 2.07, Epsilon: 0.24
[INFO] Global step: 1530, Cumulative rewards: 13.340039999999998, Runtime (s): 1364.29
--------------------------------------
 
graph: 55, nodes: 193, edges: 570
[INFO] model update: t: 1531, loss: 45645.3359375
[INFO] Global_t: 1531, Episode_t: 1, Action: 15, Reward: 2.65, Epsilon: 0.24
[INFO] model update: t: 1532, loss: 24061.501953125
[INFO] Global_t: 1532, Episode_t: 2, Action: 51, Reward: 2.70, Epsilon: 0.24
[INFO] model update: t: 1533, loss: 58492.4375
[INFO] Global_t: 1533, Episode_t: 3, Action: 81, Reward: 2.19, Epsilon: 0.24
[INFO] model update: t: 1534, loss: 35605.3125
[INFO] Global_t: 1534, Episode_t: 4, Action: 6, Reward: 3.89, Epsilon: 0.24
[INFO] model update: t: 1535, loss: 32619.44140625
[INFO] Global_t: 1535, Episode_t: 5, Action: 11, Reward: 2.63, Epsilon: 0.24
[INFO] model update: t: 1536, loss: 22123.904296875
[INFO] Global_t: 1536, Episode_t: 6, Action: 105, Reward: 1.47, Epsilon: 0.24
[INFO] Global step: 1536, Cumulative rewards: 15.525719999999998, Runtime (s): 1366.13
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6147210597991943
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6032919883728027
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.344271183013916
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.485860824584961
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.448305606842041
average cummulative reward vector is:  [0.08014211 0.07031597 0.07021393 0.06544439 0.07050726]
average cummulative reward is:  0.07132473249989804
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 56, nodes: 201, edges: 594
[INFO] model update: t: 1537, loss: 29245.009765625
[INFO] Global_t: 1537, Episode_t: 1, Action: 39, Reward: 2.04, Epsilon: 0.24
[INFO] model update: t: 1538, loss: 23793.328125
[INFO] Global_t: 1538, Episode_t: 2, Action: 14, Reward: 2.63, Epsilon: 0.24
[INFO] model update: t: 1539, loss: 18631.748046875
[INFO] Global_t: 1539, Episode_t: 3, Action: 17, Reward: 3.01, Epsilon: 0.24
[INFO] model update: t: 1540, loss: 20208.33203125
[INFO] Global_t: 1540, Episode_t: 4, Action: 28, Reward: 1.80, Epsilon: 0.24
[INFO] model update: t: 1541, loss: 13355.4462890625
[INFO] Global_t: 1541, Episode_t: 5, Action: 0, Reward: 2.83, Epsilon: 0.24
[INFO] model update: t: 1542, loss: 9378.13671875
[INFO] Global_t: 1542, Episode_t: 6, Action: 7, Reward: 2.85, Epsilon: 0.23
[INFO] Global step: 1542, Cumulative rewards: 15.16176, Runtime (s): 1375.64
--------------------------------------
 
graph: 57, nodes: 195, edges: 575
[INFO] model update: t: 1543, loss: 47472.640625
[INFO] Global_t: 1543, Episode_t: 1, Action: 6, Reward: 3.04, Epsilon: 0.23
[INFO] model update: t: 1544, loss: 31318.939453125
[INFO] Global_t: 1544, Episode_t: 2, Action: 24, Reward: 2.56, Epsilon: 0.23
[INFO] model update: t: 1545, loss: 53662.65625
[INFO] Global_t: 1545, Episode_t: 3, Action: 4, Reward: 4.45, Epsilon: 0.23
[INFO] model update: t: 1546, loss: 21044.865234375
[INFO] Global_t: 1546, Episode_t: 4, Action: 133, Reward: 2.20, Epsilon: 0.23
[INFO] model update: t: 1547, loss: 38207.08984375
[INFO] Global_t: 1547, Episode_t: 5, Action: 146, Reward: 2.40, Epsilon: 0.23
[INFO] model update: t: 1548, loss: 65598.9609375
[INFO] Global_t: 1548, Episode_t: 6, Action: 8, Reward: 3.10, Epsilon: 0.23
[INFO] Global step: 1548, Cumulative rewards: 17.752799999999997, Runtime (s): 1376.97
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7637724876403809
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6724069118499756
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2885799407958984
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.590531587600708
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3940606117248535
average cummulative reward vector is:  [0.08845974 0.07321921 0.06628087 0.06639042 0.07268522]
average cummulative reward is:  0.07340709194730384
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 58, nodes: 215, edges: 636
[INFO] model update: t: 1549, loss: 23800.822265625
[INFO] Global_t: 1549, Episode_t: 1, Action: 213, Reward: 2.20, Epsilon: 0.23
[INFO] model update: t: 1550, loss: 78736.5703125
[INFO] Global_t: 1550, Episode_t: 2, Action: 4, Reward: 4.21, Epsilon: 0.23
[INFO] model update: t: 1551, loss: 17205.375
[INFO] Global_t: 1551, Episode_t: 3, Action: 13, Reward: 2.65, Epsilon: 0.23
[INFO] model update: t: 1552, loss: 44076.1015625
[INFO] Global_t: 1552, Episode_t: 4, Action: 7, Reward: 2.74, Epsilon: 0.23
[INFO] model update: t: 1553, loss: 18434.365234375
[INFO] Global_t: 1553, Episode_t: 5, Action: 57, Reward: 1.96, Epsilon: 0.23
[INFO] model update: t: 1554, loss: 53620.21484375
[INFO] Global_t: 1554, Episode_t: 6, Action: 83, Reward: 1.30, Epsilon: 0.23
[INFO] Global step: 1554, Cumulative rewards: 15.05664, Runtime (s): 1386.91
--------------------------------------
 
graph: 59, nodes: 193, edges: 570
[INFO] model update: t: 1555, loss: 32210.015625
[INFO] Global_t: 1555, Episode_t: 1, Action: 37, Reward: 2.29, Epsilon: 0.23
[INFO] model update: t: 1556, loss: 43605.609375
[INFO] Global_t: 1556, Episode_t: 2, Action: 22, Reward: 2.44, Epsilon: 0.23
[INFO] model update: t: 1557, loss: 54293.0234375
[INFO] Global_t: 1557, Episode_t: 3, Action: 62, Reward: 2.53, Epsilon: 0.23
[INFO] model update: t: 1558, loss: 35585.67578125
[INFO] Global_t: 1558, Episode_t: 4, Action: 95, Reward: 1.57, Epsilon: 0.23
[INFO] model update: t: 1559, loss: 65903.375
[INFO] Global_t: 1559, Episode_t: 5, Action: 12, Reward: 2.81, Epsilon: 0.23
[INFO] model update: t: 1560, loss: 20699.146484375
[INFO] Global_t: 1560, Episode_t: 6, Action: 36, Reward: 1.97, Epsilon: 0.23
[INFO] Global step: 1560, Cumulative rewards: 13.612680000000001, Runtime (s): 1388.93
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.745668888092041
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.649043321609497
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.65510892868042
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.697641372680664
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.366368293762207
average cummulative reward vector is:  [0.08737053 0.07172616 0.08271148 0.07560257 0.07078522]
average cummulative reward is:  0.07763918885605088
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 60, nodes: 193, edges: 569
[INFO] model update: t: 1561, loss: 48192.16015625
[INFO] Global_t: 1561, Episode_t: 1, Action: 184, Reward: 1.84, Epsilon: 0.23
[INFO] model update: t: 1562, loss: 47756.28515625
[INFO] Global_t: 1562, Episode_t: 2, Action: 105, Reward: 1.70, Epsilon: 0.23
[INFO] model update: t: 1563, loss: 52349.82421875
[INFO] Global_t: 1563, Episode_t: 3, Action: 5, Reward: 2.80, Epsilon: 0.22
[INFO] model update: t: 1564, loss: 40215.13671875
[INFO] Global_t: 1564, Episode_t: 4, Action: 87, Reward: 1.53, Epsilon: 0.22
[INFO] model update: t: 1565, loss: 61241.62109375
[INFO] Global_t: 1565, Episode_t: 5, Action: 49, Reward: 1.50, Epsilon: 0.22
[INFO] model update: t: 1566, loss: 25812.26953125
[INFO] Global_t: 1566, Episode_t: 6, Action: 53, Reward: 1.01, Epsilon: 0.22
[INFO] Global step: 1566, Cumulative rewards: 10.370279999999998, Runtime (s): 1398.99
--------------------------------------
 
graph: 61, nodes: 215, edges: 636
[INFO] model update: t: 1567, loss: 15869.6044921875
[INFO] Global_t: 1567, Episode_t: 1, Action: 13, Reward: 2.87, Epsilon: 0.22
[INFO] model update: t: 1568, loss: 55783.15234375
[INFO] Global_t: 1568, Episode_t: 2, Action: 26, Reward: 3.77, Epsilon: 0.22
[INFO] model update: t: 1569, loss: 18197.07421875
[INFO] Global_t: 1569, Episode_t: 3, Action: 54, Reward: 2.96, Epsilon: 0.22
[INFO] model update: t: 1570, loss: 42840.96875
[INFO] Global_t: 1570, Episode_t: 4, Action: 192, Reward: 1.25, Epsilon: 0.22
[INFO] model update: t: 1571, loss: 13013.263671875
[INFO] Global_t: 1571, Episode_t: 5, Action: 29, Reward: 1.87, Epsilon: 0.22
[INFO] model update: t: 1572, loss: 60606.39453125
[INFO] Global_t: 1572, Episode_t: 6, Action: 19, Reward: 2.60, Epsilon: 0.22
[INFO] Global step: 1572, Cumulative rewards: 15.320639999999997, Runtime (s): 1401.29
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9234001636505127
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.702000617980957
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3505187034606934
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6216440200805664
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.266638994216919
average cummulative reward vector is:  [0.09700526 0.07051273 0.0697123  0.07214907 0.06496102]
average cummulative reward is:  0.0748680753294561
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 62, nodes: 198, edges: 585
[INFO] model update: t: 1573, loss: 22135.02734375
[INFO] Global_t: 1573, Episode_t: 1, Action: 82, Reward: 1.93, Epsilon: 0.22
[INFO] model update: t: 1574, loss: 28802.95703125
[INFO] Global_t: 1574, Episode_t: 2, Action: 64, Reward: 2.51, Epsilon: 0.22
[INFO] model update: t: 1575, loss: 21332.205078125
[INFO] Global_t: 1575, Episode_t: 3, Action: 19, Reward: 3.17, Epsilon: 0.22
[INFO] model update: t: 1576, loss: 20375.62109375
[INFO] Global_t: 1576, Episode_t: 4, Action: 11, Reward: 2.78, Epsilon: 0.22
[INFO] model update: t: 1577, loss: 55913.4140625
[INFO] Global_t: 1577, Episode_t: 5, Action: 6, Reward: 2.77, Epsilon: 0.22
[INFO] model update: t: 1578, loss: 15346.15234375
[INFO] Global_t: 1578, Episode_t: 6, Action: 26, Reward: 1.82, Epsilon: 0.22
[INFO] Global step: 1578, Cumulative rewards: 14.97984, Runtime (s): 1411.00
--------------------------------------
 
graph: 63, nodes: 191, edges: 564
[INFO] model update: t: 1579, loss: 28078.478515625
[INFO] Global_t: 1579, Episode_t: 1, Action: 22, Reward: 2.40, Epsilon: 0.22
[INFO] model update: t: 1580, loss: 39060.203125
[INFO] Global_t: 1580, Episode_t: 2, Action: 43, Reward: 2.53, Epsilon: 0.22
[INFO] model update: t: 1581, loss: 33309.75
[INFO] Global_t: 1581, Episode_t: 3, Action: 16, Reward: 2.54, Epsilon: 0.22
[INFO] model update: t: 1582, loss: 47111.7578125
[INFO] Global_t: 1582, Episode_t: 4, Action: 24, Reward: 2.18, Epsilon: 0.22
[INFO] model update: t: 1583, loss: 24603.923828125
[INFO] Global_t: 1583, Episode_t: 5, Action: 18, Reward: 3.77, Epsilon: 0.21
[INFO] model update: t: 1584, loss: 33699.09375
[INFO] Global_t: 1584, Episode_t: 6, Action: 179, Reward: 1.26, Epsilon: 0.21
[INFO] Global step: 1584, Cumulative rewards: 14.67, Runtime (s): 1412.59
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.79612398147583
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6157827377319336
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4368891716003418
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.493236780166626
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4632630348205566
average cummulative reward vector is:  [0.08467447 0.07019514 0.0757429  0.06562593 0.07660538]
average cummulative reward is:  0.07456876393429762
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 64, nodes: 184, edges: 543
[INFO] model update: t: 1585, loss: 17850.44921875
[INFO] Global_t: 1585, Episode_t: 1, Action: 25, Reward: 2.67, Epsilon: 0.21
[INFO] model update: t: 1586, loss: 63444.89453125
[INFO] Global_t: 1586, Episode_t: 2, Action: 67, Reward: 3.00, Epsilon: 0.21
[INFO] model update: t: 1587, loss: 27687.2734375
[INFO] Global_t: 1587, Episode_t: 3, Action: 66, Reward: 2.29, Epsilon: 0.21
[INFO] model update: t: 1588, loss: 37029.140625
[INFO] Global_t: 1588, Episode_t: 4, Action: 154, Reward: 1.52, Epsilon: 0.21
[INFO] model update: t: 1589, loss: 25930.6640625
[INFO] Global_t: 1589, Episode_t: 5, Action: 99, Reward: 1.71, Epsilon: 0.21
[INFO] model update: t: 1590, loss: 40390.5078125
[INFO] Global_t: 1590, Episode_t: 6, Action: 33, Reward: 1.63, Epsilon: 0.21
[INFO] Global step: 1590, Cumulative rewards: 12.831479999999999, Runtime (s): 1422.84
--------------------------------------
 
graph: 65, nodes: 220, edges: 650
[INFO] model update: t: 1591, loss: 17747.24609375
[INFO] Global_t: 1591, Episode_t: 1, Action: 124, Reward: 2.77, Epsilon: 0.21
[INFO] model update: t: 1592, loss: 16882.32421875
[INFO] Global_t: 1592, Episode_t: 2, Action: 28, Reward: 3.28, Epsilon: 0.21
[INFO] model update: t: 1593, loss: 13081.701171875
[INFO] Global_t: 1593, Episode_t: 3, Action: 185, Reward: 1.83, Epsilon: 0.21
[INFO] model update: t: 1594, loss: 33039.3125
[INFO] Global_t: 1594, Episode_t: 4, Action: 199, Reward: 1.92, Epsilon: 0.21
[INFO] model update: t: 1595, loss: 13542.59375
[INFO] Global_t: 1595, Episode_t: 5, Action: 23, Reward: 3.27, Epsilon: 0.21
[INFO] model update: t: 1596, loss: 28362.33984375
[INFO] Global_t: 1596, Episode_t: 6, Action: 9, Reward: 2.56, Epsilon: 0.21
[INFO] Global step: 1596, Cumulative rewards: 15.631439999999998, Runtime (s): 1424.92
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.638242483139038
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.3904056549072266
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3738806247711182
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.43894362449646
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4272816181182861
average cummulative reward vector is:  [0.08152342 0.05968194 0.07181011 0.06292827 0.07378387]
average cummulative reward is:  0.06994552335649458
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 66, nodes: 200, edges: 591
[INFO] model update: t: 1597, loss: 15885.498046875
[INFO] Global_t: 1597, Episode_t: 1, Action: 41, Reward: 2.51, Epsilon: 0.21
[INFO] model update: t: 1598, loss: 22513.16015625
[INFO] Global_t: 1598, Episode_t: 2, Action: 195, Reward: 1.64, Epsilon: 0.21
[INFO] model update: t: 1599, loss: 14641.7763671875
[INFO] Global_t: 1599, Episode_t: 3, Action: 18, Reward: 3.62, Epsilon: 0.21
[INFO] model update: t: 1600, loss: 19835.8125
[INFO] Global_t: 1600, Episode_t: 4, Action: 35, Reward: 1.67, Epsilon: 0.21
[INFO] model update: t: 1601, loss: 23479.177734375
[INFO] Global_t: 1601, Episode_t: 5, Action: 53, Reward: 1.38, Epsilon: 0.21
[INFO] model update: t: 1602, loss: 27833.533203125
[INFO] Global_t: 1602, Episode_t: 6, Action: 6, Reward: 2.41, Epsilon: 0.21
[INFO] Global step: 1602, Cumulative rewards: 13.2234, Runtime (s): 1434.17
--------------------------------------
 
graph: 67, nodes: 183, edges: 540
[INFO] model update: t: 1603, loss: 20627.52734375
[INFO] Global_t: 1603, Episode_t: 1, Action: 44, Reward: 2.03, Epsilon: 0.21
[INFO] model update: t: 1604, loss: 28905.30859375
[INFO] Global_t: 1604, Episode_t: 2, Action: 139, Reward: 1.09, Epsilon: 0.20
[INFO] model update: t: 1605, loss: 11372.15625
[INFO] Global_t: 1605, Episode_t: 3, Action: 10, Reward: 3.13, Epsilon: 0.20
[INFO] model update: t: 1606, loss: 62980.10546875
[INFO] Global_t: 1606, Episode_t: 4, Action: 13, Reward: 1.81, Epsilon: 0.20
[INFO] model update: t: 1607, loss: 36415.6640625
[INFO] Global_t: 1607, Episode_t: 5, Action: 128, Reward: 2.03, Epsilon: 0.20
[INFO] model update: t: 1608, loss: 16770.63671875
[INFO] Global_t: 1608, Episode_t: 6, Action: 117, Reward: 0.56, Epsilon: 0.20
[INFO] Global step: 1608, Cumulative rewards: 10.658639999999997, Runtime (s): 1436.12
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7848968505859375
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4940342903137207
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4449553489685059
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6319527626037598
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.2676222324371338
average cummulative reward vector is:  [0.08650211 0.06487824 0.07615984 0.07253131 0.06492124]
average cummulative reward is:  0.07299854540796544
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 68, nodes: 219, edges: 648
[INFO] model update: t: 1609, loss: 28649.822265625
[INFO] Global_t: 1609, Episode_t: 1, Action: 127, Reward: 2.14, Epsilon: 0.20
[INFO] model update: t: 1610, loss: 22396.017578125
[INFO] Global_t: 1610, Episode_t: 2, Action: 15, Reward: 2.84, Epsilon: 0.20
[INFO] model update: t: 1611, loss: 30643.587890625
[INFO] Global_t: 1611, Episode_t: 3, Action: 201, Reward: 2.00, Epsilon: 0.20
[INFO] model update: t: 1612, loss: 34527.69140625
[INFO] Global_t: 1612, Episode_t: 4, Action: 218, Reward: 1.84, Epsilon: 0.20
[INFO] model update: t: 1613, loss: 16458.806640625
[INFO] Global_t: 1613, Episode_t: 5, Action: 57, Reward: 2.13, Epsilon: 0.20
[INFO] model update: t: 1614, loss: 50084.19140625
[INFO] Global_t: 1614, Episode_t: 6, Action: 140, Reward: 1.61, Epsilon: 0.20
[INFO] Global step: 1614, Cumulative rewards: 12.564840000000002, Runtime (s): 1445.68
--------------------------------------
 
graph: 69, nodes: 191, edges: 564
[INFO] model update: t: 1615, loss: 66730.84375
[INFO] Global_t: 1615, Episode_t: 1, Action: 4, Reward: 2.58, Epsilon: 0.20
[INFO] model update: t: 1616, loss: 28570.603515625
[INFO] Global_t: 1616, Episode_t: 2, Action: 17, Reward: 2.71, Epsilon: 0.20
[INFO] model update: t: 1617, loss: 112857.2421875
[INFO] Global_t: 1617, Episode_t: 3, Action: 126, Reward: 1.92, Epsilon: 0.20
[INFO] model update: t: 1618, loss: 19550.96484375
[INFO] Global_t: 1618, Episode_t: 4, Action: 170, Reward: 1.52, Epsilon: 0.20
[INFO] model update: t: 1619, loss: 84497.1796875
[INFO] Global_t: 1619, Episode_t: 5, Action: 20, Reward: 1.76, Epsilon: 0.20
[INFO] model update: t: 1620, loss: 21536.78515625
[INFO] Global_t: 1620, Episode_t: 6, Action: 103, Reward: 1.85, Epsilon: 0.20
[INFO] Global step: 1620, Cumulative rewards: 12.336599999999999, Runtime (s): 1447.36
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6474685668945312
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.4674155712127686
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4579496383666992
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4209611415863037
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4266862869262695
average cummulative reward vector is:  [0.08183421 0.063225   0.07715546 0.0621771  0.0740914 ]
average cummulative reward is:  0.07169663513207816
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 70, nodes: 194, edges: 573
[INFO] model update: t: 1621, loss: 74133.578125
[INFO] Global_t: 1621, Episode_t: 1, Action: 8, Reward: 3.22, Epsilon: 0.20
[INFO] model update: t: 1622, loss: 11997.798828125
[INFO] Global_t: 1622, Episode_t: 2, Action: 5, Reward: 3.09, Epsilon: 0.20
[INFO] model update: t: 1623, loss: 32962.6328125
[INFO] Global_t: 1623, Episode_t: 3, Action: 34, Reward: 2.49, Epsilon: 0.20
[INFO] model update: t: 1624, loss: 46646.390625
[INFO] Global_t: 1624, Episode_t: 4, Action: 82, Reward: 1.44, Epsilon: 0.19
[INFO] model update: t: 1625, loss: 37515.12109375
[INFO] Global_t: 1625, Episode_t: 5, Action: 63, Reward: 1.47, Epsilon: 0.19
[INFO] model update: t: 1626, loss: 28921.7109375
[INFO] Global_t: 1626, Episode_t: 6, Action: 21, Reward: 2.59, Epsilon: 0.19
[INFO] Global step: 1626, Cumulative rewards: 14.299439999999997, Runtime (s): 1457.15
--------------------------------------
 
graph: 71, nodes: 191, edges: 564
[INFO] model update: t: 1627, loss: 35501.4140625
[INFO] Global_t: 1627, Episode_t: 1, Action: 185, Reward: 2.47, Epsilon: 0.19
[INFO] model update: t: 1628, loss: 40717.87109375
[INFO] Global_t: 1628, Episode_t: 2, Action: 9, Reward: 3.31, Epsilon: 0.19
[INFO] model update: t: 1629, loss: 55453.6484375
[INFO] Global_t: 1629, Episode_t: 3, Action: 33, Reward: 2.68, Epsilon: 0.19
[INFO] model update: t: 1630, loss: 13928.673828125
[INFO] Global_t: 1630, Episode_t: 4, Action: 153, Reward: 1.57, Epsilon: 0.19
[INFO] model update: t: 1631, loss: 25105.892578125
[INFO] Global_t: 1631, Episode_t: 5, Action: 164, Reward: 1.81, Epsilon: 0.19
[INFO] model update: t: 1632, loss: 49499.69921875
[INFO] Global_t: 1632, Episode_t: 6, Action: 29, Reward: 2.19, Epsilon: 0.19
[INFO] Global step: 1632, Cumulative rewards: 14.03172, Runtime (s): 1458.67
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6855204105377197
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6063473224639893
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4447176456451416
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.4012551307678223
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5040881633758545
average cummulative reward vector is:  [0.08416632 0.07018588 0.07608197 0.0616757  0.0731043 ]
average cummulative reward is:  0.07304283292841325
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 72, nodes: 204, edges: 603
[INFO] model update: t: 1633, loss: 25044.751953125
[INFO] Global_t: 1633, Episode_t: 1, Action: 27, Reward: 2.86, Epsilon: 0.19
[INFO] model update: t: 1634, loss: 54569.26953125
[INFO] Global_t: 1634, Episode_t: 2, Action: 56, Reward: 2.24, Epsilon: 0.19
[INFO] model update: t: 1635, loss: 11965.1533203125
[INFO] Global_t: 1635, Episode_t: 3, Action: 155, Reward: 1.47, Epsilon: 0.19
[INFO] model update: t: 1636, loss: 63989.7265625
[INFO] Global_t: 1636, Episode_t: 4, Action: 18, Reward: 2.67, Epsilon: 0.19
[INFO] model update: t: 1637, loss: 25091.533203125
[INFO] Global_t: 1637, Episode_t: 5, Action: 55, Reward: 2.14, Epsilon: 0.19
[INFO] model update: t: 1638, loss: 54235.66015625
[INFO] Global_t: 1638, Episode_t: 6, Action: 203, Reward: 1.45, Epsilon: 0.19
[INFO] Global step: 1638, Cumulative rewards: 12.833759999999998, Runtime (s): 1468.10
--------------------------------------
 
graph: 73, nodes: 202, edges: 597
[INFO] model update: t: 1639, loss: 16120.72265625
[INFO] Global_t: 1639, Episode_t: 1, Action: 158, Reward: 2.32, Epsilon: 0.19
[INFO] model update: t: 1640, loss: 48619.1953125
[INFO] Global_t: 1640, Episode_t: 2, Action: 39, Reward: 2.56, Epsilon: 0.19
[INFO] model update: t: 1641, loss: 24914.234375
[INFO] Global_t: 1641, Episode_t: 3, Action: 5, Reward: 3.53, Epsilon: 0.19
[INFO] model update: t: 1642, loss: 21632.58203125
[INFO] Global_t: 1642, Episode_t: 4, Action: 2, Reward: 4.10, Epsilon: 0.19
[INFO] model update: t: 1643, loss: 11336.8271484375
[INFO] Global_t: 1643, Episode_t: 5, Action: 28, Reward: 2.09, Epsilon: 0.19
[INFO] model update: t: 1644, loss: 23959.1484375
[INFO] Global_t: 1644, Episode_t: 6, Action: 8, Reward: 2.38, Epsilon: 0.18
[INFO] Global step: 1644, Cumulative rewards: 16.97616, Runtime (s): 1469.93
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.663257360458374
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.550842523574829
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3548848628997803
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6264877319335938
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3845243453979492
average cummulative reward vector is:  [0.08324211 0.06723542 0.07064126 0.06812921 0.07203038]
average cummulative reward is:  0.07225567214239767
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 74, nodes: 210, edges: 620
[INFO] model update: t: 1645, loss: 18480.70703125
[INFO] Global_t: 1645, Episode_t: 1, Action: 28, Reward: 3.64, Epsilon: 0.18
[INFO] model update: t: 1646, loss: 12539.900390625
[INFO] Global_t: 1646, Episode_t: 2, Action: 5, Reward: 3.86, Epsilon: 0.18
[INFO] model update: t: 1647, loss: 39056.03125
[INFO] Global_t: 1647, Episode_t: 3, Action: 9, Reward: 2.84, Epsilon: 0.18
[INFO] model update: t: 1648, loss: 51579.48046875
[INFO] Global_t: 1648, Episode_t: 4, Action: 16, Reward: 1.54, Epsilon: 0.18
[INFO] model update: t: 1649, loss: 64326.3515625
[INFO] Global_t: 1649, Episode_t: 5, Action: 68, Reward: 1.81, Epsilon: 0.18
[INFO] model update: t: 1650, loss: 21191.123046875
[INFO] Global_t: 1650, Episode_t: 6, Action: 146, Reward: 1.55, Epsilon: 0.18
[INFO] Global step: 1650, Cumulative rewards: 15.247319999999998, Runtime (s): 1479.74
--------------------------------------
 
graph: 75, nodes: 199, edges: 588
[INFO] model update: t: 1651, loss: 17763.72265625
[INFO] Global_t: 1651, Episode_t: 1, Action: 191, Reward: 1.40, Epsilon: 0.18
[INFO] model update: t: 1652, loss: 37360.6640625
[INFO] Global_t: 1652, Episode_t: 2, Action: 107, Reward: 2.59, Epsilon: 0.18
[INFO] model update: t: 1653, loss: 20869.564453125
[INFO] Global_t: 1653, Episode_t: 3, Action: 48, Reward: 2.60, Epsilon: 0.18
[INFO] model update: t: 1654, loss: 15823.396484375
[INFO] Global_t: 1654, Episode_t: 4, Action: 7, Reward: 2.66, Epsilon: 0.18
[INFO] model update: t: 1655, loss: 14875.3720703125
[INFO] Global_t: 1655, Episode_t: 5, Action: 120, Reward: 1.95, Epsilon: 0.18
[INFO] model update: t: 1656, loss: 15428.822265625
[INFO] Global_t: 1656, Episode_t: 6, Action: 6, Reward: 3.67, Epsilon: 0.18
[INFO] Global step: 1656, Cumulative rewards: 14.869200000000001, Runtime (s): 1481.29
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7715718746185303
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.706587553024292
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5097737312316895
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6402502059936523
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.477297067642212
average cummulative reward vector is:  [0.08897711 0.07478287 0.07401421 0.0727479  0.07730941]
average cummulative reward is:  0.07756629781644275
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 76, nodes: 213, edges: 630
[INFO] model update: t: 1657, loss: 14769.125
[INFO] Global_t: 1657, Episode_t: 1, Action: 47, Reward: 2.55, Epsilon: 0.18
[INFO] model update: t: 1658, loss: 29862.921875
[INFO] Global_t: 1658, Episode_t: 2, Action: 172, Reward: 1.41, Epsilon: 0.18
[INFO] model update: t: 1659, loss: 15979.916015625
[INFO] Global_t: 1659, Episode_t: 3, Action: 7, Reward: 4.28, Epsilon: 0.18
[INFO] model update: t: 1660, loss: 43860.6484375
[INFO] Global_t: 1660, Episode_t: 4, Action: 104, Reward: 1.72, Epsilon: 0.18
[INFO] model update: t: 1661, loss: 25068.955078125
[INFO] Global_t: 1661, Episode_t: 5, Action: 4, Reward: 3.52, Epsilon: 0.18
[INFO] model update: t: 1662, loss: 29647.4609375
[INFO] Global_t: 1662, Episode_t: 6, Action: 18, Reward: 1.95, Epsilon: 0.18
[INFO] Global step: 1662, Cumulative rewards: 15.424440000000002, Runtime (s): 1491.04
--------------------------------------
 
graph: 77, nodes: 203, edges: 600
[INFO] model update: t: 1663, loss: 15887.767578125
[INFO] Global_t: 1663, Episode_t: 1, Action: 46, Reward: 2.52, Epsilon: 0.18
[INFO] model update: t: 1664, loss: 50165.875
[INFO] Global_t: 1664, Episode_t: 2, Action: 120, Reward: 2.47, Epsilon: 0.18
[INFO] model update: t: 1665, loss: 32703.046875
[INFO] Global_t: 1665, Episode_t: 3, Action: 86, Reward: 2.19, Epsilon: 0.17
[INFO] model update: t: 1666, loss: 12002.0029296875
[INFO] Global_t: 1666, Episode_t: 4, Action: 69, Reward: 1.93, Epsilon: 0.17
[INFO] model update: t: 1667, loss: 31866.28515625
[INFO] Global_t: 1667, Episode_t: 5, Action: 23, Reward: 2.52, Epsilon: 0.17
[INFO] model update: t: 1668, loss: 68046.4921875
[INFO] Global_t: 1668, Episode_t: 6, Action: 21, Reward: 2.83, Epsilon: 0.17
[INFO] Global step: 1668, Cumulative rewards: 14.46132, Runtime (s): 1492.49
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7514188289642334
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7415821552276611
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5195856094360352
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5656979084014893
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4123528003692627
average cummulative reward vector is:  [0.08753553 0.0763169  0.07496913 0.0685257  0.0734879 ]
average cummulative reward is:  0.07616703086147672
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 78, nodes: 185, edges: 546
[INFO] model update: t: 1669, loss: 21512.41015625
[INFO] Global_t: 1669, Episode_t: 1, Action: 14, Reward: 2.63, Epsilon: 0.17
[INFO] model update: t: 1670, loss: 36304.03515625
[INFO] Global_t: 1670, Episode_t: 2, Action: 7, Reward: 2.73, Epsilon: 0.17
[INFO] model update: t: 1671, loss: 21672.24609375
[INFO] Global_t: 1671, Episode_t: 3, Action: 159, Reward: 1.56, Epsilon: 0.17
[INFO] model update: t: 1672, loss: 23721.2265625
[INFO] Global_t: 1672, Episode_t: 4, Action: 49, Reward: 1.58, Epsilon: 0.17
[INFO] model update: t: 1673, loss: 12093.4716796875
[INFO] Global_t: 1673, Episode_t: 5, Action: 108, Reward: 1.33, Epsilon: 0.17
[INFO] model update: t: 1674, loss: 38897.3984375
[INFO] Global_t: 1674, Episode_t: 6, Action: 42, Reward: 2.02, Epsilon: 0.17
[INFO] Global step: 1674, Cumulative rewards: 11.847360000000002, Runtime (s): 1502.34
--------------------------------------
 
graph: 79, nodes: 203, edges: 600
[INFO] model update: t: 1675, loss: 23994.61328125
[INFO] Global_t: 1675, Episode_t: 1, Action: 186, Reward: 1.42, Epsilon: 0.17
[INFO] model update: t: 1676, loss: 51989.07421875
[INFO] Global_t: 1676, Episode_t: 2, Action: 159, Reward: 2.41, Epsilon: 0.17
[INFO] model update: t: 1677, loss: 11890.3623046875
[INFO] Global_t: 1677, Episode_t: 3, Action: 68, Reward: 2.14, Epsilon: 0.17
[INFO] model update: t: 1678, loss: 28293.8515625
[INFO] Global_t: 1678, Episode_t: 4, Action: 174, Reward: 2.02, Epsilon: 0.17
[INFO] model update: t: 1679, loss: 19464.6796875
[INFO] Global_t: 1679, Episode_t: 5, Action: 7, Reward: 2.80, Epsilon: 0.17
[INFO] model update: t: 1680, loss: 26068.1875
[INFO] Global_t: 1680, Episode_t: 6, Action: 5, Reward: 4.29, Epsilon: 0.17
[INFO] Global step: 1680, Cumulative rewards: 15.064919999999997, Runtime (s): 1503.77
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.656240463256836
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6063566207885742
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.2988479137420654
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5254082679748535
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4579236507415771
average cummulative reward vector is:  [0.08214868 0.06514884 0.06700219 0.06702196 0.07648602]
average cummulative reward is:  0.07156153934353349
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 80, nodes: 218, edges: 644
[INFO] model update: t: 1681, loss: 21477.787109375
[INFO] Global_t: 1681, Episode_t: 1, Action: 160, Reward: 2.69, Epsilon: 0.17
[INFO] model update: t: 1682, loss: 6757.546875
[INFO] Global_t: 1682, Episode_t: 2, Action: 4, Reward: 3.91, Epsilon: 0.17
[INFO] model update: t: 1683, loss: 20191.05078125
[INFO] Global_t: 1683, Episode_t: 3, Action: 13, Reward: 3.62, Epsilon: 0.17
[INFO] model update: t: 1684, loss: 30291.0
[INFO] Global_t: 1684, Episode_t: 4, Action: 12, Reward: 2.16, Epsilon: 0.17
[INFO] model update: t: 1685, loss: 19485.580078125
[INFO] Global_t: 1685, Episode_t: 5, Action: 31, Reward: 2.49, Epsilon: 0.16
[INFO] model update: t: 1686, loss: 14836.40625
[INFO] Global_t: 1686, Episode_t: 6, Action: 32, Reward: 2.47, Epsilon: 0.16
[INFO] Global step: 1686, Cumulative rewards: 17.3544, Runtime (s): 1513.84
--------------------------------------
 
graph: 81, nodes: 183, edges: 540
[INFO] model update: t: 1687, loss: 22789.603515625
[INFO] Global_t: 1687, Episode_t: 1, Action: 103, Reward: 2.20, Epsilon: 0.16
[INFO] model update: t: 1688, loss: 18922.361328125
[INFO] Global_t: 1688, Episode_t: 2, Action: 13, Reward: 3.27, Epsilon: 0.16
[INFO] model update: t: 1689, loss: 21711.37890625
[INFO] Global_t: 1689, Episode_t: 3, Action: 7, Reward: 3.17, Epsilon: 0.16
[INFO] model update: t: 1690, loss: 44002.22265625
[INFO] Global_t: 1690, Episode_t: 4, Action: 0, Reward: 3.80, Epsilon: 0.16
[INFO] model update: t: 1691, loss: 36540.796875
[INFO] Global_t: 1691, Episode_t: 5, Action: 166, Reward: 1.52, Epsilon: 0.16
[INFO] model update: t: 1692, loss: 47651.4296875
[INFO] Global_t: 1692, Episode_t: 6, Action: 4, Reward: 2.65, Epsilon: 0.16
[INFO] Global step: 1692, Cumulative rewards: 16.610400000000002, Runtime (s): 1515.81
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7253799438476562
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6159460544586182
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5602073669433594
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.615821361541748
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4011399745941162
average cummulative reward vector is:  [0.07900605 0.06920856 0.07902568 0.07040093 0.07262016]
average cummulative reward is:  0.07405227927525297
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 82, nodes: 183, edges: 540
[INFO] model update: t: 1693, loss: 16491.765625
[INFO] Global_t: 1693, Episode_t: 1, Action: 9, Reward: 5.10, Epsilon: 0.16
[INFO] model update: t: 1694, loss: 44606.2734375
[INFO] Global_t: 1694, Episode_t: 2, Action: 33, Reward: 1.96, Epsilon: 0.16
[INFO] model update: t: 1695, loss: 14192.138671875
[INFO] Global_t: 1695, Episode_t: 3, Action: 161, Reward: 1.81, Epsilon: 0.16
[INFO] model update: t: 1696, loss: 24123.6953125
[INFO] Global_t: 1696, Episode_t: 4, Action: 8, Reward: 2.23, Epsilon: 0.16
[INFO] model update: t: 1697, loss: 18704.5390625
[INFO] Global_t: 1697, Episode_t: 5, Action: 15, Reward: 1.58, Epsilon: 0.16
[INFO] model update: t: 1698, loss: 12542.953125
[INFO] Global_t: 1698, Episode_t: 6, Action: 6, Reward: 2.74, Epsilon: 0.16
[INFO] Global step: 1698, Cumulative rewards: 15.429960000000001, Runtime (s): 1525.76
--------------------------------------
 
graph: 83, nodes: 198, edges: 584
[INFO] model update: t: 1699, loss: 19780.755859375
[INFO] Global_t: 1699, Episode_t: 1, Action: 155, Reward: 2.51, Epsilon: 0.16
[INFO] model update: t: 1700, loss: 22501.70703125
[INFO] Global_t: 1700, Episode_t: 2, Action: 15, Reward: 3.29, Epsilon: 0.16
[INFO] model update: t: 1701, loss: 15944.998046875
[INFO] Global_t: 1701, Episode_t: 3, Action: 68, Reward: 1.81, Epsilon: 0.16
[INFO] model update: t: 1702, loss: 41864.640625
[INFO] Global_t: 1702, Episode_t: 4, Action: 53, Reward: 1.68, Epsilon: 0.16
[INFO] model update: t: 1703, loss: 23759.9296875
[INFO] Global_t: 1703, Episode_t: 5, Action: 11, Reward: 1.92, Epsilon: 0.16
[INFO] model update: t: 1704, loss: 25339.2421875
[INFO] Global_t: 1704, Episode_t: 6, Action: 7, Reward: 3.59, Epsilon: 0.16
[INFO] Global step: 1704, Cumulative rewards: 14.805239999999998, Runtime (s): 1527.86
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.650378704071045
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6473140716552734
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4995622634887695
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5420970916748047
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.454712152481079
average cummulative reward vector is:  [0.08097105 0.06837384 0.07839153 0.06752687 0.07536048]
average cummulative reward is:  0.07412475566173253
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 84, nodes: 205, edges: 606
[INFO] model update: t: 1705, loss: 13469.73828125
[INFO] Global_t: 1705, Episode_t: 1, Action: 40, Reward: 2.68, Epsilon: 0.16
[INFO] model update: t: 1706, loss: 31425.044921875
[INFO] Global_t: 1706, Episode_t: 2, Action: 23, Reward: 3.12, Epsilon: 0.15
[INFO] model update: t: 1707, loss: 23560.06640625
[INFO] Global_t: 1707, Episode_t: 3, Action: 38, Reward: 2.40, Epsilon: 0.15
[INFO] model update: t: 1708, loss: 21948.654296875
[INFO] Global_t: 1708, Episode_t: 4, Action: 57, Reward: 2.04, Epsilon: 0.15
[INFO] model update: t: 1709, loss: 22692.60546875
[INFO] Global_t: 1709, Episode_t: 5, Action: 8, Reward: 2.30, Epsilon: 0.15
[INFO] model update: t: 1710, loss: 30650.60546875
[INFO] Global_t: 1710, Episode_t: 6, Action: 35, Reward: 1.65, Epsilon: 0.15
[INFO] Global step: 1710, Cumulative rewards: 14.189160000000001, Runtime (s): 1537.61
--------------------------------------
 
graph: 85, nodes: 212, edges: 627
[INFO] model update: t: 1711, loss: 16857.2578125
[INFO] Global_t: 1711, Episode_t: 1, Action: 198, Reward: 1.19, Epsilon: 0.15
[INFO] model update: t: 1712, loss: 17318.7109375
[INFO] Global_t: 1712, Episode_t: 2, Action: 29, Reward: 2.22, Epsilon: 0.15
[INFO] model update: t: 1713, loss: 13198.6708984375
[INFO] Global_t: 1713, Episode_t: 3, Action: 33, Reward: 2.13, Epsilon: 0.15
[INFO] model update: t: 1714, loss: 19725.08984375
[INFO] Global_t: 1714, Episode_t: 4, Action: 158, Reward: 1.93, Epsilon: 0.15
[INFO] model update: t: 1715, loss: 24904.619140625
[INFO] Global_t: 1715, Episode_t: 5, Action: 27, Reward: 2.17, Epsilon: 0.15
[INFO] model update: t: 1716, loss: 16041.9296875
[INFO] Global_t: 1716, Episode_t: 6, Action: 6, Reward: 4.17, Epsilon: 0.15
[INFO] Global step: 1716, Cumulative rewards: 13.805159999999999, Runtime (s): 1539.09
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7657897472381592
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7384309768676758
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3452112674713135
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5439791679382324
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3549296855926514
average cummulative reward vector is:  [0.08839237 0.07513588 0.06981038 0.06750701 0.07013306]
average cummulative reward is:  0.07419574088525338
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 86, nodes: 200, edges: 591
[INFO] model update: t: 1717, loss: 9954.7109375
[INFO] Global_t: 1717, Episode_t: 1, Action: 190, Reward: 2.10, Epsilon: 0.15
[INFO] model update: t: 1718, loss: 12603.193359375
[INFO] Global_t: 1718, Episode_t: 2, Action: 18, Reward: 3.26, Epsilon: 0.15
[INFO] model update: t: 1719, loss: 17835.76953125
[INFO] Global_t: 1719, Episode_t: 3, Action: 74, Reward: 1.96, Epsilon: 0.15
[INFO] model update: t: 1720, loss: 24465.7734375
[INFO] Global_t: 1720, Episode_t: 4, Action: 177, Reward: 1.77, Epsilon: 0.15
[INFO] model update: t: 1721, loss: 9689.05859375
[INFO] Global_t: 1721, Episode_t: 5, Action: 144, Reward: 1.90, Epsilon: 0.15
[INFO] model update: t: 1722, loss: 7669.267578125
[INFO] Global_t: 1722, Episode_t: 6, Action: 61, Reward: 1.19, Epsilon: 0.15
[INFO] Global step: 1722, Cumulative rewards: 12.177599999999998, Runtime (s): 1548.91
--------------------------------------
 
graph: 87, nodes: 218, edges: 645
[INFO] model update: t: 1723, loss: 9751.3330078125
[INFO] Global_t: 1723, Episode_t: 1, Action: 77, Reward: 2.27, Epsilon: 0.15
[INFO] model update: t: 1724, loss: 24945.0703125
[INFO] Global_t: 1724, Episode_t: 2, Action: 37, Reward: 2.86, Epsilon: 0.15
[INFO] model update: t: 1725, loss: 24210.65234375
[INFO] Global_t: 1725, Episode_t: 3, Action: 18, Reward: 2.67, Epsilon: 0.15
[INFO] model update: t: 1726, loss: 22858.21484375
[INFO] Global_t: 1726, Episode_t: 4, Action: 209, Reward: 1.40, Epsilon: 0.14
[INFO] model update: t: 1727, loss: 6299.06396484375
[INFO] Global_t: 1727, Episode_t: 5, Action: 145, Reward: 0.93, Epsilon: 0.14
[INFO] model update: t: 1728, loss: 16503.3046875
[INFO] Global_t: 1728, Episode_t: 6, Action: 15, Reward: 2.03, Epsilon: 0.14
[INFO] Global step: 1728, Cumulative rewards: 12.166200000000002, Runtime (s): 1550.96
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6457853317260742
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.700488805770874
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5266995429992676
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7240333557128906
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.354259729385376
average cummulative reward vector is:  [0.08129632 0.0735287  0.08036667 0.0748222  0.06666613]
average cummulative reward is:  0.07533600229075688
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 88, nodes: 204, edges: 603
[INFO] model update: t: 1729, loss: 19749.08984375
[INFO] Global_t: 1729, Episode_t: 1, Action: 10, Reward: 2.52, Epsilon: 0.14
[INFO] model update: t: 1730, loss: 25602.416015625
[INFO] Global_t: 1730, Episode_t: 2, Action: 11, Reward: 3.34, Epsilon: 0.14
[INFO] model update: t: 1731, loss: 14961.8837890625
[INFO] Global_t: 1731, Episode_t: 3, Action: 9, Reward: 4.31, Epsilon: 0.14
[INFO] model update: t: 1732, loss: 25486.291015625
[INFO] Global_t: 1732, Episode_t: 4, Action: 42, Reward: 1.20, Epsilon: 0.14
[INFO] model update: t: 1733, loss: 18165.56640625
[INFO] Global_t: 1733, Episode_t: 5, Action: 5, Reward: 2.09, Epsilon: 0.14
[INFO] model update: t: 1734, loss: 23883.58984375
[INFO] Global_t: 1734, Episode_t: 6, Action: 7, Reward: 2.38, Epsilon: 0.14
[INFO] Global step: 1734, Cumulative rewards: 15.839399999999998, Runtime (s): 1561.33
--------------------------------------
 
graph: 89, nodes: 199, edges: 588
[INFO] model update: t: 1735, loss: 19063.025390625
[INFO] Global_t: 1735, Episode_t: 1, Action: 44, Reward: 2.05, Epsilon: 0.14
[INFO] model update: t: 1736, loss: 17215.283203125
[INFO] Global_t: 1736, Episode_t: 2, Action: 10, Reward: 3.23, Epsilon: 0.14
[INFO] model update: t: 1737, loss: 17036.826171875
[INFO] Global_t: 1737, Episode_t: 3, Action: 180, Reward: 1.14, Epsilon: 0.14
[INFO] model update: t: 1738, loss: 38592.7109375
[INFO] Global_t: 1738, Episode_t: 4, Action: 0, Reward: 3.99, Epsilon: 0.14
[INFO] model update: t: 1739, loss: 16126.150390625
[INFO] Global_t: 1739, Episode_t: 5, Action: 25, Reward: 1.36, Epsilon: 0.14
[INFO] model update: t: 1740, loss: 35337.73828125
[INFO] Global_t: 1740, Episode_t: 6, Action: 12, Reward: 1.80, Epsilon: 0.14
[INFO] Global step: 1740, Cumulative rewards: 13.560479999999998, Runtime (s): 1563.24
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.763791799545288
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6166675090789795
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5679247379302979
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7705020904541016
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4914441108703613
average cummulative reward vector is:  [0.08514184 0.06941644 0.07702268 0.07752477 0.07778172]
average cummulative reward is:  0.0773774883342649
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 90, nodes: 207, edges: 612
[INFO] model update: t: 1741, loss: 39542.41015625
[INFO] Global_t: 1741, Episode_t: 1, Action: 83, Reward: 2.32, Epsilon: 0.14
[INFO] model update: t: 1742, loss: 22781.830078125
[INFO] Global_t: 1742, Episode_t: 2, Action: 166, Reward: 1.27, Epsilon: 0.14
[INFO] model update: t: 1743, loss: 51254.80859375
[INFO] Global_t: 1743, Episode_t: 3, Action: 17, Reward: 3.22, Epsilon: 0.14
[INFO] model update: t: 1744, loss: 30185.75
[INFO] Global_t: 1744, Episode_t: 4, Action: 3, Reward: 3.70, Epsilon: 0.14
[INFO] model update: t: 1745, loss: 57986.40625
[INFO] Global_t: 1745, Episode_t: 5, Action: 22, Reward: 2.35, Epsilon: 0.14
[INFO] model update: t: 1746, loss: 31974.904296875
[INFO] Global_t: 1746, Episode_t: 6, Action: 1, Reward: 4.57, Epsilon: 0.13
[INFO] Global step: 1746, Cumulative rewards: 17.425559999999997, Runtime (s): 1573.53
--------------------------------------
 
graph: 91, nodes: 198, edges: 585
[INFO] model update: t: 1747, loss: 53575.24609375
[INFO] Global_t: 1747, Episode_t: 1, Action: 159, Reward: 2.30, Epsilon: 0.13
[INFO] model update: t: 1748, loss: 28046.58203125
[INFO] Global_t: 1748, Episode_t: 2, Action: 14, Reward: 2.93, Epsilon: 0.13
[INFO] model update: t: 1749, loss: 58831.125
[INFO] Global_t: 1749, Episode_t: 3, Action: 16, Reward: 2.39, Epsilon: 0.13
[INFO] model update: t: 1750, loss: 30826.826171875
[INFO] Global_t: 1750, Episode_t: 4, Action: 7, Reward: 2.91, Epsilon: 0.13
[INFO] model update: t: 1751, loss: 32952.90234375
[INFO] Global_t: 1751, Episode_t: 5, Action: 187, Reward: 1.07, Epsilon: 0.13
[INFO] model update: t: 1752, loss: 29891.00390625
[INFO] Global_t: 1752, Episode_t: 6, Action: 149, Reward: 1.79, Epsilon: 0.13
[INFO] Global step: 1752, Cumulative rewards: 13.39416, Runtime (s): 1575.34
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6282212734222412
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8215477466583252
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4464211463928223
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7796885967254639
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.471848487854004
average cummulative reward vector is:  [0.08049658 0.07408009 0.07557186 0.0776278  0.07621774]
average cummulative reward is:  0.07679881502745198
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 92, nodes: 183, edges: 539
[INFO] model update: t: 1753, loss: 22090.15625
[INFO] Global_t: 1753, Episode_t: 1, Action: 85, Reward: 1.80, Epsilon: 0.13
[INFO] model update: t: 1754, loss: 24985.37890625
[INFO] Global_t: 1754, Episode_t: 2, Action: 69, Reward: 2.40, Epsilon: 0.13
[INFO] model update: t: 1755, loss: 21712.3046875
[INFO] Global_t: 1755, Episode_t: 3, Action: 18, Reward: 2.44, Epsilon: 0.13
[INFO] model update: t: 1756, loss: 30042.1796875
[INFO] Global_t: 1756, Episode_t: 4, Action: 66, Reward: 1.84, Epsilon: 0.13
[INFO] model update: t: 1757, loss: 36909.23046875
[INFO] Global_t: 1757, Episode_t: 5, Action: 3, Reward: 4.12, Epsilon: 0.13
[INFO] model update: t: 1758, loss: 35092.4375
[INFO] Global_t: 1758, Episode_t: 6, Action: 120, Reward: 1.53, Epsilon: 0.13
[INFO] Global step: 1758, Cumulative rewards: 14.13372, Runtime (s): 1585.27
--------------------------------------
 
graph: 93, nodes: 217, edges: 642
[INFO] model update: t: 1759, loss: 22585.56640625
[INFO] Global_t: 1759, Episode_t: 1, Action: 170, Reward: 2.45, Epsilon: 0.13
[INFO] model update: t: 1760, loss: 22533.765625
[INFO] Global_t: 1760, Episode_t: 2, Action: 29, Reward: 2.81, Epsilon: 0.13
[INFO] model update: t: 1761, loss: 20923.1796875
[INFO] Global_t: 1761, Episode_t: 3, Action: 16, Reward: 2.67, Epsilon: 0.13
[INFO] model update: t: 1762, loss: 26658.431640625
[INFO] Global_t: 1762, Episode_t: 4, Action: 15, Reward: 3.31, Epsilon: 0.13
[INFO] model update: t: 1763, loss: 17778.07421875
[INFO] Global_t: 1763, Episode_t: 5, Action: 6, Reward: 3.60, Epsilon: 0.13
[INFO] model update: t: 1764, loss: 23018.7265625
[INFO] Global_t: 1764, Episode_t: 6, Action: 35, Reward: 2.33, Epsilon: 0.13
[INFO] Global step: 1764, Cumulative rewards: 17.172359999999998, Runtime (s): 1586.85
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7926161289215088
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6598889827728271
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4497644901275635
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.849454641342163
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3630902767181396
average cummulative reward vector is:  [0.08418921 0.07181389 0.07591011 0.08127336 0.07002984]
average cummulative reward is:  0.07664328238009618
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 94, nodes: 198, edges: 585
[INFO] model update: t: 1765, loss: 17361.28125
[INFO] Global_t: 1765, Episode_t: 1, Action: 20, Reward: 2.26, Epsilon: 0.13
[INFO] model update: t: 1766, loss: 22703.328125
[INFO] Global_t: 1766, Episode_t: 2, Action: 65, Reward: 1.71, Epsilon: 0.13
[INFO] model update: t: 1767, loss: 21829.794921875
[INFO] Global_t: 1767, Episode_t: 3, Action: 119, Reward: 2.72, Epsilon: 0.12
[INFO] model update: t: 1768, loss: 28895.81640625
[INFO] Global_t: 1768, Episode_t: 4, Action: 8, Reward: 2.62, Epsilon: 0.12
[INFO] model update: t: 1769, loss: 32974.2421875
[INFO] Global_t: 1769, Episode_t: 5, Action: 7, Reward: 2.37, Epsilon: 0.12
[INFO] model update: t: 1770, loss: 92562.046875
[INFO] Global_t: 1770, Episode_t: 6, Action: 28, Reward: 2.32, Epsilon: 0.12
[INFO] Global step: 1770, Cumulative rewards: 13.995359999999998, Runtime (s): 1596.91
--------------------------------------
 
graph: 95, nodes: 202, edges: 597
[INFO] model update: t: 1771, loss: 64084.96875
[INFO] Global_t: 1771, Episode_t: 1, Action: 7, Reward: 3.37, Epsilon: 0.12
[INFO] model update: t: 1772, loss: 58369.8203125
[INFO] Global_t: 1772, Episode_t: 2, Action: 57, Reward: 2.45, Epsilon: 0.12
[INFO] model update: t: 1773, loss: 52597.6875
[INFO] Global_t: 1773, Episode_t: 3, Action: 146, Reward: 2.70, Epsilon: 0.12
[INFO] model update: t: 1774, loss: 68028.5859375
[INFO] Global_t: 1774, Episode_t: 4, Action: 11, Reward: 3.00, Epsilon: 0.12
[INFO] model update: t: 1775, loss: 74706.5
[INFO] Global_t: 1775, Episode_t: 5, Action: 115, Reward: 2.19, Epsilon: 0.12
[INFO] model update: t: 1776, loss: 69004.84375
[INFO] Global_t: 1776, Episode_t: 6, Action: 65, Reward: 1.98, Epsilon: 0.12
[INFO] Global step: 1776, Cumulative rewards: 15.692639999999997, Runtime (s): 1598.93
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5163986682891846
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8483390808105469
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3267521858215332
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7153236865997314
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.475200891494751
average cummulative reward vector is:  [0.07481974 0.08045671 0.06824781 0.07515631 0.07678602]
average cummulative reward is:  0.07509331878586195
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 96, nodes: 200, edges: 591
[INFO] model update: t: 1777, loss: 47210.83984375
[INFO] Global_t: 1777, Episode_t: 1, Action: 177, Reward: 2.09, Epsilon: 0.12
[INFO] model update: t: 1778, loss: 105771.7578125
[INFO] Global_t: 1778, Episode_t: 2, Action: 14, Reward: 3.27, Epsilon: 0.12
[INFO] model update: t: 1779, loss: 23991.205078125
[INFO] Global_t: 1779, Episode_t: 3, Action: 6, Reward: 4.49, Epsilon: 0.12
[INFO] model update: t: 1780, loss: 201294.125
[INFO] Global_t: 1780, Episode_t: 4, Action: 36, Reward: 1.28, Epsilon: 0.12
[INFO] model update: t: 1781, loss: 74243.71875
[INFO] Global_t: 1781, Episode_t: 5, Action: 7, Reward: 2.15, Epsilon: 0.12
[INFO] model update: t: 1782, loss: 72910.03125
[INFO] Global_t: 1782, Episode_t: 6, Action: 4, Reward: 2.61, Epsilon: 0.12
[INFO] Global step: 1782, Cumulative rewards: 15.88272, Runtime (s): 1609.32
--------------------------------------
 
graph: 97, nodes: 206, edges: 609
[INFO] model update: t: 1783, loss: 80109.28125
[INFO] Global_t: 1783, Episode_t: 1, Action: 12, Reward: 2.12, Epsilon: 0.12
[INFO] model update: t: 1784, loss: 109816.78125
[INFO] Global_t: 1784, Episode_t: 2, Action: 166, Reward: 1.90, Epsilon: 0.12
[INFO] model update: t: 1785, loss: 50322.3359375
[INFO] Global_t: 1785, Episode_t: 3, Action: 22, Reward: 2.85, Epsilon: 0.12
[INFO] model update: t: 1786, loss: 74670.0078125
[INFO] Global_t: 1786, Episode_t: 4, Action: 110, Reward: 1.34, Epsilon: 0.12
[INFO] model update: t: 1787, loss: 18462.728515625
[INFO] Global_t: 1787, Episode_t: 5, Action: 3, Reward: 3.48, Epsilon: 0.11
[INFO] model update: t: 1788, loss: 34352.328125
[INFO] Global_t: 1788, Episode_t: 6, Action: 15, Reward: 2.27, Epsilon: 0.11
[INFO] Global step: 1788, Cumulative rewards: 13.96284, Runtime (s): 1611.18
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.795905590057373
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6615450382232666
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4850287437438965
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.672729730606079
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4946606159210205
average cummulative reward vector is:  [0.09059    0.07216852 0.07821967 0.0733021  0.07305565]
average cummulative reward is:  0.07746718772293894
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 98, nodes: 206, edges: 607
[INFO] model update: t: 1789, loss: 17899.87890625
[INFO] Global_t: 1789, Episode_t: 1, Action: 24, Reward: 2.32, Epsilon: 0.11
[INFO] model update: t: 1790, loss: 22138.8984375
[INFO] Global_t: 1790, Episode_t: 2, Action: 9, Reward: 3.16, Epsilon: 0.11
[INFO] model update: t: 1791, loss: 31887.98828125
[INFO] Global_t: 1791, Episode_t: 3, Action: 30, Reward: 2.41, Epsilon: 0.11
[INFO] model update: t: 1792, loss: 62908.296875
[INFO] Global_t: 1792, Episode_t: 4, Action: 73, Reward: 1.65, Epsilon: 0.11
[INFO] model update: t: 1793, loss: 33657.66015625
[INFO] Global_t: 1793, Episode_t: 5, Action: 8, Reward: 2.48, Epsilon: 0.11
[INFO] model update: t: 1794, loss: 16951.984375
[INFO] Global_t: 1794, Episode_t: 6, Action: 2, Reward: 2.79, Epsilon: 0.11
[INFO] Global step: 1794, Cumulative rewards: 14.79816, Runtime (s): 1621.34
--------------------------------------
 
graph: 99, nodes: 181, edges: 533
[INFO] model update: t: 1795, loss: 17821.57421875
[INFO] Global_t: 1795, Episode_t: 1, Action: 59, Reward: 2.84, Epsilon: 0.11
[INFO] model update: t: 1796, loss: 19746.56640625
[INFO] Global_t: 1796, Episode_t: 2, Action: 22, Reward: 3.29, Epsilon: 0.11
[INFO] model update: t: 1797, loss: 29477.796875
[INFO] Global_t: 1797, Episode_t: 3, Action: 111, Reward: 2.55, Epsilon: 0.11
[INFO] model update: t: 1798, loss: 8967.8056640625
[INFO] Global_t: 1798, Episode_t: 4, Action: 42, Reward: 2.14, Epsilon: 0.11
[INFO] model update: t: 1799, loss: 12287.7060546875
[INFO] Global_t: 1799, Episode_t: 5, Action: 61, Reward: 2.23, Epsilon: 0.11
[INFO] model update: t: 1800, loss: 21182.2734375
[INFO] Global_t: 1800, Episode_t: 6, Action: 6, Reward: 2.86, Epsilon: 0.11
[INFO] Global step: 1800, Cumulative rewards: 15.909840000000003, Runtime (s): 1623.00
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7738206386566162
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6777830123901367
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4098913669586182
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8258345127105713
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3928399085998535
average cummulative reward vector is:  [0.08852211 0.07299213 0.07348333 0.07531729 0.07175618]
average cummulative reward is:  0.07641420814828918
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 100, nodes: 188, edges: 555
[INFO] model update: t: 1801, loss: 18800.26171875
[INFO] Global_t: 1801, Episode_t: 1, Action: 73, Reward: 2.43, Epsilon: 0.11
[INFO] model update: t: 1802, loss: 17099.78515625
[INFO] Global_t: 1802, Episode_t: 2, Action: 32, Reward: 2.45, Epsilon: 0.11
[INFO] model update: t: 1803, loss: 25713.39453125
[INFO] Global_t: 1803, Episode_t: 3, Action: 33, Reward: 2.30, Epsilon: 0.11
[INFO] model update: t: 1804, loss: 12772.015625
[INFO] Global_t: 1804, Episode_t: 4, Action: 12, Reward: 2.23, Epsilon: 0.11
[INFO] model update: t: 1805, loss: 42853.46875
[INFO] Global_t: 1805, Episode_t: 5, Action: 14, Reward: 2.43, Epsilon: 0.11
[INFO] model update: t: 1806, loss: 17737.1484375
[INFO] Global_t: 1806, Episode_t: 6, Action: 16, Reward: 2.07, Epsilon: 0.11
[INFO] Global step: 1806, Cumulative rewards: 13.910400000000001, Runtime (s): 1633.12
--------------------------------------
 
graph: 101, nodes: 211, edges: 624
[INFO] model update: t: 1807, loss: 15170.296875
[INFO] Global_t: 1807, Episode_t: 1, Action: 56, Reward: 2.56, Epsilon: 0.11
[INFO] model update: t: 1808, loss: 33673.99609375
[INFO] Global_t: 1808, Episode_t: 2, Action: 17, Reward: 3.36, Epsilon: 0.10
[INFO] model update: t: 1809, loss: 42766.578125
[INFO] Global_t: 1809, Episode_t: 3, Action: 67, Reward: 2.95, Epsilon: 0.10
[INFO] model update: t: 1810, loss: 15896.0703125
[INFO] Global_t: 1810, Episode_t: 4, Action: 7, Reward: 2.20, Epsilon: 0.10
[INFO] model update: t: 1811, loss: 23907.876953125
[INFO] Global_t: 1811, Episode_t: 5, Action: 13, Reward: 3.02, Epsilon: 0.10
[INFO] model update: t: 1812, loss: 17889.765625
[INFO] Global_t: 1812, Episode_t: 6, Action: 10, Reward: 2.62, Epsilon: 0.10
[INFO] Global step: 1812, Cumulative rewards: 16.70028, Runtime (s): 1635.40
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5623986721038818
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6662516593933105
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5888614654541016
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6947805881500244
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3809618949890137
average cummulative reward vector is:  [0.07754053 0.0718662  0.07771421 0.0740778  0.07127339]
average cummulative reward is:  0.07449442570097167
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 102, nodes: 180, edges: 531
[INFO] model update: t: 1813, loss: 28254.681640625
[INFO] Global_t: 1813, Episode_t: 1, Action: 123, Reward: 2.39, Epsilon: 0.10
[INFO] model update: t: 1814, loss: 34332.4375
[INFO] Global_t: 1814, Episode_t: 2, Action: 21, Reward: 2.81, Epsilon: 0.10
[INFO] model update: t: 1815, loss: 28321.24609375
[INFO] Global_t: 1815, Episode_t: 3, Action: 9, Reward: 3.00, Epsilon: 0.10
[INFO] model update: t: 1816, loss: 20391.369140625
[INFO] Global_t: 1816, Episode_t: 4, Action: 20, Reward: 2.27, Epsilon: 0.10
[INFO] model update: t: 1817, loss: 11499.06640625
[INFO] Global_t: 1817, Episode_t: 5, Action: 12, Reward: 2.42, Epsilon: 0.10
[INFO] model update: t: 1818, loss: 12176.634765625
[INFO] Global_t: 1818, Episode_t: 6, Action: 42, Reward: 2.22, Epsilon: 0.10
[INFO] Global step: 1818, Cumulative rewards: 15.11028, Runtime (s): 1645.04
--------------------------------------
 
graph: 103, nodes: 187, edges: 551
[INFO] model update: t: 1819, loss: 13457.052734375
[INFO] Global_t: 1819, Episode_t: 1, Action: 23, Reward: 2.01, Epsilon: 0.10
[INFO] model update: t: 1820, loss: 17989.666015625
[INFO] Global_t: 1820, Episode_t: 2, Action: 22, Reward: 2.73, Epsilon: 0.10
[INFO] model update: t: 1821, loss: 16902.6484375
[INFO] Global_t: 1821, Episode_t: 3, Action: 1, Reward: 4.28, Epsilon: 0.10
[INFO] model update: t: 1822, loss: 30804.7265625
[INFO] Global_t: 1822, Episode_t: 4, Action: 6, Reward: 2.38, Epsilon: 0.10
[INFO] model update: t: 1823, loss: 20971.142578125
[INFO] Global_t: 1823, Episode_t: 5, Action: 12, Reward: 2.12, Epsilon: 0.10
[INFO] model update: t: 1824, loss: 28467.5546875
[INFO] Global_t: 1824, Episode_t: 6, Action: 14, Reward: 2.76, Epsilon: 0.10
[INFO] Global step: 1824, Cumulative rewards: 16.28388, Runtime (s): 1646.99
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6610209941864014
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8401298522949219
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3374667167663574
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8196539878845215
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3749432563781738
average cummulative reward vector is:  [0.08269158 0.07485694 0.06867404 0.07938715 0.06991694]
average cummulative reward is:  0.07510533042484822
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 104, nodes: 185, edges: 546
[INFO] model update: t: 1825, loss: 31685.46875
[INFO] Global_t: 1825, Episode_t: 1, Action: 57, Reward: 2.33, Epsilon: 0.10
[INFO] model update: t: 1826, loss: 34795.81640625
[INFO] Global_t: 1826, Episode_t: 2, Action: 110, Reward: 1.86, Epsilon: 0.10
[INFO] model update: t: 1827, loss: 17402.02734375
[INFO] Global_t: 1827, Episode_t: 3, Action: 60, Reward: 1.94, Epsilon: 0.10
[INFO] model update: t: 1828, loss: 30221.8046875
[INFO] Global_t: 1828, Episode_t: 4, Action: 10, Reward: 3.16, Epsilon: 0.09
[INFO] model update: t: 1829, loss: 11400.9560546875
[INFO] Global_t: 1829, Episode_t: 5, Action: 31, Reward: 2.68, Epsilon: 0.09
[INFO] model update: t: 1830, loss: 43043.0390625
[INFO] Global_t: 1830, Episode_t: 6, Action: 19, Reward: 2.85, Epsilon: 0.09
[INFO] Global step: 1830, Cumulative rewards: 14.821079999999998, Runtime (s): 1656.91
--------------------------------------
 
graph: 105, nodes: 180, edges: 531
[INFO] model update: t: 1831, loss: 10348.296875
[INFO] Global_t: 1831, Episode_t: 1, Action: 7, Reward: 3.84, Epsilon: 0.09
[INFO] model update: t: 1832, loss: 18860.68359375
[INFO] Global_t: 1832, Episode_t: 2, Action: 11, Reward: 2.91, Epsilon: 0.09
[INFO] model update: t: 1833, loss: 32550.1796875
[INFO] Global_t: 1833, Episode_t: 3, Action: 12, Reward: 3.22, Epsilon: 0.09
[INFO] model update: t: 1834, loss: 40124.8125
[INFO] Global_t: 1834, Episode_t: 4, Action: 26, Reward: 1.94, Epsilon: 0.09
[INFO] model update: t: 1835, loss: 37247.7421875
[INFO] Global_t: 1835, Episode_t: 5, Action: 24, Reward: 1.14, Epsilon: 0.09
[INFO] model update: t: 1836, loss: 17793.322265625
[INFO] Global_t: 1836, Episode_t: 6, Action: 9, Reward: 1.96, Epsilon: 0.09
[INFO] Global step: 1836, Cumulative rewards: 15.01536, Runtime (s): 1658.88
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6496868133544922
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5719921588897705
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4574429988861084
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.640148639678955
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3867273330688477
average cummulative reward vector is:  [0.07665763 0.06761157 0.07575546 0.0714014  0.07136935]
average cummulative reward is:  0.07255908536835287
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 106, nodes: 206, edges: 608
[INFO] model update: t: 1837, loss: 21983.021484375
[INFO] Global_t: 1837, Episode_t: 1, Action: 5, Reward: 3.30, Epsilon: 0.09
[INFO] model update: t: 1838, loss: 33109.96484375
[INFO] Global_t: 1838, Episode_t: 2, Action: 9, Reward: 3.33, Epsilon: 0.09
[INFO] model update: t: 1839, loss: 28681.73046875
[INFO] Global_t: 1839, Episode_t: 3, Action: 12, Reward: 2.63, Epsilon: 0.09
[INFO] model update: t: 1840, loss: 19746.40234375
[INFO] Global_t: 1840, Episode_t: 4, Action: 15, Reward: 1.78, Epsilon: 0.09
[INFO] model update: t: 1841, loss: 31101.56640625
[INFO] Global_t: 1841, Episode_t: 5, Action: 6, Reward: 2.03, Epsilon: 0.09
[INFO] model update: t: 1842, loss: 16964.931640625
[INFO] Global_t: 1842, Episode_t: 6, Action: 113, Reward: 1.44, Epsilon: 0.09
[INFO] Global step: 1842, Cumulative rewards: 14.511000000000001, Runtime (s): 1668.55
--------------------------------------
 
graph: 107, nodes: 205, edges: 606
[INFO] model update: t: 1843, loss: 26185.54296875
[INFO] Global_t: 1843, Episode_t: 1, Action: 6, Reward: 4.23, Epsilon: 0.09
[INFO] model update: t: 1844, loss: 34076.6796875
[INFO] Global_t: 1844, Episode_t: 2, Action: 4, Reward: 3.63, Epsilon: 0.09
[INFO] model update: t: 1845, loss: 13058.708984375
[INFO] Global_t: 1845, Episode_t: 3, Action: 1, Reward: 3.31, Epsilon: 0.09
[INFO] model update: t: 1846, loss: 17164.685546875
[INFO] Global_t: 1846, Episode_t: 4, Action: 31, Reward: 2.02, Epsilon: 0.09
[INFO] model update: t: 1847, loss: 29644.259765625
[INFO] Global_t: 1847, Episode_t: 5, Action: 9, Reward: 2.62, Epsilon: 0.09
[INFO] model update: t: 1848, loss: 11269.572265625
[INFO] Global_t: 1848, Episode_t: 6, Action: 7, Reward: 1.81, Epsilon: 0.08
[INFO] Global step: 1848, Cumulative rewards: 17.61732, Runtime (s): 1670.61
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.200855255126953
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9479658603668213
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.7523164749145508
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.844677209854126
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3174140453338623
average cummulative reward vector is:  [0.10126316 0.08378449 0.09242486 0.0802285  0.06665565]
average cummulative reward is:  0.08487133237152863
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 108, nodes: 215, edges: 636
[INFO] model update: t: 1849, loss: 182162.0
[INFO] Global_t: 1849, Episode_t: 1, Action: 181, Reward: 2.55, Epsilon: 0.08
[INFO] model update: t: 1850, loss: 158296.890625
[INFO] Global_t: 1850, Episode_t: 2, Action: 7, Reward: 4.38, Epsilon: 0.08
[INFO] model update: t: 1851, loss: 127706.03125
[INFO] Global_t: 1851, Episode_t: 3, Action: 23, Reward: 2.67, Epsilon: 0.08
[INFO] model update: t: 1852, loss: 146215.828125
[INFO] Global_t: 1852, Episode_t: 4, Action: 17, Reward: 1.50, Epsilon: 0.08
[INFO] model update: t: 1853, loss: 44168.28125
[INFO] Global_t: 1853, Episode_t: 5, Action: 43, Reward: 2.55, Epsilon: 0.08
[INFO] model update: t: 1854, loss: 39238.828125
[INFO] Global_t: 1854, Episode_t: 6, Action: 8, Reward: 2.61, Epsilon: 0.08
[INFO] Global step: 1854, Cumulative rewards: 16.25628, Runtime (s): 1682.28
--------------------------------------
 
graph: 109, nodes: 186, edges: 549
[INFO] model update: t: 1855, loss: 46858.46875
[INFO] Global_t: 1855, Episode_t: 1, Action: 151, Reward: 2.32, Epsilon: 0.08
[INFO] model update: t: 1856, loss: 30371.8203125
[INFO] Global_t: 1856, Episode_t: 2, Action: 15, Reward: 3.16, Epsilon: 0.08
[INFO] model update: t: 1857, loss: 32451.41796875
[INFO] Global_t: 1857, Episode_t: 3, Action: 12, Reward: 2.83, Epsilon: 0.08
[INFO] model update: t: 1858, loss: 51892.31640625
[INFO] Global_t: 1858, Episode_t: 4, Action: 5, Reward: 3.32, Epsilon: 0.08
[INFO] model update: t: 1859, loss: 44104.421875
[INFO] Global_t: 1859, Episode_t: 5, Action: 62, Reward: 1.96, Epsilon: 0.08
[INFO] model update: t: 1860, loss: 16289.947265625
[INFO] Global_t: 1860, Episode_t: 6, Action: 82, Reward: 1.75, Epsilon: 0.08
[INFO] Global step: 1860, Cumulative rewards: 15.333960000000001, Runtime (s): 1684.16
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.5372114181518555
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.82340407371521
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.581240177154541
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7170512676239014
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5576362609863281
average cummulative reward vector is:  [0.07570421 0.0783169  0.08167104 0.07492173 0.07509677]
average cummulative reward is:  0.07714213001826821
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 110, nodes: 180, edges: 531
[INFO] model update: t: 1861, loss: 31805.0078125
[INFO] Global_t: 1861, Episode_t: 1, Action: 5, Reward: 4.51, Epsilon: 0.08
[INFO] model update: t: 1862, loss: 25601.859375
[INFO] Global_t: 1862, Episode_t: 2, Action: 8, Reward: 3.11, Epsilon: 0.08
[INFO] model update: t: 1863, loss: 43510.78125
[INFO] Global_t: 1863, Episode_t: 3, Action: 17, Reward: 3.00, Epsilon: 0.08
[INFO] model update: t: 1864, loss: 25264.6015625
[INFO] Global_t: 1864, Episode_t: 4, Action: 15, Reward: 1.96, Epsilon: 0.08
[INFO] model update: t: 1865, loss: 24182.97265625
[INFO] Global_t: 1865, Episode_t: 5, Action: 58, Reward: 1.91, Epsilon: 0.08
[INFO] model update: t: 1866, loss: 36265.703125
[INFO] Global_t: 1866, Episode_t: 6, Action: 27, Reward: 1.75, Epsilon: 0.08
[INFO] Global step: 1866, Cumulative rewards: 16.238039999999998, Runtime (s): 1694.26
--------------------------------------
 
graph: 111, nodes: 200, edges: 591
[INFO] model update: t: 1867, loss: 11892.43359375
[INFO] Global_t: 1867, Episode_t: 1, Action: 92, Reward: 2.54, Epsilon: 0.08
[INFO] model update: t: 1868, loss: 9378.826171875
[INFO] Global_t: 1868, Episode_t: 2, Action: 22, Reward: 2.94, Epsilon: 0.08
[INFO] model update: t: 1869, loss: 18699.42578125
[INFO] Global_t: 1869, Episode_t: 3, Action: 4, Reward: 4.27, Epsilon: 0.07
[INFO] model update: t: 1870, loss: 169198.078125
[INFO] Global_t: 1870, Episode_t: 4, Action: 27, Reward: 2.10, Epsilon: 0.07
[INFO] model update: t: 1871, loss: 40815.9609375
[INFO] Global_t: 1871, Episode_t: 5, Action: 15, Reward: 2.00, Epsilon: 0.07
[INFO] model update: t: 1872, loss: 20506.265625
[INFO] Global_t: 1872, Episode_t: 6, Action: 18, Reward: 2.45, Epsilon: 0.07
[INFO] Global step: 1872, Cumulative rewards: 16.29504, Runtime (s): 1696.03
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6538894176483154
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8684144020080566
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6264359951019287
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.997239351272583
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.6070866584777832
average cummulative reward vector is:  [0.08187974 0.07943611 0.08416694 0.0793757  0.08154274]
average cummulative reward is:  0.08128024614279802
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 112, nodes: 216, edges: 639
[INFO] model update: t: 1873, loss: 32446.87890625
[INFO] Global_t: 1873, Episode_t: 1, Action: 31, Reward: 2.36, Epsilon: 0.07
[INFO] model update: t: 1874, loss: 27979.046875
[INFO] Global_t: 1874, Episode_t: 2, Action: 20, Reward: 3.36, Epsilon: 0.07
[INFO] model update: t: 1875, loss: 33682.3828125
[INFO] Global_t: 1875, Episode_t: 3, Action: 8, Reward: 4.07, Epsilon: 0.07
[INFO] model update: t: 1876, loss: 50526.41015625
[INFO] Global_t: 1876, Episode_t: 4, Action: 7, Reward: 2.08, Epsilon: 0.07
[INFO] model update: t: 1877, loss: 39536.046875
[INFO] Global_t: 1877, Episode_t: 5, Action: 25, Reward: 2.13, Epsilon: 0.07
[INFO] model update: t: 1878, loss: 38611.72265625
[INFO] Global_t: 1878, Episode_t: 6, Action: 2, Reward: 2.81, Epsilon: 0.07
[INFO] Global step: 1878, Cumulative rewards: 16.811400000000003, Runtime (s): 1707.09
--------------------------------------
 
graph: 113, nodes: 217, edges: 642
[INFO] model update: t: 1879, loss: 30626.962890625
[INFO] Global_t: 1879, Episode_t: 1, Action: 26, Reward: 3.39, Epsilon: 0.07
[INFO] model update: t: 1880, loss: 25962.67578125
[INFO] Global_t: 1880, Episode_t: 2, Action: 9, Reward: 4.15, Epsilon: 0.07
[INFO] model update: t: 1881, loss: 41214.0546875
[INFO] Global_t: 1881, Episode_t: 3, Action: 14, Reward: 3.19, Epsilon: 0.07
[INFO] model update: t: 1882, loss: 34630.6015625
[INFO] Global_t: 1882, Episode_t: 4, Action: 18, Reward: 2.21, Epsilon: 0.07
[INFO] model update: t: 1883, loss: 45301.71875
[INFO] Global_t: 1883, Episode_t: 5, Action: 4, Reward: 3.57, Epsilon: 0.07
[INFO] model update: t: 1884, loss: 20967.6640625
[INFO] Global_t: 1884, Episode_t: 6, Action: 12, Reward: 1.70, Epsilon: 0.07
[INFO] Global step: 1884, Cumulative rewards: 18.216839999999998, Runtime (s): 1709.28
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.677154541015625
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  2.019057035446167
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6014039516448975
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8177211284637451
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5784411430358887
average cummulative reward vector is:  [0.08054816 0.08150347 0.08338333 0.07881121 0.08197661]
average cummulative reward is:  0.08124455826135786
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 114, nodes: 190, edges: 561
[INFO] model update: t: 1885, loss: 28773.306640625
[INFO] Global_t: 1885, Episode_t: 1, Action: 94, Reward: 2.55, Epsilon: 0.07
[INFO] model update: t: 1886, loss: 27650.916015625
[INFO] Global_t: 1886, Episode_t: 2, Action: 6, Reward: 3.13, Epsilon: 0.07
[INFO] model update: t: 1887, loss: 21993.5546875
[INFO] Global_t: 1887, Episode_t: 3, Action: 12, Reward: 3.78, Epsilon: 0.07
[INFO] model update: t: 1888, loss: 81373.2109375
[INFO] Global_t: 1888, Episode_t: 4, Action: 16, Reward: 3.19, Epsilon: 0.07
[INFO] model update: t: 1889, loss: 43848.42578125
[INFO] Global_t: 1889, Episode_t: 5, Action: 1, Reward: 3.38, Epsilon: 0.06
[INFO] model update: t: 1890, loss: 18326.8984375
[INFO] Global_t: 1890, Episode_t: 6, Action: 72, Reward: 2.17, Epsilon: 0.06
[INFO] Global step: 1890, Cumulative rewards: 18.19032, Runtime (s): 1719.73
--------------------------------------
 
graph: 115, nodes: 198, edges: 585
[INFO] model update: t: 1891, loss: 40922.03125
[INFO] Global_t: 1891, Episode_t: 1, Action: 46, Reward: 2.57, Epsilon: 0.06
[INFO] model update: t: 1892, loss: 61579.38671875
[INFO] Global_t: 1892, Episode_t: 2, Action: 7, Reward: 3.24, Epsilon: 0.06
[INFO] model update: t: 1893, loss: 139722.421875
[INFO] Global_t: 1893, Episode_t: 3, Action: 10, Reward: 3.33, Epsilon: 0.06
[INFO] model update: t: 1894, loss: 44354.25
[INFO] Global_t: 1894, Episode_t: 4, Action: 13, Reward: 2.15, Epsilon: 0.06
[INFO] model update: t: 1895, loss: 73960.75
[INFO] Global_t: 1895, Episode_t: 5, Action: 12, Reward: 2.48, Epsilon: 0.06
[INFO] model update: t: 1896, loss: 44251.296875
[INFO] Global_t: 1896, Episode_t: 6, Action: 17, Reward: 1.82, Epsilon: 0.06
[INFO] Global step: 1896, Cumulative rewards: 15.59424, Runtime (s): 1721.57
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.0121729373931885
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.888695478439331
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6230549812316895
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5993971824645996
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4643981456756592
average cummulative reward vector is:  [0.09508132 0.08100486 0.08378005 0.06882944 0.07548817]
average cummulative reward is:  0.08083676856814814
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 116, nodes: 182, edges: 537
[INFO] model update: t: 1897, loss: 57328.1640625
[INFO] Global_t: 1897, Episode_t: 1, Action: 7, Reward: 2.78, Epsilon: 0.06
[INFO] model update: t: 1898, loss: 42751.21875
[INFO] Global_t: 1898, Episode_t: 2, Action: 150, Reward: 2.19, Epsilon: 0.06
[INFO] model update: t: 1899, loss: 46451.1796875
[INFO] Global_t: 1899, Episode_t: 3, Action: 0, Reward: 4.48, Epsilon: 0.06
[INFO] model update: t: 1900, loss: 27545.44140625
[INFO] Global_t: 1900, Episode_t: 4, Action: 32, Reward: 2.26, Epsilon: 0.06
[INFO] model update: t: 1901, loss: 35135.1015625
[INFO] Global_t: 1901, Episode_t: 5, Action: 10, Reward: 2.79, Epsilon: 0.06
[INFO] model update: t: 1902, loss: 16938.712890625
[INFO] Global_t: 1902, Episode_t: 6, Action: 5, Reward: 2.35, Epsilon: 0.06
[INFO] Global step: 1902, Cumulative rewards: 16.85664, Runtime (s): 1732.24
--------------------------------------
 
graph: 117, nodes: 196, edges: 579
[INFO] model update: t: 1903, loss: 23801.96875
[INFO] Global_t: 1903, Episode_t: 1, Action: 9, Reward: 3.15, Epsilon: 0.06
[INFO] model update: t: 1904, loss: 30825.8046875
[INFO] Global_t: 1904, Episode_t: 2, Action: 80, Reward: 1.77, Epsilon: 0.06
[INFO] model update: t: 1905, loss: 114807.3203125
[INFO] Global_t: 1905, Episode_t: 3, Action: 27, Reward: 2.55, Epsilon: 0.06
[INFO] model update: t: 1906, loss: 31432.671875
[INFO] Global_t: 1906, Episode_t: 4, Action: 0, Reward: 3.85, Epsilon: 0.06
[INFO] model update: t: 1907, loss: 31820.953125
[INFO] Global_t: 1907, Episode_t: 5, Action: 195, Reward: 1.20, Epsilon: 0.06
[INFO] model update: t: 1908, loss: 26052.18359375
[INFO] Global_t: 1908, Episode_t: 6, Action: 1, Reward: 3.41, Epsilon: 0.06
[INFO] Global step: 1908, Cumulative rewards: 15.924480000000003, Runtime (s): 1734.53
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6397230625152588
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8035733699798584
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6155152320861816
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8026652336120605
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4475798606872559
average cummulative reward vector is:  [0.08153289 0.07699884 0.08417869 0.07896612 0.07324516]
average cummulative reward is:  0.07898434172793492
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 118, nodes: 180, edges: 531
[INFO] model update: t: 1909, loss: 49121.47265625
[INFO] Global_t: 1909, Episode_t: 1, Action: 10, Reward: 2.88, Epsilon: 0.06
[INFO] model update: t: 1910, loss: 33744.6953125
[INFO] Global_t: 1910, Episode_t: 2, Action: 16, Reward: 3.72, Epsilon: 0.05
[INFO] model update: t: 1911, loss: 10757.595703125
[INFO] Global_t: 1911, Episode_t: 3, Action: 9, Reward: 1.92, Epsilon: 0.05
[INFO] model update: t: 1912, loss: 47805.1640625
[INFO] Global_t: 1912, Episode_t: 4, Action: 55, Reward: 1.83, Epsilon: 0.05
[INFO] model update: t: 1913, loss: 57085.52734375
[INFO] Global_t: 1913, Episode_t: 5, Action: 7, Reward: 2.17, Epsilon: 0.05
[INFO] model update: t: 1914, loss: 16764.685546875
[INFO] Global_t: 1914, Episode_t: 6, Action: 5, Reward: 2.51, Epsilon: 0.05
[INFO] Global step: 1914, Cumulative rewards: 15.031799999999999, Runtime (s): 1744.82
--------------------------------------
 
graph: 119, nodes: 182, edges: 537
[INFO] model update: t: 1915, loss: 20708.58984375
[INFO] Global_t: 1915, Episode_t: 1, Action: 155, Reward: 2.66, Epsilon: 0.05
[INFO] model update: t: 1916, loss: 36082.5234375
[INFO] Global_t: 1916, Episode_t: 2, Action: 22, Reward: 2.63, Epsilon: 0.05
[INFO] model update: t: 1917, loss: 67045.6328125
[INFO] Global_t: 1917, Episode_t: 3, Action: 3, Reward: 4.89, Epsilon: 0.05
[INFO] model update: t: 1918, loss: 12339.4951171875
[INFO] Global_t: 1918, Episode_t: 4, Action: 95, Reward: 2.40, Epsilon: 0.05
[INFO] model update: t: 1919, loss: 55069.06640625
[INFO] Global_t: 1919, Episode_t: 5, Action: 12, Reward: 4.11, Epsilon: 0.05
[INFO] model update: t: 1920, loss: 17228.44921875
[INFO] Global_t: 1920, Episode_t: 6, Action: 106, Reward: 2.14, Epsilon: 0.05
[INFO] Global step: 1920, Cumulative rewards: 18.83136, Runtime (s): 1746.22
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6868770122528076
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.998901128768921
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4622962474822998
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9627315998077393
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4799273014068604
average cummulative reward vector is:  [0.08367368 0.08494421 0.07562295 0.08144463 0.07585995]
average cummulative reward is:  0.08030908407958896
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 120, nodes: 219, edges: 648
[INFO] model update: t: 1921, loss: 62959.73046875
[INFO] Global_t: 1921, Episode_t: 1, Action: 18, Reward: 2.16, Epsilon: 0.05
[INFO] model update: t: 1922, loss: 11566.78125
[INFO] Global_t: 1922, Episode_t: 2, Action: 15, Reward: 2.87, Epsilon: 0.05
[INFO] model update: t: 1923, loss: 56057.04296875
[INFO] Global_t: 1923, Episode_t: 3, Action: 0, Reward: 4.66, Epsilon: 0.05
[INFO] model update: t: 1924, loss: 15059.7880859375
[INFO] Global_t: 1924, Episode_t: 4, Action: 34, Reward: 2.07, Epsilon: 0.05
[INFO] model update: t: 1925, loss: 37553.015625
[INFO] Global_t: 1925, Episode_t: 5, Action: 49, Reward: 2.03, Epsilon: 0.05
[INFO] model update: t: 1926, loss: 27853.828125
[INFO] Global_t: 1926, Episode_t: 6, Action: 41, Reward: 1.79, Epsilon: 0.05
[INFO] Global step: 1926, Cumulative rewards: 15.59256, Runtime (s): 1756.77
--------------------------------------
 
graph: 121, nodes: 182, edges: 536
[INFO] model update: t: 1927, loss: 33809.30859375
[INFO] Global_t: 1927, Episode_t: 1, Action: 15, Reward: 2.46, Epsilon: 0.05
[INFO] model update: t: 1928, loss: 31154.099609375
[INFO] Global_t: 1928, Episode_t: 2, Action: 28, Reward: 3.24, Epsilon: 0.05
[INFO] model update: t: 1929, loss: 16313.748046875
[INFO] Global_t: 1929, Episode_t: 3, Action: 5, Reward: 4.03, Epsilon: 0.05
[INFO] model update: t: 1930, loss: 19920.30859375
[INFO] Global_t: 1930, Episode_t: 4, Action: 7, Reward: 2.08, Epsilon: 0.04
[INFO] model update: t: 1931, loss: 16602.09375
[INFO] Global_t: 1931, Episode_t: 5, Action: 19, Reward: 2.44, Epsilon: 0.04
[INFO] model update: t: 1932, loss: 12912.2490234375
[INFO] Global_t: 1932, Episode_t: 6, Action: 6, Reward: 3.08, Epsilon: 0.04
[INFO] Global step: 1932, Cumulative rewards: 17.329679999999996, Runtime (s): 1758.97
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6652727127075195
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6556012630462646
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6899042129516602
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8224842548370361
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5067439079284668
average cummulative reward vector is:  [0.08260632 0.07108148 0.08239235 0.07993248 0.07798441]
average cummulative reward is:  0.07879940644707914
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 122, nodes: 206, edges: 609
[INFO] model update: t: 1933, loss: 24275.28515625
[INFO] Global_t: 1933, Episode_t: 1, Action: 15, Reward: 2.26, Epsilon: 0.04
[INFO] model update: t: 1934, loss: 19227.962890625
[INFO] Global_t: 1934, Episode_t: 2, Action: 14, Reward: 3.73, Epsilon: 0.04
[INFO] model update: t: 1935, loss: 17560.6875
[INFO] Global_t: 1935, Episode_t: 3, Action: 22, Reward: 2.65, Epsilon: 0.04
[INFO] model update: t: 1936, loss: 15484.59375
[INFO] Global_t: 1936, Episode_t: 4, Action: 28, Reward: 2.22, Epsilon: 0.04
[INFO] model update: t: 1937, loss: 28250.62109375
[INFO] Global_t: 1937, Episode_t: 5, Action: 16, Reward: 2.21, Epsilon: 0.04
[INFO] model update: t: 1938, loss: 25024.31640625
[INFO] Global_t: 1938, Episode_t: 6, Action: 68, Reward: 1.65, Epsilon: 0.04
[INFO] Global step: 1938, Cumulative rewards: 14.728079999999995, Runtime (s): 1769.25
--------------------------------------
 
graph: 123, nodes: 182, edges: 537
[INFO] model update: t: 1939, loss: 34830.66796875
[INFO] Global_t: 1939, Episode_t: 1, Action: 37, Reward: 2.82, Epsilon: 0.04
[INFO] model update: t: 1940, loss: 27537.755859375
[INFO] Global_t: 1940, Episode_t: 2, Action: 19, Reward: 3.17, Epsilon: 0.04
[INFO] model update: t: 1941, loss: 49175.375
[INFO] Global_t: 1941, Episode_t: 3, Action: 124, Reward: 1.57, Epsilon: 0.04
[INFO] model update: t: 1942, loss: 11681.423828125
[INFO] Global_t: 1942, Episode_t: 4, Action: 23, Reward: 2.37, Epsilon: 0.04
[INFO] model update: t: 1943, loss: 57154.2421875
[INFO] Global_t: 1943, Episode_t: 5, Action: 8, Reward: 3.68, Epsilon: 0.04
[INFO] model update: t: 1944, loss: 13038.23046875
[INFO] Global_t: 1944, Episode_t: 6, Action: 6, Reward: 2.26, Epsilon: 0.04
[INFO] Global step: 1944, Cumulative rewards: 15.873, Runtime (s): 1770.92
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7997782230377197
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6798741817474365
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.593151330947876
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.758807897567749
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4426243305206299
average cummulative reward vector is:  [0.08966053 0.06661968 0.08333115 0.07665794 0.0739629 ]
average cummulative reward is:  0.07804643938674782
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 124, nodes: 194, edges: 573
[INFO] model update: t: 1945, loss: 39550.18359375
[INFO] Global_t: 1945, Episode_t: 1, Action: 101, Reward: 2.27, Epsilon: 0.04
[INFO] model update: t: 1946, loss: 13227.8056640625
[INFO] Global_t: 1946, Episode_t: 2, Action: 38, Reward: 2.97, Epsilon: 0.04
[INFO] model update: t: 1947, loss: 31100.814453125
[INFO] Global_t: 1947, Episode_t: 3, Action: 7, Reward: 4.37, Epsilon: 0.04
[INFO] model update: t: 1948, loss: 40887.30859375
[INFO] Global_t: 1948, Episode_t: 4, Action: 57, Reward: 1.72, Epsilon: 0.04
[INFO] model update: t: 1949, loss: 41553.8515625
[INFO] Global_t: 1949, Episode_t: 5, Action: 35, Reward: 1.76, Epsilon: 0.04
[INFO] model update: t: 1950, loss: 24863.283203125
[INFO] Global_t: 1950, Episode_t: 6, Action: 2, Reward: 2.48, Epsilon: 0.03
[INFO] Global step: 1950, Cumulative rewards: 15.579959999999996, Runtime (s): 1781.46
--------------------------------------
 
graph: 125, nodes: 209, edges: 617
[INFO] model update: t: 1951, loss: 23016.01953125
[INFO] Global_t: 1951, Episode_t: 1, Action: 11, Reward: 2.91, Epsilon: 0.03
[INFO] model update: t: 1952, loss: 14819.35546875
[INFO] Global_t: 1952, Episode_t: 2, Action: 124, Reward: 2.76, Epsilon: 0.03
[INFO] model update: t: 1953, loss: 18328.080078125
[INFO] Global_t: 1953, Episode_t: 3, Action: 133, Reward: 2.21, Epsilon: 0.03
[INFO] model update: t: 1954, loss: 17572.83203125
[INFO] Global_t: 1954, Episode_t: 4, Action: 5, Reward: 3.14, Epsilon: 0.03
[INFO] model update: t: 1955, loss: 21349.99609375
[INFO] Global_t: 1955, Episode_t: 5, Action: 33, Reward: 2.86, Epsilon: 0.03
[INFO] model update: t: 1956, loss: 9931.685546875
[INFO] Global_t: 1956, Episode_t: 6, Action: 40, Reward: 2.63, Epsilon: 0.03
[INFO] Global step: 1956, Cumulative rewards: 16.519439999999996, Runtime (s): 1783.40
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8822879791259766
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8326377868652344
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5964195728302002
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9312551021575928
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5292582511901855
average cummulative reward vector is:  [0.08828158 0.07872315 0.08347978 0.08436238 0.07955376]
average cummulative reward is:  0.08288013102694236
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 126, nodes: 218, edges: 645
[INFO] model update: t: 1957, loss: 33693.328125
[INFO] Global_t: 1957, Episode_t: 1, Action: 9, Reward: 3.89, Epsilon: 0.03
[INFO] model update: t: 1958, loss: 19890.45703125
[INFO] Global_t: 1958, Episode_t: 2, Action: 5, Reward: 3.40, Epsilon: 0.03
[INFO] model update: t: 1959, loss: 32158.966796875
[INFO] Global_t: 1959, Episode_t: 3, Action: 10, Reward: 3.78, Epsilon: 0.03
[INFO] model update: t: 1960, loss: 18929.609375
[INFO] Global_t: 1960, Episode_t: 4, Action: 145, Reward: 2.20, Epsilon: 0.03
[INFO] model update: t: 1961, loss: 64280.7109375
[INFO] Global_t: 1961, Episode_t: 5, Action: 2, Reward: 3.79, Epsilon: 0.03
[INFO] model update: t: 1962, loss: 15470.208984375
[INFO] Global_t: 1962, Episode_t: 6, Action: 33, Reward: 1.77, Epsilon: 0.03
[INFO] Global step: 1962, Cumulative rewards: 18.83196, Runtime (s): 1794.16
--------------------------------------
 
graph: 127, nodes: 189, edges: 558
[INFO] model update: t: 1963, loss: 43238.23046875
[INFO] Global_t: 1963, Episode_t: 1, Action: 53, Reward: 2.38, Epsilon: 0.03
[INFO] model update: t: 1964, loss: 24742.96875
[INFO] Global_t: 1964, Episode_t: 2, Action: 4, Reward: 3.99, Epsilon: 0.03
[INFO] model update: t: 1965, loss: 21489.05078125
[INFO] Global_t: 1965, Episode_t: 3, Action: 38, Reward: 2.51, Epsilon: 0.03
[INFO] model update: t: 1966, loss: 24963.51171875
[INFO] Global_t: 1966, Episode_t: 4, Action: 7, Reward: 2.62, Epsilon: 0.03
[INFO] model update: t: 1967, loss: 28464.78125
[INFO] Global_t: 1967, Episode_t: 5, Action: 21, Reward: 2.19, Epsilon: 0.03
[INFO] model update: t: 1968, loss: 14886.609375
[INFO] Global_t: 1968, Episode_t: 6, Action: 18, Reward: 2.10, Epsilon: 0.03
[INFO] Global step: 1968, Cumulative rewards: 15.781559999999999, Runtime (s): 1796.21
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.778235673904419
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7347168922424316
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.3120296001434326
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7916712760925293
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.473595142364502
average cummulative reward vector is:  [0.08809079 0.07486829 0.06674672 0.07848435 0.07598763]
average cummulative reward is:  0.07683555560503827
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 128, nodes: 198, edges: 585
[INFO] model update: t: 1969, loss: 57860.92578125
[INFO] Global_t: 1969, Episode_t: 1, Action: 7, Reward: 3.13, Epsilon: 0.03
[INFO] model update: t: 1970, loss: 51800.0546875
[INFO] Global_t: 1970, Episode_t: 2, Action: 19, Reward: 2.94, Epsilon: 0.03
[INFO] model update: t: 1971, loss: 10082.7158203125
[INFO] Global_t: 1971, Episode_t: 3, Action: 190, Reward: 1.20, Epsilon: 0.02
[INFO] model update: t: 1972, loss: 29143.751953125
[INFO] Global_t: 1972, Episode_t: 4, Action: 186, Reward: 1.41, Epsilon: 0.02
[INFO] model update: t: 1973, loss: 10203.359375
[INFO] Global_t: 1973, Episode_t: 5, Action: 8, Reward: 3.39, Epsilon: 0.02
[INFO] model update: t: 1974, loss: 16552.37109375
[INFO] Global_t: 1974, Episode_t: 6, Action: 4, Reward: 3.88, Epsilon: 0.02
[INFO] Global step: 1974, Cumulative rewards: 15.9426, Runtime (s): 1806.36
--------------------------------------
 
graph: 129, nodes: 211, edges: 624
[INFO] model update: t: 1975, loss: 28946.056640625
[INFO] Global_t: 1975, Episode_t: 1, Action: 4, Reward: 3.54, Epsilon: 0.02
[INFO] model update: t: 1976, loss: 14380.826171875
[INFO] Global_t: 1976, Episode_t: 2, Action: 7, Reward: 3.99, Epsilon: 0.02
[INFO] model update: t: 1977, loss: 60208.36328125
[INFO] Global_t: 1977, Episode_t: 3, Action: 120, Reward: 2.74, Epsilon: 0.02
[INFO] model update: t: 1978, loss: 43469.8125
[INFO] Global_t: 1978, Episode_t: 4, Action: 32, Reward: 1.87, Epsilon: 0.02
[INFO] model update: t: 1979, loss: 25990.2421875
[INFO] Global_t: 1979, Episode_t: 5, Action: 115, Reward: 1.80, Epsilon: 0.02
[INFO] model update: t: 1980, loss: 40391.66015625
[INFO] Global_t: 1980, Episode_t: 6, Action: 39, Reward: 1.31, Epsilon: 0.02
[INFO] Global step: 1980, Cumulative rewards: 15.246599999999997, Runtime (s): 1808.26
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8831076622009277
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9576940536499023
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6434264183044434
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8625750541687012
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5198285579681396
average cummulative reward vector is:  [0.09401079 0.08448588 0.08514344 0.07619766 0.07814919]
average cummulative reward is:  0.08359739376521073
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 130, nodes: 205, edges: 606
[INFO] model update: t: 1981, loss: 16523.431640625
[INFO] Global_t: 1981, Episode_t: 1, Action: 20, Reward: 2.94, Epsilon: 0.02
[INFO] model update: t: 1982, loss: 32255.609375
[INFO] Global_t: 1982, Episode_t: 2, Action: 16, Reward: 3.66, Epsilon: 0.02
[INFO] model update: t: 1983, loss: 21129.1875
[INFO] Global_t: 1983, Episode_t: 3, Action: 36, Reward: 2.53, Epsilon: 0.02
[INFO] model update: t: 1984, loss: 35974.1796875
[INFO] Global_t: 1984, Episode_t: 4, Action: 12, Reward: 3.03, Epsilon: 0.02
[INFO] model update: t: 1985, loss: 19222.19921875
[INFO] Global_t: 1985, Episode_t: 5, Action: 17, Reward: 2.64, Epsilon: 0.02
[INFO] model update: t: 1986, loss: 11092.791015625
[INFO] Global_t: 1986, Episode_t: 6, Action: 75, Reward: 2.08, Epsilon: 0.02
[INFO] Global step: 1986, Cumulative rewards: 16.88448, Runtime (s): 1818.88
--------------------------------------
 
graph: 131, nodes: 210, edges: 620
[INFO] model update: t: 1987, loss: 10001.279296875
[INFO] Global_t: 1987, Episode_t: 1, Action: 15, Reward: 3.05, Epsilon: 0.02
[INFO] model update: t: 1988, loss: 7877.83740234375
[INFO] Global_t: 1988, Episode_t: 2, Action: 104, Reward: 2.79, Epsilon: 0.02
[INFO] model update: t: 1989, loss: 21815.1328125
[INFO] Global_t: 1989, Episode_t: 3, Action: 31, Reward: 3.20, Epsilon: 0.02
[INFO] model update: t: 1990, loss: 11145.21875
[INFO] Global_t: 1990, Episode_t: 4, Action: 143, Reward: 2.61, Epsilon: 0.02
[INFO] model update: t: 1991, loss: 15065.220703125
[INFO] Global_t: 1991, Episode_t: 5, Action: 96, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 1992, loss: 14724.6845703125
[INFO] Global_t: 1992, Episode_t: 6, Action: 25, Reward: 2.89, Epsilon: 0.01
[INFO] Global step: 1992, Cumulative rewards: 17.2476, Runtime (s): 1820.26
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7430517673492432
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.806527853012085
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.7980401515960693
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8558387756347656
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.3976387977600098
average cummulative reward vector is:  [0.08670632 0.07839792 0.08699454 0.08096589 0.07108871]
average cummulative reward is:  0.08083067310063052
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 132, nodes: 213, edges: 630
[INFO] model update: t: 1993, loss: 12415.259765625
[INFO] Global_t: 1993, Episode_t: 1, Action: 23, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 1994, loss: 10978.5595703125
[INFO] Global_t: 1994, Episode_t: 2, Action: 14, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 1995, loss: 17044.09375
[INFO] Global_t: 1995, Episode_t: 3, Action: 32, Reward: 3.12, Epsilon: 0.01
[INFO] model update: t: 1996, loss: 30288.494140625
[INFO] Global_t: 1996, Episode_t: 4, Action: 11, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 1997, loss: 19816.4296875
[INFO] Global_t: 1997, Episode_t: 5, Action: 1, Reward: 3.08, Epsilon: 0.01
[INFO] model update: t: 1998, loss: 16179.130859375
[INFO] Global_t: 1998, Episode_t: 6, Action: 7, Reward: 2.67, Epsilon: 0.01
[INFO] Global step: 1998, Cumulative rewards: 16.447079999999996, Runtime (s): 1831.05
--------------------------------------
 
graph: 133, nodes: 213, edges: 630
[INFO] model update: t: 1999, loss: 15548.82421875
[INFO] Global_t: 1999, Episode_t: 1, Action: 78, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 2000, loss: 22245.12109375
[INFO] Global_t: 2000, Episode_t: 2, Action: 12, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 2001, loss: 21323.912109375
[INFO] Global_t: 2001, Episode_t: 3, Action: 128, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 2002, loss: 24624.40234375
[INFO] Global_t: 2002, Episode_t: 4, Action: 4, Reward: 4.24, Epsilon: 0.01
[INFO] model update: t: 2003, loss: 18023.21484375
[INFO] Global_t: 2003, Episode_t: 5, Action: 36, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 2004, loss: 40760.609375
[INFO] Global_t: 2004, Episode_t: 6, Action: 26, Reward: 2.76, Epsilon: 0.01
[INFO] Global step: 2004, Cumulative rewards: 18.31632, Runtime (s): 1832.80
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8660142421722412
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.914088487625122
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.668323278427124
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.767796516418457
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.340993881225586
average cummulative reward vector is:  [0.09261289 0.07764907 0.08631639 0.07764509 0.06808091]
average cummulative reward is:  0.08046087393799553
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 134, nodes: 215, edges: 635
[INFO] model update: t: 2005, loss: 44621.09375
[INFO] Global_t: 2005, Episode_t: 1, Action: 148, Reward: 2.75, Epsilon: 0.01
[INFO] model update: t: 2006, loss: 22059.322265625
[INFO] Global_t: 2006, Episode_t: 2, Action: 22, Reward: 2.93, Epsilon: 0.01
[INFO] model update: t: 2007, loss: 9111.2939453125
[INFO] Global_t: 2007, Episode_t: 3, Action: 46, Reward: 3.40, Epsilon: 0.01
[INFO] model update: t: 2008, loss: 12519.232421875
[INFO] Global_t: 2008, Episode_t: 4, Action: 11, Reward: 3.11, Epsilon: 0.01
[INFO] model update: t: 2009, loss: 14579.20703125
[INFO] Global_t: 2009, Episode_t: 5, Action: 84, Reward: 1.86, Epsilon: 0.01
[INFO] model update: t: 2010, loss: 63350.15625
[INFO] Global_t: 2010, Episode_t: 6, Action: 163, Reward: 1.62, Epsilon: 0.01
[INFO] Global step: 2010, Cumulative rewards: 15.659759999999999, Runtime (s): 1843.42
--------------------------------------
 
graph: 135, nodes: 211, edges: 624
[INFO] model update: t: 2011, loss: 17438.705078125
[INFO] Global_t: 2011, Episode_t: 1, Action: 27, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 2012, loss: 8732.7529296875
[INFO] Global_t: 2012, Episode_t: 2, Action: 25, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 2013, loss: 21651.947265625
[INFO] Global_t: 2013, Episode_t: 3, Action: 6, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 2014, loss: 12710.4140625
[INFO] Global_t: 2014, Episode_t: 4, Action: 10, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 2015, loss: 17101.39453125
[INFO] Global_t: 2015, Episode_t: 5, Action: 20, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 2016, loss: 28565.3515625
[INFO] Global_t: 2016, Episode_t: 6, Action: 12, Reward: 2.26, Epsilon: 0.01
[INFO] Global step: 2016, Cumulative rewards: 16.267080000000004, Runtime (s): 1845.03
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9195661544799805
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8041508197784424
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5528783798217773
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9618146419525146
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5823242664337158
average cummulative reward vector is:  [0.08929289 0.07732593 0.07995683 0.08516729 0.08160618]
average cummulative reward is:  0.0826698247558372
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 136, nodes: 211, edges: 624
[INFO] model update: t: 2017, loss: 25644.068359375
[INFO] Global_t: 2017, Episode_t: 1, Action: 72, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 2018, loss: 45638.13671875
[INFO] Global_t: 2018, Episode_t: 2, Action: 105, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 2019, loss: 23675.28515625
[INFO] Global_t: 2019, Episode_t: 3, Action: 4, Reward: 4.52, Epsilon: 0.01
[INFO] model update: t: 2020, loss: 46532.578125
[INFO] Global_t: 2020, Episode_t: 4, Action: 10, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 2021, loss: 81055.09375
[INFO] Global_t: 2021, Episode_t: 5, Action: 9, Reward: 4.46, Epsilon: 0.01
[INFO] model update: t: 2022, loss: 11510.705078125
[INFO] Global_t: 2022, Episode_t: 6, Action: 23, Reward: 2.19, Epsilon: 0.01
[INFO] Global step: 2022, Cumulative rewards: 17.812920000000002, Runtime (s): 1855.54
--------------------------------------
 
graph: 137, nodes: 210, edges: 621
[INFO] model update: t: 2023, loss: 17934.28125
[INFO] Global_t: 2023, Episode_t: 1, Action: 21, Reward: 3.07, Epsilon: 0.01
[INFO] model update: t: 2024, loss: 17399.763671875
[INFO] Global_t: 2024, Episode_t: 2, Action: 172, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 2025, loss: 36640.0
[INFO] Global_t: 2025, Episode_t: 3, Action: 151, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 2026, loss: 22286.341796875
[INFO] Global_t: 2026, Episode_t: 4, Action: 122, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 2027, loss: 49287.3125
[INFO] Global_t: 2027, Episode_t: 5, Action: 53, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 2028, loss: 49125.2265625
[INFO] Global_t: 2028, Episode_t: 6, Action: 13, Reward: 4.14, Epsilon: 0.01
[INFO] Global step: 2028, Cumulative rewards: 17.087519999999998, Runtime (s): 1857.35
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.710667371749878
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7324881553649902
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6793994903564453
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.160597085952759
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.318269968032837
average cummulative reward vector is:  [0.08323    0.07348819 0.08691038 0.09374206 0.06580726]
average cummulative reward is:  0.08063557821947763
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 138, nodes: 185, edges: 545
[INFO] model update: t: 2029, loss: 24007.29296875
[INFO] Global_t: 2029, Episode_t: 1, Action: 164, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 2030, loss: 30103.30078125
[INFO] Global_t: 2030, Episode_t: 2, Action: 23, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 2031, loss: 11102.31640625
[INFO] Global_t: 2031, Episode_t: 3, Action: 82, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 2032, loss: 17700.650390625
[INFO] Global_t: 2032, Episode_t: 4, Action: 142, Reward: 1.77, Epsilon: 0.01
[INFO] model update: t: 2033, loss: 11640.0888671875
[INFO] Global_t: 2033, Episode_t: 5, Action: 22, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 2034, loss: 47019.4609375
[INFO] Global_t: 2034, Episode_t: 6, Action: 30, Reward: 1.71, Epsilon: 0.01
[INFO] Global step: 2034, Cumulative rewards: 11.89812, Runtime (s): 1867.92
--------------------------------------
 
graph: 139, nodes: 184, edges: 543
[INFO] model update: t: 2035, loss: 34503.859375
[INFO] Global_t: 2035, Episode_t: 1, Action: 40, Reward: 2.14, Epsilon: 0.01
[INFO] model update: t: 2036, loss: 13783.556640625
[INFO] Global_t: 2036, Episode_t: 2, Action: 21, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 2037, loss: 27747.25
[INFO] Global_t: 2037, Episode_t: 3, Action: 7, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 2038, loss: 9203.2578125
[INFO] Global_t: 2038, Episode_t: 4, Action: 15, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 2039, loss: 22619.07421875
[INFO] Global_t: 2039, Episode_t: 5, Action: 31, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 2040, loss: 68647.109375
[INFO] Global_t: 2040, Episode_t: 6, Action: 44, Reward: 2.23, Epsilon: 0.01
[INFO] Global step: 2040, Cumulative rewards: 14.35104, Runtime (s): 1869.65
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7984237670898438
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8606207370758057
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.7132060527801514
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.5178115367889404
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.6185283660888672
average cummulative reward vector is:  [0.08947658 0.08084421 0.08911284 0.06495561 0.07697339]
average cummulative reward is:  0.08027252560275913
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 140, nodes: 220, edges: 651
[INFO] model update: t: 2041, loss: 84779.984375
[INFO] Global_t: 2041, Episode_t: 1, Action: 57, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 2042, loss: 10764.576171875
[INFO] Global_t: 2042, Episode_t: 2, Action: 9, Reward: 3.31, Epsilon: 0.01
[INFO] model update: t: 2043, loss: 62317.23828125
[INFO] Global_t: 2043, Episode_t: 3, Action: 3, Reward: 3.72, Epsilon: 0.01
[INFO] model update: t: 2044, loss: 10594.50390625
[INFO] Global_t: 2044, Episode_t: 4, Action: 11, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 2045, loss: 73839.015625
[INFO] Global_t: 2045, Episode_t: 5, Action: 78, Reward: 2.33, Epsilon: 0.01
[INFO] model update: t: 2046, loss: 9018.458984375
[INFO] Global_t: 2046, Episode_t: 6, Action: 46, Reward: 2.80, Epsilon: 0.01
[INFO] Global step: 2046, Cumulative rewards: 18.28188, Runtime (s): 1879.94
--------------------------------------
 
graph: 141, nodes: 205, edges: 606
[INFO] model update: t: 2047, loss: 76543.140625
[INFO] Global_t: 2047, Episode_t: 1, Action: 15, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 2048, loss: 18424.5
[INFO] Global_t: 2048, Episode_t: 2, Action: 39, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 2049, loss: 65220.52734375
[INFO] Global_t: 2049, Episode_t: 3, Action: 194, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 2050, loss: 21048.921875
[INFO] Global_t: 2050, Episode_t: 4, Action: 118, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 2051, loss: 69398.5625
[INFO] Global_t: 2051, Episode_t: 5, Action: 33, Reward: 3.35, Epsilon: 0.01
[INFO] model update: t: 2052, loss: 43060.90625
[INFO] Global_t: 2052, Episode_t: 6, Action: 42, Reward: 2.85, Epsilon: 0.01
[INFO] Global step: 2052, Cumulative rewards: 16.52796, Runtime (s): 1881.30
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7879645824432373
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9122824668884277
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5138428211212158
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9930622577667236
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5974452495574951
average cummulative reward vector is:  [0.08874132 0.08265486 0.07797213 0.08143364 0.08257823]
average cummulative reward is:  0.0826760357428781
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 142, nodes: 201, edges: 593
[INFO] model update: t: 2053, loss: 56697.7734375
[INFO] Global_t: 2053, Episode_t: 1, Action: 87, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 2054, loss: 40737.75
[INFO] Global_t: 2054, Episode_t: 2, Action: 8, Reward: 4.17, Epsilon: 0.01
[INFO] model update: t: 2055, loss: 108198.984375
[INFO] Global_t: 2055, Episode_t: 3, Action: 19, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 2056, loss: 84030.40625
[INFO] Global_t: 2056, Episode_t: 4, Action: 16, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 2057, loss: 16855.55859375
[INFO] Global_t: 2057, Episode_t: 5, Action: 26, Reward: 1.25, Epsilon: 0.01
[INFO] model update: t: 2058, loss: 55036.265625
[INFO] Global_t: 2058, Episode_t: 6, Action: 56, Reward: 2.02, Epsilon: 0.01
[INFO] Global step: 2058, Cumulative rewards: 14.91288, Runtime (s): 1892.17
--------------------------------------
 
graph: 143, nodes: 194, edges: 573
[INFO] model update: t: 2059, loss: 20729.41796875
[INFO] Global_t: 2059, Episode_t: 1, Action: 6, Reward: 3.70, Epsilon: 0.01
[INFO] model update: t: 2060, loss: 64029.703125
[INFO] Global_t: 2060, Episode_t: 2, Action: 21, Reward: 3.15, Epsilon: 0.01
[INFO] model update: t: 2061, loss: 23203.71875
[INFO] Global_t: 2061, Episode_t: 3, Action: 8, Reward: 2.85, Epsilon: 0.01
[INFO] model update: t: 2062, loss: 62423.9765625
[INFO] Global_t: 2062, Episode_t: 4, Action: 28, Reward: 1.71, Epsilon: 0.01
[INFO] model update: t: 2063, loss: 15246.625
[INFO] Global_t: 2063, Episode_t: 5, Action: 24, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 2064, loss: 17523.34765625
[INFO] Global_t: 2064, Episode_t: 6, Action: 17, Reward: 2.37, Epsilon: 0.01
[INFO] Global step: 2064, Cumulative rewards: 16.325039999999998, Runtime (s): 1894.28
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8759138584136963
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8135161399841309
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.438823938369751
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7765519618988037
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.6195285320281982
average cummulative reward vector is:  [0.09379368 0.07318426 0.07401339 0.07726799 0.08373253]
average cummulative reward is:  0.08039836979677073
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 144, nodes: 219, edges: 648
[INFO] model update: t: 2065, loss: 8099.349609375
[INFO] Global_t: 2065, Episode_t: 1, Action: 91, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 2066, loss: 6806.83642578125
[INFO] Global_t: 2066, Episode_t: 2, Action: 14, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 2067, loss: 7266.41845703125
[INFO] Global_t: 2067, Episode_t: 3, Action: 38, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 2068, loss: 13775.330078125
[INFO] Global_t: 2068, Episode_t: 4, Action: 9, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 2069, loss: 43694.078125
[INFO] Global_t: 2069, Episode_t: 5, Action: 10, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 2070, loss: 22133.11328125
[INFO] Global_t: 2070, Episode_t: 6, Action: 15, Reward: 2.24, Epsilon: 0.01
[INFO] Global step: 2070, Cumulative rewards: 15.47904, Runtime (s): 1904.84
--------------------------------------
 
graph: 145, nodes: 217, edges: 642
[INFO] model update: t: 2071, loss: 12026.8076171875
[INFO] Global_t: 2071, Episode_t: 1, Action: 41, Reward: 2.54, Epsilon: 0.01
[INFO] model update: t: 2072, loss: 23587.02734375
[INFO] Global_t: 2072, Episode_t: 2, Action: 12, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 2073, loss: 7662.1083984375
[INFO] Global_t: 2073, Episode_t: 3, Action: 16, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 2074, loss: 14189.927734375
[INFO] Global_t: 2074, Episode_t: 4, Action: 23, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 2075, loss: 10884.8564453125
[INFO] Global_t: 2075, Episode_t: 5, Action: 32, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 2076, loss: 38309.375
[INFO] Global_t: 2076, Episode_t: 6, Action: 18, Reward: 3.05, Epsilon: 0.01
[INFO] Global step: 2076, Cumulative rewards: 17.13468, Runtime (s): 1906.54
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7588376998901367
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6539337635040283
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5793349742889404
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.606255054473877
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5247759819030762
average cummulative reward vector is:  [0.08066579 0.0712537  0.08077596 0.06933061 0.0786078 ]
average cummulative reward is:  0.07612677052742023
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 146, nodes: 207, edges: 612
[INFO] model update: t: 2077, loss: 12531.865234375
[INFO] Global_t: 2077, Episode_t: 1, Action: 12, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 2078, loss: 21649.63671875
[INFO] Global_t: 2078, Episode_t: 2, Action: 145, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 2079, loss: 12055.03515625
[INFO] Global_t: 2079, Episode_t: 3, Action: 7, Reward: 4.02, Epsilon: 0.01
[INFO] model update: t: 2080, loss: 40296.8515625
[INFO] Global_t: 2080, Episode_t: 4, Action: 5, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 2081, loss: 25822.33984375
[INFO] Global_t: 2081, Episode_t: 5, Action: 11, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 2082, loss: 34559.80078125
[INFO] Global_t: 2082, Episode_t: 6, Action: 53, Reward: 1.58, Epsilon: 0.01
[INFO] Global step: 2082, Cumulative rewards: 17.56632, Runtime (s): 1916.66
--------------------------------------
 
graph: 147, nodes: 202, edges: 597
[INFO] model update: t: 2083, loss: 49057.7109375
[INFO] Global_t: 2083, Episode_t: 1, Action: 134, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 2084, loss: 17882.91796875
[INFO] Global_t: 2084, Episode_t: 2, Action: 7, Reward: 4.15, Epsilon: 0.01
[INFO] model update: t: 2085, loss: 23252.97265625
[INFO] Global_t: 2085, Episode_t: 3, Action: 108, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 2086, loss: 24747.876953125
[INFO] Global_t: 2086, Episode_t: 4, Action: 110, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 2087, loss: 14792.009765625
[INFO] Global_t: 2087, Episode_t: 5, Action: 63, Reward: 1.58, Epsilon: 0.01
[INFO] model update: t: 2088, loss: 12547.880859375
[INFO] Global_t: 2088, Episode_t: 6, Action: 58, Reward: 2.07, Epsilon: 0.01
[INFO] Global step: 2088, Cumulative rewards: 14.46156, Runtime (s): 1918.48
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7966251373291016
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7708024978637695
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6588103771209717
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.725738525390625
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4274699687957764
average cummulative reward vector is:  [0.08939632 0.07697847 0.08636858 0.07542547 0.07269247]
average cummulative reward is:  0.08017226153093356
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 148, nodes: 199, edges: 587
[INFO] model update: t: 2089, loss: 12189.1591796875
[INFO] Global_t: 2089, Episode_t: 1, Action: 4, Reward: 4.10, Epsilon: 0.01
[INFO] model update: t: 2090, loss: 28841.564453125
[INFO] Global_t: 2090, Episode_t: 2, Action: 121, Reward: 1.87, Epsilon: 0.01
[INFO] model update: t: 2091, loss: 11695.91015625
[INFO] Global_t: 2091, Episode_t: 3, Action: 12, Reward: 3.36, Epsilon: 0.01
[INFO] model update: t: 2092, loss: 12646.9765625
[INFO] Global_t: 2092, Episode_t: 4, Action: 50, Reward: 3.30, Epsilon: 0.01
[INFO] model update: t: 2093, loss: 16038.99609375
[INFO] Global_t: 2093, Episode_t: 5, Action: 76, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 2094, loss: 35459.90625
[INFO] Global_t: 2094, Episode_t: 6, Action: 13, Reward: 3.31, Epsilon: 0.01
[INFO] Global step: 2094, Cumulative rewards: 17.97036, Runtime (s): 1928.49
--------------------------------------
 
graph: 149, nodes: 208, edges: 615
[INFO] model update: t: 2095, loss: 16902.69140625
[INFO] Global_t: 2095, Episode_t: 1, Action: 39, Reward: 3.18, Epsilon: 0.01
[INFO] model update: t: 2096, loss: 25653.419921875
[INFO] Global_t: 2096, Episode_t: 2, Action: 20, Reward: 3.64, Epsilon: 0.01
[INFO] model update: t: 2097, loss: 10802.759765625
[INFO] Global_t: 2097, Episode_t: 3, Action: 51, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 2098, loss: 14671.970703125
[INFO] Global_t: 2098, Episode_t: 4, Action: 31, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 2099, loss: 34638.9765625
[INFO] Global_t: 2099, Episode_t: 5, Action: 45, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 2100, loss: 8125.3193359375
[INFO] Global_t: 2100, Episode_t: 6, Action: 16, Reward: 2.32, Epsilon: 0.01
[INFO] Global step: 2100, Cumulative rewards: 16.358759999999997, Runtime (s): 1930.20
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8325986862182617
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8493669033050537
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6503775119781494
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.9315190315246582
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.557889461517334
average cummulative reward vector is:  [0.09081921 0.08080278 0.08563907 0.08458551 0.07312392]
average cummulative reward is:  0.08299409961844387
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 150, nodes: 216, edges: 639
[INFO] model update: t: 2101, loss: 76710.046875
[INFO] Global_t: 2101, Episode_t: 1, Action: 35, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 2102, loss: 50742.8203125
[INFO] Global_t: 2102, Episode_t: 2, Action: 53, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 2103, loss: 22477.4765625
[INFO] Global_t: 2103, Episode_t: 3, Action: 9, Reward: 3.53, Epsilon: 0.01
[INFO] model update: t: 2104, loss: 38371.53125
[INFO] Global_t: 2104, Episode_t: 4, Action: 8, Reward: 3.27, Epsilon: 0.01
[INFO] model update: t: 2105, loss: 23379.34375
[INFO] Global_t: 2105, Episode_t: 5, Action: 28, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 2106, loss: 39880.56640625
[INFO] Global_t: 2106, Episode_t: 6, Action: 37, Reward: 2.74, Epsilon: 0.01
[INFO] Global step: 2106, Cumulative rewards: 16.32828, Runtime (s): 1940.80
--------------------------------------
 
graph: 151, nodes: 204, edges: 601
[INFO] model update: t: 2107, loss: 29386.9609375
[INFO] Global_t: 2107, Episode_t: 1, Action: 189, Reward: 2.31, Epsilon: 0.01
[INFO] model update: t: 2108, loss: 78959.1484375
[INFO] Global_t: 2108, Episode_t: 2, Action: 100, Reward: 2.15, Epsilon: 0.01
[INFO] model update: t: 2109, loss: 35718.19140625
[INFO] Global_t: 2109, Episode_t: 3, Action: 22, Reward: 2.21, Epsilon: 0.01
[INFO] model update: t: 2110, loss: 37865.6875
[INFO] Global_t: 2110, Episode_t: 4, Action: 2, Reward: 4.04, Epsilon: 0.01
[INFO] model update: t: 2111, loss: 59967.453125
[INFO] Global_t: 2111, Episode_t: 5, Action: 25, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 2112, loss: 60682.6328125
[INFO] Global_t: 2112, Episode_t: 6, Action: 33, Reward: 2.25, Epsilon: 0.01
[INFO] Global step: 2112, Cumulative rewards: 15.96924, Runtime (s): 1942.57
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6777606010437012
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6283698081970215
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6976068019866943
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8151960372924805
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.477036714553833
average cummulative reward vector is:  [0.08010921 0.06986065 0.08821421 0.07403645 0.07585968]
average cummulative reward is:  0.07761603846844456
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 152, nodes: 208, edges: 615
[INFO] model update: t: 2113, loss: 55101.5390625
[INFO] Global_t: 2113, Episode_t: 1, Action: 11, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 2114, loss: 18972.58984375
[INFO] Global_t: 2114, Episode_t: 2, Action: 15, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 2115, loss: 46977.5703125
[INFO] Global_t: 2115, Episode_t: 3, Action: 44, Reward: 2.22, Epsilon: 0.01
[INFO] model update: t: 2116, loss: 16431.34375
[INFO] Global_t: 2116, Episode_t: 4, Action: 51, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 2117, loss: 35530.828125
[INFO] Global_t: 2117, Episode_t: 5, Action: 5, Reward: 3.77, Epsilon: 0.01
[INFO] model update: t: 2118, loss: 13777.8828125
[INFO] Global_t: 2118, Episode_t: 6, Action: 70, Reward: 2.12, Epsilon: 0.01
[INFO] Global step: 2118, Cumulative rewards: 16.09944, Runtime (s): 1952.63
--------------------------------------
 
graph: 153, nodes: 211, edges: 623
[INFO] model update: t: 2119, loss: 32648.73828125
[INFO] Global_t: 2119, Episode_t: 1, Action: 21, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 2120, loss: 20621.74609375
[INFO] Global_t: 2120, Episode_t: 2, Action: 22, Reward: 3.34, Epsilon: 0.01
[INFO] model update: t: 2121, loss: 50177.0
[INFO] Global_t: 2121, Episode_t: 3, Action: 8, Reward: 3.83, Epsilon: 0.01
[INFO] model update: t: 2122, loss: 18178.875
[INFO] Global_t: 2122, Episode_t: 4, Action: 20, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 2123, loss: 25725.67578125
[INFO] Global_t: 2123, Episode_t: 5, Action: 34, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 2124, loss: 37247.5703125
[INFO] Global_t: 2124, Episode_t: 6, Action: 26, Reward: 1.83, Epsilon: 0.01
[INFO] Global step: 2124, Cumulative rewards: 16.692, Runtime (s): 1954.38
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.6141655445098877
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7471604347229004
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.7623674869537354
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.859560251235962
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4439780712127686
average cummulative reward vector is:  [0.07936974 0.07479514 0.08513716 0.08065818 0.0730664 ]
average cummulative reward is:  0.07860532192409905
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 154, nodes: 189, edges: 558
[INFO] model update: t: 2125, loss: 57708.51953125
[INFO] Global_t: 2125, Episode_t: 1, Action: 12, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 2126, loss: 46097.890625
[INFO] Global_t: 2126, Episode_t: 2, Action: 28, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 2127, loss: 18230.701171875
[INFO] Global_t: 2127, Episode_t: 3, Action: 8, Reward: 3.85, Epsilon: 0.01
[INFO] model update: t: 2128, loss: 13475.548828125
[INFO] Global_t: 2128, Episode_t: 4, Action: 52, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 2129, loss: 54956.96875
[INFO] Global_t: 2129, Episode_t: 5, Action: 39, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 2130, loss: 23269.72265625
[INFO] Global_t: 2130, Episode_t: 6, Action: 177, Reward: 2.12, Epsilon: 0.01
[INFO] Global step: 2130, Cumulative rewards: 18.229320000000005, Runtime (s): 1964.67
--------------------------------------
 
graph: 155, nodes: 203, edges: 599
[INFO] model update: t: 2131, loss: 30970.11328125
[INFO] Global_t: 2131, Episode_t: 1, Action: 30, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 2132, loss: 25110.58984375
[INFO] Global_t: 2132, Episode_t: 2, Action: 69, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 2133, loss: 32481.2734375
[INFO] Global_t: 2133, Episode_t: 3, Action: 17, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 2134, loss: 30134.4296875
[INFO] Global_t: 2134, Episode_t: 4, Action: 130, Reward: 2.38, Epsilon: 0.01
[INFO] model update: t: 2135, loss: 71737.03125
[INFO] Global_t: 2135, Episode_t: 5, Action: 60, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 2136, loss: 15491.625
[INFO] Global_t: 2136, Episode_t: 6, Action: 70, Reward: 2.30, Epsilon: 0.01
[INFO] Global step: 2136, Cumulative rewards: 14.988839999999998, Runtime (s): 1966.00
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.788611888885498
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7457537651062012
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6127562522888184
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7300636768341064
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4327549934387207
average cummulative reward vector is:  [0.08903711 0.07508218 0.07680191 0.07488458 0.07282151]
average cummulative reward is:  0.07772545571459724
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 156, nodes: 192, edges: 567
[INFO] model update: t: 2137, loss: 40848.875
[INFO] Global_t: 2137, Episode_t: 1, Action: 11, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 2138, loss: 8811.740234375
[INFO] Global_t: 2138, Episode_t: 2, Action: 7, Reward: 3.88, Epsilon: 0.01
[INFO] model update: t: 2139, loss: 33358.6875
[INFO] Global_t: 2139, Episode_t: 3, Action: 6, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 2140, loss: 20377.595703125
[INFO] Global_t: 2140, Episode_t: 4, Action: 12, Reward: 1.81, Epsilon: 0.01
[INFO] model update: t: 2141, loss: 36297.43359375
[INFO] Global_t: 2141, Episode_t: 5, Action: 123, Reward: 1.66, Epsilon: 0.01
[INFO] model update: t: 2142, loss: 24195.029296875
[INFO] Global_t: 2142, Episode_t: 6, Action: 39, Reward: 2.16, Epsilon: 0.01
[INFO] Global step: 2142, Cumulative rewards: 15.703199999999997, Runtime (s): 1976.12
--------------------------------------
 
graph: 157, nodes: 220, edges: 651
[INFO] model update: t: 2143, loss: 32250.69140625
[INFO] Global_t: 2143, Episode_t: 1, Action: 130, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 2144, loss: 52597.48046875
[INFO] Global_t: 2144, Episode_t: 2, Action: 185, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 2145, loss: 10878.880859375
[INFO] Global_t: 2145, Episode_t: 3, Action: 219, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 2146, loss: 29946.078125
[INFO] Global_t: 2146, Episode_t: 4, Action: 27, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 2147, loss: 10982.4169921875
[INFO] Global_t: 2147, Episode_t: 5, Action: 28, Reward: 2.96, Epsilon: 0.01
[INFO] model update: t: 2148, loss: 71388.1015625
[INFO] Global_t: 2148, Episode_t: 6, Action: 18, Reward: 2.42, Epsilon: 0.01
[INFO] Global step: 2148, Cumulative rewards: 15.359999999999998, Runtime (s): 1977.44
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.683946132659912
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8084688186645508
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5226411819458008
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7952759265899658
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.6788532733917236
average cummulative reward vector is:  [0.08308684 0.07244745 0.07821585 0.07805    0.08613226]
average cummulative reward is:  0.0795864801736037
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 158, nodes: 209, edges: 618
[INFO] model update: t: 2149, loss: 44189.890625
[INFO] Global_t: 2149, Episode_t: 1, Action: 55, Reward: 2.85, Epsilon: 0.01
[INFO] model update: t: 2150, loss: 25711.13671875
[INFO] Global_t: 2150, Episode_t: 2, Action: 28, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 2151, loss: 58496.625
[INFO] Global_t: 2151, Episode_t: 3, Action: 39, Reward: 2.68, Epsilon: 0.01
[INFO] model update: t: 2152, loss: 12632.4375
[INFO] Global_t: 2152, Episode_t: 4, Action: 15, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 2153, loss: 145952.703125
[INFO] Global_t: 2153, Episode_t: 5, Action: 141, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 2154, loss: 75544.0
[INFO] Global_t: 2154, Episode_t: 6, Action: 41, Reward: 2.78, Epsilon: 0.01
[INFO] Global step: 2154, Cumulative rewards: 16.291439999999998, Runtime (s): 1987.66
--------------------------------------
 
graph: 159, nodes: 191, edges: 564
[INFO] model update: t: 2155, loss: 37012.421875
[INFO] Global_t: 2155, Episode_t: 1, Action: 24, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 2156, loss: 36354.6953125
[INFO] Global_t: 2156, Episode_t: 2, Action: 6, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 2157, loss: 90998.109375
[INFO] Global_t: 2157, Episode_t: 3, Action: 14, Reward: 3.17, Epsilon: 0.01
[INFO] model update: t: 2158, loss: 120007.625
[INFO] Global_t: 2158, Episode_t: 4, Action: 44, Reward: 1.65, Epsilon: 0.01
[INFO] model update: t: 2159, loss: 43891.203125
[INFO] Global_t: 2159, Episode_t: 5, Action: 26, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 2160, loss: 137182.3125
[INFO] Global_t: 2160, Episode_t: 6, Action: 13, Reward: 2.74, Epsilon: 0.01
[INFO] Global step: 2160, Cumulative rewards: 15.74256, Runtime (s): 1989.88
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9564573764801025
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6959648132324219
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4417901039123535
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.731250524520874
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4271676540374756
average cummulative reward vector is:  [0.08998316 0.0720919  0.07343907 0.07581262 0.07205753]
average cummulative reward is:  0.07667685415705734
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 160, nodes: 220, edges: 650
[INFO] model update: t: 2161, loss: 35754.8515625
[INFO] Global_t: 2161, Episode_t: 1, Action: 132, Reward: 2.30, Epsilon: 0.01
[INFO] model update: t: 2162, loss: 203777.515625
[INFO] Global_t: 2162, Episode_t: 2, Action: 17, Reward: 4.05, Epsilon: 0.01
[INFO] model update: t: 2163, loss: 8815.8720703125
[INFO] Global_t: 2163, Episode_t: 3, Action: 7, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 2164, loss: 254633.640625
[INFO] Global_t: 2164, Episode_t: 4, Action: 9, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 2165, loss: 226582.9375
[INFO] Global_t: 2165, Episode_t: 5, Action: 11, Reward: 3.37, Epsilon: 0.01
[INFO] model update: t: 2166, loss: 83478.109375
[INFO] Global_t: 2166, Episode_t: 6, Action: 186, Reward: 1.97, Epsilon: 0.01
[INFO] Global step: 2166, Cumulative rewards: 16.291199999999996, Runtime (s): 2000.09
--------------------------------------
 
graph: 161, nodes: 194, edges: 573
[INFO] model update: t: 2167, loss: 267099.6875
[INFO] Global_t: 2167, Episode_t: 1, Action: 3, Reward: 3.47, Epsilon: 0.01
[INFO] model update: t: 2168, loss: 43772.84375
[INFO] Global_t: 2168, Episode_t: 2, Action: 24, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 2169, loss: 185459.9375
[INFO] Global_t: 2169, Episode_t: 3, Action: 5, Reward: 3.90, Epsilon: 0.01
[INFO] model update: t: 2170, loss: 42745.109375
[INFO] Global_t: 2170, Episode_t: 4, Action: 17, Reward: 1.72, Epsilon: 0.01
[INFO] model update: t: 2171, loss: 233606.734375
[INFO] Global_t: 2171, Episode_t: 5, Action: 7, Reward: 1.55, Epsilon: 0.01
[INFO] model update: t: 2172, loss: 19321.130859375
[INFO] Global_t: 2172, Episode_t: 6, Action: 9, Reward: 1.90, Epsilon: 0.01
[INFO] Global step: 2172, Cumulative rewards: 15.003120000000001, Runtime (s): 2002.30
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8783607482910156
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.662691593170166
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5042126178741455
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8625917434692383
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5300602912902832
average cummulative reward vector is:  [0.09267316 0.07117731 0.07804754 0.08156075 0.07859489]
average cummulative reward is:  0.08041073076596558
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 162, nodes: 191, edges: 564
[INFO] model update: t: 2173, loss: 267349.1875
[INFO] Global_t: 2173, Episode_t: 1, Action: 8, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 2174, loss: 187410.640625
[INFO] Global_t: 2174, Episode_t: 2, Action: 15, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 2175, loss: 88233.6484375
[INFO] Global_t: 2175, Episode_t: 3, Action: 69, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 2176, loss: 167186.28125
[INFO] Global_t: 2176, Episode_t: 4, Action: 9, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 2177, loss: 49303.24609375
[INFO] Global_t: 2177, Episode_t: 5, Action: 46, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 2178, loss: 231554.4375
[INFO] Global_t: 2178, Episode_t: 6, Action: 17, Reward: 2.99, Epsilon: 0.01
[INFO] Global step: 2178, Cumulative rewards: 15.62172, Runtime (s): 2012.76
--------------------------------------
 
graph: 163, nodes: 213, edges: 629
[INFO] model update: t: 2179, loss: 18474.056640625
[INFO] Global_t: 2179, Episode_t: 1, Action: 29, Reward: 2.67, Epsilon: 0.01
[INFO] model update: t: 2180, loss: 120511.03125
[INFO] Global_t: 2180, Episode_t: 2, Action: 17, Reward: 3.23, Epsilon: 0.01
[INFO] model update: t: 2181, loss: 42481.3359375
[INFO] Global_t: 2181, Episode_t: 3, Action: 70, Reward: 2.98, Epsilon: 0.01
[INFO] model update: t: 2182, loss: 73140.109375
[INFO] Global_t: 2182, Episode_t: 4, Action: 46, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 2183, loss: 61924.0078125
[INFO] Global_t: 2183, Episode_t: 5, Action: 59, Reward: 3.14, Epsilon: 0.01
[INFO] model update: t: 2184, loss: 39561.0390625
[INFO] Global_t: 2184, Episode_t: 6, Action: 13, Reward: 3.02, Epsilon: 0.01
[INFO] Global step: 2184, Cumulative rewards: 17.75532, Runtime (s): 2014.56
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9510908126831055
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5485987663269043
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5106425285339355
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.925140380859375
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4829788208007812
average cummulative reward vector is:  [0.09708789 0.06583148 0.07807869 0.07870911 0.075725  ]
average cummulative reward is:  0.07908643537848929
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 164, nodes: 182, edges: 537
[INFO] model update: t: 2185, loss: 51481.7890625
[INFO] Global_t: 2185, Episode_t: 1, Action: 7, Reward: 3.09, Epsilon: 0.01
[INFO] model update: t: 2186, loss: 46946.4765625
[INFO] Global_t: 2186, Episode_t: 2, Action: 20, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 2187, loss: 75520.25
[INFO] Global_t: 2187, Episode_t: 3, Action: 11, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 2188, loss: 14881.0693359375
[INFO] Global_t: 2188, Episode_t: 4, Action: 10, Reward: 2.32, Epsilon: 0.01
[INFO] model update: t: 2189, loss: 62868.8203125
[INFO] Global_t: 2189, Episode_t: 5, Action: 15, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 2190, loss: 17689.0625
[INFO] Global_t: 2190, Episode_t: 6, Action: 21, Reward: 1.53, Epsilon: 0.01
[INFO] Global step: 2190, Cumulative rewards: 14.515919999999998, Runtime (s): 2024.68
--------------------------------------
 
graph: 165, nodes: 180, edges: 531
[INFO] model update: t: 2191, loss: 31701.04296875
[INFO] Global_t: 2191, Episode_t: 1, Action: 136, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 2192, loss: 13354.58203125
[INFO] Global_t: 2192, Episode_t: 2, Action: 6, Reward: 3.61, Epsilon: 0.01
[INFO] model update: t: 2193, loss: 24511.568359375
[INFO] Global_t: 2193, Episode_t: 3, Action: 24, Reward: 2.43, Epsilon: 0.01
[INFO] model update: t: 2194, loss: 15558.8359375
[INFO] Global_t: 2194, Episode_t: 4, Action: 1, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 2195, loss: 16643.4609375
[INFO] Global_t: 2195, Episode_t: 5, Action: 11, Reward: 1.80, Epsilon: 0.01
[INFO] model update: t: 2196, loss: 10334.349609375
[INFO] Global_t: 2196, Episode_t: 6, Action: 46, Reward: 1.85, Epsilon: 0.01
[INFO] Global step: 2196, Cumulative rewards: 15.269279999999997, Runtime (s): 2026.47
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7036283016204834
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6013405323028564
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4701611995697021
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  2.0579824447631836
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.512570858001709
average cummulative reward vector is:  [0.08398474 0.06884282 0.07629016 0.08479252 0.07745968]
average cummulative reward is:  0.07827398512688927
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 166, nodes: 185, edges: 544
[INFO] model update: t: 2197, loss: 20769.927734375
[INFO] Global_t: 2197, Episode_t: 1, Action: 9, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 2198, loss: 33440.58203125
[INFO] Global_t: 2198, Episode_t: 2, Action: 14, Reward: 2.66, Epsilon: 0.01
[INFO] model update: t: 2199, loss: 29797.66015625
[INFO] Global_t: 2199, Episode_t: 3, Action: 32, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 2200, loss: 103830.75
[INFO] Global_t: 2200, Episode_t: 4, Action: 11, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 2201, loss: 72112.140625
[INFO] Global_t: 2201, Episode_t: 5, Action: 30, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 2202, loss: 12106.1015625
[INFO] Global_t: 2202, Episode_t: 6, Action: 95, Reward: 1.47, Epsilon: 0.01
[INFO] Global step: 2202, Cumulative rewards: 14.568599999999996, Runtime (s): 2036.67
--------------------------------------
 
graph: 167, nodes: 181, edges: 533
[INFO] model update: t: 2203, loss: 35174.96875
[INFO] Global_t: 2203, Episode_t: 1, Action: 4, Reward: 3.15, Epsilon: 0.01
[INFO] model update: t: 2204, loss: 8969.36328125
[INFO] Global_t: 2204, Episode_t: 2, Action: 15, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 2205, loss: 43137.4765625
[INFO] Global_t: 2205, Episode_t: 3, Action: 5, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 2206, loss: 19608.421875
[INFO] Global_t: 2206, Episode_t: 4, Action: 95, Reward: 1.21, Epsilon: 0.01
[INFO] model update: t: 2207, loss: 70602.3828125
[INFO] Global_t: 2207, Episode_t: 5, Action: 12, Reward: 1.92, Epsilon: 0.01
[INFO] model update: t: 2208, loss: 19937.005859375
[INFO] Global_t: 2208, Episode_t: 6, Action: 42, Reward: 1.73, Epsilon: 0.01
[INFO] Global step: 2208, Cumulative rewards: 13.539599999999998, Runtime (s): 2038.42
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.906708002090454
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8428690433502197
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5224003791809082
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6455752849578857
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.7090075016021729
average cummulative reward vector is:  [0.09484474 0.07407778 0.07883005 0.0716979  0.08773602]
average cummulative reward is:  0.08143729759326597
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 168, nodes: 201, edges: 594
[INFO] model update: t: 2209, loss: 47443.3671875
[INFO] Global_t: 2209, Episode_t: 1, Action: 15, Reward: 3.26, Epsilon: 0.01
[INFO] model update: t: 2210, loss: 39568.2734375
[INFO] Global_t: 2210, Episode_t: 2, Action: 5, Reward: 3.20, Epsilon: 0.01
[INFO] model update: t: 2211, loss: 21722.599609375
[INFO] Global_t: 2211, Episode_t: 3, Action: 7, Reward: 3.56, Epsilon: 0.01
[INFO] model update: t: 2212, loss: 62547.875
[INFO] Global_t: 2212, Episode_t: 4, Action: 14, Reward: 1.99, Epsilon: 0.01
[INFO] model update: t: 2213, loss: 12711.2578125
[INFO] Global_t: 2213, Episode_t: 5, Action: 22, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 2214, loss: 94361.125
[INFO] Global_t: 2214, Episode_t: 6, Action: 56, Reward: 2.13, Epsilon: 0.01
[INFO] Global step: 2214, Cumulative rewards: 16.14204, Runtime (s): 2049.37
--------------------------------------
 
graph: 169, nodes: 215, edges: 635
[INFO] model update: t: 2215, loss: 28786.123046875
[INFO] Global_t: 2215, Episode_t: 1, Action: 195, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 2216, loss: 64191.453125
[INFO] Global_t: 2216, Episode_t: 2, Action: 25, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 2217, loss: 44869.6015625
[INFO] Global_t: 2217, Episode_t: 3, Action: 145, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 2218, loss: 18279.296875
[INFO] Global_t: 2218, Episode_t: 4, Action: 213, Reward: 2.29, Epsilon: 0.01
[INFO] model update: t: 2219, loss: 19351.07421875
[INFO] Global_t: 2219, Episode_t: 5, Action: 187, Reward: 2.01, Epsilon: 0.01
[INFO] model update: t: 2220, loss: 16796.3046875
[INFO] Global_t: 2220, Episode_t: 6, Action: 5, Reward: 3.48, Epsilon: 0.01
[INFO] Global step: 2220, Cumulative rewards: 15.56652, Runtime (s): 2050.97
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9879333972930908
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8628172874450684
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5685725212097168
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8423571586608887
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5014619827270508
average cummulative reward vector is:  [0.09273947 0.08053981 0.08257842 0.08134393 0.07692043]
average cummulative reward is:  0.08282441182814869
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 170, nodes: 206, edges: 609
[INFO] model update: t: 2221, loss: 16235.998046875
[INFO] Global_t: 2221, Episode_t: 1, Action: 12, Reward: 3.44, Epsilon: 0.01
[INFO] model update: t: 2222, loss: 16002.3203125
[INFO] Global_t: 2222, Episode_t: 2, Action: 25, Reward: 2.65, Epsilon: 0.01
[INFO] model update: t: 2223, loss: 9827.423828125
[INFO] Global_t: 2223, Episode_t: 3, Action: 15, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 2224, loss: 28080.4375
[INFO] Global_t: 2224, Episode_t: 4, Action: 27, Reward: 2.36, Epsilon: 0.01
[INFO] model update: t: 2225, loss: 12800.666015625
[INFO] Global_t: 2225, Episode_t: 5, Action: 5, Reward: 2.89, Epsilon: 0.01
[INFO] model update: t: 2226, loss: 13841.962890625
[INFO] Global_t: 2226, Episode_t: 6, Action: 34, Reward: 1.76, Epsilon: 0.01
[INFO] Global step: 2226, Cumulative rewards: 15.552599999999998, Runtime (s): 2061.75
--------------------------------------
 
graph: 171, nodes: 202, edges: 597
[INFO] model update: t: 2227, loss: 11381.6103515625
[INFO] Global_t: 2227, Episode_t: 1, Action: 10, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 2228, loss: 35013.09375
[INFO] Global_t: 2228, Episode_t: 2, Action: 7, Reward: 3.75, Epsilon: 0.01
[INFO] model update: t: 2229, loss: 14876.869140625
[INFO] Global_t: 2229, Episode_t: 3, Action: 160, Reward: 2.09, Epsilon: 0.01
[INFO] model update: t: 2230, loss: 40007.41015625
[INFO] Global_t: 2230, Episode_t: 4, Action: 1, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 2231, loss: 37450.8359375
[INFO] Global_t: 2231, Episode_t: 5, Action: 22, Reward: 1.94, Epsilon: 0.01
[INFO] model update: t: 2232, loss: 21260.806640625
[INFO] Global_t: 2232, Episode_t: 6, Action: 6, Reward: 2.20, Epsilon: 0.01
[INFO] Global step: 2232, Cumulative rewards: 15.564839999999998, Runtime (s): 2063.90
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9033784866333008
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6869163513183594
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.502671480178833
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8793678283691406
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5192253589630127
average cummulative reward vector is:  [0.09021868 0.07010417 0.07534617 0.08074533 0.07791828]
average cummulative reward is:  0.07886652648265542
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 172, nodes: 206, edges: 609
[INFO] model update: t: 2233, loss: 28506.513671875
[INFO] Global_t: 2233, Episode_t: 1, Action: 15, Reward: 3.12, Epsilon: 0.01
[INFO] model update: t: 2234, loss: 63502.45703125
[INFO] Global_t: 2234, Episode_t: 2, Action: 79, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 2235, loss: 11152.8203125
[INFO] Global_t: 2235, Episode_t: 3, Action: 67, Reward: 2.03, Epsilon: 0.01
[INFO] model update: t: 2236, loss: 86724.921875
[INFO] Global_t: 2236, Episode_t: 4, Action: 37, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 2237, loss: 17115.15625
[INFO] Global_t: 2237, Episode_t: 5, Action: 9, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 2238, loss: 68936.34375
[INFO] Global_t: 2238, Episode_t: 6, Action: 38, Reward: 1.68, Epsilon: 0.01
[INFO] Global step: 2238, Cumulative rewards: 14.519279999999998, Runtime (s): 2074.24
--------------------------------------
 
graph: 173, nodes: 217, edges: 641
[INFO] model update: t: 2239, loss: 38748.96875
[INFO] Global_t: 2239, Episode_t: 1, Action: 193, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 2240, loss: 48082.1015625
[INFO] Global_t: 2240, Episode_t: 2, Action: 19, Reward: 3.94, Epsilon: 0.01
[INFO] model update: t: 2241, loss: 20452.48046875
[INFO] Global_t: 2241, Episode_t: 3, Action: 114, Reward: 2.87, Epsilon: 0.01
[INFO] model update: t: 2242, loss: 25880.234375
[INFO] Global_t: 2242, Episode_t: 4, Action: 33, Reward: 2.02, Epsilon: 0.01
[INFO] model update: t: 2243, loss: 24057.671875
[INFO] Global_t: 2243, Episode_t: 5, Action: 5, Reward: 1.93, Epsilon: 0.01
[INFO] model update: t: 2244, loss: 20638.552734375
[INFO] Global_t: 2244, Episode_t: 6, Action: 20, Reward: 2.96, Epsilon: 0.01
[INFO] Global step: 2244, Cumulative rewards: 16.483079999999998, Runtime (s): 2076.61
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  2.061723470687866
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7017326354980469
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5440890789031982
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.773207426071167
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5070092678070068
average cummulative reward vector is:  [0.10256789 0.07361968 0.08014071 0.07133271 0.07722796]
average cummulative reward is:  0.08097778966298057
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 174, nodes: 217, edges: 640
[INFO] model update: t: 2245, loss: 41324.6328125
[INFO] Global_t: 2245, Episode_t: 1, Action: 13, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 2246, loss: 14152.76953125
[INFO] Global_t: 2246, Episode_t: 2, Action: 19, Reward: 2.86, Epsilon: 0.01
[INFO] model update: t: 2247, loss: 19521.32421875
[INFO] Global_t: 2247, Episode_t: 3, Action: 44, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 2248, loss: 22376.943359375
[INFO] Global_t: 2248, Episode_t: 4, Action: 11, Reward: 3.59, Epsilon: 0.01
[INFO] model update: t: 2249, loss: 7696.40771484375
[INFO] Global_t: 2249, Episode_t: 5, Action: 24, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 2250, loss: 15186.1796875
[INFO] Global_t: 2250, Episode_t: 6, Action: 12, Reward: 2.60, Epsilon: 0.01
[INFO] Global step: 2250, Cumulative rewards: 16.90512, Runtime (s): 2087.23
--------------------------------------
 
graph: 175, nodes: 200, edges: 591
[INFO] model update: t: 2251, loss: 20208.42578125
[INFO] Global_t: 2251, Episode_t: 1, Action: 91, Reward: 2.51, Epsilon: 0.01
[INFO] model update: t: 2252, loss: 23719.4296875
[INFO] Global_t: 2252, Episode_t: 2, Action: 7, Reward: 3.05, Epsilon: 0.01
[INFO] model update: t: 2253, loss: 18242.82421875
[INFO] Global_t: 2253, Episode_t: 3, Action: 8, Reward: 3.03, Epsilon: 0.01
[INFO] model update: t: 2254, loss: 66754.8046875
[INFO] Global_t: 2254, Episode_t: 4, Action: 24, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 2255, loss: 23514.81640625
[INFO] Global_t: 2255, Episode_t: 5, Action: 13, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 2256, loss: 20465.9765625
[INFO] Global_t: 2256, Episode_t: 6, Action: 50, Reward: 2.16, Epsilon: 0.01
[INFO] Global step: 2256, Cumulative rewards: 16.49544, Runtime (s): 2088.93
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.780339241027832
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8637259006500244
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.533522129058838
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.6373827457427979
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4309372901916504
average cummulative reward vector is:  [0.08696184 0.08032569 0.07201093 0.07137967 0.07233441]
average cummulative reward is:  0.0766025094021606
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 176, nodes: 180, edges: 531
[INFO] model update: t: 2257, loss: 25751.55078125
[INFO] Global_t: 2257, Episode_t: 1, Action: 7, Reward: 2.97, Epsilon: 0.01
[INFO] model update: t: 2258, loss: 13659.087890625
[INFO] Global_t: 2258, Episode_t: 2, Action: 129, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 2259, loss: 13421.810546875
[INFO] Global_t: 2259, Episode_t: 3, Action: 23, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 2260, loss: 19048.3125
[INFO] Global_t: 2260, Episode_t: 4, Action: 15, Reward: 2.47, Epsilon: 0.01
[INFO] model update: t: 2261, loss: 20062.7109375
[INFO] Global_t: 2261, Episode_t: 5, Action: 31, Reward: 2.58, Epsilon: 0.01
[INFO] model update: t: 2262, loss: 19671.8125
[INFO] Global_t: 2262, Episode_t: 6, Action: 12, Reward: 3.69, Epsilon: 0.01
[INFO] Global step: 2262, Cumulative rewards: 15.926280000000002, Runtime (s): 2098.77
--------------------------------------
 
graph: 177, nodes: 192, edges: 567
[INFO] model update: t: 2263, loss: 23129.5703125
[INFO] Global_t: 2263, Episode_t: 1, Action: 31, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 2264, loss: 12332.87890625
[INFO] Global_t: 2264, Episode_t: 2, Action: 1, Reward: 3.76, Epsilon: 0.01
[INFO] model update: t: 2265, loss: 18047.109375
[INFO] Global_t: 2265, Episode_t: 3, Action: 26, Reward: 2.05, Epsilon: 0.01
[INFO] model update: t: 2266, loss: 19989.58203125
[INFO] Global_t: 2266, Episode_t: 4, Action: 10, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 2267, loss: 17670.59375
[INFO] Global_t: 2267, Episode_t: 5, Action: 25, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 2268, loss: 31359.2890625
[INFO] Global_t: 2268, Episode_t: 6, Action: 17, Reward: 3.57, Epsilon: 0.01
[INFO] Global step: 2268, Cumulative rewards: 16.9104, Runtime (s): 2100.31
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8637547492980957
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.9384171962738037
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4513375759124756
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8741893768310547
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.574256420135498
average cummulative reward vector is:  [0.09231579 0.07832616 0.07455792 0.08144089 0.08080753]
average cummulative reward is:  0.08148965702210942
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 178, nodes: 209, edges: 618
[INFO] model update: t: 2269, loss: 22310.419921875
[INFO] Global_t: 2269, Episode_t: 1, Action: 14, Reward: 3.43, Epsilon: 0.01
[INFO] model update: t: 2270, loss: 45336.3125
[INFO] Global_t: 2270, Episode_t: 2, Action: 38, Reward: 2.82, Epsilon: 0.01
[INFO] model update: t: 2271, loss: 12760.900390625
[INFO] Global_t: 2271, Episode_t: 3, Action: 18, Reward: 3.18, Epsilon: 0.01
[INFO] model update: t: 2272, loss: 77201.65625
[INFO] Global_t: 2272, Episode_t: 4, Action: 10, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 2273, loss: 83076.3125
[INFO] Global_t: 2273, Episode_t: 5, Action: 12, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 2274, loss: 15874.28515625
[INFO] Global_t: 2274, Episode_t: 6, Action: 102, Reward: 1.09, Epsilon: 0.01
[INFO] Global step: 2274, Cumulative rewards: 15.807719999999998, Runtime (s): 2111.09
--------------------------------------
 
graph: 179, nodes: 205, edges: 606
[INFO] model update: t: 2275, loss: 89974.4375
[INFO] Global_t: 2275, Episode_t: 1, Action: 12, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 2276, loss: 15539.318359375
[INFO] Global_t: 2276, Episode_t: 2, Action: 1, Reward: 4.75, Epsilon: 0.01
[INFO] model update: t: 2277, loss: 97672.0625
[INFO] Global_t: 2277, Episode_t: 3, Action: 38, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 2278, loss: 42019.2109375
[INFO] Global_t: 2278, Episode_t: 4, Action: 6, Reward: 2.72, Epsilon: 0.01
[INFO] model update: t: 2279, loss: 54708.4296875
[INFO] Global_t: 2279, Episode_t: 5, Action: 11, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 2280, loss: 35512.65625
[INFO] Global_t: 2280, Episode_t: 6, Action: 19, Reward: 2.23, Epsilon: 0.01
[INFO] Global step: 2280, Cumulative rewards: 17.12916, Runtime (s): 2113.63
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9235596656799316
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.811537504196167
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5327966213226318
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7448108196258545
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4604454040527344
average cummulative reward vector is:  [0.08822447 0.07825486 0.07877459 0.07604953 0.0743629 ]
average cummulative reward is:  0.07913327217906857
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 180, nodes: 202, edges: 596
[INFO] model update: t: 2281, loss: 60647.8984375
[INFO] Global_t: 2281, Episode_t: 1, Action: 51, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 2282, loss: 83437.6953125
[INFO] Global_t: 2282, Episode_t: 2, Action: 11, Reward: 2.90, Epsilon: 0.01
[INFO] model update: t: 2283, loss: 37293.11328125
[INFO] Global_t: 2283, Episode_t: 3, Action: 10, Reward: 3.81, Epsilon: 0.01
[INFO] model update: t: 2284, loss: 120209.0859375
[INFO] Global_t: 2284, Episode_t: 4, Action: 30, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 2285, loss: 14561.4921875
[INFO] Global_t: 2285, Episode_t: 5, Action: 66, Reward: 1.67, Epsilon: 0.01
[INFO] model update: t: 2286, loss: 72806.75
[INFO] Global_t: 2286, Episode_t: 6, Action: 95, Reward: 2.31, Epsilon: 0.01
[INFO] Global step: 2286, Cumulative rewards: 15.74148, Runtime (s): 2124.04
--------------------------------------
 
graph: 181, nodes: 205, edges: 606
[INFO] model update: t: 2287, loss: 41056.03125
[INFO] Global_t: 2287, Episode_t: 1, Action: 115, Reward: 2.91, Epsilon: 0.01
[INFO] model update: t: 2288, loss: 90087.0625
[INFO] Global_t: 2288, Episode_t: 2, Action: 106, Reward: 2.35, Epsilon: 0.01
[INFO] model update: t: 2289, loss: 128932.875
[INFO] Global_t: 2289, Episode_t: 3, Action: 78, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 2290, loss: 14495.427734375
[INFO] Global_t: 2290, Episode_t: 4, Action: 8, Reward: 3.49, Epsilon: 0.01
[INFO] model update: t: 2291, loss: 136716.65625
[INFO] Global_t: 2291, Episode_t: 5, Action: 89, Reward: 1.70, Epsilon: 0.01
[INFO] model update: t: 2292, loss: 68425.6875
[INFO] Global_t: 2292, Episode_t: 6, Action: 32, Reward: 2.91, Epsilon: 0.01
[INFO] Global step: 2292, Cumulative rewards: 15.747239999999998, Runtime (s): 2126.04
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.9372663497924805
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7059860229492188
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6655449867248535
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.81296706199646
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5868427753448486
average cummulative reward vector is:  [0.09543658 0.07293565 0.0870276  0.07859019 0.0745664 ]
average cummulative reward is:  0.08171128149785642
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 182, nodes: 205, edges: 606
[INFO] model update: t: 2293, loss: 57631.5234375
[INFO] Global_t: 2293, Episode_t: 1, Action: 9, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 2294, loss: 95772.2890625
[INFO] Global_t: 2294, Episode_t: 2, Action: 90, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 2295, loss: 49533.8515625
[INFO] Global_t: 2295, Episode_t: 3, Action: 29, Reward: 3.04, Epsilon: 0.01
[INFO] model update: t: 2296, loss: 156060.78125
[INFO] Global_t: 2296, Episode_t: 4, Action: 14, Reward: 2.06, Epsilon: 0.01
[INFO] model update: t: 2297, loss: 21805.7265625
[INFO] Global_t: 2297, Episode_t: 5, Action: 5, Reward: 2.74, Epsilon: 0.01
[INFO] model update: t: 2298, loss: 288779.09375
[INFO] Global_t: 2298, Episode_t: 6, Action: 12, Reward: 1.84, Epsilon: 0.01
[INFO] Global step: 2298, Cumulative rewards: 15.164399999999999, Runtime (s): 2136.94
--------------------------------------
 
graph: 183, nodes: 217, edges: 642
[INFO] model update: t: 2299, loss: 107685.875
[INFO] Global_t: 2299, Episode_t: 1, Action: 41, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 2300, loss: 104243.1796875
[INFO] Global_t: 2300, Episode_t: 2, Action: 62, Reward: 2.52, Epsilon: 0.01
[INFO] model update: t: 2301, loss: 177185.265625
[INFO] Global_t: 2301, Episode_t: 3, Action: 11, Reward: 3.29, Epsilon: 0.01
[INFO] model update: t: 2302, loss: 37197.90625
[INFO] Global_t: 2302, Episode_t: 4, Action: 38, Reward: 1.79, Epsilon: 0.01
[INFO] model update: t: 2303, loss: 122735.359375
[INFO] Global_t: 2303, Episode_t: 5, Action: 13, Reward: 2.92, Epsilon: 0.01
[INFO] model update: t: 2304, loss: 44517.1640625
[INFO] Global_t: 2304, Episode_t: 6, Action: 4, Reward: 2.70, Epsilon: 0.01
[INFO] Global step: 2304, Cumulative rewards: 16.216440000000002, Runtime (s): 2138.98
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.708570957183838
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7441084384918213
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4335277080535889
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.85325288772583
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.547360897064209
average cummulative reward vector is:  [0.08439921 0.07501366 0.07338142 0.0750736  0.07915618]
average cummulative reward is:  0.07740481392505812
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 184, nodes: 196, edges: 579
[INFO] model update: t: 2305, loss: 41176.55859375
[INFO] Global_t: 2305, Episode_t: 1, Action: 81, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 2306, loss: 27803.904296875
[INFO] Global_t: 2306, Episode_t: 2, Action: 23, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 2307, loss: 55167.68359375
[INFO] Global_t: 2307, Episode_t: 3, Action: 7, Reward: 3.10, Epsilon: 0.01
[INFO] model update: t: 2308, loss: 19894.28125
[INFO] Global_t: 2308, Episode_t: 4, Action: 28, Reward: 1.96, Epsilon: 0.01
[INFO] model update: t: 2309, loss: 29423.421875
[INFO] Global_t: 2309, Episode_t: 5, Action: 39, Reward: 2.49, Epsilon: 0.01
[INFO] model update: t: 2310, loss: 24339.9921875
[INFO] Global_t: 2310, Episode_t: 6, Action: 4, Reward: 2.97, Epsilon: 0.01
[INFO] Global step: 2310, Cumulative rewards: 15.606720000000001, Runtime (s): 2149.28
--------------------------------------
 
graph: 185, nodes: 180, edges: 530
[INFO] model update: t: 2311, loss: 9490.158203125
[INFO] Global_t: 2311, Episode_t: 1, Action: 7, Reward: 3.16, Epsilon: 0.01
[INFO] model update: t: 2312, loss: 29247.76171875
[INFO] Global_t: 2312, Episode_t: 2, Action: 12, Reward: 3.00, Epsilon: 0.01
[INFO] model update: t: 2313, loss: 12068.919921875
[INFO] Global_t: 2313, Episode_t: 3, Action: 15, Reward: 2.60, Epsilon: 0.01
[INFO] model update: t: 2314, loss: 9965.7470703125
[INFO] Global_t: 2314, Episode_t: 4, Action: 27, Reward: 2.24, Epsilon: 0.01
[INFO] model update: t: 2315, loss: 9531.802734375
[INFO] Global_t: 2315, Episode_t: 5, Action: 0, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 2316, loss: 11420.072265625
[INFO] Global_t: 2316, Episode_t: 6, Action: 9, Reward: 1.77, Epsilon: 0.01
[INFO] Global step: 2316, Cumulative rewards: 15.618959999999998, Runtime (s): 2150.89
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7078537940979004
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.6584429740905762
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.6870794296264648
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8251256942749023
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.4085123538970947
average cummulative reward vector is:  [0.08443816 0.07079491 0.08094399 0.07934766 0.07102231]
average cummulative reward is:  0.07730940595050828
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 186, nodes: 210, edges: 621
[INFO] model update: t: 2317, loss: 16039.921875
[INFO] Global_t: 2317, Episode_t: 1, Action: 38, Reward: 2.83, Epsilon: 0.01
[INFO] model update: t: 2318, loss: 22462.69140625
[INFO] Global_t: 2318, Episode_t: 2, Action: 15, Reward: 3.22, Epsilon: 0.01
[INFO] model update: t: 2319, loss: 19833.423828125
[INFO] Global_t: 2319, Episode_t: 3, Action: 53, Reward: 2.73, Epsilon: 0.01
[INFO] model update: t: 2320, loss: 35507.74609375
[INFO] Global_t: 2320, Episode_t: 4, Action: 57, Reward: 2.45, Epsilon: 0.01
[INFO] model update: t: 2321, loss: 23052.330078125
[INFO] Global_t: 2321, Episode_t: 5, Action: 16, Reward: 3.50, Epsilon: 0.01
[INFO] model update: t: 2322, loss: 36305.72265625
[INFO] Global_t: 2322, Episode_t: 6, Action: 7, Reward: 3.88, Epsilon: 0.01
[INFO] Global step: 2322, Cumulative rewards: 18.60588, Runtime (s): 2160.75
--------------------------------------
 
graph: 187, nodes: 210, edges: 621
[INFO] model update: t: 2323, loss: 23118.27734375
[INFO] Global_t: 2323, Episode_t: 1, Action: 90, Reward: 3.12, Epsilon: 0.01
[INFO] model update: t: 2324, loss: 12883.1708984375
[INFO] Global_t: 2324, Episode_t: 2, Action: 18, Reward: 2.99, Epsilon: 0.01
[INFO] model update: t: 2325, loss: 29234.12109375
[INFO] Global_t: 2325, Episode_t: 3, Action: 7, Reward: 3.48, Epsilon: 0.01
[INFO] model update: t: 2326, loss: 39439.53515625
[INFO] Global_t: 2326, Episode_t: 4, Action: 171, Reward: 1.82, Epsilon: 0.01
[INFO] model update: t: 2327, loss: 11162.916015625
[INFO] Global_t: 2327, Episode_t: 5, Action: 24, Reward: 2.46, Epsilon: 0.01
[INFO] model update: t: 2328, loss: 59004.78125
[INFO] Global_t: 2328, Episode_t: 6, Action: 6, Reward: 2.92, Epsilon: 0.01
[INFO] Global step: 2328, Cumulative rewards: 16.781639999999996, Runtime (s): 2162.84
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8984081745147705
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.8928766250610352
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5348179340362549
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8111555576324463
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.486180305480957
average cummulative reward vector is:  [0.09428421 0.07609421 0.07972158 0.07885888 0.07536102]
average cummulative reward is:  0.0808639816397563
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 188, nodes: 198, edges: 585
[INFO] model update: t: 2329, loss: 18997.388671875
[INFO] Global_t: 2329, Episode_t: 1, Action: 39, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 2330, loss: 38257.1171875
[INFO] Global_t: 2330, Episode_t: 2, Action: 25, Reward: 2.62, Epsilon: 0.01
[INFO] model update: t: 2331, loss: 35357.6171875
[INFO] Global_t: 2331, Episode_t: 3, Action: 9, Reward: 2.37, Epsilon: 0.01
[INFO] model update: t: 2332, loss: 39292.24609375
[INFO] Global_t: 2332, Episode_t: 4, Action: 24, Reward: 2.79, Epsilon: 0.01
[INFO] model update: t: 2333, loss: 100557.6484375
[INFO] Global_t: 2333, Episode_t: 5, Action: 94, Reward: 2.13, Epsilon: 0.01
[INFO] model update: t: 2334, loss: 12304.912109375
[INFO] Global_t: 2334, Episode_t: 6, Action: 17, Reward: 2.39, Epsilon: 0.01
[INFO] Global step: 2334, Cumulative rewards: 14.63412, Runtime (s): 2173.11
--------------------------------------
 
graph: 189, nodes: 180, edges: 531
[INFO] model update: t: 2335, loss: 72390.96875
[INFO] Global_t: 2335, Episode_t: 1, Action: 51, Reward: 2.44, Epsilon: 0.01
[INFO] model update: t: 2336, loss: 74612.5625
[INFO] Global_t: 2336, Episode_t: 2, Action: 18, Reward: 3.51, Epsilon: 0.01
[INFO] model update: t: 2337, loss: 15949.7470703125
[INFO] Global_t: 2337, Episode_t: 3, Action: 119, Reward: 2.26, Epsilon: 0.01
[INFO] model update: t: 2338, loss: 28889.828125
[INFO] Global_t: 2338, Episode_t: 4, Action: 0, Reward: 2.16, Epsilon: 0.01
[INFO] model update: t: 2339, loss: 16951.421875
[INFO] Global_t: 2339, Episode_t: 5, Action: 11, Reward: 2.53, Epsilon: 0.01
[INFO] model update: t: 2340, loss: 13336.681640625
[INFO] Global_t: 2340, Episode_t: 6, Action: 4, Reward: 2.49, Epsilon: 0.01
[INFO] Global step: 2340, Cumulative rewards: 15.389520000000001, Runtime (s): 2174.94
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.8373596668243408
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.5643060207366943
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5000920295715332
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.847904920578003
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5501282215118408
average cummulative reward vector is:  [0.08435921 0.06699954 0.07770437 0.0811479  0.07984005]
average cummulative reward is:  0.07801021402155098
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 190, nodes: 194, edges: 573
[INFO] model update: t: 2341, loss: 13733.759765625
[INFO] Global_t: 2341, Episode_t: 1, Action: 14, Reward: 2.71, Epsilon: 0.01
[INFO] model update: t: 2342, loss: 16315.5107421875
[INFO] Global_t: 2342, Episode_t: 2, Action: 23, Reward: 3.25, Epsilon: 0.01
[INFO] model update: t: 2343, loss: 12351.984375
[INFO] Global_t: 2343, Episode_t: 3, Action: 51, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 2344, loss: 48044.3359375
[INFO] Global_t: 2344, Episode_t: 4, Action: 17, Reward: 2.25, Epsilon: 0.01
[INFO] model update: t: 2345, loss: 34088.875
[INFO] Global_t: 2345, Episode_t: 5, Action: 19, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 2346, loss: 27497.3203125
[INFO] Global_t: 2346, Episode_t: 6, Action: 37, Reward: 2.66, Epsilon: 0.01
[INFO] Global step: 2346, Cumulative rewards: 16.17564, Runtime (s): 2184.65
--------------------------------------
 
graph: 191, nodes: 183, edges: 539
[INFO] model update: t: 2347, loss: 25872.765625
[INFO] Global_t: 2347, Episode_t: 1, Action: 16, Reward: 3.21, Epsilon: 0.01
[INFO] model update: t: 2348, loss: 23059.490234375
[INFO] Global_t: 2348, Episode_t: 2, Action: 14, Reward: 2.76, Epsilon: 0.01
[INFO] model update: t: 2349, loss: 65112.72265625
[INFO] Global_t: 2349, Episode_t: 3, Action: 11, Reward: 2.28, Epsilon: 0.01
[INFO] model update: t: 2350, loss: 12528.859375
[INFO] Global_t: 2350, Episode_t: 4, Action: 10, Reward: 2.42, Epsilon: 0.01
[INFO] model update: t: 2351, loss: 46528.1015625
[INFO] Global_t: 2351, Episode_t: 5, Action: 34, Reward: 1.95, Epsilon: 0.01
[INFO] model update: t: 2352, loss: 30052.84375
[INFO] Global_t: 2352, Episode_t: 6, Action: 6, Reward: 2.98, Epsilon: 0.01
[INFO] Global step: 2352, Cumulative rewards: 15.59808, Runtime (s): 2186.94
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.79998779296875
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.815180778503418
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.5646417140960693
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.7326819896697998
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.543945074081421
average cummulative reward vector is:  [0.08989658 0.07606366 0.08183005 0.07106636 0.07873038]
average cummulative reward is:  0.0795174044967715
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 192, nodes: 214, edges: 633
[INFO] model update: t: 2353, loss: 11240.255859375
[INFO] Global_t: 2353, Episode_t: 1, Action: 45, Reward: 2.39, Epsilon: 0.01
[INFO] model update: t: 2354, loss: 28321.408203125
[INFO] Global_t: 2354, Episode_t: 2, Action: 7, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 2355, loss: 11620.728515625
[INFO] Global_t: 2355, Episode_t: 3, Action: 80, Reward: 2.50, Epsilon: 0.01
[INFO] model update: t: 2356, loss: 8435.529296875
[INFO] Global_t: 2356, Episode_t: 4, Action: 18, Reward: 3.32, Epsilon: 0.01
[INFO] model update: t: 2357, loss: 23632.07421875
[INFO] Global_t: 2357, Episode_t: 5, Action: 171, Reward: 1.98, Epsilon: 0.01
[INFO] model update: t: 2358, loss: 19468.466796875
[INFO] Global_t: 2358, Episode_t: 6, Action: 14, Reward: 2.65, Epsilon: 0.01
[INFO] Global step: 2358, Cumulative rewards: 15.326760000000002, Runtime (s): 2197.44
--------------------------------------
 
graph: 193, nodes: 218, edges: 645
[INFO] model update: t: 2359, loss: 20610.998046875
[INFO] Global_t: 2359, Episode_t: 1, Action: 80, Reward: 2.84, Epsilon: 0.01
[INFO] model update: t: 2360, loss: 16667.591796875
[INFO] Global_t: 2360, Episode_t: 2, Action: 15, Reward: 2.95, Epsilon: 0.01
[INFO] model update: t: 2361, loss: 18297.41796875
[INFO] Global_t: 2361, Episode_t: 3, Action: 120, Reward: 2.61, Epsilon: 0.01
[INFO] model update: t: 2362, loss: 52498.6796875
[INFO] Global_t: 2362, Episode_t: 4, Action: 1, Reward: 2.57, Epsilon: 0.01
[INFO] model update: t: 2363, loss: 12509.03125
[INFO] Global_t: 2363, Episode_t: 5, Action: 16, Reward: 2.34, Epsilon: 0.01
[INFO] model update: t: 2364, loss: 19182.767578125
[INFO] Global_t: 2364, Episode_t: 6, Action: 26, Reward: 2.57, Epsilon: 0.01
[INFO] Global step: 2364, Cumulative rewards: 15.87516, Runtime (s): 2199.53
--------------------------------------
 
----------------------------------------------start evaluation---------------------------------------------------------
graph: 100000, nodes: 190, edges: 561
runtime for one graph is:  1.7758426666259766
graph: 100001, nodes: 216, edges: 639
runtime for one graph is:  1.7971360683441162
graph: 100002, nodes: 183, edges: 540
runtime for one graph is:  1.4391019344329834
graph: 100003, nodes: 214, edges: 633
runtime for one graph is:  1.8884210586547852
graph: 100004, nodes: 186, edges: 549
runtime for one graph is:  1.5473685264587402
average cummulative reward vector is:  [0.08843868 0.07855046 0.07451093 0.08163411 0.07231156]
average cummulative reward is:  0.07908914948491112
----------------------------------------------end evaluation---------------------------------------------------------
 
graph: 194, nodes: 213, edges: 630
[INFO] model update: t: 2365, loss: 38801.703125
[INFO] Global_t: 2365, Episode_t: 1, Action: 32, Reward: 3.15, Epsilon: 0.01
[INFO] model update: t: 2366, loss: 12100.626953125
[INFO] Global_t: 2366, Episode_t: 2, Action: 60, Reward: 2.63, Epsilon: 0.01
[INFO] model update: t: 2367, loss: 19033.876953125
[INFO] Global_t: 2367, Episode_t: 3, Action: 63, Reward: 2.80, Epsilon: 0.01
[INFO] model update: t: 2368, loss: 25833.46875
[INFO] Global_t: 2368, Episode_t: 4, Action: 44, Reward: 2.40, Epsilon: 0.01
[INFO] model update: t: 2369, loss: 9733.9228515625
[INFO] Global_t: 2369, Episode_t: 5, Action: 31, Reward: 2.00, Epsilon: 0.01
[INFO] model update: t: 2370, loss: 24249.26171875
[INFO] Global_t: 2370, Episode_t: 6, Action: 23, Reward: 3.08, Epsilon: 0.01
[INFO] Global step: 2370, Cumulative rewards: 16.06212, Runtime (s): 2210.00
--------------------------------------
 
graph: 195, nodes: 189, edges: 558
[INFO] model update: t: 2371, loss: 15818.498046875
[INFO] Global_t: 2371, Episode_t: 1, Action: 27, Reward: 2.55, Epsilon: 0.01
[INFO] model update: t: 2372, loss: 33367.92578125
[INFO] Global_t: 2372, Episode_t: 2, Action: 22, Reward: 2.48, Epsilon: 0.01
[INFO] model update: t: 2373, loss: 31016.453125
[INFO] Global_t: 2373, Episode_t: 3, Action: 5, Reward: 3.79, Epsilon: 0.01
[INFO] model update: t: 2374, loss: 18390.330078125
[INFO] Global_t: 2374, Episode_t: 4, Action: 37, Reward: 2.20, Epsilon: 0.01
[INFO] model update: t: 2375, loss: 53261.7265625